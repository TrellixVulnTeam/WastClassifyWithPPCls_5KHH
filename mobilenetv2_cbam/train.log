[2022/06/18 21:23:49] ppcls INFO: 
===========================================================
==        PaddleClas is powered by PaddlePaddle !        ==
===========================================================
==                                                       ==
==   For more info please go to the following website.   ==
==                                                       ==
==       https://github.com/PaddlePaddle/PaddleClas      ==
===========================================================

[2022/06/18 21:23:49] ppcls INFO: Arch : 
[2022/06/18 21:23:49] ppcls INFO:     class_num : 4
[2022/06/18 21:23:49] ppcls INFO:     name : MobileNetV2
[2022/06/18 21:23:49] ppcls INFO: DataLoader : 
[2022/06/18 21:23:49] ppcls INFO:     Eval : 
[2022/06/18 21:23:49] ppcls INFO:         dataset : 
[2022/06/18 21:23:49] ppcls INFO:             cls_label_path : ./dataset/val.txt
[2022/06/18 21:23:49] ppcls INFO:             image_root : .
[2022/06/18 21:23:49] ppcls INFO:             name : ImageNetDataset
[2022/06/18 21:23:49] ppcls INFO:             transform_ops : 
[2022/06/18 21:23:49] ppcls INFO:                 DecodeImage : 
[2022/06/18 21:23:49] ppcls INFO:                     channel_first : False
[2022/06/18 21:23:49] ppcls INFO:                     to_rgb : True
[2022/06/18 21:23:49] ppcls INFO:                 ResizeImage : 
[2022/06/18 21:23:49] ppcls INFO:                     resize_short : 256
[2022/06/18 21:23:49] ppcls INFO:                 CropImage : 
[2022/06/18 21:23:49] ppcls INFO:                     size : 224
[2022/06/18 21:23:49] ppcls INFO:                 NormalizeImage : 
[2022/06/18 21:23:49] ppcls INFO:                     mean : [0.53870025, 0.58465116, 0.62831561]
[2022/06/18 21:23:49] ppcls INFO:                     order : 
[2022/06/18 21:23:49] ppcls INFO:                     scale : 1.0/255.0
[2022/06/18 21:23:49] ppcls INFO:                     std : [0.24331439, 0.23134713, 0.22307978]
[2022/06/18 21:23:49] ppcls INFO:         loader : 
[2022/06/18 21:23:49] ppcls INFO:             num_workers : 4
[2022/06/18 21:23:49] ppcls INFO:             use_shared_memory : True
[2022/06/18 21:23:49] ppcls INFO:         sampler : 
[2022/06/18 21:23:49] ppcls INFO:             batch_size : 64
[2022/06/18 21:23:49] ppcls INFO:             drop_last : False
[2022/06/18 21:23:49] ppcls INFO:             name : DistributedBatchSampler
[2022/06/18 21:23:49] ppcls INFO:             shuffle : False
[2022/06/18 21:23:49] ppcls INFO:     Train : 
[2022/06/18 21:23:49] ppcls INFO:         dataset : 
[2022/06/18 21:23:49] ppcls INFO:             cls_label_path : ./dataset/train.txt
[2022/06/18 21:23:49] ppcls INFO:             image_root : .
[2022/06/18 21:23:49] ppcls INFO:             name : ImageNetDataset
[2022/06/18 21:23:49] ppcls INFO:             transform_ops : 
[2022/06/18 21:23:49] ppcls INFO:                 DecodeImage : 
[2022/06/18 21:23:49] ppcls INFO:                     channel_first : False
[2022/06/18 21:23:49] ppcls INFO:                     to_rgb : True
[2022/06/18 21:23:49] ppcls INFO:                 RandCropImage : 
[2022/06/18 21:23:49] ppcls INFO:                     size : 224
[2022/06/18 21:23:49] ppcls INFO:                 RandFlipImage : 
[2022/06/18 21:23:49] ppcls INFO:                     flip_code : 1
[2022/06/18 21:23:49] ppcls INFO:                 NormalizeImage : 
[2022/06/18 21:23:49] ppcls INFO:                     mean : [0.53870025, 0.58465116, 0.62831561]
[2022/06/18 21:23:49] ppcls INFO:                     order : 
[2022/06/18 21:23:49] ppcls INFO:                     scale : 1.0/255.0
[2022/06/18 21:23:49] ppcls INFO:                     std : [0.24331439, 0.23134713, 0.22307978]
[2022/06/18 21:23:49] ppcls INFO:         loader : 
[2022/06/18 21:23:49] ppcls INFO:             num_workers : 8
[2022/06/18 21:23:49] ppcls INFO:             use_shared_memory : True
[2022/06/18 21:23:49] ppcls INFO:         sampler : 
[2022/06/18 21:23:49] ppcls INFO:             batch_size : 64
[2022/06/18 21:23:49] ppcls INFO:             drop_last : False
[2022/06/18 21:23:49] ppcls INFO:             name : DistributedBatchSampler
[2022/06/18 21:23:49] ppcls INFO:             shuffle : True
[2022/06/18 21:23:49] ppcls INFO: Global : 
[2022/06/18 21:23:49] ppcls INFO:     checkpoints : None
[2022/06/18 21:23:49] ppcls INFO:     device : gpu
[2022/06/18 21:23:49] ppcls INFO:     epochs : 300
[2022/06/18 21:23:49] ppcls INFO:     eval_during_train : True
[2022/06/18 21:23:49] ppcls INFO:     eval_interval : 5
[2022/06/18 21:23:49] ppcls INFO:     image_shape : [3, 224, 224]
[2022/06/18 21:23:49] ppcls INFO:     output_dir : /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes
[2022/06/18 21:23:49] ppcls INFO:     pretrained_model : None
[2022/06/18 21:23:49] ppcls INFO:     print_batch_step : 10
[2022/06/18 21:23:49] ppcls INFO:     save_inference_dir : ./inference
[2022/06/18 21:23:49] ppcls INFO:     save_interval : 10
[2022/06/18 21:23:49] ppcls INFO:     to_static : False
[2022/06/18 21:23:49] ppcls INFO:     use_visualdl : False
[2022/06/18 21:23:49] ppcls INFO: Infer : 
[2022/06/18 21:23:49] ppcls INFO:     PostProcess : 
[2022/06/18 21:23:49] ppcls INFO:         class_id_map_file : ppcls/utils/imagenet1k_label_list.txt
[2022/06/18 21:23:49] ppcls INFO:         name : Topk
[2022/06/18 21:23:49] ppcls INFO:         topk : 5
[2022/06/18 21:23:49] ppcls INFO:     batch_size : 10
[2022/06/18 21:23:49] ppcls INFO:     infer_imgs : docs/images/inference_deployment/whl_demo.jpg
[2022/06/18 21:23:49] ppcls INFO:     transforms : 
[2022/06/18 21:23:49] ppcls INFO:         DecodeImage : 
[2022/06/18 21:23:49] ppcls INFO:             channel_first : False
[2022/06/18 21:23:49] ppcls INFO:             to_rgb : True
[2022/06/18 21:23:49] ppcls INFO:         ResizeImage : 
[2022/06/18 21:23:49] ppcls INFO:             resize_short : 256
[2022/06/18 21:23:49] ppcls INFO:         CropImage : 
[2022/06/18 21:23:49] ppcls INFO:             size : 224
[2022/06/18 21:23:49] ppcls INFO:         NormalizeImage : 
[2022/06/18 21:23:49] ppcls INFO:             mean : [0.485, 0.456, 0.406]
[2022/06/18 21:23:49] ppcls INFO:             order : 
[2022/06/18 21:23:49] ppcls INFO:             scale : 1.0/255.0
[2022/06/18 21:23:49] ppcls INFO:             std : [0.229, 0.224, 0.225]
[2022/06/18 21:23:49] ppcls INFO:         ToCHWImage : None
[2022/06/18 21:23:49] ppcls INFO: Loss : 
[2022/06/18 21:23:49] ppcls INFO:     Eval : 
[2022/06/18 21:23:49] ppcls INFO:         CELoss : 
[2022/06/18 21:23:49] ppcls INFO:             weight : 1.0
[2022/06/18 21:23:49] ppcls INFO:     Train : 
[2022/06/18 21:23:49] ppcls INFO:         CELoss : 
[2022/06/18 21:23:49] ppcls INFO:             weight : 1.0
[2022/06/18 21:23:49] ppcls INFO: Metric : 
[2022/06/18 21:23:49] ppcls INFO:     Eval : 
[2022/06/18 21:23:49] ppcls INFO:         TopkAcc : 
[2022/06/18 21:23:49] ppcls INFO:             topk : [1, 5]
[2022/06/18 21:23:49] ppcls INFO:     Train : 
[2022/06/18 21:23:49] ppcls INFO:         TopkAcc : 
[2022/06/18 21:23:49] ppcls INFO:             topk : [1, 5]
[2022/06/18 21:23:49] ppcls INFO: Optimizer : 
[2022/06/18 21:23:49] ppcls INFO:     lr : 
[2022/06/18 21:23:49] ppcls INFO:         learning_rate : 0.09
[2022/06/18 21:23:49] ppcls INFO:         name : Cosine
[2022/06/18 21:23:49] ppcls INFO:     momentum : 0.9
[2022/06/18 21:23:49] ppcls INFO:     name : Momentum
[2022/06/18 21:23:49] ppcls INFO:     regularizer : 
[2022/06/18 21:23:49] ppcls INFO:         coeff : 4e-05
[2022/06/18 21:23:49] ppcls INFO:         name : L2
[2022/06/18 21:23:49] ppcls INFO: profiler_options : None
[2022/06/18 21:23:49] ppcls INFO: train with paddle 2.3.0 and device Place(gpu:0)
[2022/06/18 21:24:28] ppcls WARNING: The training strategy provided by PaddleClas is based on 4 gpus. But the number of gpu is 8 in current training. Please modify the stategy (learning rate, batch size and so on) if use this config to train.
[2022/06/18 21:24:40] ppcls WARNING: The output dims(4) is less than k(5), and the argument 5 of Topk has been removed.
[2022/06/18 21:24:41] ppcls INFO: [Train][Epoch 1/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.09000000, top1: 0.18750, CELoss: 1.60773, loss: 1.60773, batch_cost: 8.52989s, reader_cost: 5.14489, ips: 7.50303 samples/s, eta: 5 days, 1:33:03
[2022/06/18 21:24:47] ppcls INFO: [Train][Epoch 1/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08999999, top1: 0.51705, CELoss: 2.70997, loss: 2.70997, batch_cost: 0.76664s, reader_cost: 0.00215, ips: 83.48097 samples/s, eta: 10:55:21
[2022/06/18 21:24:51] ppcls INFO: [Train][Epoch 1/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08999996, top1: 0.56027, CELoss: 2.18476, loss: 2.18476, batch_cost: 0.57082s, reader_cost: 0.00699, ips: 112.11892 samples/s, eta: 8:07:51
[2022/06/18 21:24:57] ppcls INFO: [Train][Epoch 1/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08999991, top1: 0.59627, CELoss: 1.83480, loss: 1.83480, batch_cost: 0.58450s, reader_cost: 0.01034, ips: 109.49547 samples/s, eta: 8:19:27
[2022/06/18 21:25:03] ppcls INFO: [Train][Epoch 1/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08999985, top1: 0.61776, CELoss: 1.64847, loss: 1.64847, batch_cost: 0.56981s, reader_cost: 0.01369, ips: 112.31721 samples/s, eta: 8:06:48
[2022/06/18 21:25:09] ppcls INFO: [Train][Epoch 1/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08999977, top1: 0.62990, CELoss: 1.52225, loss: 1.52225, batch_cost: 0.58262s, reader_cost: 0.01202, ips: 109.84796 samples/s, eta: 8:17:39
[2022/06/18 21:25:15] ppcls INFO: [Train][Epoch 1/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08999968, top1: 0.64498, CELoss: 1.40700, loss: 1.40700, batch_cost: 0.59285s, reader_cost: 0.01087, ips: 107.95251 samples/s, eta: 8:26:17
[2022/06/18 21:25:22] ppcls INFO: [Train][Epoch 1/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08999956, top1: 0.65493, CELoss: 1.32983, loss: 1.32983, batch_cost: 0.59717s, reader_cost: 0.03231, ips: 107.17249 samples/s, eta: 8:29:52
[2022/06/18 21:25:29] ppcls INFO: [Train][Epoch 1/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08999943, top1: 0.66570, CELoss: 1.25797, loss: 1.25797, batch_cost: 0.61080s, reader_cost: 0.02846, ips: 104.78042 samples/s, eta: 8:41:25
[2022/06/18 21:25:34] ppcls INFO: [Train][Epoch 1/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08999929, top1: 0.67325, CELoss: 1.20594, loss: 1.20594, batch_cost: 0.60607s, reader_cost: 0.02631, ips: 105.59823 samples/s, eta: 8:37:16
[2022/06/18 21:25:40] ppcls INFO: [Train][Epoch 1/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08999912, top1: 0.68239, CELoss: 1.15723, loss: 1.15723, batch_cost: 0.60113s, reader_cost: 0.03220, ips: 106.46555 samples/s, eta: 8:32:58
[2022/06/18 21:25:47] ppcls INFO: [Train][Epoch 1/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08999894, top1: 0.68806, CELoss: 1.12084, loss: 1.12084, batch_cost: 0.60855s, reader_cost: 0.03241, ips: 105.16736 samples/s, eta: 8:39:11
[2022/06/18 21:25:52] ppcls INFO: [Train][Epoch 1/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08999874, top1: 0.69486, CELoss: 1.08664, loss: 1.08664, batch_cost: 0.59918s, reader_cost: 0.02992, ips: 106.81266 samples/s, eta: 8:31:06
[2022/06/18 21:25:58] ppcls INFO: [Train][Epoch 1/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08999853, top1: 0.70169, CELoss: 1.05645, loss: 1.05645, batch_cost: 0.60074s, reader_cost: 0.03181, ips: 106.53446 samples/s, eta: 8:32:20
[2022/06/18 21:26:04] ppcls INFO: [Train][Epoch 1/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08999830, top1: 0.70567, CELoss: 1.03200, loss: 1.03200, batch_cost: 0.59717s, reader_cost: 0.03553, ips: 107.17212 samples/s, eta: 8:29:11
[2022/06/18 21:26:10] ppcls INFO: [Train][Epoch 1/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08999805, top1: 0.70716, CELoss: 1.01531, loss: 1.01531, batch_cost: 0.60284s, reader_cost: 0.03608, ips: 106.16330 samples/s, eta: 8:33:55
[2022/06/18 21:26:15] ppcls INFO: [Train][Epoch 1/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08999779, top1: 0.71089, CELoss: 0.99508, loss: 0.99508, batch_cost: 0.59369s, reader_cost: 0.03652, ips: 107.79986 samples/s, eta: 8:26:01
[2022/06/18 21:26:17] ppcls INFO: [Train][Epoch 1/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08999750, top1: 0.71260, CELoss: 0.98135, loss: 0.98135, batch_cost: 0.57079s, reader_cost: 0.03516, ips: 85.84560 samples/s, eta: 8:06:24
[2022/06/18 21:26:17] ppcls INFO: [Train][Epoch 1/300][Avg]top1: 0.71260, CELoss: 0.98135, loss: 0.98135
[2022/06/18 21:26:18] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:26:23] ppcls INFO: [Train][Epoch 2/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08999747, top1: 0.76562, CELoss: 0.69433, loss: 0.69433, batch_cost: 0.60203s, reader_cost: 0.05882, ips: 106.30763 samples/s, eta: 8:33:01
[2022/06/18 21:26:31] ppcls INFO: [Train][Epoch 2/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08999717, top1: 0.75284, CELoss: 0.71244, loss: 0.71244, batch_cost: 0.78164s, reader_cost: 0.01846, ips: 81.87911 samples/s, eta: 11:05:56
[2022/06/18 21:26:37] ppcls INFO: [Train][Epoch 2/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08999686, top1: 0.75074, CELoss: 0.70794, loss: 0.70794, batch_cost: 0.65598s, reader_cost: 0.02106, ips: 97.56347 samples/s, eta: 9:18:46
[2022/06/18 21:26:42] ppcls INFO: [Train][Epoch 2/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08999652, top1: 0.74597, CELoss: 0.72481, loss: 0.72481, batch_cost: 0.62224s, reader_cost: 0.02215, ips: 102.85391 samples/s, eta: 8:49:55
[2022/06/18 21:26:50] ppcls INFO: [Train][Epoch 2/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08999617, top1: 0.74162, CELoss: 0.73265, loss: 0.73265, batch_cost: 0.64967s, reader_cost: 0.01813, ips: 98.51201 samples/s, eta: 9:13:10
[2022/06/18 21:26:55] ppcls INFO: [Train][Epoch 2/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08999580, top1: 0.74020, CELoss: 0.74428, loss: 0.74428, batch_cost: 0.63001s, reader_cost: 0.01948, ips: 101.58613 samples/s, eta: 8:56:20
[2022/06/18 21:27:01] ppcls INFO: [Train][Epoch 2/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08999542, top1: 0.74513, CELoss: 0.73864, loss: 0.73864, batch_cost: 0.62773s, reader_cost: 0.01993, ips: 101.95445 samples/s, eta: 8:54:17
[2022/06/18 21:27:06] ppcls INFO: [Train][Epoch 2/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08999502, top1: 0.74846, CELoss: 0.73028, loss: 0.73028, batch_cost: 0.61006s, reader_cost: 0.01904, ips: 104.90687 samples/s, eta: 8:39:09
[2022/06/18 21:27:13] ppcls INFO: [Train][Epoch 2/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08999460, top1: 0.75116, CELoss: 0.72448, loss: 0.72448, batch_cost: 0.61128s, reader_cost: 0.01812, ips: 104.69893 samples/s, eta: 8:40:05
[2022/06/18 21:27:19] ppcls INFO: [Train][Epoch 2/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08999416, top1: 0.75309, CELoss: 0.71847, loss: 0.71847, batch_cost: 0.61456s, reader_cost: 0.01829, ips: 104.13980 samples/s, eta: 8:42:46
[2022/06/18 21:27:25] ppcls INFO: [Train][Epoch 2/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08999371, top1: 0.75356, CELoss: 0.71907, loss: 0.71907, batch_cost: 0.61605s, reader_cost: 0.01784, ips: 103.88809 samples/s, eta: 8:43:56
[2022/06/18 21:27:30] ppcls INFO: [Train][Epoch 2/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08999324, top1: 0.75718, CELoss: 0.70903, loss: 0.70903, batch_cost: 0.60252s, reader_cost: 0.01726, ips: 106.22039 samples/s, eta: 8:32:20
[2022/06/18 21:27:36] ppcls INFO: [Train][Epoch 2/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08999276, top1: 0.75671, CELoss: 0.71275, loss: 0.71275, batch_cost: 0.59861s, reader_cost: 0.01652, ips: 106.91443 samples/s, eta: 8:28:54
[2022/06/18 21:27:42] ppcls INFO: [Train][Epoch 2/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08999225, top1: 0.75740, CELoss: 0.71211, loss: 0.71211, batch_cost: 0.60207s, reader_cost: 0.01554, ips: 106.29957 samples/s, eta: 8:31:45
[2022/06/18 21:27:49] ppcls INFO: [Train][Epoch 2/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08999173, top1: 0.75842, CELoss: 0.70782, loss: 0.70782, batch_cost: 0.60927s, reader_cost: 0.01650, ips: 105.04327 samples/s, eta: 8:37:46
[2022/06/18 21:27:55] ppcls INFO: [Train][Epoch 2/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08999120, top1: 0.75766, CELoss: 0.71020, loss: 0.71020, batch_cost: 0.60983s, reader_cost: 0.01689, ips: 104.94696 samples/s, eta: 8:38:08
[2022/06/18 21:28:00] ppcls INFO: [Train][Epoch 2/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08999064, top1: 0.75786, CELoss: 0.70941, loss: 0.70941, batch_cost: 0.59957s, reader_cost: 0.01662, ips: 106.74386 samples/s, eta: 8:29:19
[2022/06/18 21:28:02] ppcls INFO: [Train][Epoch 2/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08999007, top1: 0.75917, CELoss: 0.70653, loss: 0.70653, batch_cost: 0.57596s, reader_cost: 0.01566, ips: 85.07547 samples/s, eta: 8:09:10
[2022/06/18 21:28:02] ppcls INFO: [Train][Epoch 2/300][Avg]top1: 0.75917, CELoss: 0.70653, loss: 0.70653
[2022/06/18 21:28:02] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:28:08] ppcls INFO: [Train][Epoch 3/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08999002, top1: 0.75000, CELoss: 0.73879, loss: 0.73879, batch_cost: 0.60540s, reader_cost: 0.04317, ips: 105.71466 samples/s, eta: 8:34:10
[2022/06/18 21:28:15] ppcls INFO: [Train][Epoch 3/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08998943, top1: 0.75142, CELoss: 0.69642, loss: 0.69642, batch_cost: 0.66622s, reader_cost: 0.03187, ips: 96.06471 samples/s, eta: 9:25:42
[2022/06/18 21:28:22] ppcls INFO: [Train][Epoch 3/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08998882, top1: 0.77158, CELoss: 0.65357, loss: 0.65357, batch_cost: 0.68015s, reader_cost: 0.09852, ips: 94.09695 samples/s, eta: 9:37:25
[2022/06/18 21:28:28] ppcls INFO: [Train][Epoch 3/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08998820, top1: 0.77520, CELoss: 0.66373, loss: 0.66373, batch_cost: 0.64497s, reader_cost: 0.07014, ips: 99.22967 samples/s, eta: 9:07:26
[2022/06/18 21:28:35] ppcls INFO: [Train][Epoch 3/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08998756, top1: 0.76982, CELoss: 0.67313, loss: 0.67313, batch_cost: 0.64964s, reader_cost: 0.06083, ips: 98.51599 samples/s, eta: 9:11:18
[2022/06/18 21:28:41] ppcls INFO: [Train][Epoch 3/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08998690, top1: 0.77053, CELoss: 0.67588, loss: 0.67588, batch_cost: 0.65391s, reader_cost: 0.05079, ips: 97.87210 samples/s, eta: 9:14:49
[2022/06/18 21:28:48] ppcls INFO: [Train][Epoch 3/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08998623, top1: 0.76895, CELoss: 0.67539, loss: 0.67539, batch_cost: 0.64980s, reader_cost: 0.04725, ips: 98.49243 samples/s, eta: 9:11:13
[2022/06/18 21:28:53] ppcls INFO: [Train][Epoch 3/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08998554, top1: 0.77113, CELoss: 0.67624, loss: 0.67624, batch_cost: 0.63574s, reader_cost: 0.04248, ips: 100.66968 samples/s, eta: 8:59:11
[2022/06/18 21:28:59] ppcls INFO: [Train][Epoch 3/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08998483, top1: 0.77160, CELoss: 0.67918, loss: 0.67918, batch_cost: 0.63099s, reader_cost: 0.03982, ips: 101.42848 samples/s, eta: 8:55:03
[2022/06/18 21:29:06] ppcls INFO: [Train][Epoch 3/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08998411, top1: 0.76923, CELoss: 0.68009, loss: 0.68009, batch_cost: 0.64365s, reader_cost: 0.03599, ips: 99.43262 samples/s, eta: 9:05:41
[2022/06/18 21:29:13] ppcls INFO: [Train][Epoch 3/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08998337, top1: 0.77011, CELoss: 0.67779, loss: 0.67779, batch_cost: 0.64251s, reader_cost: 0.03280, ips: 99.60960 samples/s, eta: 9:04:36
[2022/06/18 21:29:18] ppcls INFO: [Train][Epoch 3/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08998261, top1: 0.77309, CELoss: 0.67065, loss: 0.67065, batch_cost: 0.63154s, reader_cost: 0.03071, ips: 101.33996 samples/s, eta: 8:55:12
[2022/06/18 21:29:24] ppcls INFO: [Train][Epoch 3/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08998183, top1: 0.77389, CELoss: 0.66787, loss: 0.66787, batch_cost: 0.63141s, reader_cost: 0.02865, ips: 101.36023 samples/s, eta: 8:54:59
[2022/06/18 21:29:30] ppcls INFO: [Train][Epoch 3/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08998104, top1: 0.77302, CELoss: 0.67143, loss: 0.67143, batch_cost: 0.62819s, reader_cost: 0.02704, ips: 101.88021 samples/s, eta: 8:52:09
[2022/06/18 21:29:37] ppcls INFO: [Train][Epoch 3/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08998023, top1: 0.77327, CELoss: 0.66978, loss: 0.66978, batch_cost: 0.62827s, reader_cost: 0.02651, ips: 101.86656 samples/s, eta: 8:52:07
[2022/06/18 21:29:43] ppcls INFO: [Train][Epoch 3/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08997941, top1: 0.77194, CELoss: 0.67181, loss: 0.67181, batch_cost: 0.62703s, reader_cost: 0.02534, ips: 102.06852 samples/s, eta: 8:50:58
[2022/06/18 21:29:47] ppcls INFO: [Train][Epoch 3/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08997857, top1: 0.77407, CELoss: 0.66785, loss: 0.66785, batch_cost: 0.61729s, reader_cost: 0.02404, ips: 103.67953 samples/s, eta: 8:42:36
[2022/06/18 21:29:50] ppcls INFO: [Train][Epoch 3/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08997771, top1: 0.77381, CELoss: 0.66780, loss: 0.66780, batch_cost: 0.59265s, reader_cost: 0.02262, ips: 82.67956 samples/s, eta: 8:21:39
[2022/06/18 21:29:50] ppcls INFO: [Train][Epoch 3/300][Avg]top1: 0.77381, CELoss: 0.66780, loss: 0.66780
[2022/06/18 21:29:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:29:57] ppcls INFO: [Train][Epoch 4/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08997762, top1: 0.79688, CELoss: 0.68368, loss: 0.68368, batch_cost: 0.63130s, reader_cost: 0.05991, ips: 101.37782 samples/s, eta: 8:54:21
[2022/06/18 21:30:04] ppcls INFO: [Train][Epoch 4/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08997674, top1: 0.76705, CELoss: 0.68610, loss: 0.68610, batch_cost: 0.69641s, reader_cost: 0.01986, ips: 91.90006 samples/s, eta: 9:49:21
[2022/06/18 21:30:09] ppcls INFO: [Train][Epoch 4/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08997585, top1: 0.77158, CELoss: 0.68346, loss: 0.68346, batch_cost: 0.59400s, reader_cost: 0.02303, ips: 107.74368 samples/s, eta: 8:22:35
[2022/06/18 21:30:15] ppcls INFO: [Train][Epoch 4/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08997494, top1: 0.77722, CELoss: 0.66280, loss: 0.66280, batch_cost: 0.58398s, reader_cost: 0.02113, ips: 109.59283 samples/s, eta: 8:14:01
[2022/06/18 21:30:21] ppcls INFO: [Train][Epoch 4/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08997401, top1: 0.78430, CELoss: 0.64785, loss: 0.64785, batch_cost: 0.58890s, reader_cost: 0.02254, ips: 108.67676 samples/s, eta: 8:18:05
[2022/06/18 21:30:29] ppcls INFO: [Train][Epoch 4/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08997307, top1: 0.78094, CELoss: 0.65692, loss: 0.65692, batch_cost: 0.62542s, reader_cost: 0.02198, ips: 102.33090 samples/s, eta: 8:48:52
[2022/06/18 21:30:33] ppcls INFO: [Train][Epoch 4/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08997210, top1: 0.78304, CELoss: 0.65515, loss: 0.65515, batch_cost: 0.59944s, reader_cost: 0.02208, ips: 106.76614 samples/s, eta: 8:26:47
[2022/06/18 21:30:39] ppcls INFO: [Train][Epoch 4/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08997113, top1: 0.78477, CELoss: 0.64964, loss: 0.64964, batch_cost: 0.59387s, reader_cost: 0.02393, ips: 107.76751 samples/s, eta: 8:21:59
[2022/06/18 21:30:46] ppcls INFO: [Train][Epoch 4/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08997013, top1: 0.78627, CELoss: 0.64568, loss: 0.64568, batch_cost: 0.60225s, reader_cost: 0.02246, ips: 106.26736 samples/s, eta: 8:28:58
[2022/06/18 21:30:51] ppcls INFO: [Train][Epoch 4/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08996912, top1: 0.78177, CELoss: 0.64991, loss: 0.64991, batch_cost: 0.59737s, reader_cost: 0.02208, ips: 107.13680 samples/s, eta: 8:24:44
[2022/06/18 21:30:57] ppcls INFO: [Train][Epoch 4/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08996809, top1: 0.78280, CELoss: 0.64611, loss: 0.64611, batch_cost: 0.60072s, reader_cost: 0.02340, ips: 106.53825 samples/s, eta: 8:27:28
[2022/06/18 21:31:04] ppcls INFO: [Train][Epoch 4/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08996704, top1: 0.78294, CELoss: 0.64499, loss: 0.64499, batch_cost: 0.60250s, reader_cost: 0.02306, ips: 106.22330 samples/s, eta: 8:28:53
[2022/06/18 21:31:10] ppcls INFO: [Train][Epoch 4/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08996598, top1: 0.78241, CELoss: 0.64453, loss: 0.64453, batch_cost: 0.60774s, reader_cost: 0.02190, ips: 105.30902 samples/s, eta: 8:33:12
[2022/06/18 21:31:15] ppcls INFO: [Train][Epoch 4/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08996490, top1: 0.78161, CELoss: 0.64707, loss: 0.64707, batch_cost: 0.59903s, reader_cost: 0.02172, ips: 106.83981 samples/s, eta: 8:25:44
[2022/06/18 21:31:22] ppcls INFO: [Train][Epoch 4/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08996380, top1: 0.78236, CELoss: 0.64519, loss: 0.64519, batch_cost: 0.60409s, reader_cost: 0.02084, ips: 105.94410 samples/s, eta: 8:29:55
[2022/06/18 21:31:28] ppcls INFO: [Train][Epoch 4/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08996269, top1: 0.78197, CELoss: 0.64708, loss: 0.64708, batch_cost: 0.60368s, reader_cost: 0.02021, ips: 106.01693 samples/s, eta: 8:29:28
[2022/06/18 21:31:33] ppcls INFO: [Train][Epoch 4/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08996156, top1: 0.78280, CELoss: 0.64297, loss: 0.64297, batch_cost: 0.59594s, reader_cost: 0.01999, ips: 107.39287 samples/s, eta: 8:22:50
[2022/06/18 21:31:35] ppcls INFO: [Train][Epoch 4/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08996041, top1: 0.78269, CELoss: 0.64382, loss: 0.64382, batch_cost: 0.57289s, reader_cost: 0.01881, ips: 85.53194 samples/s, eta: 8:03:17
[2022/06/18 21:31:35] ppcls INFO: [Train][Epoch 4/300][Avg]top1: 0.78269, CELoss: 0.64382, loss: 0.64382
[2022/06/18 21:31:36] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:31:41] ppcls INFO: [Train][Epoch 5/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08996030, top1: 0.75000, CELoss: 0.62539, loss: 0.62539, batch_cost: 0.60118s, reader_cost: 0.04670, ips: 106.45669 samples/s, eta: 8:27:09
[2022/06/18 21:31:48] ppcls INFO: [Train][Epoch 5/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08995913, top1: 0.78409, CELoss: 0.61482, loss: 0.61482, batch_cost: 0.70324s, reader_cost: 0.03001, ips: 91.00757 samples/s, eta: 9:53:08
[2022/06/18 21:31:55] ppcls INFO: [Train][Epoch 5/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08995795, top1: 0.78125, CELoss: 0.62849, loss: 0.62849, batch_cost: 0.67016s, reader_cost: 0.01448, ips: 95.49904 samples/s, eta: 9:25:07
[2022/06/18 21:32:01] ppcls INFO: [Train][Epoch 5/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08995675, top1: 0.78427, CELoss: 0.62280, loss: 0.62280, batch_cost: 0.65762s, reader_cost: 0.01167, ips: 97.32130 samples/s, eta: 9:14:26
[2022/06/18 21:32:07] ppcls INFO: [Train][Epoch 5/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08995553, top1: 0.78620, CELoss: 0.62075, loss: 0.62075, batch_cost: 0.64132s, reader_cost: 0.01632, ips: 99.79351 samples/s, eta: 9:00:35
[2022/06/18 21:32:14] ppcls INFO: [Train][Epoch 5/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08995430, top1: 0.78309, CELoss: 0.63126, loss: 0.63126, batch_cost: 0.64392s, reader_cost: 0.01651, ips: 99.39198 samples/s, eta: 9:02:40
[2022/06/18 21:32:20] ppcls INFO: [Train][Epoch 5/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08995305, top1: 0.78586, CELoss: 0.62694, loss: 0.62694, batch_cost: 0.63954s, reader_cost: 0.01619, ips: 100.07208 samples/s, eta: 8:58:52
[2022/06/18 21:32:26] ppcls INFO: [Train][Epoch 5/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08995178, top1: 0.78389, CELoss: 0.63105, loss: 0.63105, batch_cost: 0.63457s, reader_cost: 0.01663, ips: 100.85563 samples/s, eta: 8:54:34
[2022/06/18 21:32:32] ppcls INFO: [Train][Epoch 5/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08995050, top1: 0.78569, CELoss: 0.63136, loss: 0.63136, batch_cost: 0.63041s, reader_cost: 0.01499, ips: 101.52141 samples/s, eta: 8:50:58
[2022/06/18 21:32:37] ppcls INFO: [Train][Epoch 5/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08994920, top1: 0.78777, CELoss: 0.62519, loss: 0.62519, batch_cost: 0.61964s, reader_cost: 0.01561, ips: 103.28661 samples/s, eta: 8:41:47
[2022/06/18 21:32:44] ppcls INFO: [Train][Epoch 5/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08994788, top1: 0.78697, CELoss: 0.62532, loss: 0.62532, batch_cost: 0.62052s, reader_cost: 0.01524, ips: 103.13897 samples/s, eta: 8:42:26
[2022/06/18 21:32:50] ppcls INFO: [Train][Epoch 5/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08994655, top1: 0.78533, CELoss: 0.62341, loss: 0.62341, batch_cost: 0.62320s, reader_cost: 0.01509, ips: 102.69584 samples/s, eta: 8:44:35
[2022/06/18 21:32:56] ppcls INFO: [Train][Epoch 5/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08994519, top1: 0.78409, CELoss: 0.62562, loss: 0.62562, batch_cost: 0.61877s, reader_cost: 0.01446, ips: 103.43134 samples/s, eta: 8:40:45
[2022/06/18 21:33:01] ppcls INFO: [Train][Epoch 5/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08994383, top1: 0.78566, CELoss: 0.62301, loss: 0.62301, batch_cost: 0.61482s, reader_cost: 0.01539, ips: 104.09612 samples/s, eta: 8:37:19
[2022/06/18 21:33:08] ppcls INFO: [Train][Epoch 5/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08994244, top1: 0.78757, CELoss: 0.61839, loss: 0.61839, batch_cost: 0.61678s, reader_cost: 0.01500, ips: 103.76392 samples/s, eta: 8:38:52
[2022/06/18 21:33:14] ppcls INFO: [Train][Epoch 5/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08994104, top1: 0.78777, CELoss: 0.61784, loss: 0.61784, batch_cost: 0.61562s, reader_cost: 0.01438, ips: 103.95952 samples/s, eta: 8:37:48
[2022/06/18 21:33:19] ppcls INFO: [Train][Epoch 5/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08993962, top1: 0.78785, CELoss: 0.61699, loss: 0.61699, batch_cost: 0.61111s, reader_cost: 0.01524, ips: 104.72736 samples/s, eta: 8:33:54
[2022/06/18 21:33:21] ppcls INFO: [Train][Epoch 5/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08993818, top1: 0.78763, CELoss: 0.61842, loss: 0.61842, batch_cost: 0.58656s, reader_cost: 0.01433, ips: 83.53773 samples/s, eta: 8:13:09
[2022/06/18 21:33:22] ppcls INFO: [Train][Epoch 5/300][Avg]top1: 0.78763, CELoss: 0.61842, loss: 0.61842
[2022/06/18 21:33:29] ppcls WARNING: The output dims(4) is less than k(5), and the argument 5 of Topk has been removed.
[2022/06/18 21:33:29] ppcls INFO: [Eval][Epoch 5][Iter: 0/16]CELoss: 0.96954, loss: 0.96954, top1: 0.71289, batch_cost: 7.08735s, reader_cost: 3.82956, ips: 9.03017 images/sec
[2022/06/18 21:33:37] ppcls INFO: [Eval][Epoch 5][Iter: 10/16]CELoss: 0.95856, loss: 0.95856, top1: 0.64684, batch_cost: 0.58998s, reader_cost: 0.00170, ips: 108.47738 images/sec
[2022/06/18 21:33:39] ppcls INFO: [Eval][Epoch 5][Avg]CELoss: 0.93363, loss: 0.93363, top1: 0.65968
[2022/06/18 21:33:39] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 21:33:39] ppcls INFO: [Eval][Epoch 5][best metric: 0.6596814393997192]
[2022/06/18 21:33:39] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:33:45] ppcls INFO: [Train][Epoch 6/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08993804, top1: 0.76562, CELoss: 0.81022, loss: 0.81022, batch_cost: 0.61880s, reader_cost: 0.04445, ips: 103.42610 samples/s, eta: 8:40:15
[2022/06/18 21:33:52] ppcls INFO: [Train][Epoch 6/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08993659, top1: 0.80824, CELoss: 0.61383, loss: 0.61383, batch_cost: 0.80499s, reader_cost: 0.05285, ips: 79.50378 samples/s, eta: 11:16:39
[2022/06/18 21:33:58] ppcls INFO: [Train][Epoch 6/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08993512, top1: 0.80952, CELoss: 0.60136, loss: 0.60136, batch_cost: 0.67537s, reader_cost: 0.11669, ips: 94.76259 samples/s, eta: 9:27:35
[2022/06/18 21:34:04] ppcls INFO: [Train][Epoch 6/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08993363, top1: 0.80847, CELoss: 0.60033, loss: 0.60033, batch_cost: 0.66119s, reader_cost: 0.12039, ips: 96.79466 samples/s, eta: 9:15:34
[2022/06/18 21:34:11] ppcls INFO: [Train][Epoch 6/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08993212, top1: 0.80107, CELoss: 0.61222, loss: 0.61222, batch_cost: 0.64777s, reader_cost: 0.09521, ips: 98.80107 samples/s, eta: 9:04:10
[2022/06/18 21:34:17] ppcls INFO: [Train][Epoch 6/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08993060, top1: 0.80270, CELoss: 0.60275, loss: 0.60275, batch_cost: 0.64766s, reader_cost: 0.09610, ips: 98.81705 samples/s, eta: 9:03:58
[2022/06/18 21:34:23] ppcls INFO: [Train][Epoch 6/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08992906, top1: 0.79944, CELoss: 0.60509, loss: 0.60509, batch_cost: 0.63911s, reader_cost: 0.11022, ips: 100.13998 samples/s, eta: 8:56:41
[2022/06/18 21:34:29] ppcls INFO: [Train][Epoch 6/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08992751, top1: 0.80282, CELoss: 0.59934, loss: 0.59934, batch_cost: 0.62765s, reader_cost: 0.09525, ips: 101.96694 samples/s, eta: 8:46:58
[2022/06/18 21:34:35] ppcls INFO: [Train][Epoch 6/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08992594, top1: 0.80556, CELoss: 0.59430, loss: 0.59430, batch_cost: 0.62630s, reader_cost: 0.09800, ips: 102.18800 samples/s, eta: 8:45:43
[2022/06/18 21:34:41] ppcls INFO: [Train][Epoch 6/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08992435, top1: 0.80185, CELoss: 0.60329, loss: 0.60329, batch_cost: 0.62310s, reader_cost: 0.09647, ips: 102.71258 samples/s, eta: 8:42:56
[2022/06/18 21:34:46] ppcls INFO: [Train][Epoch 6/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08992274, top1: 0.80090, CELoss: 0.60135, loss: 0.60135, batch_cost: 0.61569s, reader_cost: 0.09618, ips: 103.94834 samples/s, eta: 8:36:36
[2022/06/18 21:34:52] ppcls INFO: [Train][Epoch 6/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08992112, top1: 0.80222, CELoss: 0.59829, loss: 0.59829, batch_cost: 0.61420s, reader_cost: 0.10142, ips: 104.20135 samples/s, eta: 8:35:15
[2022/06/18 21:34:59] ppcls INFO: [Train][Epoch 6/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08991948, top1: 0.80075, CELoss: 0.59951, loss: 0.59951, batch_cost: 0.61637s, reader_cost: 0.10583, ips: 103.83426 samples/s, eta: 8:36:58
[2022/06/18 21:35:05] ppcls INFO: [Train][Epoch 6/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08991782, top1: 0.79866, CELoss: 0.60156, loss: 0.60156, batch_cost: 0.61346s, reader_cost: 0.09780, ips: 104.32647 samples/s, eta: 8:34:26
[2022/06/18 21:35:11] ppcls INFO: [Train][Epoch 6/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08991615, top1: 0.79710, CELoss: 0.60403, loss: 0.60403, batch_cost: 0.61624s, reader_cost: 0.09674, ips: 103.85537 samples/s, eta: 8:36:40
[2022/06/18 21:35:17] ppcls INFO: [Train][Epoch 6/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08991446, top1: 0.79729, CELoss: 0.60401, loss: 0.60401, batch_cost: 0.61649s, reader_cost: 0.09375, ips: 103.81410 samples/s, eta: 8:36:46
[2022/06/18 21:35:23] ppcls INFO: [Train][Epoch 6/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08991275, top1: 0.79804, CELoss: 0.60457, loss: 0.60457, batch_cost: 0.61060s, reader_cost: 0.08923, ips: 104.81570 samples/s, eta: 8:31:43
[2022/06/18 21:35:25] ppcls INFO: [Train][Epoch 6/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08991103, top1: 0.79861, CELoss: 0.60286, loss: 0.60286, batch_cost: 0.58619s, reader_cost: 0.08386, ips: 83.59030 samples/s, eta: 8:11:10
[2022/06/18 21:35:25] ppcls INFO: [Train][Epoch 6/300][Avg]top1: 0.79861, CELoss: 0.60286, loss: 0.60286
[2022/06/18 21:35:25] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:35:31] ppcls INFO: [Train][Epoch 7/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08991086, top1: 0.68750, CELoss: 0.83215, loss: 0.83215, batch_cost: 0.61818s, reader_cost: 0.11402, ips: 103.52893 samples/s, eta: 8:37:58
[2022/06/18 21:35:38] ppcls INFO: [Train][Epoch 7/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08990911, top1: 0.78409, CELoss: 0.62978, loss: 0.62978, batch_cost: 0.71615s, reader_cost: 0.06100, ips: 89.36640 samples/s, eta: 9:59:56
[2022/06/18 21:35:44] ppcls INFO: [Train][Epoch 7/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08990736, top1: 0.79464, CELoss: 0.60326, loss: 0.60326, batch_cost: 0.65145s, reader_cost: 0.08616, ips: 98.24266 samples/s, eta: 9:05:37
[2022/06/18 21:35:51] ppcls INFO: [Train][Epoch 7/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08990558, top1: 0.79587, CELoss: 0.59094, loss: 0.59094, batch_cost: 0.64258s, reader_cost: 0.06067, ips: 99.59910 samples/s, eta: 8:58:05
[2022/06/18 21:35:57] ppcls INFO: [Train][Epoch 7/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08990379, top1: 0.79916, CELoss: 0.58539, loss: 0.58539, batch_cost: 0.64233s, reader_cost: 0.04928, ips: 99.63753 samples/s, eta: 8:57:46
[2022/06/18 21:36:03] ppcls INFO: [Train][Epoch 7/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08990198, top1: 0.79565, CELoss: 0.59258, loss: 0.59258, batch_cost: 0.63917s, reader_cost: 0.04403, ips: 100.12952 samples/s, eta: 8:55:01
[2022/06/18 21:36:10] ppcls INFO: [Train][Epoch 7/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08990015, top1: 0.79764, CELoss: 0.59203, loss: 0.59203, batch_cost: 0.63892s, reader_cost: 0.03769, ips: 100.16976 samples/s, eta: 8:54:42
[2022/06/18 21:36:16] ppcls INFO: [Train][Epoch 7/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08989831, top1: 0.79621, CELoss: 0.59947, loss: 0.59947, batch_cost: 0.63639s, reader_cost: 0.03292, ips: 100.56702 samples/s, eta: 8:52:29
[2022/06/18 21:36:22] ppcls INFO: [Train][Epoch 7/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08989645, top1: 0.79919, CELoss: 0.59467, loss: 0.59467, batch_cost: 0.63938s, reader_cost: 0.03127, ips: 100.09704 samples/s, eta: 8:54:53
[2022/06/18 21:36:28] ppcls INFO: [Train][Epoch 7/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08989457, top1: 0.79584, CELoss: 0.59793, loss: 0.59793, batch_cost: 0.62665s, reader_cost: 0.02935, ips: 102.13005 samples/s, eta: 8:44:07
[2022/06/18 21:36:34] ppcls INFO: [Train][Epoch 7/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08989268, top1: 0.79564, CELoss: 0.59510, loss: 0.59510, batch_cost: 0.63102s, reader_cost: 0.02885, ips: 101.42305 samples/s, eta: 8:47:40
[2022/06/18 21:36:40] ppcls INFO: [Train][Epoch 7/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08989077, top1: 0.79462, CELoss: 0.59690, loss: 0.59690, batch_cost: 0.62615s, reader_cost: 0.03064, ips: 102.21167 samples/s, eta: 8:43:30
[2022/06/18 21:36:47] ppcls INFO: [Train][Epoch 7/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08988884, top1: 0.79429, CELoss: 0.60052, loss: 0.60052, batch_cost: 0.62674s, reader_cost: 0.02940, ips: 102.11634 samples/s, eta: 8:43:53
[2022/06/18 21:36:53] ppcls INFO: [Train][Epoch 7/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08988689, top1: 0.79521, CELoss: 0.59761, loss: 0.59761, batch_cost: 0.62516s, reader_cost: 0.02811, ips: 102.37301 samples/s, eta: 8:42:28
[2022/06/18 21:36:59] ppcls INFO: [Train][Epoch 7/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08988493, top1: 0.79621, CELoss: 0.59436, loss: 0.59436, batch_cost: 0.62253s, reader_cost: 0.03283, ips: 102.80669 samples/s, eta: 8:40:09
[2022/06/18 21:37:05] ppcls INFO: [Train][Epoch 7/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08988296, top1: 0.79646, CELoss: 0.59259, loss: 0.59259, batch_cost: 0.62264s, reader_cost: 0.03666, ips: 102.78779 samples/s, eta: 8:40:09
[2022/06/18 21:37:10] ppcls INFO: [Train][Epoch 7/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08988096, top1: 0.79571, CELoss: 0.59152, loss: 0.59152, batch_cost: 0.61705s, reader_cost: 0.03894, ips: 103.71922 samples/s, eta: 8:35:22
[2022/06/18 21:37:12] ppcls INFO: [Train][Epoch 7/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08987895, top1: 0.79513, CELoss: 0.59193, loss: 0.59193, batch_cost: 0.59223s, reader_cost: 0.03668, ips: 82.73879 samples/s, eta: 8:14:32
[2022/06/18 21:37:13] ppcls INFO: [Train][Epoch 7/300][Avg]top1: 0.79513, CELoss: 0.59193, loss: 0.59193
[2022/06/18 21:37:13] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:37:19] ppcls INFO: [Train][Epoch 8/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08987875, top1: 0.78125, CELoss: 0.62877, loss: 0.62877, batch_cost: 0.62568s, reader_cost: 0.07005, ips: 102.28872 samples/s, eta: 8:42:28
[2022/06/18 21:37:26] ppcls INFO: [Train][Epoch 8/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08987672, top1: 0.79545, CELoss: 0.55925, loss: 0.55925, batch_cost: 0.74963s, reader_cost: 0.00502, ips: 85.37498 samples/s, eta: 10:25:51
[2022/06/18 21:37:32] ppcls INFO: [Train][Epoch 8/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08987467, top1: 0.80804, CELoss: 0.55748, loss: 0.55748, batch_cost: 0.67396s, reader_cost: 0.00881, ips: 94.96092 samples/s, eta: 9:22:34
[2022/06/18 21:37:38] ppcls INFO: [Train][Epoch 8/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08987261, top1: 0.81048, CELoss: 0.54830, loss: 0.54830, batch_cost: 0.64086s, reader_cost: 0.01118, ips: 99.86653 samples/s, eta: 8:54:49
[2022/06/18 21:37:45] ppcls INFO: [Train][Epoch 8/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08987053, top1: 0.80716, CELoss: 0.55558, loss: 0.55558, batch_cost: 0.64636s, reader_cost: 0.01178, ips: 99.01601 samples/s, eta: 8:59:18
[2022/06/18 21:37:51] ppcls INFO: [Train][Epoch 8/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08986843, top1: 0.80453, CELoss: 0.56335, loss: 0.56335, batch_cost: 0.63643s, reader_cost: 0.01826, ips: 100.56122 samples/s, eta: 8:50:55
[2022/06/18 21:37:56] ppcls INFO: [Train][Epoch 8/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08986631, top1: 0.80353, CELoss: 0.57031, loss: 0.57031, batch_cost: 0.62490s, reader_cost: 0.01977, ips: 102.41564 samples/s, eta: 8:41:12
[2022/06/18 21:38:02] ppcls INFO: [Train][Epoch 8/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08986418, top1: 0.80502, CELoss: 0.56809, loss: 0.56809, batch_cost: 0.62099s, reader_cost: 0.02063, ips: 103.06165 samples/s, eta: 8:37:49
[2022/06/18 21:38:09] ppcls INFO: [Train][Epoch 8/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08986204, top1: 0.80440, CELoss: 0.57083, loss: 0.57083, batch_cost: 0.62350s, reader_cost: 0.01857, ips: 102.64558 samples/s, eta: 8:39:49
[2022/06/18 21:38:15] ppcls INFO: [Train][Epoch 8/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08985987, top1: 0.80529, CELoss: 0.56740, loss: 0.56740, batch_cost: 0.62072s, reader_cost: 0.02130, ips: 103.10658 samples/s, eta: 8:37:23
[2022/06/18 21:38:21] ppcls INFO: [Train][Epoch 8/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08985769, top1: 0.80399, CELoss: 0.57204, loss: 0.57204, batch_cost: 0.62258s, reader_cost: 0.02117, ips: 102.79727 samples/s, eta: 8:38:51
[2022/06/18 21:38:27] ppcls INFO: [Train][Epoch 8/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08985549, top1: 0.80476, CELoss: 0.57134, loss: 0.57134, batch_cost: 0.61576s, reader_cost: 0.02047, ips: 103.93648 samples/s, eta: 8:33:03
[2022/06/18 21:38:33] ppcls INFO: [Train][Epoch 8/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08985328, top1: 0.80256, CELoss: 0.57439, loss: 0.57439, batch_cost: 0.61443s, reader_cost: 0.01990, ips: 104.16095 samples/s, eta: 8:31:51
[2022/06/18 21:38:39] ppcls INFO: [Train][Epoch 8/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08985104, top1: 0.80427, CELoss: 0.56995, loss: 0.56995, batch_cost: 0.61782s, reader_cost: 0.01976, ips: 103.59052 samples/s, eta: 8:34:34
[2022/06/18 21:38:46] ppcls INFO: [Train][Epoch 8/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08984880, top1: 0.80452, CELoss: 0.56870, loss: 0.56870, batch_cost: 0.62536s, reader_cost: 0.01927, ips: 102.34033 samples/s, eta: 8:40:45
[2022/06/18 21:38:51] ppcls INFO: [Train][Epoch 8/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08984653, top1: 0.80464, CELoss: 0.56912, loss: 0.56912, batch_cost: 0.61407s, reader_cost: 0.01974, ips: 104.22327 samples/s, eta: 8:31:14
[2022/06/18 21:38:56] ppcls INFO: [Train][Epoch 8/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08984425, top1: 0.80474, CELoss: 0.56952, loss: 0.56952, batch_cost: 0.60809s, reader_cost: 0.01879, ips: 105.24700 samples/s, eta: 8:26:10
[2022/06/18 21:38:59] ppcls INFO: [Train][Epoch 8/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08984195, top1: 0.80565, CELoss: 0.56899, loss: 0.56899, batch_cost: 0.58590s, reader_cost: 0.01768, ips: 83.63152 samples/s, eta: 8:07:35
[2022/06/18 21:38:59] ppcls INFO: [Train][Epoch 8/300][Avg]top1: 0.80565, CELoss: 0.56899, loss: 0.56899
[2022/06/18 21:38:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:39:06] ppcls INFO: [Train][Epoch 9/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08984172, top1: 0.85938, CELoss: 0.46158, loss: 0.46158, batch_cost: 0.62222s, reader_cost: 0.05084, ips: 102.85682 samples/s, eta: 8:37:48
[2022/06/18 21:39:13] ppcls INFO: [Train][Epoch 9/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08983940, top1: 0.80966, CELoss: 0.56183, loss: 0.56183, batch_cost: 0.87528s, reader_cost: 0.44062, ips: 73.11942 samples/s, eta: 12:08:15
[2022/06/18 21:39:19] ppcls INFO: [Train][Epoch 9/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08983706, top1: 0.81027, CELoss: 0.55885, loss: 0.55885, batch_cost: 0.68771s, reader_cost: 0.18662, ips: 93.06313 samples/s, eta: 9:32:04
[2022/06/18 21:39:25] ppcls INFO: [Train][Epoch 9/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08983471, top1: 0.80796, CELoss: 0.56438, loss: 0.56438, batch_cost: 0.65020s, reader_cost: 0.11914, ips: 98.43091 samples/s, eta: 9:00:46
[2022/06/18 21:39:31] ppcls INFO: [Train][Epoch 9/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08983235, top1: 0.80983, CELoss: 0.55776, loss: 0.55776, batch_cost: 0.62555s, reader_cost: 0.09550, ips: 102.31006 samples/s, eta: 8:40:09
[2022/06/18 21:39:36] ppcls INFO: [Train][Epoch 9/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08982996, top1: 0.81097, CELoss: 0.55910, loss: 0.55910, batch_cost: 0.60480s, reader_cost: 0.07881, ips: 105.82063 samples/s, eta: 8:22:48
[2022/06/18 21:39:43] ppcls INFO: [Train][Epoch 9/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08982756, top1: 0.80610, CELoss: 0.56915, loss: 0.56915, batch_cost: 0.62737s, reader_cost: 0.06608, ips: 102.01272 samples/s, eta: 8:41:28
[2022/06/18 21:39:50] ppcls INFO: [Train][Epoch 9/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08982514, top1: 0.80546, CELoss: 0.57394, loss: 0.57394, batch_cost: 0.62637s, reader_cost: 0.05744, ips: 102.17648 samples/s, eta: 8:40:31
[2022/06/18 21:39:55] ppcls INFO: [Train][Epoch 9/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08982270, top1: 0.80093, CELoss: 0.58002, loss: 0.58002, batch_cost: 0.61608s, reader_cost: 0.05271, ips: 103.88182 samples/s, eta: 8:31:53
[2022/06/18 21:40:02] ppcls INFO: [Train][Epoch 9/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08982025, top1: 0.80323, CELoss: 0.57728, loss: 0.57728, batch_cost: 0.62016s, reader_cost: 0.04786, ips: 103.19943 samples/s, eta: 8:35:09
[2022/06/18 21:40:08] ppcls INFO: [Train][Epoch 9/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08981778, top1: 0.80430, CELoss: 0.57645, loss: 0.57645, batch_cost: 0.61711s, reader_cost: 0.04319, ips: 103.70973 samples/s, eta: 8:32:31
[2022/06/18 21:40:14] ppcls INFO: [Train][Epoch 9/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08981530, top1: 0.80307, CELoss: 0.57841, loss: 0.57841, batch_cost: 0.62020s, reader_cost: 0.04074, ips: 103.19234 samples/s, eta: 8:34:59
[2022/06/18 21:40:19] ppcls INFO: [Train][Epoch 9/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08981279, top1: 0.80372, CELoss: 0.57438, loss: 0.57438, batch_cost: 0.61393s, reader_cost: 0.03878, ips: 104.24679 samples/s, eta: 8:29:40
[2022/06/18 21:40:25] ppcls INFO: [Train][Epoch 9/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08981028, top1: 0.80355, CELoss: 0.57217, loss: 0.57217, batch_cost: 0.61191s, reader_cost: 0.03694, ips: 104.59127 samples/s, eta: 8:27:54
[2022/06/18 21:40:32] ppcls INFO: [Train][Epoch 9/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08980774, top1: 0.80419, CELoss: 0.57054, loss: 0.57054, batch_cost: 0.61842s, reader_cost: 0.03880, ips: 103.48988 samples/s, eta: 8:33:12
[2022/06/18 21:40:38] ppcls INFO: [Train][Epoch 9/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08980519, top1: 0.80536, CELoss: 0.56784, loss: 0.56784, batch_cost: 0.61372s, reader_cost: 0.03719, ips: 104.28155 samples/s, eta: 8:29:12
[2022/06/18 21:40:43] ppcls INFO: [Train][Epoch 9/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08980262, top1: 0.80493, CELoss: 0.57115, loss: 0.57115, batch_cost: 0.60445s, reader_cost: 0.03591, ips: 105.88117 samples/s, eta: 8:21:24
[2022/06/18 21:40:45] ppcls INFO: [Train][Epoch 9/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08980003, top1: 0.80648, CELoss: 0.56855, loss: 0.56855, batch_cost: 0.58139s, reader_cost: 0.03376, ips: 84.28121 samples/s, eta: 8:02:10
[2022/06/18 21:40:45] ppcls INFO: [Train][Epoch 9/300][Avg]top1: 0.80648, CELoss: 0.56855, loss: 0.56855
[2022/06/18 21:40:45] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:40:51] ppcls INFO: [Train][Epoch 10/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08979977, top1: 0.79688, CELoss: 0.62460, loss: 0.62460, batch_cost: 0.61236s, reader_cost: 0.06181, ips: 104.51425 samples/s, eta: 8:27:51
[2022/06/18 21:40:57] ppcls INFO: [Train][Epoch 10/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08979716, top1: 0.81392, CELoss: 0.52779, loss: 0.52779, batch_cost: 0.63103s, reader_cost: 0.00271, ips: 101.42216 samples/s, eta: 8:43:14
[2022/06/18 21:41:05] ppcls INFO: [Train][Epoch 10/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08979454, top1: 0.81473, CELoss: 0.54385, loss: 0.54385, batch_cost: 0.67616s, reader_cost: 0.01119, ips: 94.65184 samples/s, eta: 9:20:32
[2022/06/18 21:41:10] ppcls INFO: [Train][Epoch 10/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08979190, top1: 0.80595, CELoss: 0.56102, loss: 0.56102, batch_cost: 0.63531s, reader_cost: 0.00856, ips: 100.73784 samples/s, eta: 8:46:34
[2022/06/18 21:41:17] ppcls INFO: [Train][Epoch 10/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08978925, top1: 0.80602, CELoss: 0.56393, loss: 0.56393, batch_cost: 0.63633s, reader_cost: 0.01283, ips: 100.57747 samples/s, eta: 8:47:18
[2022/06/18 21:41:23] ppcls INFO: [Train][Epoch 10/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08978658, top1: 0.80208, CELoss: 0.57907, loss: 0.57907, batch_cost: 0.63062s, reader_cost: 0.01299, ips: 101.48693 samples/s, eta: 8:42:28
[2022/06/18 21:41:28] ppcls INFO: [Train][Epoch 10/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08978389, top1: 0.80046, CELoss: 0.57824, loss: 0.57824, batch_cost: 0.61621s, reader_cost: 0.01320, ips: 103.86067 samples/s, eta: 8:30:26
[2022/06/18 21:41:34] ppcls INFO: [Train][Epoch 10/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08978118, top1: 0.80414, CELoss: 0.57026, loss: 0.57026, batch_cost: 0.61671s, reader_cost: 0.01302, ips: 103.77601 samples/s, eta: 8:30:45
[2022/06/18 21:41:41] ppcls INFO: [Train][Epoch 10/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08977846, top1: 0.80710, CELoss: 0.56389, loss: 0.56389, batch_cost: 0.61682s, reader_cost: 0.01321, ips: 103.75855 samples/s, eta: 8:30:44
[2022/06/18 21:41:47] ppcls INFO: [Train][Epoch 10/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08977572, top1: 0.80683, CELoss: 0.56657, loss: 0.56657, batch_cost: 0.61633s, reader_cost: 0.01310, ips: 103.84130 samples/s, eta: 8:30:13
[2022/06/18 21:41:52] ppcls INFO: [Train][Epoch 10/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08977296, top1: 0.80585, CELoss: 0.56778, loss: 0.56778, batch_cost: 0.61240s, reader_cost: 0.01272, ips: 104.50603 samples/s, eta: 8:26:52
[2022/06/18 21:41:59] ppcls INFO: [Train][Epoch 10/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08977019, top1: 0.80785, CELoss: 0.56098, loss: 0.56098, batch_cost: 0.61225s, reader_cost: 0.01221, ips: 104.53179 samples/s, eta: 8:26:39
[2022/06/18 21:42:04] ppcls INFO: [Train][Epoch 10/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08976740, top1: 0.80682, CELoss: 0.56343, loss: 0.56343, batch_cost: 0.60687s, reader_cost: 0.01206, ips: 105.45959 samples/s, eta: 8:22:05
[2022/06/18 21:42:10] ppcls INFO: [Train][Epoch 10/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08976459, top1: 0.80761, CELoss: 0.56183, loss: 0.56183, batch_cost: 0.60634s, reader_cost: 0.01220, ips: 105.55100 samples/s, eta: 8:21:33
[2022/06/18 21:42:17] ppcls INFO: [Train][Epoch 10/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08976177, top1: 0.80862, CELoss: 0.55886, loss: 0.55886, batch_cost: 0.61161s, reader_cost: 0.01227, ips: 104.64236 samples/s, eta: 8:25:48
[2022/06/18 21:42:22] ppcls INFO: [Train][Epoch 10/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08975893, top1: 0.80867, CELoss: 0.55864, loss: 0.55864, batch_cost: 0.60402s, reader_cost: 0.01248, ips: 105.95707 samples/s, eta: 8:19:25
[2022/06/18 21:42:27] ppcls INFO: [Train][Epoch 10/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08975607, top1: 0.80707, CELoss: 0.56101, loss: 0.56101, batch_cost: 0.60027s, reader_cost: 0.01187, ips: 106.61806 samples/s, eta: 8:16:14
[2022/06/18 21:42:29] ppcls INFO: [Train][Epoch 10/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08975320, top1: 0.80703, CELoss: 0.56055, loss: 0.56055, batch_cost: 0.57650s, reader_cost: 0.01116, ips: 84.99561 samples/s, eta: 7:56:29
[2022/06/18 21:42:30] ppcls INFO: [Train][Epoch 10/300][Avg]top1: 0.80703, CELoss: 0.56055, loss: 0.56055
[2022/06/18 21:42:37] ppcls INFO: [Eval][Epoch 10][Iter: 0/16]CELoss: 0.96409, loss: 0.96409, top1: 0.71289, batch_cost: 6.79836s, reader_cost: 3.66141, ips: 9.41403 images/sec
[2022/06/18 21:42:45] ppcls INFO: [Eval][Epoch 10][Iter: 10/16]CELoss: 0.92559, loss: 0.92559, top1: 0.66673, batch_cost: 0.58850s, reader_cost: 0.00378, ips: 108.75032 images/sec
[2022/06/18 21:42:46] ppcls INFO: [Eval][Epoch 10][Avg]CELoss: 0.86847, loss: 0.86847, top1: 0.67684
[2022/06/18 21:42:46] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 21:42:46] ppcls INFO: [Eval][Epoch 10][best metric: 0.6768382787704468]
[2022/06/18 21:42:46] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_10
[2022/06/18 21:42:47] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:42:55] ppcls INFO: [Train][Epoch 11/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08975291, top1: 0.78125, CELoss: 0.56202, loss: 0.56202, batch_cost: 0.62454s, reader_cost: 0.05959, ips: 102.47471 samples/s, eta: 8:36:11
[2022/06/18 21:43:00] ppcls INFO: [Train][Epoch 11/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08975002, top1: 0.80824, CELoss: 0.54602, loss: 0.54602, batch_cost: 0.51911s, reader_cost: 0.01675, ips: 123.28775 samples/s, eta: 7:08:57
[2022/06/18 21:43:06] ppcls INFO: [Train][Epoch 11/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08974711, top1: 0.80060, CELoss: 0.56963, loss: 0.56963, batch_cost: 0.55198s, reader_cost: 0.00987, ips: 115.94641 samples/s, eta: 7:36:01
[2022/06/18 21:43:11] ppcls INFO: [Train][Epoch 11/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08974418, top1: 0.80444, CELoss: 0.56182, loss: 0.56182, batch_cost: 0.56171s, reader_cost: 0.01366, ips: 113.93879 samples/s, eta: 7:43:58
[2022/06/18 21:43:18] ppcls INFO: [Train][Epoch 11/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08974124, top1: 0.80030, CELoss: 0.56591, loss: 0.56591, batch_cost: 0.59726s, reader_cost: 0.06251, ips: 107.15691 samples/s, eta: 8:13:13
[2022/06/18 21:43:24] ppcls INFO: [Train][Epoch 11/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08973828, top1: 0.80300, CELoss: 0.56317, loss: 0.56317, batch_cost: 0.60417s, reader_cost: 0.07186, ips: 105.93087 samples/s, eta: 8:18:50
[2022/06/18 21:43:30] ppcls INFO: [Train][Epoch 11/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08973530, top1: 0.80251, CELoss: 0.56474, loss: 0.56474, batch_cost: 0.59644s, reader_cost: 0.06839, ips: 107.30371 samples/s, eta: 8:12:21
[2022/06/18 21:43:36] ppcls INFO: [Train][Epoch 11/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08973231, top1: 0.80260, CELoss: 0.56450, loss: 0.56450, batch_cost: 0.58914s, reader_cost: 0.06902, ips: 108.63367 samples/s, eta: 8:06:14
[2022/06/18 21:43:43] ppcls INFO: [Train][Epoch 11/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08972930, top1: 0.80401, CELoss: 0.56010, loss: 0.56010, batch_cost: 0.60265s, reader_cost: 0.09058, ips: 106.19781 samples/s, eta: 8:17:17
[2022/06/18 21:43:48] ppcls INFO: [Train][Epoch 11/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08972627, top1: 0.80168, CELoss: 0.56641, loss: 0.56641, batch_cost: 0.60101s, reader_cost: 0.09309, ips: 106.48811 samples/s, eta: 8:15:49
[2022/06/18 21:43:55] ppcls INFO: [Train][Epoch 11/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08972323, top1: 0.80461, CELoss: 0.56284, loss: 0.56284, batch_cost: 0.60383s, reader_cost: 0.09720, ips: 105.98983 samples/s, eta: 8:18:03
[2022/06/18 21:44:00] ppcls INFO: [Train][Epoch 11/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08972017, top1: 0.80574, CELoss: 0.56033, loss: 0.56033, batch_cost: 0.59600s, reader_cost: 0.09394, ips: 107.38166 samples/s, eta: 8:11:30
[2022/06/18 21:44:07] ppcls INFO: [Train][Epoch 11/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08971709, top1: 0.80669, CELoss: 0.55888, loss: 0.55888, batch_cost: 0.60497s, reader_cost: 0.10755, ips: 105.79097 samples/s, eta: 8:18:47
[2022/06/18 21:44:13] ppcls INFO: [Train][Epoch 11/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08971400, top1: 0.80844, CELoss: 0.55359, loss: 0.55359, batch_cost: 0.60206s, reader_cost: 0.10527, ips: 106.30157 samples/s, eta: 8:16:17
[2022/06/18 21:44:18] ppcls INFO: [Train][Epoch 11/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08971089, top1: 0.81062, CELoss: 0.55194, loss: 0.55194, batch_cost: 0.60051s, reader_cost: 0.10396, ips: 106.57589 samples/s, eta: 8:14:55
[2022/06/18 21:44:25] ppcls INFO: [Train][Epoch 11/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08970776, top1: 0.81002, CELoss: 0.55382, loss: 0.55382, batch_cost: 0.60725s, reader_cost: 0.09786, ips: 105.39273 samples/s, eta: 8:20:22
[2022/06/18 21:44:30] ppcls INFO: [Train][Epoch 11/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08970462, top1: 0.81046, CELoss: 0.55355, loss: 0.55355, batch_cost: 0.59894s, reader_cost: 0.09181, ips: 106.85528 samples/s, eta: 8:13:25
[2022/06/18 21:44:32] ppcls INFO: [Train][Epoch 11/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08970146, top1: 0.81087, CELoss: 0.55171, loss: 0.55171, batch_cost: 0.57535s, reader_cost: 0.08630, ips: 85.16526 samples/s, eta: 7:53:53
[2022/06/18 21:44:33] ppcls INFO: [Train][Epoch 11/300][Avg]top1: 0.81087, CELoss: 0.55171, loss: 0.55171
[2022/06/18 21:44:33] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:44:40] ppcls INFO: [Train][Epoch 12/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08970114, top1: 0.79688, CELoss: 0.42223, loss: 0.42223, batch_cost: 0.61285s, reader_cost: 0.11353, ips: 104.43097 samples/s, eta: 8:24:46
[2022/06/18 21:44:46] ppcls INFO: [Train][Epoch 12/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08969796, top1: 0.81250, CELoss: 0.53141, loss: 0.53141, batch_cost: 0.76576s, reader_cost: 0.18210, ips: 83.57690 samples/s, eta: 10:30:35
[2022/06/18 21:44:53] ppcls INFO: [Train][Epoch 12/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08969477, top1: 0.81696, CELoss: 0.53565, loss: 0.53565, batch_cost: 0.69840s, reader_cost: 0.13238, ips: 91.63800 samples/s, eta: 9:35:00
[2022/06/18 21:44:59] ppcls INFO: [Train][Epoch 12/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08969155, top1: 0.80292, CELoss: 0.55275, loss: 0.55275, batch_cost: 0.65721s, reader_cost: 0.10988, ips: 97.38161 samples/s, eta: 9:00:58
[2022/06/18 21:45:04] ppcls INFO: [Train][Epoch 12/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08968832, top1: 0.80640, CELoss: 0.55147, loss: 0.55147, batch_cost: 0.63285s, reader_cost: 0.08386, ips: 101.12934 samples/s, eta: 8:40:49
[2022/06/18 21:45:11] ppcls INFO: [Train][Epoch 12/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08968508, top1: 0.81158, CELoss: 0.54302, loss: 0.54302, batch_cost: 0.63838s, reader_cost: 0.09723, ips: 100.25303 samples/s, eta: 8:45:16
[2022/06/18 21:45:17] ppcls INFO: [Train][Epoch 12/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08968181, top1: 0.81737, CELoss: 0.53510, loss: 0.53510, batch_cost: 0.62626s, reader_cost: 0.08306, ips: 102.19416 samples/s, eta: 8:35:11
[2022/06/18 21:45:23] ppcls INFO: [Train][Epoch 12/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08967853, top1: 0.81536, CELoss: 0.53333, loss: 0.53333, batch_cost: 0.63250s, reader_cost: 0.08080, ips: 101.18568 samples/s, eta: 8:40:13
[2022/06/18 21:45:29] ppcls INFO: [Train][Epoch 12/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08967524, top1: 0.81674, CELoss: 0.53664, loss: 0.53664, batch_cost: 0.61791s, reader_cost: 0.07283, ips: 103.57481 samples/s, eta: 8:28:07
[2022/06/18 21:45:35] ppcls INFO: [Train][Epoch 12/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08967193, top1: 0.81576, CELoss: 0.53915, loss: 0.53915, batch_cost: 0.62296s, reader_cost: 0.08031, ips: 102.73508 samples/s, eta: 8:32:10
[2022/06/18 21:45:41] ppcls INFO: [Train][Epoch 12/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08966860, top1: 0.81668, CELoss: 0.53673, loss: 0.53673, batch_cost: 0.61419s, reader_cost: 0.07541, ips: 104.20251 samples/s, eta: 8:24:51
[2022/06/18 21:45:47] ppcls INFO: [Train][Epoch 12/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08966525, top1: 0.81813, CELoss: 0.53400, loss: 0.53400, batch_cost: 0.61280s, reader_cost: 0.07596, ips: 104.43898 samples/s, eta: 8:23:36
[2022/06/18 21:45:52] ppcls INFO: [Train][Epoch 12/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08966188, top1: 0.81767, CELoss: 0.53346, loss: 0.53346, batch_cost: 0.60737s, reader_cost: 0.07082, ips: 105.37228 samples/s, eta: 8:19:02
[2022/06/18 21:45:59] ppcls INFO: [Train][Epoch 12/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08965850, top1: 0.81667, CELoss: 0.53315, loss: 0.53315, batch_cost: 0.61620s, reader_cost: 0.07351, ips: 103.86262 samples/s, eta: 8:26:11
[2022/06/18 21:46:05] ppcls INFO: [Train][Epoch 12/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08965511, top1: 0.81760, CELoss: 0.53173, loss: 0.53173, batch_cost: 0.61061s, reader_cost: 0.06938, ips: 104.81312 samples/s, eta: 8:21:30
[2022/06/18 21:46:11] ppcls INFO: [Train][Epoch 12/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08965169, top1: 0.81861, CELoss: 0.52980, loss: 0.52980, batch_cost: 0.61000s, reader_cost: 0.06607, ips: 104.91835 samples/s, eta: 8:20:54
[2022/06/18 21:46:16] ppcls INFO: [Train][Epoch 12/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08964826, top1: 0.81735, CELoss: 0.53311, loss: 0.53311, batch_cost: 0.60237s, reader_cost: 0.06215, ips: 106.24633 samples/s, eta: 8:14:32
[2022/06/18 21:46:18] ppcls INFO: [Train][Epoch 12/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08964482, top1: 0.81700, CELoss: 0.53462, loss: 0.53462, batch_cost: 0.57850s, reader_cost: 0.05842, ips: 84.70174 samples/s, eta: 7:54:50
[2022/06/18 21:46:18] ppcls INFO: [Train][Epoch 12/300][Avg]top1: 0.81700, CELoss: 0.53462, loss: 0.53462
[2022/06/18 21:46:18] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:46:24] ppcls INFO: [Train][Epoch 13/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08964447, top1: 0.82812, CELoss: 0.50509, loss: 0.50509, batch_cost: 0.61012s, reader_cost: 0.08833, ips: 104.89692 samples/s, eta: 8:20:47
[2022/06/18 21:46:31] ppcls INFO: [Train][Epoch 13/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08964100, top1: 0.82528, CELoss: 0.48454, loss: 0.48454, batch_cost: 0.67139s, reader_cost: 0.00732, ips: 95.32504 samples/s, eta: 9:10:57
[2022/06/18 21:46:37] ppcls INFO: [Train][Epoch 13/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08963752, top1: 0.81399, CELoss: 0.53057, loss: 0.53057, batch_cost: 0.63161s, reader_cost: 0.03556, ips: 101.32770 samples/s, eta: 8:38:13
[2022/06/18 21:46:43] ppcls INFO: [Train][Epoch 13/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08963402, top1: 0.80444, CELoss: 0.54339, loss: 0.54339, batch_cost: 0.62064s, reader_cost: 0.02640, ips: 103.12008 samples/s, eta: 8:29:06
[2022/06/18 21:46:49] ppcls INFO: [Train][Epoch 13/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08963051, top1: 0.80907, CELoss: 0.53402, loss: 0.53402, batch_cost: 0.60966s, reader_cost: 0.04175, ips: 104.97702 samples/s, eta: 8:20:00
[2022/06/18 21:46:57] ppcls INFO: [Train][Epoch 13/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08962698, top1: 0.80790, CELoss: 0.54196, loss: 0.54196, batch_cost: 0.65055s, reader_cost: 0.03514, ips: 98.37848 samples/s, eta: 8:53:25
[2022/06/18 21:47:02] ppcls INFO: [Train][Epoch 13/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08962343, top1: 0.80661, CELoss: 0.55467, loss: 0.55467, batch_cost: 0.62191s, reader_cost: 0.03019, ips: 102.90846 samples/s, eta: 8:29:50
[2022/06/18 21:47:08] ppcls INFO: [Train][Epoch 13/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08961986, top1: 0.80678, CELoss: 0.55159, loss: 0.55159, batch_cost: 0.61696s, reader_cost: 0.02905, ips: 103.73518 samples/s, eta: 8:25:40
[2022/06/18 21:47:14] ppcls INFO: [Train][Epoch 13/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08961628, top1: 0.80729, CELoss: 0.54922, loss: 0.54922, batch_cost: 0.61624s, reader_cost: 0.02817, ips: 103.85499 samples/s, eta: 8:24:59
[2022/06/18 21:47:21] ppcls INFO: [Train][Epoch 13/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08961268, top1: 0.80701, CELoss: 0.55328, loss: 0.55328, batch_cost: 0.62242s, reader_cost: 0.02717, ips: 102.82426 samples/s, eta: 8:29:56
[2022/06/18 21:47:27] ppcls INFO: [Train][Epoch 13/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08960906, top1: 0.80492, CELoss: 0.55408, loss: 0.55408, batch_cost: 0.62117s, reader_cost: 0.02653, ips: 103.03138 samples/s, eta: 8:28:49
[2022/06/18 21:47:32] ppcls INFO: [Train][Epoch 13/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08960543, top1: 0.80490, CELoss: 0.55141, loss: 0.55141, batch_cost: 0.61522s, reader_cost: 0.02629, ips: 104.02814 samples/s, eta: 8:23:50
[2022/06/18 21:47:39] ppcls INFO: [Train][Epoch 13/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08960178, top1: 0.80656, CELoss: 0.54935, loss: 0.54935, batch_cost: 0.61491s, reader_cost: 0.02491, ips: 104.07946 samples/s, eta: 8:23:29
[2022/06/18 21:47:45] ppcls INFO: [Train][Epoch 13/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08959811, top1: 0.80749, CELoss: 0.54781, loss: 0.54781, batch_cost: 0.61679s, reader_cost: 0.02460, ips: 103.76230 samples/s, eta: 8:24:55
[2022/06/18 21:47:51] ppcls INFO: [Train][Epoch 13/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08959443, top1: 0.80751, CELoss: 0.54829, loss: 0.54829, batch_cost: 0.61286s, reader_cost: 0.02308, ips: 104.42855 samples/s, eta: 8:21:36
[2022/06/18 21:47:57] ppcls INFO: [Train][Epoch 13/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08959073, top1: 0.80826, CELoss: 0.54653, loss: 0.54653, batch_cost: 0.61127s, reader_cost: 0.02170, ips: 104.70005 samples/s, eta: 8:20:12
[2022/06/18 21:48:02] ppcls INFO: [Train][Epoch 13/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08958701, top1: 0.81017, CELoss: 0.54279, loss: 0.54279, batch_cost: 0.60523s, reader_cost: 0.02137, ips: 105.74515 samples/s, eta: 8:15:09
[2022/06/18 21:48:04] ppcls INFO: [Train][Epoch 13/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08958328, top1: 0.81151, CELoss: 0.53832, loss: 0.53832, batch_cost: 0.58120s, reader_cost: 0.02012, ips: 84.30889 samples/s, eta: 7:55:23
[2022/06/18 21:48:04] ppcls INFO: [Train][Epoch 13/300][Avg]top1: 0.81151, CELoss: 0.53832, loss: 0.53832
[2022/06/18 21:48:04] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:48:11] ppcls INFO: [Train][Epoch 14/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08958290, top1: 0.82812, CELoss: 0.47378, loss: 0.47378, batch_cost: 0.61762s, reader_cost: 0.05374, ips: 103.62332 samples/s, eta: 8:25:11
[2022/06/18 21:48:17] ppcls INFO: [Train][Epoch 14/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08957915, top1: 0.81960, CELoss: 0.50229, loss: 0.50229, batch_cost: 0.66548s, reader_cost: 0.01518, ips: 96.17175 samples/s, eta: 9:04:12
[2022/06/18 21:48:23] ppcls INFO: [Train][Epoch 14/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08957538, top1: 0.81994, CELoss: 0.52545, loss: 0.52545, batch_cost: 0.62995s, reader_cost: 0.00989, ips: 101.59594 samples/s, eta: 8:35:03
[2022/06/18 21:48:30] ppcls INFO: [Train][Epoch 14/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08957160, top1: 0.82913, CELoss: 0.51471, loss: 0.51471, batch_cost: 0.64091s, reader_cost: 0.00877, ips: 99.85792 samples/s, eta: 8:43:54
[2022/06/18 21:48:36] ppcls INFO: [Train][Epoch 14/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08956780, top1: 0.82508, CELoss: 0.52504, loss: 0.52504, batch_cost: 0.63830s, reader_cost: 0.01112, ips: 100.26600 samples/s, eta: 8:41:40
[2022/06/18 21:48:43] ppcls INFO: [Train][Epoch 14/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08956398, top1: 0.82445, CELoss: 0.52540, loss: 0.52540, batch_cost: 0.64083s, reader_cost: 0.01246, ips: 99.87093 samples/s, eta: 8:43:37
[2022/06/18 21:48:48] ppcls INFO: [Train][Epoch 14/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08956014, top1: 0.82147, CELoss: 0.53446, loss: 0.53446, batch_cost: 0.62275s, reader_cost: 0.01227, ips: 102.76961 samples/s, eta: 8:28:45
[2022/06/18 21:48:54] ppcls INFO: [Train][Epoch 14/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08955629, top1: 0.82262, CELoss: 0.53545, loss: 0.53545, batch_cost: 0.61785s, reader_cost: 0.01234, ips: 103.58567 samples/s, eta: 8:24:38
[2022/06/18 21:49:01] ppcls INFO: [Train][Epoch 14/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08955242, top1: 0.82272, CELoss: 0.53370, loss: 0.53370, batch_cost: 0.62179s, reader_cost: 0.01309, ips: 102.92810 samples/s, eta: 8:27:46
[2022/06/18 21:49:08] ppcls INFO: [Train][Epoch 14/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08954854, top1: 0.82091, CELoss: 0.53645, loss: 0.53645, batch_cost: 0.63214s, reader_cost: 0.01313, ips: 101.24268 samples/s, eta: 8:36:06
[2022/06/18 21:49:13] ppcls INFO: [Train][Epoch 14/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08954464, top1: 0.82054, CELoss: 0.53293, loss: 0.53293, batch_cost: 0.61959s, reader_cost: 0.01367, ips: 103.29395 samples/s, eta: 8:25:45
[2022/06/18 21:49:20] ppcls INFO: [Train][Epoch 14/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08954072, top1: 0.81968, CELoss: 0.53703, loss: 0.53703, batch_cost: 0.62689s, reader_cost: 0.01433, ips: 102.09161 samples/s, eta: 8:31:36
[2022/06/18 21:49:26] ppcls INFO: [Train][Epoch 14/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08953678, top1: 0.81973, CELoss: 0.53419, loss: 0.53419, batch_cost: 0.62378s, reader_cost: 0.01377, ips: 102.60037 samples/s, eta: 8:28:58
[2022/06/18 21:49:32] ppcls INFO: [Train][Epoch 14/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08953283, top1: 0.82037, CELoss: 0.53166, loss: 0.53166, batch_cost: 0.62212s, reader_cost: 0.01460, ips: 102.87470 samples/s, eta: 8:27:30
[2022/06/18 21:49:38] ppcls INFO: [Train][Epoch 14/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08952886, top1: 0.82081, CELoss: 0.53187, loss: 0.53187, batch_cost: 0.62399s, reader_cost: 0.01486, ips: 102.56623 samples/s, eta: 8:28:56
[2022/06/18 21:49:44] ppcls INFO: [Train][Epoch 14/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08952487, top1: 0.81923, CELoss: 0.53348, loss: 0.53348, batch_cost: 0.62095s, reader_cost: 0.01447, ips: 103.06733 samples/s, eta: 8:26:21
[2022/06/18 21:49:50] ppcls INFO: [Train][Epoch 14/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08952087, top1: 0.81764, CELoss: 0.53538, loss: 0.53538, batch_cost: 0.61604s, reader_cost: 0.01443, ips: 103.88908 samples/s, eta: 8:22:14
[2022/06/18 21:49:52] ppcls INFO: [Train][Epoch 14/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08951685, top1: 0.81911, CELoss: 0.53332, loss: 0.53332, batch_cost: 0.59131s, reader_cost: 0.01356, ips: 82.86681 samples/s, eta: 8:01:59
[2022/06/18 21:49:52] ppcls INFO: [Train][Epoch 14/300][Avg]top1: 0.81911, CELoss: 0.53332, loss: 0.53332
[2022/06/18 21:49:52] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:49:59] ppcls INFO: [Train][Epoch 15/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08951645, top1: 0.78125, CELoss: 0.53522, loss: 0.53522, batch_cost: 0.62628s, reader_cost: 0.03885, ips: 102.19142 samples/s, eta: 8:30:28
[2022/06/18 21:50:05] ppcls INFO: [Train][Epoch 15/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08951241, top1: 0.83097, CELoss: 0.49003, loss: 0.49003, batch_cost: 0.63457s, reader_cost: 0.04037, ips: 100.85563 samples/s, eta: 8:37:07
[2022/06/18 21:50:11] ppcls INFO: [Train][Epoch 15/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08950836, top1: 0.83333, CELoss: 0.49638, loss: 0.49638, batch_cost: 0.63214s, reader_cost: 0.04036, ips: 101.24404 samples/s, eta: 8:35:02
[2022/06/18 21:50:18] ppcls INFO: [Train][Epoch 15/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08950429, top1: 0.83417, CELoss: 0.49609, loss: 0.49609, batch_cost: 0.63487s, reader_cost: 0.02722, ips: 100.80826 samples/s, eta: 8:37:09
[2022/06/18 21:50:23] ppcls INFO: [Train][Epoch 15/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08950020, top1: 0.83308, CELoss: 0.49992, loss: 0.49992, batch_cost: 0.61439s, reader_cost: 0.02267, ips: 104.16854 samples/s, eta: 8:20:22
[2022/06/18 21:50:29] ppcls INFO: [Train][Epoch 15/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08949610, top1: 0.83303, CELoss: 0.49525, loss: 0.49525, batch_cost: 0.60481s, reader_cost: 0.02031, ips: 105.81902 samples/s, eta: 8:12:28
[2022/06/18 21:50:35] ppcls INFO: [Train][Epoch 15/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08949197, top1: 0.83453, CELoss: 0.49048, loss: 0.49048, batch_cost: 0.60167s, reader_cost: 0.02136, ips: 106.37011 samples/s, eta: 8:09:49
[2022/06/18 21:50:42] ppcls INFO: [Train][Epoch 15/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08948784, top1: 0.83033, CELoss: 0.49787, loss: 0.49787, batch_cost: 0.61102s, reader_cost: 0.01982, ips: 104.74278 samples/s, eta: 8:17:19
[2022/06/18 21:50:47] ppcls INFO: [Train][Epoch 15/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08948368, top1: 0.82793, CELoss: 0.50560, loss: 0.50560, batch_cost: 0.60926s, reader_cost: 0.03687, ips: 105.04509 samples/s, eta: 8:15:47
[2022/06/18 21:50:53] ppcls INFO: [Train][Epoch 15/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08947951, top1: 0.82864, CELoss: 0.50797, loss: 0.50797, batch_cost: 0.59998s, reader_cost: 0.03554, ips: 106.67106 samples/s, eta: 8:08:08
[2022/06/18 21:51:01] ppcls INFO: [Train][Epoch 15/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08947532, top1: 0.82735, CELoss: 0.50819, loss: 0.50819, batch_cost: 0.61899s, reader_cost: 0.05193, ips: 103.39394 samples/s, eta: 8:23:30
[2022/06/18 21:51:07] ppcls INFO: [Train][Epoch 15/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08947112, top1: 0.82447, CELoss: 0.51235, loss: 0.51235, batch_cost: 0.62154s, reader_cost: 0.04763, ips: 102.97001 samples/s, eta: 8:25:28
[2022/06/18 21:51:12] ppcls INFO: [Train][Epoch 15/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08946690, top1: 0.82464, CELoss: 0.51202, loss: 0.51202, batch_cost: 0.61035s, reader_cost: 0.04482, ips: 104.85872 samples/s, eta: 8:16:16
[2022/06/18 21:51:17] ppcls INFO: [Train][Epoch 15/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08946266, top1: 0.82288, CELoss: 0.51471, loss: 0.51471, batch_cost: 0.60317s, reader_cost: 0.04237, ips: 106.10607 samples/s, eta: 8:10:20
[2022/06/18 21:51:24] ppcls INFO: [Train][Epoch 15/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08945841, top1: 0.82414, CELoss: 0.51213, loss: 0.51213, batch_cost: 0.60580s, reader_cost: 0.04110, ips: 105.64459 samples/s, eta: 8:12:22
[2022/06/18 21:51:30] ppcls INFO: [Train][Epoch 15/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08945414, top1: 0.82202, CELoss: 0.51643, loss: 0.51643, batch_cost: 0.60747s, reader_cost: 0.03933, ips: 105.35446 samples/s, eta: 8:13:37
[2022/06/18 21:51:35] ppcls INFO: [Train][Epoch 15/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08944985, top1: 0.82172, CELoss: 0.51777, loss: 0.51777, batch_cost: 0.60208s, reader_cost: 0.03709, ips: 106.29813 samples/s, eta: 8:09:09
[2022/06/18 21:51:37] ppcls INFO: [Train][Epoch 15/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08944554, top1: 0.82167, CELoss: 0.51843, loss: 0.51843, batch_cost: 0.57887s, reader_cost: 0.03488, ips: 84.64759 samples/s, eta: 7:50:11
[2022/06/18 21:51:38] ppcls INFO: [Train][Epoch 15/300][Avg]top1: 0.82167, CELoss: 0.51843, loss: 0.51843
[2022/06/18 21:51:45] ppcls INFO: [Eval][Epoch 15][Iter: 0/16]CELoss: 1.04254, loss: 1.04254, top1: 0.72070, batch_cost: 6.99348s, reader_cost: 3.55290, ips: 9.15139 images/sec
[2022/06/18 21:51:53] ppcls INFO: [Eval][Epoch 15][Iter: 10/16]CELoss: 0.89433, loss: 0.89433, top1: 0.67773, batch_cost: 0.57338s, reader_cost: 0.00253, ips: 111.61924 images/sec
[2022/06/18 21:51:54] ppcls INFO: [Eval][Epoch 15][Avg]CELoss: 0.85149, loss: 0.85149, top1: 0.69289
[2022/06/18 21:51:54] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 21:51:54] ppcls INFO: [Eval][Epoch 15][best metric: 0.6928921937942505]
[2022/06/18 21:51:54] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:52:00] ppcls INFO: [Train][Epoch 16/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08944511, top1: 0.84375, CELoss: 0.45923, loss: 0.45923, batch_cost: 0.61099s, reader_cost: 0.06674, ips: 104.74821 samples/s, eta: 8:16:16
[2022/06/18 21:52:07] ppcls INFO: [Train][Epoch 16/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08944079, top1: 0.82244, CELoss: 0.49791, loss: 0.49791, batch_cost: 0.74574s, reader_cost: 0.00405, ips: 85.82066 samples/s, eta: 10:05:36
[2022/06/18 21:52:13] ppcls INFO: [Train][Epoch 16/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08943645, top1: 0.79911, CELoss: 0.54807, loss: 0.54807, batch_cost: 0.68592s, reader_cost: 0.00472, ips: 93.30469 samples/s, eta: 9:16:54
[2022/06/18 21:52:20] ppcls INFO: [Train][Epoch 16/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08943209, top1: 0.81502, CELoss: 0.52002, loss: 0.52002, batch_cost: 0.66851s, reader_cost: 0.00640, ips: 95.73518 samples/s, eta: 9:02:39
[2022/06/18 21:52:26] ppcls INFO: [Train][Epoch 16/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08942772, top1: 0.81631, CELoss: 0.52241, loss: 0.52241, batch_cost: 0.65177s, reader_cost: 0.00670, ips: 98.19468 samples/s, eta: 8:48:57
[2022/06/18 21:52:32] ppcls INFO: [Train][Epoch 16/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08942333, top1: 0.81832, CELoss: 0.51917, loss: 0.51917, batch_cost: 0.64098s, reader_cost: 0.00639, ips: 99.84643 samples/s, eta: 8:40:06
[2022/06/18 21:52:38] ppcls INFO: [Train][Epoch 16/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08941893, top1: 0.81634, CELoss: 0.53052, loss: 0.53052, batch_cost: 0.63927s, reader_cost: 0.00622, ips: 100.11414 samples/s, eta: 8:38:36
[2022/06/18 21:52:44] ppcls INFO: [Train][Epoch 16/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08941450, top1: 0.81558, CELoss: 0.52804, loss: 0.52804, batch_cost: 0.63452s, reader_cost: 0.00620, ips: 100.86368 samples/s, eta: 8:34:38
[2022/06/18 21:52:51] ppcls INFO: [Train][Epoch 16/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08941007, top1: 0.81520, CELoss: 0.52947, loss: 0.52947, batch_cost: 0.63393s, reader_cost: 0.00792, ips: 100.95804 samples/s, eta: 8:34:03
[2022/06/18 21:52:56] ppcls INFO: [Train][Epoch 16/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08940561, top1: 0.81920, CELoss: 0.52294, loss: 0.52294, batch_cost: 0.62415s, reader_cost: 0.00791, ips: 102.53948 samples/s, eta: 8:26:01
[2022/06/18 21:53:04] ppcls INFO: [Train][Epoch 16/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08940114, top1: 0.81807, CELoss: 0.52464, loss: 0.52464, batch_cost: 0.64168s, reader_cost: 0.00730, ips: 99.73862 samples/s, eta: 8:40:07
[2022/06/18 21:53:10] ppcls INFO: [Train][Epoch 16/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08939665, top1: 0.81757, CELoss: 0.52577, loss: 0.52577, batch_cost: 0.63423s, reader_cost: 0.00684, ips: 100.91025 samples/s, eta: 8:33:59
[2022/06/18 21:53:16] ppcls INFO: [Train][Epoch 16/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08939214, top1: 0.81624, CELoss: 0.52469, loss: 0.52469, batch_cost: 0.63381s, reader_cost: 0.00628, ips: 100.97663 samples/s, eta: 8:33:32
[2022/06/18 21:53:21] ppcls INFO: [Train][Epoch 16/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08938762, top1: 0.81775, CELoss: 0.52251, loss: 0.52251, batch_cost: 0.62632s, reader_cost: 0.00701, ips: 102.18441 samples/s, eta: 8:27:22
[2022/06/18 21:53:28] ppcls INFO: [Train][Epoch 16/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08938308, top1: 0.81804, CELoss: 0.51922, loss: 0.51922, batch_cost: 0.62726s, reader_cost: 0.00700, ips: 102.03172 samples/s, eta: 8:28:01
[2022/06/18 21:53:33] ppcls INFO: [Train][Epoch 16/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08937852, top1: 0.81933, CELoss: 0.51902, loss: 0.51902, batch_cost: 0.62121s, reader_cost: 0.00691, ips: 103.02477 samples/s, eta: 8:23:01
[2022/06/18 21:53:42] ppcls INFO: [Train][Epoch 16/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08937395, top1: 0.81813, CELoss: 0.51996, loss: 0.51996, batch_cost: 0.63780s, reader_cost: 0.00670, ips: 100.34446 samples/s, eta: 8:36:21
[2022/06/18 21:53:44] ppcls INFO: [Train][Epoch 16/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08936936, top1: 0.81846, CELoss: 0.51831, loss: 0.51831, batch_cost: 0.61197s, reader_cost: 0.00634, ips: 80.06990 samples/s, eta: 8:15:20
[2022/06/18 21:53:45] ppcls INFO: [Train][Epoch 16/300][Avg]top1: 0.81846, CELoss: 0.51831, loss: 0.51831
[2022/06/18 21:53:45] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:53:51] ppcls INFO: [Train][Epoch 17/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08936890, top1: 0.81250, CELoss: 0.47818, loss: 0.47818, batch_cost: 0.64428s, reader_cost: 0.03262, ips: 99.33570 samples/s, eta: 8:41:28
[2022/06/18 21:53:58] ppcls INFO: [Train][Epoch 17/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08936429, top1: 0.80824, CELoss: 0.52417, loss: 0.52417, batch_cost: 0.78565s, reader_cost: 0.00400, ips: 81.46165 samples/s, eta: 10:35:46
[2022/06/18 21:54:04] ppcls INFO: [Train][Epoch 17/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08935967, top1: 0.80134, CELoss: 0.53637, loss: 0.53637, batch_cost: 0.65904s, reader_cost: 0.00260, ips: 97.11101 samples/s, eta: 8:53:12
[2022/06/18 21:54:09] ppcls INFO: [Train][Epoch 17/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08935503, top1: 0.81200, CELoss: 0.53249, loss: 0.53249, batch_cost: 0.62811s, reader_cost: 0.00554, ips: 101.89222 samples/s, eta: 8:28:04
[2022/06/18 21:54:17] ppcls INFO: [Train][Epoch 17/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08935037, top1: 0.81059, CELoss: 0.53832, loss: 0.53832, batch_cost: 0.67313s, reader_cost: 0.00864, ips: 95.07820 samples/s, eta: 9:04:22
[2022/06/18 21:54:22] ppcls INFO: [Train][Epoch 17/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08934570, top1: 0.81618, CELoss: 0.52730, loss: 0.52730, batch_cost: 0.63129s, reader_cost: 0.00722, ips: 101.37923 samples/s, eta: 8:30:26
[2022/06/18 21:54:28] ppcls INFO: [Train][Epoch 17/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08934101, top1: 0.82095, CELoss: 0.52030, loss: 0.52030, batch_cost: 0.62159s, reader_cost: 0.01040, ips: 102.96214 samples/s, eta: 8:22:29
[2022/06/18 21:54:34] ppcls INFO: [Train][Epoch 17/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08933630, top1: 0.81844, CELoss: 0.52957, loss: 0.52957, batch_cost: 0.62286s, reader_cost: 0.01039, ips: 102.75143 samples/s, eta: 8:23:25
[2022/06/18 21:54:41] ppcls INFO: [Train][Epoch 17/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08933158, top1: 0.81944, CELoss: 0.52725, loss: 0.52725, batch_cost: 0.62765s, reader_cost: 0.01259, ips: 101.96793 samples/s, eta: 8:27:10
[2022/06/18 21:54:47] ppcls INFO: [Train][Epoch 17/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08932684, top1: 0.81937, CELoss: 0.52853, loss: 0.52853, batch_cost: 0.62701s, reader_cost: 0.01339, ips: 102.07210 samples/s, eta: 8:26:33
[2022/06/18 21:54:52] ppcls INFO: [Train][Epoch 17/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08932208, top1: 0.82147, CELoss: 0.52512, loss: 0.52512, batch_cost: 0.61688s, reader_cost: 0.01326, ips: 103.74850 samples/s, eta: 8:18:16
[2022/06/18 21:55:00] ppcls INFO: [Train][Epoch 17/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08931731, top1: 0.81940, CELoss: 0.52426, loss: 0.52426, batch_cost: 0.62830s, reader_cost: 0.01401, ips: 101.86284 samples/s, eta: 8:27:23
[2022/06/18 21:55:05] ppcls INFO: [Train][Epoch 17/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08931252, top1: 0.81896, CELoss: 0.52451, loss: 0.52451, batch_cost: 0.61836s, reader_cost: 0.01375, ips: 103.49961 samples/s, eta: 8:19:15
[2022/06/18 21:55:11] ppcls INFO: [Train][Epoch 17/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08930771, top1: 0.81787, CELoss: 0.52546, loss: 0.52546, batch_cost: 0.61978s, reader_cost: 0.01378, ips: 103.26194 samples/s, eta: 8:20:18
[2022/06/18 21:55:17] ppcls INFO: [Train][Epoch 17/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08930288, top1: 0.82015, CELoss: 0.52134, loss: 0.52134, batch_cost: 0.61915s, reader_cost: 0.01324, ips: 103.36718 samples/s, eta: 8:19:41
[2022/06/18 21:55:24] ppcls INFO: [Train][Epoch 17/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08929804, top1: 0.82036, CELoss: 0.52154, loss: 0.52154, batch_cost: 0.62055s, reader_cost: 0.01240, ips: 103.13497 samples/s, eta: 8:20:43
[2022/06/18 21:55:29] ppcls INFO: [Train][Epoch 17/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08929319, top1: 0.82123, CELoss: 0.52182, loss: 0.52182, batch_cost: 0.61173s, reader_cost: 0.01246, ips: 104.62054 samples/s, eta: 8:13:30
[2022/06/18 21:55:31] ppcls INFO: [Train][Epoch 17/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08928831, top1: 0.82094, CELoss: 0.52059, loss: 0.52059, batch_cost: 0.58720s, reader_cost: 0.01177, ips: 83.44727 samples/s, eta: 7:53:36
[2022/06/18 21:55:31] ppcls INFO: [Train][Epoch 17/300][Avg]top1: 0.82094, CELoss: 0.52059, loss: 0.52059
[2022/06/18 21:55:31] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:55:38] ppcls INFO: [Train][Epoch 18/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08928783, top1: 0.79688, CELoss: 0.61124, loss: 0.61124, batch_cost: 0.62595s, reader_cost: 0.05098, ips: 102.24428 samples/s, eta: 8:24:51
[2022/06/18 21:55:45] ppcls INFO: [Train][Epoch 18/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08928293, top1: 0.82670, CELoss: 0.49778, loss: 0.49778, batch_cost: 0.73781s, reader_cost: 0.00065, ips: 86.74288 samples/s, eta: 9:54:57
[2022/06/18 21:55:50] ppcls INFO: [Train][Epoch 18/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08927803, top1: 0.82589, CELoss: 0.51033, loss: 0.51033, batch_cost: 0.61927s, reader_cost: 0.00161, ips: 103.34675 samples/s, eta: 8:19:16
[2022/06/18 21:55:56] ppcls INFO: [Train][Epoch 18/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08927310, top1: 0.82661, CELoss: 0.50738, loss: 0.50738, batch_cost: 0.60076s, reader_cost: 0.01517, ips: 106.53235 samples/s, eta: 8:04:14
[2022/06/18 21:56:04] ppcls INFO: [Train][Epoch 18/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08926816, top1: 0.82470, CELoss: 0.50502, loss: 0.50502, batch_cost: 0.63888s, reader_cost: 0.01289, ips: 100.17597 samples/s, eta: 8:34:51
[2022/06/18 21:56:09] ppcls INFO: [Train][Epoch 18/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08926320, top1: 0.82659, CELoss: 0.49665, loss: 0.49665, batch_cost: 0.61345s, reader_cost: 0.01363, ips: 104.32719 samples/s, eta: 8:14:16
[2022/06/18 21:56:15] ppcls INFO: [Train][Epoch 18/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08925823, top1: 0.82761, CELoss: 0.49241, loss: 0.49241, batch_cost: 0.61646s, reader_cost: 0.01773, ips: 103.81883 samples/s, eta: 8:16:35
[2022/06/18 21:56:21] ppcls INFO: [Train][Epoch 18/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08925324, top1: 0.82768, CELoss: 0.48869, loss: 0.48869, batch_cost: 0.61690s, reader_cost: 0.01727, ips: 103.74382 samples/s, eta: 8:16:50
[2022/06/18 21:56:27] ppcls INFO: [Train][Epoch 18/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08924823, top1: 0.82504, CELoss: 0.49760, loss: 0.49760, batch_cost: 0.61192s, reader_cost: 0.01692, ips: 104.58904 samples/s, eta: 8:12:43
[2022/06/18 21:56:34] ppcls INFO: [Train][Epoch 18/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08924320, top1: 0.82435, CELoss: 0.49892, loss: 0.49892, batch_cost: 0.62005s, reader_cost: 0.04898, ips: 103.21724 samples/s, eta: 8:19:10
[2022/06/18 21:56:39] ppcls INFO: [Train][Epoch 18/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08923816, top1: 0.82209, CELoss: 0.50199, loss: 0.50199, batch_cost: 0.61264s, reader_cost: 0.04614, ips: 104.46635 samples/s, eta: 8:13:06
[2022/06/18 21:56:46] ppcls INFO: [Train][Epoch 18/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08923310, top1: 0.82418, CELoss: 0.50132, loss: 0.50132, batch_cost: 0.61914s, reader_cost: 0.05943, ips: 103.36978 samples/s, eta: 8:18:13
[2022/06/18 21:56:51] ppcls INFO: [Train][Epoch 18/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08922803, top1: 0.82425, CELoss: 0.50204, loss: 0.50204, batch_cost: 0.60701s, reader_cost: 0.05557, ips: 105.43446 samples/s, eta: 8:08:22
[2022/06/18 21:56:57] ppcls INFO: [Train][Epoch 18/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08922294, top1: 0.82383, CELoss: 0.50246, loss: 0.50246, batch_cost: 0.60408s, reader_cost: 0.05156, ips: 105.94682 samples/s, eta: 8:05:54
[2022/06/18 21:57:03] ppcls INFO: [Train][Epoch 18/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08921783, top1: 0.82358, CELoss: 0.50296, loss: 0.50296, batch_cost: 0.60510s, reader_cost: 0.05660, ips: 105.76703 samples/s, eta: 8:06:38
[2022/06/18 21:57:09] ppcls INFO: [Train][Epoch 18/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08921271, top1: 0.82481, CELoss: 0.49969, loss: 0.49969, batch_cost: 0.60891s, reader_cost: 0.05765, ips: 105.10663 samples/s, eta: 8:09:35
[2022/06/18 21:57:15] ppcls INFO: [Train][Epoch 18/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08920757, top1: 0.82492, CELoss: 0.49898, loss: 0.49898, batch_cost: 0.60469s, reader_cost: 0.06281, ips: 105.84007 samples/s, eta: 8:06:05
[2022/06/18 21:57:17] ppcls INFO: [Train][Epoch 18/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08920241, top1: 0.82441, CELoss: 0.50112, loss: 0.50112, batch_cost: 0.58073s, reader_cost: 0.05905, ips: 84.37676 samples/s, eta: 7:46:44
[2022/06/18 21:57:17] ppcls INFO: [Train][Epoch 18/300][Avg]top1: 0.82441, CELoss: 0.50112, loss: 0.50112
[2022/06/18 21:57:18] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:57:24] ppcls INFO: [Train][Epoch 19/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08920189, top1: 0.85938, CELoss: 0.50752, loss: 0.50752, batch_cost: 0.61383s, reader_cost: 0.08574, ips: 104.26291 samples/s, eta: 8:13:20
[2022/06/18 21:57:31] ppcls INFO: [Train][Epoch 19/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08919672, top1: 0.81108, CELoss: 0.54683, loss: 0.54683, batch_cost: 0.73709s, reader_cost: 0.00129, ips: 86.82819 samples/s, eta: 9:52:16
[2022/06/18 21:57:37] ppcls INFO: [Train][Epoch 19/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08919153, top1: 0.82887, CELoss: 0.50462, loss: 0.50462, batch_cost: 0.65603s, reader_cost: 0.00224, ips: 97.55690 samples/s, eta: 8:47:01
[2022/06/18 21:57:43] ppcls INFO: [Train][Epoch 19/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08918632, top1: 0.83165, CELoss: 0.50222, loss: 0.50222, batch_cost: 0.64311s, reader_cost: 0.01289, ips: 99.51638 samples/s, eta: 8:36:32
[2022/06/18 21:57:49] ppcls INFO: [Train][Epoch 19/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08918109, top1: 0.83613, CELoss: 0.49320, loss: 0.49320, batch_cost: 0.64473s, reader_cost: 0.07526, ips: 99.26596 samples/s, eta: 8:37:44
[2022/06/18 21:57:55] ppcls INFO: [Train][Epoch 19/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08917585, top1: 0.83119, CELoss: 0.49949, loss: 0.49949, batch_cost: 0.62600s, reader_cost: 0.06111, ips: 102.23719 samples/s, eta: 8:22:35
[2022/06/18 21:58:01] ppcls INFO: [Train][Epoch 19/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08917059, top1: 0.83171, CELoss: 0.49631, loss: 0.49631, batch_cost: 0.61446s, reader_cost: 0.05202, ips: 104.15567 samples/s, eta: 8:13:13
[2022/06/18 21:58:07] ppcls INFO: [Train][Epoch 19/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08916532, top1: 0.83187, CELoss: 0.49643, loss: 0.49643, batch_cost: 0.61999s, reader_cost: 0.06002, ips: 103.22797 samples/s, eta: 8:17:33
[2022/06/18 21:58:13] ppcls INFO: [Train][Epoch 19/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08916003, top1: 0.83256, CELoss: 0.49403, loss: 0.49403, batch_cost: 0.61719s, reader_cost: 0.06772, ips: 103.69580 samples/s, eta: 8:15:12
[2022/06/18 21:58:19] ppcls INFO: [Train][Epoch 19/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08915472, top1: 0.83122, CELoss: 0.49386, loss: 0.49386, batch_cost: 0.61050s, reader_cost: 0.06123, ips: 104.83253 samples/s, eta: 8:09:44
[2022/06/18 21:58:25] ppcls INFO: [Train][Epoch 19/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08914939, top1: 0.83060, CELoss: 0.49517, loss: 0.49517, batch_cost: 0.61134s, reader_cost: 0.06149, ips: 104.68876 samples/s, eta: 8:10:18
[2022/06/18 21:58:31] ppcls INFO: [Train][Epoch 19/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08914405, top1: 0.83122, CELoss: 0.49331, loss: 0.49331, batch_cost: 0.61035s, reader_cost: 0.05682, ips: 104.85856 samples/s, eta: 8:09:24
[2022/06/18 21:58:37] ppcls INFO: [Train][Epoch 19/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08913869, top1: 0.83135, CELoss: 0.49253, loss: 0.49253, batch_cost: 0.61036s, reader_cost: 0.06396, ips: 104.85558 samples/s, eta: 8:09:19
[2022/06/18 21:58:43] ppcls INFO: [Train][Epoch 19/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08913332, top1: 0.83242, CELoss: 0.48990, loss: 0.48990, batch_cost: 0.61111s, reader_cost: 0.07212, ips: 104.72691 samples/s, eta: 8:09:49
[2022/06/18 21:58:49] ppcls INFO: [Train][Epoch 19/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08912793, top1: 0.83333, CELoss: 0.48590, loss: 0.48590, batch_cost: 0.61105s, reader_cost: 0.06799, ips: 104.73759 samples/s, eta: 8:09:40
[2022/06/18 21:58:56] ppcls INFO: [Train][Epoch 19/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08912252, top1: 0.83433, CELoss: 0.48541, loss: 0.48541, batch_cost: 0.61297s, reader_cost: 0.06874, ips: 104.41041 samples/s, eta: 8:11:06
[2022/06/18 21:59:01] ppcls INFO: [Train][Epoch 19/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08911710, top1: 0.83569, CELoss: 0.48243, loss: 0.48243, batch_cost: 0.60598s, reader_cost: 0.06950, ips: 105.61422 samples/s, eta: 8:05:24
[2022/06/18 21:59:03] ppcls INFO: [Train][Epoch 19/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08911166, top1: 0.83539, CELoss: 0.48327, loss: 0.48327, batch_cost: 0.58227s, reader_cost: 0.06533, ips: 84.15319 samples/s, eta: 7:46:19
[2022/06/18 21:59:03] ppcls INFO: [Train][Epoch 19/300][Avg]top1: 0.83539, CELoss: 0.48327, loss: 0.48327
[2022/06/18 21:59:04] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 21:59:10] ppcls INFO: [Train][Epoch 20/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08911111, top1: 0.82812, CELoss: 0.53517, loss: 0.53517, batch_cost: 0.61812s, reader_cost: 0.09408, ips: 103.54036 samples/s, eta: 8:15:01
[2022/06/18 21:59:16] ppcls INFO: [Train][Epoch 20/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08910565, top1: 0.82244, CELoss: 0.52397, loss: 0.52397, batch_cost: 0.58379s, reader_cost: 0.02618, ips: 109.62753 samples/s, eta: 7:47:26
[2022/06/18 21:59:22] ppcls INFO: [Train][Epoch 20/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08910018, top1: 0.81399, CELoss: 0.53465, loss: 0.53465, batch_cost: 0.59383s, reader_cost: 0.02112, ips: 107.77558 samples/s, eta: 7:55:22
[2022/06/18 21:59:28] ppcls INFO: [Train][Epoch 20/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08909469, top1: 0.82460, CELoss: 0.50991, loss: 0.50991, batch_cost: 0.60375s, reader_cost: 0.01742, ips: 106.00439 samples/s, eta: 8:03:12
[2022/06/18 21:59:35] ppcls INFO: [Train][Epoch 20/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08908918, top1: 0.82546, CELoss: 0.50072, loss: 0.50072, batch_cost: 0.62196s, reader_cost: 0.01790, ips: 102.90128 samples/s, eta: 8:17:40
[2022/06/18 21:59:42] ppcls INFO: [Train][Epoch 20/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08908365, top1: 0.82353, CELoss: 0.50823, loss: 0.50823, batch_cost: 0.65587s, reader_cost: 0.01696, ips: 97.58024 samples/s, eta: 8:44:42
[2022/06/18 21:59:47] ppcls INFO: [Train][Epoch 20/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08907811, top1: 0.82249, CELoss: 0.50632, loss: 0.50632, batch_cost: 0.62664s, reader_cost: 0.01785, ips: 102.13123 samples/s, eta: 8:21:13
[2022/06/18 21:59:53] ppcls INFO: [Train][Epoch 20/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08907256, top1: 0.82240, CELoss: 0.50392, loss: 0.50392, batch_cost: 0.61967s, reader_cost: 0.02340, ips: 103.28069 samples/s, eta: 8:15:32
[2022/06/18 22:00:00] ppcls INFO: [Train][Epoch 20/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08906698, top1: 0.82234, CELoss: 0.50283, loss: 0.50283, batch_cost: 0.63254s, reader_cost: 0.02211, ips: 101.17873 samples/s, eta: 8:25:43
[2022/06/18 22:00:07] ppcls INFO: [Train][Epoch 20/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08906139, top1: 0.82486, CELoss: 0.50052, loss: 0.50052, batch_cost: 0.63914s, reader_cost: 0.02072, ips: 100.13422 samples/s, eta: 8:30:53
[2022/06/18 22:00:12] ppcls INFO: [Train][Epoch 20/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08905578, top1: 0.82503, CELoss: 0.49963, loss: 0.49963, batch_cost: 0.62688s, reader_cost: 0.02038, ips: 102.09277 samples/s, eta: 8:20:59
[2022/06/18 22:00:18] ppcls INFO: [Train][Epoch 20/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08905016, top1: 0.82376, CELoss: 0.50293, loss: 0.50293, batch_cost: 0.61783s, reader_cost: 0.01906, ips: 103.58781 samples/s, eta: 8:13:39
[2022/06/18 22:00:24] ppcls INFO: [Train][Epoch 20/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08904452, top1: 0.82348, CELoss: 0.50479, loss: 0.50479, batch_cost: 0.61620s, reader_cost: 0.02015, ips: 103.86171 samples/s, eta: 8:12:15
[2022/06/18 22:00:30] ppcls INFO: [Train][Epoch 20/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08903886, top1: 0.82479, CELoss: 0.50233, loss: 0.50233, batch_cost: 0.61340s, reader_cost: 0.02044, ips: 104.33721 samples/s, eta: 8:09:54
[2022/06/18 22:00:36] ppcls INFO: [Train][Epoch 20/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08903319, top1: 0.82702, CELoss: 0.49956, loss: 0.49956, batch_cost: 0.61444s, reader_cost: 0.01934, ips: 104.15994 samples/s, eta: 8:10:38
[2022/06/18 22:00:44] ppcls INFO: [Train][Epoch 20/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08902750, top1: 0.82844, CELoss: 0.49608, loss: 0.49608, batch_cost: 0.62711s, reader_cost: 0.01847, ips: 102.05484 samples/s, eta: 8:20:39
[2022/06/18 22:00:49] ppcls INFO: [Train][Epoch 20/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08902179, top1: 0.83104, CELoss: 0.49135, loss: 0.49135, batch_cost: 0.62153s, reader_cost: 0.01745, ips: 102.97151 samples/s, eta: 8:16:05
[2022/06/18 22:00:51] ppcls INFO: [Train][Epoch 20/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08901607, top1: 0.83146, CELoss: 0.49208, loss: 0.49208, batch_cost: 0.59659s, reader_cost: 0.01648, ips: 82.13366 samples/s, eta: 7:56:05
[2022/06/18 22:00:52] ppcls INFO: [Train][Epoch 20/300][Avg]top1: 0.83146, CELoss: 0.49208, loss: 0.49208
[2022/06/18 22:00:59] ppcls INFO: [Eval][Epoch 20][Iter: 0/16]CELoss: 0.97825, loss: 0.97825, top1: 0.69141, batch_cost: 7.19162s, reader_cost: 3.48332, ips: 8.89924 images/sec
[2022/06/18 22:01:07] ppcls INFO: [Eval][Epoch 20][Iter: 10/16]CELoss: 0.83883, loss: 0.83883, top1: 0.68661, batch_cost: 0.60459s, reader_cost: 0.00187, ips: 105.85672 images/sec
[2022/06/18 22:01:09] ppcls INFO: [Eval][Epoch 20][Avg]CELoss: 0.79788, loss: 0.79788, top1: 0.69265
[2022/06/18 22:01:09] ppcls INFO: [Eval][Epoch 20][best metric: 0.6928921937942505]
[2022/06/18 22:01:09] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_20
[2022/06/18 22:01:09] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:01:15] ppcls INFO: [Train][Epoch 21/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08901550, top1: 0.84375, CELoss: 0.40786, loss: 0.40786, batch_cost: 0.63228s, reader_cost: 0.05152, ips: 101.22045 samples/s, eta: 8:24:33
[2022/06/18 22:01:23] ppcls INFO: [Train][Epoch 21/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08900975, top1: 0.81392, CELoss: 0.49545, loss: 0.49545, batch_cost: 0.88455s, reader_cost: 0.42486, ips: 72.35297 samples/s, eta: 11:45:43
[2022/06/18 22:01:28] ppcls INFO: [Train][Epoch 21/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08900400, top1: 0.81250, CELoss: 0.51441, loss: 0.51441, batch_cost: 0.65673s, reader_cost: 0.18790, ips: 97.45192 samples/s, eta: 8:43:51
[2022/06/18 22:01:34] ppcls INFO: [Train][Epoch 21/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08899822, top1: 0.80494, CELoss: 0.53432, loss: 0.53432, batch_cost: 0.63096s, reader_cost: 0.12193, ips: 101.43229 samples/s, eta: 8:23:11
[2022/06/18 22:01:42] ppcls INFO: [Train][Epoch 21/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08899243, top1: 0.80069, CELoss: 0.54532, loss: 0.54532, batch_cost: 0.66078s, reader_cost: 0.14837, ips: 96.85586 samples/s, eta: 8:46:51
[2022/06/18 22:01:48] ppcls INFO: [Train][Epoch 21/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08898663, top1: 0.80790, CELoss: 0.52721, loss: 0.52721, batch_cost: 0.65429s, reader_cost: 0.14955, ips: 97.81526 samples/s, eta: 8:41:34
[2022/06/18 22:01:54] ppcls INFO: [Train][Epoch 21/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08898080, top1: 0.81250, CELoss: 0.51756, loss: 0.51756, batch_cost: 0.65034s, reader_cost: 0.13793, ips: 98.40964 samples/s, eta: 8:38:19
[2022/06/18 22:02:00] ppcls INFO: [Train][Epoch 21/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08897496, top1: 0.81140, CELoss: 0.52841, loss: 0.52841, batch_cost: 0.63502s, reader_cost: 0.12079, ips: 100.78468 samples/s, eta: 8:26:00
[2022/06/18 22:02:06] ppcls INFO: [Train][Epoch 21/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08896910, top1: 0.81539, CELoss: 0.52018, loss: 0.52018, batch_cost: 0.62920s, reader_cost: 0.12403, ips: 101.71621 samples/s, eta: 8:21:15
[2022/06/18 22:02:11] ppcls INFO: [Train][Epoch 21/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08896323, top1: 0.81731, CELoss: 0.52105, loss: 0.52105, batch_cost: 0.62347s, reader_cost: 0.11020, ips: 102.65072 samples/s, eta: 8:16:35
[2022/06/18 22:02:18] ppcls INFO: [Train][Epoch 21/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08895734, top1: 0.82101, CELoss: 0.51339, loss: 0.51339, batch_cost: 0.62917s, reader_cost: 0.10579, ips: 101.72112 samples/s, eta: 8:21:01
[2022/06/18 22:02:24] ppcls INFO: [Train][Epoch 21/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08895144, top1: 0.82151, CELoss: 0.51401, loss: 0.51401, batch_cost: 0.62084s, reader_cost: 0.09979, ips: 103.08586 samples/s, eta: 8:14:17
[2022/06/18 22:02:30] ppcls INFO: [Train][Epoch 21/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08894551, top1: 0.82257, CELoss: 0.51173, loss: 0.51173, batch_cost: 0.61818s, reader_cost: 0.09505, ips: 103.53013 samples/s, eta: 8:12:04
[2022/06/18 22:02:36] ppcls INFO: [Train][Epoch 21/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08893957, top1: 0.82228, CELoss: 0.51041, loss: 0.51041, batch_cost: 0.61746s, reader_cost: 0.08832, ips: 103.64970 samples/s, eta: 8:11:23
[2022/06/18 22:02:42] ppcls INFO: [Train][Epoch 21/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08893362, top1: 0.82114, CELoss: 0.51254, loss: 0.51254, batch_cost: 0.61682s, reader_cost: 0.08400, ips: 103.75852 samples/s, eta: 8:10:46
[2022/06/18 22:02:48] ppcls INFO: [Train][Epoch 21/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08892765, top1: 0.82047, CELoss: 0.51207, loss: 0.51207, batch_cost: 0.61508s, reader_cost: 0.07946, ips: 104.05178 samples/s, eta: 8:09:17
[2022/06/18 22:02:53] ppcls INFO: [Train][Epoch 21/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08892166, top1: 0.82046, CELoss: 0.51184, loss: 0.51184, batch_cost: 0.61179s, reader_cost: 0.07809, ips: 104.61061 samples/s, eta: 8:06:34
[2022/06/18 22:02:55] ppcls INFO: [Train][Epoch 21/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08891565, top1: 0.82185, CELoss: 0.50891, loss: 0.50891, batch_cost: 0.58750s, reader_cost: 0.07341, ips: 83.40363 samples/s, eta: 7:47:09
[2022/06/18 22:02:56] ppcls INFO: [Train][Epoch 21/300][Avg]top1: 0.82185, CELoss: 0.50891, loss: 0.50891
[2022/06/18 22:02:56] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:03:03] ppcls INFO: [Train][Epoch 22/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08891505, top1: 0.85938, CELoss: 0.41409, loss: 0.41409, batch_cost: 0.62594s, reader_cost: 0.11140, ips: 102.24560 samples/s, eta: 8:17:43
[2022/06/18 22:03:10] ppcls INFO: [Train][Epoch 22/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08890903, top1: 0.86648, CELoss: 0.40735, loss: 0.40735, batch_cost: 0.81132s, reader_cost: 0.02404, ips: 78.88332 samples/s, eta: 10:44:59
[2022/06/18 22:03:16] ppcls INFO: [Train][Epoch 22/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08890299, top1: 0.85119, CELoss: 0.44200, loss: 0.44200, batch_cost: 0.67289s, reader_cost: 0.01896, ips: 95.11229 samples/s, eta: 8:54:49
[2022/06/18 22:03:22] ppcls INFO: [Train][Epoch 22/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08889693, top1: 0.85030, CELoss: 0.44570, loss: 0.44570, batch_cost: 0.63423s, reader_cost: 0.01931, ips: 100.91005 samples/s, eta: 8:23:59
[2022/06/18 22:03:28] ppcls INFO: [Train][Epoch 22/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08889086, top1: 0.83956, CELoss: 0.47015, loss: 0.47015, batch_cost: 0.63778s, reader_cost: 0.01632, ips: 100.34746 samples/s, eta: 8:26:42
[2022/06/18 22:03:34] ppcls INFO: [Train][Epoch 22/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08888477, top1: 0.83456, CELoss: 0.48042, loss: 0.48042, batch_cost: 0.63157s, reader_cost: 0.01608, ips: 101.33476 samples/s, eta: 8:21:39
[2022/06/18 22:03:40] ppcls INFO: [Train][Epoch 22/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08887867, top1: 0.83325, CELoss: 0.48268, loss: 0.48268, batch_cost: 0.61900s, reader_cost: 0.01510, ips: 103.39183 samples/s, eta: 8:11:34
[2022/06/18 22:03:46] ppcls INFO: [Train][Epoch 22/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08887254, top1: 0.83539, CELoss: 0.47955, loss: 0.47955, batch_cost: 0.62083s, reader_cost: 0.01496, ips: 103.08837 samples/s, eta: 8:12:55
[2022/06/18 22:03:52] ppcls INFO: [Train][Epoch 22/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08886641, top1: 0.83719, CELoss: 0.47784, loss: 0.47784, batch_cost: 0.61132s, reader_cost: 0.01552, ips: 104.69220 samples/s, eta: 8:05:16
[2022/06/18 22:03:58] ppcls INFO: [Train][Epoch 22/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08886025, top1: 0.83379, CELoss: 0.48487, loss: 0.48487, batch_cost: 0.61102s, reader_cost: 0.01524, ips: 104.74278 samples/s, eta: 8:04:56
[2022/06/18 22:04:04] ppcls INFO: [Train][Epoch 22/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08885408, top1: 0.83571, CELoss: 0.48395, loss: 0.48395, batch_cost: 0.60676s, reader_cost: 0.01631, ips: 105.47902 samples/s, eta: 8:01:27
[2022/06/18 22:04:09] ppcls INFO: [Train][Epoch 22/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08884789, top1: 0.83530, CELoss: 0.48321, loss: 0.48321, batch_cost: 0.60120s, reader_cost: 0.01645, ips: 106.45368 samples/s, eta: 7:56:56
[2022/06/18 22:04:14] ppcls INFO: [Train][Epoch 22/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08884169, top1: 0.83665, CELoss: 0.48033, loss: 0.48033, batch_cost: 0.59272s, reader_cost: 0.01600, ips: 107.97633 samples/s, eta: 7:50:07
[2022/06/18 22:04:22] ppcls INFO: [Train][Epoch 22/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08883547, top1: 0.83564, CELoss: 0.48346, loss: 0.48346, batch_cost: 0.60497s, reader_cost: 0.01595, ips: 105.78956 samples/s, eta: 7:59:44
[2022/06/18 22:04:28] ppcls INFO: [Train][Epoch 22/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08882923, top1: 0.83555, CELoss: 0.48424, loss: 0.48424, batch_cost: 0.61098s, reader_cost: 0.01527, ips: 104.74948 samples/s, eta: 8:04:23
[2022/06/18 22:04:33] ppcls INFO: [Train][Epoch 22/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08882298, top1: 0.83475, CELoss: 0.48676, loss: 0.48676, batch_cost: 0.60302s, reader_cost: 0.01489, ips: 106.13191 samples/s, eta: 7:57:59
[2022/06/18 22:04:39] ppcls INFO: [Train][Epoch 22/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08881671, top1: 0.83482, CELoss: 0.48680, loss: 0.48680, batch_cost: 0.60132s, reader_cost: 0.01416, ips: 106.43246 samples/s, eta: 7:56:32
[2022/06/18 22:04:43] ppcls INFO: [Train][Epoch 22/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08881042, top1: 0.83475, CELoss: 0.48564, loss: 0.48564, batch_cost: 0.58630s, reader_cost: 0.01344, ips: 83.57534 samples/s, eta: 7:44:31
[2022/06/18 22:04:43] ppcls INFO: [Train][Epoch 22/300][Avg]top1: 0.83475, CELoss: 0.48564, loss: 0.48564
[2022/06/18 22:04:43] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:04:50] ppcls INFO: [Train][Epoch 23/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08880979, top1: 0.85938, CELoss: 0.41536, loss: 0.41536, batch_cost: 0.62138s, reader_cost: 0.04696, ips: 102.99634 samples/s, eta: 8:12:19
[2022/06/18 22:04:57] ppcls INFO: [Train][Epoch 23/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08880349, top1: 0.83381, CELoss: 0.47909, loss: 0.47909, batch_cost: 0.76305s, reader_cost: 0.00132, ips: 83.87366 samples/s, eta: 10:04:26
[2022/06/18 22:05:02] ppcls INFO: [Train][Epoch 23/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08879717, top1: 0.82738, CELoss: 0.47901, loss: 0.47901, batch_cost: 0.60637s, reader_cost: 0.00078, ips: 105.54614 samples/s, eta: 8:00:13
[2022/06/18 22:05:08] ppcls INFO: [Train][Epoch 23/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08879083, top1: 0.82661, CELoss: 0.48520, loss: 0.48520, batch_cost: 0.60369s, reader_cost: 0.00103, ips: 106.01555 samples/s, eta: 7:57:59
[2022/06/18 22:05:14] ppcls INFO: [Train][Epoch 23/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08878448, top1: 0.82317, CELoss: 0.49336, loss: 0.49336, batch_cost: 0.60582s, reader_cost: 0.00546, ips: 105.64265 samples/s, eta: 7:59:35
[2022/06/18 22:05:21] ppcls INFO: [Train][Epoch 23/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08877811, top1: 0.82322, CELoss: 0.48928, loss: 0.48928, batch_cost: 0.61129s, reader_cost: 0.00706, ips: 104.69680 samples/s, eta: 8:03:48
[2022/06/18 22:05:27] ppcls INFO: [Train][Epoch 23/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08877172, top1: 0.82812, CELoss: 0.48216, loss: 0.48216, batch_cost: 0.60944s, reader_cost: 0.00633, ips: 105.01364 samples/s, eta: 8:02:15
[2022/06/18 22:05:33] ppcls INFO: [Train][Epoch 23/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08876532, top1: 0.82724, CELoss: 0.48326, loss: 0.48326, batch_cost: 0.61078s, reader_cost: 0.00791, ips: 104.78458 samples/s, eta: 8:03:12
[2022/06/18 22:05:39] ppcls INFO: [Train][Epoch 23/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08875890, top1: 0.83025, CELoss: 0.47859, loss: 0.47859, batch_cost: 0.61479s, reader_cost: 0.01095, ips: 104.10132 samples/s, eta: 8:06:16
[2022/06/18 22:05:46] ppcls INFO: [Train][Epoch 23/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08875246, top1: 0.83053, CELoss: 0.47598, loss: 0.47598, batch_cost: 0.61887s, reader_cost: 0.01052, ips: 103.41424 samples/s, eta: 8:09:24
[2022/06/18 22:05:51] ppcls INFO: [Train][Epoch 23/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08874601, top1: 0.83060, CELoss: 0.47666, loss: 0.47666, batch_cost: 0.60982s, reader_cost: 0.01095, ips: 104.94818 samples/s, eta: 8:02:08
[2022/06/18 22:05:57] ppcls INFO: [Train][Epoch 23/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08873954, top1: 0.83376, CELoss: 0.47294, loss: 0.47294, batch_cost: 0.61257s, reader_cost: 0.01102, ips: 104.47749 samples/s, eta: 8:04:13
[2022/06/18 22:06:03] ppcls INFO: [Train][Epoch 23/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08873306, top1: 0.83497, CELoss: 0.47022, loss: 0.47022, batch_cost: 0.60462s, reader_cost: 0.01184, ips: 105.85216 samples/s, eta: 7:57:49
[2022/06/18 22:06:09] ppcls INFO: [Train][Epoch 23/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08872655, top1: 0.83635, CELoss: 0.46971, loss: 0.46971, batch_cost: 0.60407s, reader_cost: 0.01199, ips: 105.94829 samples/s, eta: 7:57:17
[2022/06/18 22:06:16] ppcls INFO: [Train][Epoch 23/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08872004, top1: 0.83655, CELoss: 0.46970, loss: 0.46970, batch_cost: 0.61209s, reader_cost: 0.01216, ips: 104.55995 samples/s, eta: 8:03:31
[2022/06/18 22:06:21] ppcls INFO: [Train][Epoch 23/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08871350, top1: 0.83526, CELoss: 0.47299, loss: 0.47299, batch_cost: 0.60255s, reader_cost: 0.01142, ips: 106.21481 samples/s, eta: 7:55:53
[2022/06/18 22:06:26] ppcls INFO: [Train][Epoch 23/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08870695, top1: 0.83531, CELoss: 0.47327, loss: 0.47327, batch_cost: 0.59968s, reader_cost: 0.01130, ips: 106.72368 samples/s, eta: 7:53:31
[2022/06/18 22:06:28] ppcls INFO: [Train][Epoch 23/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08870039, top1: 0.83457, CELoss: 0.47419, loss: 0.47419, batch_cost: 0.57600s, reader_cost: 0.01063, ips: 85.06907 samples/s, eta: 7:34:44
[2022/06/18 22:06:29] ppcls INFO: [Train][Epoch 23/300][Avg]top1: 0.83457, CELoss: 0.47419, loss: 0.47419
[2022/06/18 22:06:29] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:06:36] ppcls INFO: [Train][Epoch 24/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08869973, top1: 0.87500, CELoss: 0.38733, loss: 0.38733, batch_cost: 0.61375s, reader_cost: 0.04446, ips: 104.27696 samples/s, eta: 8:04:31
[2022/06/18 22:06:42] ppcls INFO: [Train][Epoch 24/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08869314, top1: 0.79972, CELoss: 0.54996, loss: 0.54996, batch_cost: 0.63528s, reader_cost: 0.00349, ips: 100.74344 samples/s, eta: 8:21:24
[2022/06/18 22:06:48] ppcls INFO: [Train][Epoch 24/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08868654, top1: 0.82515, CELoss: 0.49287, loss: 0.49287, batch_cost: 0.63158s, reader_cost: 0.00581, ips: 101.33359 samples/s, eta: 8:18:23
[2022/06/18 22:06:54] ppcls INFO: [Train][Epoch 24/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08867992, top1: 0.82661, CELoss: 0.49028, loss: 0.49028, batch_cost: 0.61796s, reader_cost: 0.00625, ips: 103.56708 samples/s, eta: 8:07:32
[2022/06/18 22:07:01] ppcls INFO: [Train][Epoch 24/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08867329, top1: 0.82546, CELoss: 0.48751, loss: 0.48751, batch_cost: 0.62404s, reader_cost: 0.00621, ips: 102.55758 samples/s, eta: 8:12:13
[2022/06/18 22:07:07] ppcls INFO: [Train][Epoch 24/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08866664, top1: 0.83119, CELoss: 0.48425, loss: 0.48425, batch_cost: 0.62131s, reader_cost: 0.01914, ips: 103.00876 samples/s, eta: 8:09:58
[2022/06/18 22:07:13] ppcls INFO: [Train][Epoch 24/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08865997, top1: 0.83350, CELoss: 0.47716, loss: 0.47716, batch_cost: 0.61946s, reader_cost: 0.03074, ips: 103.31563 samples/s, eta: 8:08:24
[2022/06/18 22:07:20] ppcls INFO: [Train][Epoch 24/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08865329, top1: 0.83187, CELoss: 0.48284, loss: 0.48284, batch_cost: 0.62871s, reader_cost: 0.04822, ips: 101.79573 samples/s, eta: 8:15:36
[2022/06/18 22:07:25] ppcls INFO: [Train][Epoch 24/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08864659, top1: 0.83140, CELoss: 0.48605, loss: 0.48605, batch_cost: 0.61423s, reader_cost: 0.04735, ips: 104.19586 samples/s, eta: 8:04:04
[2022/06/18 22:07:32] ppcls INFO: [Train][Epoch 24/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08863987, top1: 0.82933, CELoss: 0.49117, loss: 0.49117, batch_cost: 0.62074s, reader_cost: 0.05144, ips: 103.10271 samples/s, eta: 8:09:06
[2022/06/18 22:07:38] ppcls INFO: [Train][Epoch 24/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08863314, top1: 0.83060, CELoss: 0.48692, loss: 0.48692, batch_cost: 0.61744s, reader_cost: 0.04797, ips: 103.65396 samples/s, eta: 8:06:24
[2022/06/18 22:07:44] ppcls INFO: [Train][Epoch 24/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08862639, top1: 0.82953, CELoss: 0.48900, loss: 0.48900, batch_cost: 0.61502s, reader_cost: 0.04780, ips: 104.06174 samples/s, eta: 8:04:23
[2022/06/18 22:07:50] ppcls INFO: [Train][Epoch 24/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08861963, top1: 0.82993, CELoss: 0.48901, loss: 0.48901, batch_cost: 0.62060s, reader_cost: 0.04507, ips: 103.12569 samples/s, eta: 8:08:41
[2022/06/18 22:07:56] ppcls INFO: [Train][Epoch 24/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08861285, top1: 0.83075, CELoss: 0.48577, loss: 0.48577, batch_cost: 0.61815s, reader_cost: 0.04395, ips: 103.53520 samples/s, eta: 8:06:39
[2022/06/18 22:08:02] ppcls INFO: [Train][Epoch 24/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08860605, top1: 0.83156, CELoss: 0.48373, loss: 0.48373, batch_cost: 0.61738s, reader_cost: 0.04135, ips: 103.66369 samples/s, eta: 8:05:57
[2022/06/18 22:08:08] ppcls INFO: [Train][Epoch 24/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08859923, top1: 0.83278, CELoss: 0.47901, loss: 0.47901, batch_cost: 0.61421s, reader_cost: 0.03877, ips: 104.19927 samples/s, eta: 8:03:21
[2022/06/18 22:08:13] ppcls INFO: [Train][Epoch 24/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08859240, top1: 0.83356, CELoss: 0.47672, loss: 0.47672, batch_cost: 0.60679s, reader_cost: 0.03727, ips: 105.47311 samples/s, eta: 7:57:24
[2022/06/18 22:08:15] ppcls INFO: [Train][Epoch 24/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08858556, top1: 0.83338, CELoss: 0.47540, loss: 0.47540, batch_cost: 0.58284s, reader_cost: 0.03507, ips: 84.07156 samples/s, eta: 7:38:28
[2022/06/18 22:08:16] ppcls INFO: [Train][Epoch 24/300][Avg]top1: 0.83338, CELoss: 0.47540, loss: 0.47540
[2022/06/18 22:08:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:08:22] ppcls INFO: [Train][Epoch 25/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08858487, top1: 0.79688, CELoss: 0.55269, loss: 0.55269, batch_cost: 0.61924s, reader_cost: 0.06047, ips: 103.35192 samples/s, eta: 8:07:05
[2022/06/18 22:08:28] ppcls INFO: [Train][Epoch 25/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08857801, top1: 0.81676, CELoss: 0.50885, loss: 0.50885, batch_cost: 0.58378s, reader_cost: 0.00355, ips: 109.63031 samples/s, eta: 7:39:06
[2022/06/18 22:08:35] ppcls INFO: [Train][Epoch 25/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08857113, top1: 0.81399, CELoss: 0.50734, loss: 0.50734, batch_cost: 0.66812s, reader_cost: 0.03676, ips: 95.79106 samples/s, eta: 8:45:19
[2022/06/18 22:08:42] ppcls INFO: [Train][Epoch 25/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08856423, top1: 0.81452, CELoss: 0.49473, loss: 0.49473, batch_cost: 0.67268s, reader_cost: 0.02798, ips: 95.14230 samples/s, eta: 8:48:47
[2022/06/18 22:08:48] ppcls INFO: [Train][Epoch 25/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08855731, top1: 0.81212, CELoss: 0.51280, loss: 0.51280, batch_cost: 0.65562s, reader_cost: 0.02383, ips: 97.61782 samples/s, eta: 8:35:16
[2022/06/18 22:08:54] ppcls INFO: [Train][Epoch 25/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08855038, top1: 0.81556, CELoss: 0.51136, loss: 0.51136, batch_cost: 0.63890s, reader_cost: 0.02302, ips: 100.17148 samples/s, eta: 8:22:01
[2022/06/18 22:09:00] ppcls INFO: [Train][Epoch 25/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08854344, top1: 0.81634, CELoss: 0.50876, loss: 0.50876, batch_cost: 0.63922s, reader_cost: 0.02132, ips: 100.12260 samples/s, eta: 8:22:10
[2022/06/18 22:09:06] ppcls INFO: [Train][Epoch 25/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08853647, top1: 0.81866, CELoss: 0.49854, loss: 0.49854, batch_cost: 0.63197s, reader_cost: 0.02037, ips: 101.27066 samples/s, eta: 8:16:22
[2022/06/18 22:09:12] ppcls INFO: [Train][Epoch 25/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08852950, top1: 0.82157, CELoss: 0.49366, loss: 0.49366, batch_cost: 0.62103s, reader_cost: 0.01944, ips: 103.05462 samples/s, eta: 8:07:40
[2022/06/18 22:09:17] ppcls INFO: [Train][Epoch 25/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08852250, top1: 0.82383, CELoss: 0.48832, loss: 0.48832, batch_cost: 0.60827s, reader_cost: 0.01972, ips: 105.21709 samples/s, eta: 7:57:32
[2022/06/18 22:09:24] ppcls INFO: [Train][Epoch 25/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08851549, top1: 0.82689, CELoss: 0.47976, loss: 0.47976, batch_cost: 0.61656s, reader_cost: 0.01842, ips: 103.80250 samples/s, eta: 8:03:57
[2022/06/18 22:09:30] ppcls INFO: [Train][Epoch 25/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08850846, top1: 0.82883, CELoss: 0.47673, loss: 0.47673, batch_cost: 0.61868s, reader_cost: 0.01777, ips: 103.44530 samples/s, eta: 8:05:31
[2022/06/18 22:09:35] ppcls INFO: [Train][Epoch 25/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08850142, top1: 0.83148, CELoss: 0.47179, loss: 0.47179, batch_cost: 0.61109s, reader_cost: 0.01819, ips: 104.73113 samples/s, eta: 7:59:27
[2022/06/18 22:09:42] ppcls INFO: [Train][Epoch 25/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08849436, top1: 0.83158, CELoss: 0.47205, loss: 0.47205, batch_cost: 0.61579s, reader_cost: 0.01727, ips: 103.93089 samples/s, eta: 8:03:02
[2022/06/18 22:09:48] ppcls INFO: [Train][Epoch 25/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08848728, top1: 0.83156, CELoss: 0.47340, loss: 0.47340, batch_cost: 0.61170s, reader_cost: 0.01648, ips: 104.62618 samples/s, eta: 7:59:44
[2022/06/18 22:09:54] ppcls INFO: [Train][Epoch 25/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08848018, top1: 0.83226, CELoss: 0.47438, loss: 0.47438, batch_cost: 0.60952s, reader_cost: 0.01894, ips: 105.00068 samples/s, eta: 7:57:55
[2022/06/18 22:09:59] ppcls INFO: [Train][Epoch 25/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08847307, top1: 0.83210, CELoss: 0.47571, loss: 0.47571, batch_cost: 0.60752s, reader_cost: 0.02890, ips: 105.34648 samples/s, eta: 7:56:15
[2022/06/18 22:10:01] ppcls INFO: [Train][Epoch 25/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08846595, top1: 0.83219, CELoss: 0.47583, loss: 0.47583, batch_cost: 0.58318s, reader_cost: 0.02717, ips: 84.02191 samples/s, eta: 7:37:04
[2022/06/18 22:10:02] ppcls INFO: [Train][Epoch 25/300][Avg]top1: 0.83219, CELoss: 0.47583, loss: 0.47583
[2022/06/18 22:10:09] ppcls INFO: [Eval][Epoch 25][Iter: 0/16]CELoss: 0.97944, loss: 0.97944, top1: 0.69727, batch_cost: 6.82542s, reader_cost: 3.45834, ips: 9.37671 images/sec
[2022/06/18 22:10:17] ppcls INFO: [Eval][Epoch 25][Iter: 10/16]CELoss: 0.93886, loss: 0.93886, top1: 0.68146, batch_cost: 0.59270s, reader_cost: 0.00435, ips: 107.98069 images/sec
[2022/06/18 22:10:18] ppcls INFO: [Eval][Epoch 25][Avg]CELoss: 0.85662, loss: 0.85662, top1: 0.69228
[2022/06/18 22:10:18] ppcls INFO: [Eval][Epoch 25][best metric: 0.6928921937942505]
[2022/06/18 22:10:18] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:10:25] ppcls INFO: [Train][Epoch 26/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08846524, top1: 0.84375, CELoss: 0.51071, loss: 0.51071, batch_cost: 0.62037s, reader_cost: 0.05252, ips: 103.16495 samples/s, eta: 8:06:12
[2022/06/18 22:10:32] ppcls INFO: [Train][Epoch 26/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08845809, top1: 0.84517, CELoss: 0.45297, loss: 0.45297, batch_cost: 0.68313s, reader_cost: 0.01685, ips: 93.68590 samples/s, eta: 8:55:17
[2022/06/18 22:10:37] ppcls INFO: [Train][Epoch 26/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08845093, top1: 0.83854, CELoss: 0.45717, loss: 0.45717, batch_cost: 0.60541s, reader_cost: 0.01365, ips: 105.71353 samples/s, eta: 7:54:17
[2022/06/18 22:10:45] ppcls INFO: [Train][Epoch 26/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08844375, top1: 0.83417, CELoss: 0.45746, loss: 0.45746, batch_cost: 0.65657s, reader_cost: 0.01325, ips: 97.47683 samples/s, eta: 8:34:15
[2022/06/18 22:10:51] ppcls INFO: [Train][Epoch 26/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08843656, top1: 0.83308, CELoss: 0.46201, loss: 0.46201, batch_cost: 0.63794s, reader_cost: 0.01206, ips: 100.32250 samples/s, eta: 8:19:33
[2022/06/18 22:10:57] ppcls INFO: [Train][Epoch 26/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08842935, top1: 0.83150, CELoss: 0.47180, loss: 0.47180, batch_cost: 0.63867s, reader_cost: 0.01227, ips: 100.20866 samples/s, eta: 8:20:01
[2022/06/18 22:11:02] ppcls INFO: [Train][Epoch 26/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08842213, top1: 0.83427, CELoss: 0.46724, loss: 0.46724, batch_cost: 0.61924s, reader_cost: 0.01332, ips: 103.35254 samples/s, eta: 8:04:42
[2022/06/18 22:11:08] ppcls INFO: [Train][Epoch 26/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08841489, top1: 0.83517, CELoss: 0.46689, loss: 0.46689, batch_cost: 0.61335s, reader_cost: 0.01249, ips: 104.34549 samples/s, eta: 7:59:59
[2022/06/18 22:11:15] ppcls INFO: [Train][Epoch 26/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08840763, top1: 0.83738, CELoss: 0.46301, loss: 0.46301, batch_cost: 0.61669s, reader_cost: 0.01260, ips: 103.77971 samples/s, eta: 8:02:30
[2022/06/18 22:11:21] ppcls INFO: [Train][Epoch 26/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08840035, top1: 0.83516, CELoss: 0.46743, loss: 0.46743, batch_cost: 0.61491s, reader_cost: 0.01237, ips: 104.08052 samples/s, eta: 8:01:00
[2022/06/18 22:11:26] ppcls INFO: [Train][Epoch 26/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08839306, top1: 0.83787, CELoss: 0.46574, loss: 0.46574, batch_cost: 0.61004s, reader_cost: 0.01190, ips: 104.91047 samples/s, eta: 7:57:06
[2022/06/18 22:11:32] ppcls INFO: [Train][Epoch 26/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08838576, top1: 0.83812, CELoss: 0.46442, loss: 0.46442, batch_cost: 0.60333s, reader_cost: 0.01188, ips: 106.07872 samples/s, eta: 7:51:45
[2022/06/18 22:11:38] ppcls INFO: [Train][Epoch 26/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08837843, top1: 0.83742, CELoss: 0.46479, loss: 0.46479, batch_cost: 0.60822s, reader_cost: 0.01203, ips: 105.22441 samples/s, eta: 7:55:28
[2022/06/18 22:11:44] ppcls INFO: [Train][Epoch 26/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08837109, top1: 0.83779, CELoss: 0.46417, loss: 0.46417, batch_cost: 0.60375s, reader_cost: 0.01322, ips: 106.00349 samples/s, eta: 7:51:53
[2022/06/18 22:11:50] ppcls INFO: [Train][Epoch 26/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08836374, top1: 0.83887, CELoss: 0.46088, loss: 0.46088, batch_cost: 0.60111s, reader_cost: 0.01281, ips: 106.47001 samples/s, eta: 7:49:42
[2022/06/18 22:11:57] ppcls INFO: [Train][Epoch 26/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08835637, top1: 0.83713, CELoss: 0.46627, loss: 0.46627, batch_cost: 0.60930s, reader_cost: 0.02341, ips: 105.03775 samples/s, eta: 7:56:01
[2022/06/18 22:12:03] ppcls INFO: [Train][Epoch 26/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08834898, top1: 0.83773, CELoss: 0.46403, loss: 0.46403, batch_cost: 0.60797s, reader_cost: 0.03736, ips: 105.26878 samples/s, eta: 7:54:52
[2022/06/18 22:12:05] ppcls INFO: [Train][Epoch 26/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08834157, top1: 0.83676, CELoss: 0.46574, loss: 0.46574, batch_cost: 0.58382s, reader_cost: 0.03524, ips: 83.92933 samples/s, eta: 7:35:55
[2022/06/18 22:12:05] ppcls INFO: [Train][Epoch 26/300][Avg]top1: 0.83676, CELoss: 0.46574, loss: 0.46574
[2022/06/18 22:12:05] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:12:12] ppcls INFO: [Train][Epoch 27/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08834083, top1: 0.85938, CELoss: 0.40290, loss: 0.40290, batch_cost: 0.61747s, reader_cost: 0.06072, ips: 103.64803 samples/s, eta: 8:02:11
[2022/06/18 22:12:18] ppcls INFO: [Train][Epoch 27/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08833341, top1: 0.83381, CELoss: 0.50152, loss: 0.50152, batch_cost: 0.73424s, reader_cost: 0.01508, ips: 87.16491 samples/s, eta: 9:33:14
[2022/06/18 22:12:24] ppcls INFO: [Train][Epoch 27/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08832597, top1: 0.84152, CELoss: 0.48079, loss: 0.48079, batch_cost: 0.63627s, reader_cost: 0.00916, ips: 100.58657 samples/s, eta: 8:16:38
[2022/06/18 22:12:30] ppcls INFO: [Train][Epoch 27/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08831852, top1: 0.83871, CELoss: 0.47690, loss: 0.47690, batch_cost: 0.64968s, reader_cost: 0.00866, ips: 98.51006 samples/s, eta: 8:27:00
[2022/06/18 22:12:37] ppcls INFO: [Train][Epoch 27/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08831105, top1: 0.83765, CELoss: 0.48425, loss: 0.48425, batch_cost: 0.63911s, reader_cost: 0.01376, ips: 100.13939 samples/s, eta: 8:18:39
[2022/06/18 22:12:43] ppcls INFO: [Train][Epoch 27/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08830356, top1: 0.83701, CELoss: 0.48416, loss: 0.48416, batch_cost: 0.63271s, reader_cost: 0.01499, ips: 101.15176 samples/s, eta: 8:13:33
[2022/06/18 22:12:49] ppcls INFO: [Train][Epoch 27/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08829606, top1: 0.83914, CELoss: 0.48355, loss: 0.48355, batch_cost: 0.63728s, reader_cost: 0.01427, ips: 100.42626 samples/s, eta: 8:17:01
[2022/06/18 22:12:55] ppcls INFO: [Train][Epoch 27/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08828854, top1: 0.83759, CELoss: 0.48050, loss: 0.48050, batch_cost: 0.63042s, reader_cost: 0.01457, ips: 101.51983 samples/s, eta: 8:11:33
[2022/06/18 22:13:01] ppcls INFO: [Train][Epoch 27/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08828100, top1: 0.83989, CELoss: 0.47302, loss: 0.47302, batch_cost: 0.62224s, reader_cost: 0.01462, ips: 102.85346 samples/s, eta: 8:05:04
[2022/06/18 22:13:07] ppcls INFO: [Train][Epoch 27/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08827345, top1: 0.83963, CELoss: 0.46876, loss: 0.46876, batch_cost: 0.61757s, reader_cost: 0.01490, ips: 103.63218 samples/s, eta: 8:01:19
[2022/06/18 22:13:14] ppcls INFO: [Train][Epoch 27/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08826588, top1: 0.84158, CELoss: 0.46463, loss: 0.46463, batch_cost: 0.62467s, reader_cost: 0.01442, ips: 102.45349 samples/s, eta: 8:06:45
[2022/06/18 22:13:19] ppcls INFO: [Train][Epoch 27/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08825830, top1: 0.84262, CELoss: 0.46150, loss: 0.46150, batch_cost: 0.61877s, reader_cost: 0.01404, ips: 103.43035 samples/s, eta: 8:02:03
[2022/06/18 22:13:25] ppcls INFO: [Train][Epoch 27/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08825069, top1: 0.84220, CELoss: 0.45859, loss: 0.45859, batch_cost: 0.61878s, reader_cost: 0.01446, ips: 103.42871 samples/s, eta: 8:01:58
[2022/06/18 22:13:33] ppcls INFO: [Train][Epoch 27/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08824308, top1: 0.84172, CELoss: 0.45795, loss: 0.45795, batch_cost: 0.62671s, reader_cost: 0.01444, ips: 102.12064 samples/s, eta: 8:08:02
[2022/06/18 22:13:39] ppcls INFO: [Train][Epoch 27/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08823544, top1: 0.84054, CELoss: 0.45986, loss: 0.45986, batch_cost: 0.62697s, reader_cost: 0.01391, ips: 102.07888 samples/s, eta: 8:08:08
[2022/06/18 22:13:44] ppcls INFO: [Train][Epoch 27/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08822779, top1: 0.84023, CELoss: 0.46046, loss: 0.46046, batch_cost: 0.61904s, reader_cost: 0.01373, ips: 103.38517 samples/s, eta: 8:01:51
[2022/06/18 22:13:49] ppcls INFO: [Train][Epoch 27/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08822013, top1: 0.83861, CELoss: 0.46284, loss: 0.46284, batch_cost: 0.61449s, reader_cost: 0.01329, ips: 104.15107 samples/s, eta: 7:58:13
[2022/06/18 22:13:52] ppcls INFO: [Train][Epoch 27/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08821245, top1: 0.83713, CELoss: 0.46506, loss: 0.46506, batch_cost: 0.58986s, reader_cost: 0.01250, ips: 83.07093 samples/s, eta: 7:38:56
[2022/06/18 22:13:52] ppcls INFO: [Train][Epoch 27/300][Avg]top1: 0.83713, CELoss: 0.46506, loss: 0.46506
[2022/06/18 22:13:52] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:13:59] ppcls INFO: [Train][Epoch 28/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08821168, top1: 0.90625, CELoss: 0.35672, loss: 0.35672, batch_cost: 0.62599s, reader_cost: 0.03643, ips: 102.23809 samples/s, eta: 8:07:03
[2022/06/18 22:14:06] ppcls INFO: [Train][Epoch 28/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08820398, top1: 0.85653, CELoss: 0.41088, loss: 0.41088, batch_cost: 0.70226s, reader_cost: 0.00278, ips: 91.13476 samples/s, eta: 9:06:16
[2022/06/18 22:14:11] ppcls INFO: [Train][Epoch 28/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08819626, top1: 0.84003, CELoss: 0.45433, loss: 0.45433, batch_cost: 0.61966s, reader_cost: 0.00814, ips: 103.28252 samples/s, eta: 8:01:55
[2022/06/18 22:14:17] ppcls INFO: [Train][Epoch 28/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08818853, top1: 0.83921, CELoss: 0.46589, loss: 0.46589, batch_cost: 0.58884s, reader_cost: 0.01426, ips: 108.68829 samples/s, eta: 7:37:51
[2022/06/18 22:14:23] ppcls INFO: [Train][Epoch 28/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08818078, top1: 0.83346, CELoss: 0.47250, loss: 0.47250, batch_cost: 0.59709s, reader_cost: 0.01184, ips: 107.18644 samples/s, eta: 7:44:10
[2022/06/18 22:14:28] ppcls INFO: [Train][Epoch 28/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08817302, top1: 0.83548, CELoss: 0.47220, loss: 0.47220, batch_cost: 0.58889s, reader_cost: 0.01406, ips: 108.67894 samples/s, eta: 7:37:41
[2022/06/18 22:14:34] ppcls INFO: [Train][Epoch 28/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08816524, top1: 0.83607, CELoss: 0.46973, loss: 0.46973, batch_cost: 0.58748s, reader_cost: 0.01434, ips: 108.93907 samples/s, eta: 7:36:30
[2022/06/18 22:14:40] ppcls INFO: [Train][Epoch 28/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08815744, top1: 0.83627, CELoss: 0.47087, loss: 0.47087, batch_cost: 0.58603s, reader_cost: 0.01693, ips: 109.20913 samples/s, eta: 7:35:16
[2022/06/18 22:14:47] ppcls INFO: [Train][Epoch 28/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08814963, top1: 0.83449, CELoss: 0.47193, loss: 0.47193, batch_cost: 0.60133s, reader_cost: 0.01592, ips: 106.43116 samples/s, eta: 7:47:03
[2022/06/18 22:14:52] ppcls INFO: [Train][Epoch 28/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08814180, top1: 0.83568, CELoss: 0.47151, loss: 0.47151, batch_cost: 0.59056s, reader_cost: 0.01724, ips: 108.37150 samples/s, eta: 7:38:36
[2022/06/18 22:14:57] ppcls INFO: [Train][Epoch 28/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08813395, top1: 0.83772, CELoss: 0.46710, loss: 0.46710, batch_cost: 0.58420s, reader_cost: 0.01645, ips: 109.55141 samples/s, eta: 7:33:33
[2022/06/18 22:15:05] ppcls INFO: [Train][Epoch 28/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08812609, top1: 0.83727, CELoss: 0.46625, loss: 0.46625, batch_cost: 0.59903s, reader_cost: 0.01688, ips: 106.83915 samples/s, eta: 7:44:58
[2022/06/18 22:15:11] ppcls INFO: [Train][Epoch 28/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08811821, top1: 0.83536, CELoss: 0.47027, loss: 0.47027, batch_cost: 0.59656s, reader_cost: 0.01661, ips: 107.28098 samples/s, eta: 7:42:57
[2022/06/18 22:15:16] ppcls INFO: [Train][Epoch 28/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08811032, top1: 0.83492, CELoss: 0.47111, loss: 0.47111, batch_cost: 0.59584s, reader_cost: 0.01569, ips: 107.41122 samples/s, eta: 7:42:18
[2022/06/18 22:15:22] ppcls INFO: [Train][Epoch 28/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08810241, top1: 0.83500, CELoss: 0.47001, loss: 0.47001, batch_cost: 0.59320s, reader_cost: 0.01474, ips: 107.88992 samples/s, eta: 7:40:09
[2022/06/18 22:15:28] ppcls INFO: [Train][Epoch 28/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08809448, top1: 0.83609, CELoss: 0.46855, loss: 0.46855, batch_cost: 0.59570s, reader_cost: 0.01407, ips: 107.43598 samples/s, eta: 7:41:59
[2022/06/18 22:15:33] ppcls INFO: [Train][Epoch 28/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08808654, top1: 0.83511, CELoss: 0.47131, loss: 0.47131, batch_cost: 0.58835s, reader_cost: 0.01326, ips: 108.77960 samples/s, eta: 7:36:11
[2022/06/18 22:15:35] ppcls INFO: [Train][Epoch 28/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08807858, top1: 0.83493, CELoss: 0.47259, loss: 0.47259, batch_cost: 0.56515s, reader_cost: 0.01250, ips: 86.70234 samples/s, eta: 7:18:06
[2022/06/18 22:15:36] ppcls INFO: [Train][Epoch 28/300][Avg]top1: 0.83493, CELoss: 0.47259, loss: 0.47259
[2022/06/18 22:15:36] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:15:43] ppcls INFO: [Train][Epoch 29/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08807778, top1: 0.89062, CELoss: 0.36555, loss: 0.36555, batch_cost: 0.60381s, reader_cost: 0.04609, ips: 105.99429 samples/s, eta: 7:48:04
[2022/06/18 22:15:49] ppcls INFO: [Train][Epoch 29/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08806981, top1: 0.87216, CELoss: 0.38206, loss: 0.38206, batch_cost: 0.61729s, reader_cost: 0.01009, ips: 103.67965 samples/s, eta: 7:58:25
[2022/06/18 22:15:55] ppcls INFO: [Train][Epoch 29/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08806182, top1: 0.87054, CELoss: 0.38579, loss: 0.38579, batch_cost: 0.63100s, reader_cost: 0.02247, ips: 101.42587 samples/s, eta: 8:08:56
[2022/06/18 22:16:01] ppcls INFO: [Train][Epoch 29/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08805381, top1: 0.85887, CELoss: 0.40717, loss: 0.40717, batch_cost: 0.61852s, reader_cost: 0.02406, ips: 103.47321 samples/s, eta: 7:59:09
[2022/06/18 22:16:07] ppcls INFO: [Train][Epoch 29/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08804578, top1: 0.85137, CELoss: 0.42715, loss: 0.42715, batch_cost: 0.61046s, reader_cost: 0.02135, ips: 104.83944 samples/s, eta: 7:52:49
[2022/06/18 22:16:13] ppcls INFO: [Train][Epoch 29/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08803774, top1: 0.84957, CELoss: 0.43230, loss: 0.43230, batch_cost: 0.60861s, reader_cost: 0.02131, ips: 105.15764 samples/s, eta: 7:51:17
[2022/06/18 22:16:20] ppcls INFO: [Train][Epoch 29/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08802968, top1: 0.85143, CELoss: 0.43080, loss: 0.43080, batch_cost: 0.61605s, reader_cost: 0.02081, ips: 103.88764 samples/s, eta: 7:56:56
[2022/06/18 22:16:25] ppcls INFO: [Train][Epoch 29/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08802161, top1: 0.84991, CELoss: 0.43447, loss: 0.43447, batch_cost: 0.59808s, reader_cost: 0.02011, ips: 107.00854 samples/s, eta: 7:42:56
[2022/06/18 22:16:31] ppcls INFO: [Train][Epoch 29/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08801352, top1: 0.84915, CELoss: 0.43795, loss: 0.43795, batch_cost: 0.59941s, reader_cost: 0.01910, ips: 106.77144 samples/s, eta: 7:43:51
[2022/06/18 22:16:37] ppcls INFO: [Train][Epoch 29/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08800542, top1: 0.85062, CELoss: 0.43502, loss: 0.43502, batch_cost: 0.59738s, reader_cost: 0.01966, ips: 107.13526 samples/s, eta: 7:42:11
[2022/06/18 22:16:44] ppcls INFO: [Train][Epoch 29/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08799729, top1: 0.84978, CELoss: 0.43693, loss: 0.43693, batch_cost: 0.60914s, reader_cost: 0.01836, ips: 105.06571 samples/s, eta: 7:51:11
[2022/06/18 22:16:50] ppcls INFO: [Train][Epoch 29/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08798916, top1: 0.84755, CELoss: 0.44001, loss: 0.44001, batch_cost: 0.60747s, reader_cost: 0.01805, ips: 105.35419 samples/s, eta: 7:49:48
[2022/06/18 22:16:56] ppcls INFO: [Train][Epoch 29/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08798100, top1: 0.84749, CELoss: 0.43993, loss: 0.43993, batch_cost: 0.60845s, reader_cost: 0.01821, ips: 105.18519 samples/s, eta: 7:50:27
[2022/06/18 22:17:01] ppcls INFO: [Train][Epoch 29/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08797283, top1: 0.84864, CELoss: 0.43928, loss: 0.43928, batch_cost: 0.60136s, reader_cost: 0.01968, ips: 106.42623 samples/s, eta: 7:44:52
[2022/06/18 22:17:08] ppcls INFO: [Train][Epoch 29/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08796465, top1: 0.84752, CELoss: 0.44220, loss: 0.44220, batch_cost: 0.60483s, reader_cost: 0.01920, ips: 105.81416 samples/s, eta: 7:47:27
[2022/06/18 22:17:14] ppcls INFO: [Train][Epoch 29/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08795644, top1: 0.84665, CELoss: 0.44287, loss: 0.44287, batch_cost: 0.60387s, reader_cost: 0.01882, ips: 105.98299 samples/s, eta: 7:46:36
[2022/06/18 22:17:19] ppcls INFO: [Train][Epoch 29/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08794823, top1: 0.84501, CELoss: 0.44526, loss: 0.44526, batch_cost: 0.60148s, reader_cost: 0.01778, ips: 106.40398 samples/s, eta: 7:44:39
[2022/06/18 22:17:21] ppcls INFO: [Train][Epoch 29/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08793999, top1: 0.84482, CELoss: 0.44477, loss: 0.44477, batch_cost: 0.57760s, reader_cost: 0.01672, ips: 84.83394 samples/s, eta: 7:26:07
[2022/06/18 22:17:22] ppcls INFO: [Train][Epoch 29/300][Avg]top1: 0.84482, CELoss: 0.44477, loss: 0.44477
[2022/06/18 22:17:22] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:17:28] ppcls INFO: [Train][Epoch 30/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08793917, top1: 0.82812, CELoss: 0.48986, loss: 0.48986, batch_cost: 0.60850s, reader_cost: 0.04386, ips: 105.17660 samples/s, eta: 7:49:58
[2022/06/18 22:17:35] ppcls INFO: [Train][Epoch 30/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08793091, top1: 0.86506, CELoss: 0.39633, loss: 0.39633, batch_cost: 0.56647s, reader_cost: 0.01467, ips: 112.98007 samples/s, eta: 7:17:25
[2022/06/18 22:17:41] ppcls INFO: [Train][Epoch 30/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08792265, top1: 0.86086, CELoss: 0.40846, loss: 0.40846, batch_cost: 0.56892s, reader_cost: 0.01851, ips: 112.49357 samples/s, eta: 7:19:13
[2022/06/18 22:17:47] ppcls INFO: [Train][Epoch 30/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08791436, top1: 0.85282, CELoss: 0.42238, loss: 0.42238, batch_cost: 0.57694s, reader_cost: 0.01422, ips: 110.93049 samples/s, eta: 7:25:18
[2022/06/18 22:17:54] ppcls INFO: [Train][Epoch 30/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08790606, top1: 0.84566, CELoss: 0.43618, loss: 0.43618, batch_cost: 0.62296s, reader_cost: 0.01394, ips: 102.73494 samples/s, eta: 8:00:43
[2022/06/18 22:17:59] ppcls INFO: [Train][Epoch 30/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08789774, top1: 0.84712, CELoss: 0.43219, loss: 0.43219, batch_cost: 0.60439s, reader_cost: 0.01564, ips: 105.89220 samples/s, eta: 7:46:17
[2022/06/18 22:18:06] ppcls INFO: [Train][Epoch 30/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08788941, top1: 0.84785, CELoss: 0.43444, loss: 0.43444, batch_cost: 0.61224s, reader_cost: 0.01426, ips: 104.53405 samples/s, eta: 7:52:15
[2022/06/18 22:18:12] ppcls INFO: [Train][Epoch 30/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08788106, top1: 0.85035, CELoss: 0.43159, loss: 0.43159, batch_cost: 0.60595s, reader_cost: 0.01444, ips: 105.61949 samples/s, eta: 7:47:17
[2022/06/18 22:18:17] ppcls INFO: [Train][Epoch 30/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08787270, top1: 0.85147, CELoss: 0.42690, loss: 0.42690, batch_cost: 0.60391s, reader_cost: 0.01416, ips: 105.97644 samples/s, eta: 7:45:37
[2022/06/18 22:18:23] ppcls INFO: [Train][Epoch 30/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08786432, top1: 0.84959, CELoss: 0.43242, loss: 0.43242, batch_cost: 0.60099s, reader_cost: 0.01427, ips: 106.49121 samples/s, eta: 7:43:16
[2022/06/18 22:18:30] ppcls INFO: [Train][Epoch 30/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08785592, top1: 0.84978, CELoss: 0.43076, loss: 0.43076, batch_cost: 0.60948s, reader_cost: 0.01486, ips: 105.00778 samples/s, eta: 7:49:42
[2022/06/18 22:18:35] ppcls INFO: [Train][Epoch 30/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08784751, top1: 0.84966, CELoss: 0.42901, loss: 0.42901, batch_cost: 0.60172s, reader_cost: 0.01471, ips: 106.36129 samples/s, eta: 7:43:38
[2022/06/18 22:18:41] ppcls INFO: [Train][Epoch 30/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08783908, top1: 0.84853, CELoss: 0.43198, loss: 0.43198, batch_cost: 0.59979s, reader_cost: 0.01384, ips: 106.70351 samples/s, eta: 7:42:03
[2022/06/18 22:18:47] ppcls INFO: [Train][Epoch 30/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08783063, top1: 0.84983, CELoss: 0.43116, loss: 0.43116, batch_cost: 0.59603s, reader_cost: 0.01323, ips: 107.37794 samples/s, eta: 7:39:02
[2022/06/18 22:18:54] ppcls INFO: [Train][Epoch 30/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08782217, top1: 0.84874, CELoss: 0.43617, loss: 0.43617, batch_cost: 0.60443s, reader_cost: 0.01289, ips: 105.88540 samples/s, eta: 7:45:25
[2022/06/18 22:18:59] ppcls INFO: [Train][Epoch 30/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08781369, top1: 0.84830, CELoss: 0.43536, loss: 0.43536, batch_cost: 0.60063s, reader_cost: 0.01298, ips: 106.55447 samples/s, eta: 7:42:23
[2022/06/18 22:19:04] ppcls INFO: [Train][Epoch 30/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08780520, top1: 0.84967, CELoss: 0.43314, loss: 0.43314, batch_cost: 0.59356s, reader_cost: 0.01282, ips: 107.82410 samples/s, eta: 7:36:51
[2022/06/18 22:19:07] ppcls INFO: [Train][Epoch 30/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08779669, top1: 0.85031, CELoss: 0.43149, loss: 0.43149, batch_cost: 0.57171s, reader_cost: 0.01207, ips: 85.70818 samples/s, eta: 7:19:56
[2022/06/18 22:19:07] ppcls INFO: [Train][Epoch 30/300][Avg]top1: 0.85031, CELoss: 0.43149, loss: 0.43149
[2022/06/18 22:19:14] ppcls INFO: [Eval][Epoch 30][Iter: 0/16]CELoss: 1.01584, loss: 1.01584, top1: 0.72070, batch_cost: 6.90656s, reader_cost: 3.46073, ips: 9.26655 images/sec
[2022/06/18 22:19:22] ppcls INFO: [Eval][Epoch 30][Iter: 10/16]CELoss: 0.90257, loss: 0.90257, top1: 0.69389, batch_cost: 0.60903s, reader_cost: 0.01537, ips: 105.08454 images/sec
[2022/06/18 22:19:24] ppcls INFO: [Eval][Epoch 30][Avg]CELoss: 0.83192, loss: 0.83192, top1: 0.70662
[2022/06/18 22:19:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 22:19:24] ppcls INFO: [Eval][Epoch 30][best metric: 0.7066177129745483]
[2022/06/18 22:19:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_30
[2022/06/18 22:19:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:19:31] ppcls INFO: [Train][Epoch 31/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08779584, top1: 0.87500, CELoss: 0.34379, loss: 0.34379, batch_cost: 0.60841s, reader_cost: 0.04916, ips: 105.19306 samples/s, eta: 7:48:10
[2022/06/18 22:19:37] ppcls INFO: [Train][Epoch 31/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08778731, top1: 0.83523, CELoss: 0.46105, loss: 0.46105, batch_cost: 0.58733s, reader_cost: 0.01719, ips: 108.96739 samples/s, eta: 7:31:51
[2022/06/18 22:19:43] ppcls INFO: [Train][Epoch 31/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08777877, top1: 0.84375, CELoss: 0.44832, loss: 0.44832, batch_cost: 0.63117s, reader_cost: 0.05697, ips: 101.39903 samples/s, eta: 8:05:28
[2022/06/18 22:19:49] ppcls INFO: [Train][Epoch 31/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08777021, top1: 0.84325, CELoss: 0.45304, loss: 0.45304, batch_cost: 0.59236s, reader_cost: 0.03745, ips: 108.04329 samples/s, eta: 7:35:31
[2022/06/18 22:19:57] ppcls INFO: [Train][Epoch 31/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08776164, top1: 0.84947, CELoss: 0.44476, loss: 0.44476, batch_cost: 0.64701s, reader_cost: 0.03709, ips: 98.91680 samples/s, eta: 8:17:26
[2022/06/18 22:20:02] ppcls INFO: [Train][Epoch 31/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08775304, top1: 0.85049, CELoss: 0.43694, loss: 0.43694, batch_cost: 0.62155s, reader_cost: 0.03206, ips: 102.96861 samples/s, eta: 7:57:45
[2022/06/18 22:20:08] ppcls INFO: [Train][Epoch 31/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08774444, top1: 0.85041, CELoss: 0.44092, loss: 0.44092, batch_cost: 0.61758s, reader_cost: 0.03017, ips: 103.63045 samples/s, eta: 7:54:36
[2022/06/18 22:20:14] ppcls INFO: [Train][Epoch 31/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08773581, top1: 0.84859, CELoss: 0.44306, loss: 0.44306, batch_cost: 0.61316s, reader_cost: 0.02962, ips: 104.37803 samples/s, eta: 7:51:06
[2022/06/18 22:20:21] ppcls INFO: [Train][Epoch 31/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08772717, top1: 0.84587, CELoss: 0.44913, loss: 0.44913, batch_cost: 0.62207s, reader_cost: 0.02643, ips: 102.88163 samples/s, eta: 7:57:51
[2022/06/18 22:20:26] ppcls INFO: [Train][Epoch 31/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08771852, top1: 0.84615, CELoss: 0.44418, loss: 0.44418, batch_cost: 0.61160s, reader_cost: 0.02440, ips: 104.64414 samples/s, eta: 7:49:42
[2022/06/18 22:20:33] ppcls INFO: [Train][Epoch 31/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08770985, top1: 0.84437, CELoss: 0.44760, loss: 0.44760, batch_cost: 0.61633s, reader_cost: 0.02313, ips: 103.83982 samples/s, eta: 7:53:14
[2022/06/18 22:20:38] ppcls INFO: [Train][Epoch 31/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08770116, top1: 0.84699, CELoss: 0.44325, loss: 0.44325, batch_cost: 0.61017s, reader_cost: 0.02134, ips: 104.88964 samples/s, eta: 7:48:24
[2022/06/18 22:20:46] ppcls INFO: [Train][Epoch 31/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08769246, top1: 0.84801, CELoss: 0.44168, loss: 0.44168, batch_cost: 0.62213s, reader_cost: 0.02744, ips: 102.87214 samples/s, eta: 7:57:29
[2022/06/18 22:20:51] ppcls INFO: [Train][Epoch 31/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08768374, top1: 0.84685, CELoss: 0.44468, loss: 0.44468, batch_cost: 0.61323s, reader_cost: 0.02698, ips: 104.36541 samples/s, eta: 7:50:33
[2022/06/18 22:20:56] ppcls INFO: [Train][Epoch 31/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08767500, top1: 0.84608, CELoss: 0.44599, loss: 0.44599, batch_cost: 0.60868s, reader_cost: 0.02608, ips: 105.14572 samples/s, eta: 7:46:57
[2022/06/18 22:21:02] ppcls INFO: [Train][Epoch 31/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08766625, top1: 0.84520, CELoss: 0.44754, loss: 0.44754, batch_cost: 0.60612s, reader_cost: 0.02817, ips: 105.58884 samples/s, eta: 7:44:53
[2022/06/18 22:21:09] ppcls INFO: [Train][Epoch 31/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08765748, top1: 0.84569, CELoss: 0.44672, loss: 0.44672, batch_cost: 0.61069s, reader_cost: 0.02856, ips: 104.79919 samples/s, eta: 7:48:17
[2022/06/18 22:21:11] ppcls INFO: [Train][Epoch 31/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08764870, top1: 0.84628, CELoss: 0.44622, loss: 0.44622, batch_cost: 0.58631s, reader_cost: 0.02688, ips: 83.57402 samples/s, eta: 7:29:30
[2022/06/18 22:21:11] ppcls INFO: [Train][Epoch 31/300][Avg]top1: 0.84628, CELoss: 0.44622, loss: 0.44622
[2022/06/18 22:21:11] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:21:17] ppcls INFO: [Train][Epoch 32/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08764782, top1: 0.84375, CELoss: 0.36908, loss: 0.36908, batch_cost: 0.61730s, reader_cost: 0.05572, ips: 103.67730 samples/s, eta: 7:53:15
[2022/06/18 22:21:24] ppcls INFO: [Train][Epoch 32/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08763902, top1: 0.81250, CELoss: 0.49742, loss: 0.49742, batch_cost: 0.58308s, reader_cost: 0.00528, ips: 109.76161 samples/s, eta: 7:26:55
[2022/06/18 22:21:30] ppcls INFO: [Train][Epoch 32/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08763020, top1: 0.82068, CELoss: 0.49463, loss: 0.49463, batch_cost: 0.59344s, reader_cost: 0.01588, ips: 107.84628 samples/s, eta: 7:34:45
[2022/06/18 22:21:36] ppcls INFO: [Train][Epoch 32/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08762137, top1: 0.82510, CELoss: 0.48231, loss: 0.48231, batch_cost: 0.58052s, reader_cost: 0.01421, ips: 110.24591 samples/s, eta: 7:24:45
[2022/06/18 22:21:42] ppcls INFO: [Train][Epoch 32/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08761252, top1: 0.82851, CELoss: 0.47080, loss: 0.47080, batch_cost: 0.58614s, reader_cost: 0.01182, ips: 109.18801 samples/s, eta: 7:28:58
[2022/06/18 22:21:49] ppcls INFO: [Train][Epoch 32/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08760366, top1: 0.83119, CELoss: 0.46990, loss: 0.46990, batch_cost: 0.61279s, reader_cost: 0.01213, ips: 104.44000 samples/s, eta: 7:49:17
[2022/06/18 22:21:55] ppcls INFO: [Train][Epoch 32/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08759477, top1: 0.83274, CELoss: 0.46686, loss: 0.46686, batch_cost: 0.60531s, reader_cost: 0.01321, ips: 105.73131 samples/s, eta: 7:43:27
[2022/06/18 22:22:01] ppcls INFO: [Train][Epoch 32/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08758588, top1: 0.83429, CELoss: 0.46706, loss: 0.46706, batch_cost: 0.60314s, reader_cost: 0.01310, ips: 106.11061 samples/s, eta: 7:41:41
[2022/06/18 22:22:07] ppcls INFO: [Train][Epoch 32/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08757696, top1: 0.83681, CELoss: 0.46267, loss: 0.46267, batch_cost: 0.60511s, reader_cost: 0.01612, ips: 105.76652 samples/s, eta: 7:43:05
[2022/06/18 22:22:13] ppcls INFO: [Train][Epoch 32/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08756804, top1: 0.83808, CELoss: 0.45823, loss: 0.45823, batch_cost: 0.60430s, reader_cost: 0.01716, ips: 105.90709 samples/s, eta: 7:42:22
[2022/06/18 22:22:18] ppcls INFO: [Train][Epoch 32/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08755909, top1: 0.83772, CELoss: 0.45746, loss: 0.45746, batch_cost: 0.59991s, reader_cost: 0.01774, ips: 106.68210 samples/s, eta: 7:38:55
[2022/06/18 22:22:25] ppcls INFO: [Train][Epoch 32/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08755013, top1: 0.84023, CELoss: 0.44981, loss: 0.44981, batch_cost: 0.60444s, reader_cost: 0.01749, ips: 105.88355 samples/s, eta: 7:42:17
[2022/06/18 22:22:30] ppcls INFO: [Train][Epoch 32/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08754115, top1: 0.84104, CELoss: 0.44846, loss: 0.44846, batch_cost: 0.59623s, reader_cost: 0.01716, ips: 107.34047 samples/s, eta: 7:35:54
[2022/06/18 22:22:36] ppcls INFO: [Train][Epoch 32/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08753216, top1: 0.84029, CELoss: 0.45053, loss: 0.45053, batch_cost: 0.59439s, reader_cost: 0.01711, ips: 107.67267 samples/s, eta: 7:34:24
[2022/06/18 22:22:42] ppcls INFO: [Train][Epoch 32/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08752315, top1: 0.84098, CELoss: 0.44867, loss: 0.44867, batch_cost: 0.59842s, reader_cost: 0.01609, ips: 106.94882 samples/s, eta: 7:37:22
[2022/06/18 22:22:47] ppcls INFO: [Train][Epoch 32/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08751413, top1: 0.84230, CELoss: 0.44463, loss: 0.44463, batch_cost: 0.59305s, reader_cost: 0.01550, ips: 107.91691 samples/s, eta: 7:33:10
[2022/06/18 22:22:52] ppcls INFO: [Train][Epoch 32/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08750509, top1: 0.84288, CELoss: 0.44395, loss: 0.44395, batch_cost: 0.58570s, reader_cost: 0.01460, ips: 109.27135 samples/s, eta: 7:27:27
[2022/06/18 22:22:55] ppcls INFO: [Train][Epoch 32/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08749603, top1: 0.84326, CELoss: 0.44311, loss: 0.44311, batch_cost: 0.56738s, reader_cost: 0.01373, ips: 86.36160 samples/s, eta: 7:13:22
[2022/06/18 22:22:55] ppcls INFO: [Train][Epoch 32/300][Avg]top1: 0.84326, CELoss: 0.44311, loss: 0.44311
[2022/06/18 22:22:55] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:23:01] ppcls INFO: [Train][Epoch 33/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08749512, top1: 0.87500, CELoss: 0.49864, loss: 0.49864, batch_cost: 0.59956s, reader_cost: 0.04438, ips: 106.74527 samples/s, eta: 7:37:56
[2022/06/18 22:23:09] ppcls INFO: [Train][Epoch 33/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08748605, top1: 0.83097, CELoss: 0.46713, loss: 0.46713, batch_cost: 0.69503s, reader_cost: 0.02010, ips: 92.08297 samples/s, eta: 8:50:44
[2022/06/18 22:23:15] ppcls INFO: [Train][Epoch 33/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08747696, top1: 0.84152, CELoss: 0.43528, loss: 0.43528, batch_cost: 0.65515s, reader_cost: 0.01613, ips: 97.68784 samples/s, eta: 8:20:11
[2022/06/18 22:23:22] ppcls INFO: [Train][Epoch 33/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08746785, top1: 0.84476, CELoss: 0.43592, loss: 0.43592, batch_cost: 0.65680s, reader_cost: 0.02523, ips: 97.44221 samples/s, eta: 8:21:20
[2022/06/18 22:23:27] ppcls INFO: [Train][Epoch 33/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08745873, top1: 0.84337, CELoss: 0.44382, loss: 0.44382, batch_cost: 0.62695s, reader_cost: 0.02017, ips: 102.08190 samples/s, eta: 7:58:26
[2022/06/18 22:23:33] ppcls INFO: [Train][Epoch 33/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08744959, top1: 0.84436, CELoss: 0.44560, loss: 0.44560, batch_cost: 0.61417s, reader_cost: 0.01929, ips: 104.20525 samples/s, eta: 7:48:35
[2022/06/18 22:23:39] ppcls INFO: [Train][Epoch 33/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08744044, top1: 0.84426, CELoss: 0.44293, loss: 0.44293, batch_cost: 0.61189s, reader_cost: 0.01976, ips: 104.59335 samples/s, eta: 7:46:45
[2022/06/18 22:23:46] ppcls INFO: [Train][Epoch 33/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08743127, top1: 0.84617, CELoss: 0.43914, loss: 0.43914, batch_cost: 0.62192s, reader_cost: 0.01807, ips: 102.90722 samples/s, eta: 7:54:17
[2022/06/18 22:23:53] ppcls INFO: [Train][Epoch 33/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08742209, top1: 0.84471, CELoss: 0.44433, loss: 0.44433, batch_cost: 0.63362s, reader_cost: 0.01688, ips: 101.00666 samples/s, eta: 8:03:06
[2022/06/18 22:23:58] ppcls INFO: [Train][Epoch 33/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08741288, top1: 0.84306, CELoss: 0.44740, loss: 0.44740, batch_cost: 0.61691s, reader_cost: 0.01579, ips: 103.74303 samples/s, eta: 7:50:16
[2022/06/18 22:24:03] ppcls INFO: [Train][Epoch 33/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08740367, top1: 0.84298, CELoss: 0.44794, loss: 0.44794, batch_cost: 0.60810s, reader_cost: 0.01488, ips: 105.24605 samples/s, eta: 7:43:27
[2022/06/18 22:24:09] ppcls INFO: [Train][Epoch 33/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08739443, top1: 0.84319, CELoss: 0.44824, loss: 0.44824, batch_cost: 0.61217s, reader_cost: 0.01519, ips: 104.54645 samples/s, eta: 7:46:27
[2022/06/18 22:24:15] ppcls INFO: [Train][Epoch 33/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08738519, top1: 0.84517, CELoss: 0.44391, loss: 0.44391, batch_cost: 0.61034s, reader_cost: 0.01568, ips: 104.85929 samples/s, eta: 7:44:57
[2022/06/18 22:24:21] ppcls INFO: [Train][Epoch 33/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08737592, top1: 0.84375, CELoss: 0.44483, loss: 0.44483, batch_cost: 0.61023s, reader_cost: 0.01561, ips: 104.87766 samples/s, eta: 7:44:46
[2022/06/18 22:24:28] ppcls INFO: [Train][Epoch 33/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08736664, top1: 0.84331, CELoss: 0.44469, loss: 0.44469, batch_cost: 0.61182s, reader_cost: 0.01504, ips: 104.60519 samples/s, eta: 7:45:53
[2022/06/18 22:24:34] ppcls INFO: [Train][Epoch 33/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08735734, top1: 0.84458, CELoss: 0.44423, loss: 0.44423, batch_cost: 0.60955s, reader_cost: 0.01469, ips: 104.99548 samples/s, eta: 7:44:03
[2022/06/18 22:24:38] ppcls INFO: [Train][Epoch 33/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08734803, top1: 0.84472, CELoss: 0.44503, loss: 0.44503, batch_cost: 0.60142s, reader_cost: 0.01391, ips: 106.41443 samples/s, eta: 7:37:45
[2022/06/18 22:24:40] ppcls INFO: [Train][Epoch 33/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08733870, top1: 0.84482, CELoss: 0.44388, loss: 0.44388, batch_cost: 0.57751s, reader_cost: 0.01310, ips: 84.84659 samples/s, eta: 7:19:28
[2022/06/18 22:24:41] ppcls INFO: [Train][Epoch 33/300][Avg]top1: 0.84482, CELoss: 0.44388, loss: 0.44388
[2022/06/18 22:24:41] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:24:47] ppcls INFO: [Train][Epoch 34/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08733777, top1: 0.85938, CELoss: 0.38087, loss: 0.38087, batch_cost: 0.61257s, reader_cost: 0.04312, ips: 104.47824 samples/s, eta: 7:46:08
[2022/06/18 22:24:56] ppcls INFO: [Train][Epoch 34/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08732842, top1: 0.84375, CELoss: 0.41486, loss: 0.41486, batch_cost: 0.94588s, reader_cost: 0.14751, ips: 67.66188 samples/s, eta: 11:59:36
[2022/06/18 22:25:01] ppcls INFO: [Train][Epoch 34/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08731906, top1: 0.84152, CELoss: 0.42834, loss: 0.42834, batch_cost: 0.72399s, reader_cost: 0.06619, ips: 88.39903 samples/s, eta: 9:10:40
[2022/06/18 22:25:07] ppcls INFO: [Train][Epoch 34/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08730968, top1: 0.85081, CELoss: 0.41727, loss: 0.41727, batch_cost: 0.67337s, reader_cost: 0.04600, ips: 95.04470 samples/s, eta: 8:32:03
[2022/06/18 22:25:14] ppcls INFO: [Train][Epoch 34/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08730029, top1: 0.84604, CELoss: 0.42511, loss: 0.42511, batch_cost: 0.66109s, reader_cost: 0.04089, ips: 96.80952 samples/s, eta: 8:22:37
[2022/06/18 22:25:20] ppcls INFO: [Train][Epoch 34/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08729088, top1: 0.85294, CELoss: 0.41943, loss: 0.41943, batch_cost: 0.65453s, reader_cost: 0.03671, ips: 97.77936 samples/s, eta: 8:17:31
[2022/06/18 22:25:26] ppcls INFO: [Train][Epoch 34/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08728145, top1: 0.85297, CELoss: 0.42196, loss: 0.42196, batch_cost: 0.64274s, reader_cost: 0.03313, ips: 99.57349 samples/s, eta: 8:08:27
[2022/06/18 22:25:31] ppcls INFO: [Train][Epoch 34/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08727201, top1: 0.85211, CELoss: 0.41978, loss: 0.41978, batch_cost: 0.62568s, reader_cost: 0.03041, ips: 102.28809 samples/s, eta: 7:55:23
[2022/06/18 22:25:39] ppcls INFO: [Train][Epoch 34/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08726256, top1: 0.85185, CELoss: 0.41928, loss: 0.41928, batch_cost: 0.63859s, reader_cost: 0.02807, ips: 100.22113 samples/s, eta: 8:05:04
[2022/06/18 22:25:44] ppcls INFO: [Train][Epoch 34/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08725308, top1: 0.85234, CELoss: 0.41805, loss: 0.41805, batch_cost: 0.62677s, reader_cost: 0.02616, ips: 102.11019 samples/s, eta: 7:56:00
[2022/06/18 22:25:50] ppcls INFO: [Train][Epoch 34/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08724359, top1: 0.85087, CELoss: 0.42138, loss: 0.42138, batch_cost: 0.62526s, reader_cost: 0.02517, ips: 102.35664 samples/s, eta: 7:54:45
[2022/06/18 22:25:56] ppcls INFO: [Train][Epoch 34/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08723409, top1: 0.85051, CELoss: 0.42129, loss: 0.42129, batch_cost: 0.62316s, reader_cost: 0.02429, ips: 102.70218 samples/s, eta: 7:53:03
[2022/06/18 22:26:03] ppcls INFO: [Train][Epoch 34/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08722457, top1: 0.85124, CELoss: 0.41945, loss: 0.41945, batch_cost: 0.62786s, reader_cost: 0.02328, ips: 101.93420 samples/s, eta: 7:56:30
[2022/06/18 22:26:08] ppcls INFO: [Train][Epoch 34/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08721503, top1: 0.85079, CELoss: 0.42074, loss: 0.42074, batch_cost: 0.62177s, reader_cost: 0.02198, ips: 102.93243 samples/s, eta: 7:51:47
[2022/06/18 22:26:15] ppcls INFO: [Train][Epoch 34/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08720548, top1: 0.85073, CELoss: 0.41927, loss: 0.41927, batch_cost: 0.62230s, reader_cost: 0.02211, ips: 102.84492 samples/s, eta: 7:52:05
[2022/06/18 22:26:21] ppcls INFO: [Train][Epoch 34/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08719591, top1: 0.85027, CELoss: 0.42162, loss: 0.42162, batch_cost: 0.62153s, reader_cost: 0.02202, ips: 102.97237 samples/s, eta: 7:51:23
[2022/06/18 22:26:26] ppcls INFO: [Train][Epoch 34/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08718633, top1: 0.84928, CELoss: 0.42351, loss: 0.42351, batch_cost: 0.61402s, reader_cost: 0.02143, ips: 104.23099 samples/s, eta: 7:45:36
[2022/06/18 22:26:28] ppcls INFO: [Train][Epoch 34/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08717673, top1: 0.84976, CELoss: 0.42088, loss: 0.42088, batch_cost: 0.58994s, reader_cost: 0.02018, ips: 83.05929 samples/s, eta: 7:27:14
[2022/06/18 22:26:28] ppcls INFO: [Train][Epoch 34/300][Avg]top1: 0.84976, CELoss: 0.42088, loss: 0.42088
[2022/06/18 22:26:29] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:26:36] ppcls INFO: [Train][Epoch 35/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08717577, top1: 0.76562, CELoss: 0.53959, loss: 0.53959, batch_cost: 0.63094s, reader_cost: 0.05447, ips: 101.43552 samples/s, eta: 7:58:19
[2022/06/18 22:26:41] ppcls INFO: [Train][Epoch 35/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08716615, top1: 0.84233, CELoss: 0.41919, loss: 0.41919, batch_cost: 0.48666s, reader_cost: 0.03169, ips: 131.50947 samples/s, eta: 6:08:51
[2022/06/18 22:26:48] ppcls INFO: [Train][Epoch 35/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08715652, top1: 0.85193, CELoss: 0.41381, loss: 0.41381, batch_cost: 0.60820s, reader_cost: 0.02745, ips: 105.22825 samples/s, eta: 7:40:52
[2022/06/18 22:26:54] ppcls INFO: [Train][Epoch 35/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08714687, top1: 0.85786, CELoss: 0.40386, loss: 0.40386, batch_cost: 0.62303s, reader_cost: 0.02596, ips: 102.72401 samples/s, eta: 7:52:00
[2022/06/18 22:27:02] ppcls INFO: [Train][Epoch 35/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08713721, top1: 0.85556, CELoss: 0.40608, loss: 0.40608, batch_cost: 0.65279s, reader_cost: 0.02678, ips: 98.04077 samples/s, eta: 8:14:26
[2022/06/18 22:27:07] ppcls INFO: [Train][Epoch 35/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08712753, top1: 0.85815, CELoss: 0.40136, loss: 0.40136, batch_cost: 0.62005s, reader_cost: 0.02534, ips: 103.21690 samples/s, eta: 7:49:32
[2022/06/18 22:27:13] ppcls INFO: [Train][Epoch 35/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08711783, top1: 0.85605, CELoss: 0.40577, loss: 0.40577, batch_cost: 0.61479s, reader_cost: 0.02215, ips: 104.10018 samples/s, eta: 7:45:27
[2022/06/18 22:27:18] ppcls INFO: [Train][Epoch 35/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08710812, top1: 0.85805, CELoss: 0.39993, loss: 0.39993, batch_cost: 0.60474s, reader_cost: 0.02356, ips: 105.83121 samples/s, eta: 7:37:44
[2022/06/18 22:27:24] ppcls INFO: [Train][Epoch 35/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08709839, top1: 0.85802, CELoss: 0.40685, loss: 0.40685, batch_cost: 0.60034s, reader_cost: 0.02397, ips: 106.60656 samples/s, eta: 7:34:18
[2022/06/18 22:27:30] ppcls INFO: [Train][Epoch 35/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08708865, top1: 0.85731, CELoss: 0.40963, loss: 0.40963, batch_cost: 0.60946s, reader_cost: 0.02512, ips: 105.01060 samples/s, eta: 7:41:07
[2022/06/18 22:27:36] ppcls INFO: [Train][Epoch 35/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08707889, top1: 0.85396, CELoss: 0.41942, loss: 0.41942, batch_cost: 0.60525s, reader_cost: 0.02349, ips: 105.74162 samples/s, eta: 7:37:49
[2022/06/18 22:27:41] ppcls INFO: [Train][Epoch 35/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08706911, top1: 0.85459, CELoss: 0.41747, loss: 0.41747, batch_cost: 0.59435s, reader_cost: 0.02271, ips: 107.68130 samples/s, eta: 7:29:29
[2022/06/18 22:27:47] ppcls INFO: [Train][Epoch 35/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08705932, top1: 0.85537, CELoss: 0.41756, loss: 0.41756, batch_cost: 0.59391s, reader_cost: 0.02239, ips: 107.76067 samples/s, eta: 7:29:03
[2022/06/18 22:27:54] ppcls INFO: [Train][Epoch 35/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08704952, top1: 0.85520, CELoss: 0.41677, loss: 0.41677, batch_cost: 0.60623s, reader_cost: 0.02112, ips: 105.57084 samples/s, eta: 7:38:16
[2022/06/18 22:27:59] ppcls INFO: [Train][Epoch 35/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08703969, top1: 0.85461, CELoss: 0.41756, loss: 0.41756, batch_cost: 0.59397s, reader_cost: 0.01969, ips: 107.74980 samples/s, eta: 7:28:54
[2022/06/18 22:28:04] ppcls INFO: [Train][Epoch 35/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08702986, top1: 0.85524, CELoss: 0.41696, loss: 0.41696, batch_cost: 0.58771s, reader_cost: 0.01913, ips: 108.89717 samples/s, eta: 7:24:04
[2022/06/18 22:28:09] ppcls INFO: [Train][Epoch 35/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08702000, top1: 0.85413, CELoss: 0.42142, loss: 0.42142, batch_cost: 0.58391s, reader_cost: 0.01807, ips: 109.60678 samples/s, eta: 7:21:06
[2022/06/18 22:28:13] ppcls INFO: [Train][Epoch 35/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08701013, top1: 0.85333, CELoss: 0.42309, loss: 0.42309, batch_cost: 0.57422s, reader_cost: 0.01710, ips: 85.33290 samples/s, eta: 7:13:41
[2022/06/18 22:28:14] ppcls INFO: [Train][Epoch 35/300][Avg]top1: 0.85333, CELoss: 0.42309, loss: 0.42309
[2022/06/18 22:28:21] ppcls INFO: [Eval][Epoch 35][Iter: 0/16]CELoss: 0.90907, loss: 0.90907, top1: 0.71680, batch_cost: 6.87281s, reader_cost: 3.81532, ips: 9.31206 images/sec
[2022/06/18 22:28:29] ppcls INFO: [Eval][Epoch 35][Iter: 10/16]CELoss: 0.69239, loss: 0.69239, top1: 0.72994, batch_cost: 0.58755s, reader_cost: 0.00409, ips: 108.92768 images/sec
[2022/06/18 22:28:30] ppcls INFO: [Eval][Epoch 35][Avg]CELoss: 0.72591, loss: 0.72591, top1: 0.74142
[2022/06/18 22:28:30] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 22:28:30] ppcls INFO: [Eval][Epoch 35][best metric: 0.741421639919281]
[2022/06/18 22:28:31] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:28:37] ppcls INFO: [Train][Epoch 36/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08700914, top1: 0.84375, CELoss: 0.48236, loss: 0.48236, batch_cost: 0.60910s, reader_cost: 0.04088, ips: 105.07345 samples/s, eta: 7:40:01
[2022/06/18 22:28:43] ppcls INFO: [Train][Epoch 36/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08699926, top1: 0.85795, CELoss: 0.40603, loss: 0.40603, batch_cost: 0.55043s, reader_cost: 0.01807, ips: 116.27374 samples/s, eta: 6:55:37
[2022/06/18 22:28:49] ppcls INFO: [Train][Epoch 36/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08698935, top1: 0.85640, CELoss: 0.42041, loss: 0.42041, batch_cost: 0.59971s, reader_cost: 0.09481, ips: 106.71886 samples/s, eta: 7:32:43
[2022/06/18 22:28:57] ppcls INFO: [Train][Epoch 36/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08697944, top1: 0.84476, CELoss: 0.43875, loss: 0.43875, batch_cost: 0.65387s, reader_cost: 0.17702, ips: 97.87934 samples/s, eta: 8:13:30
[2022/06/18 22:29:03] ppcls INFO: [Train][Epoch 36/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08696950, top1: 0.84337, CELoss: 0.44271, loss: 0.44271, batch_cost: 0.63061s, reader_cost: 0.13666, ips: 101.48890 samples/s, eta: 7:55:50
[2022/06/18 22:29:09] ppcls INFO: [Train][Epoch 36/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08695955, top1: 0.84406, CELoss: 0.43940, loss: 0.43940, batch_cost: 0.62380s, reader_cost: 0.12608, ips: 102.59649 samples/s, eta: 7:50:36
[2022/06/18 22:29:15] ppcls INFO: [Train][Epoch 36/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08694959, top1: 0.84580, CELoss: 0.44051, loss: 0.44051, batch_cost: 0.62511s, reader_cost: 0.11576, ips: 102.38227 samples/s, eta: 7:51:29
[2022/06/18 22:29:21] ppcls INFO: [Train][Epoch 36/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08693961, top1: 0.84177, CELoss: 0.44890, loss: 0.44890, batch_cost: 0.62482s, reader_cost: 0.11285, ips: 102.42933 samples/s, eta: 7:51:10
[2022/06/18 22:29:27] ppcls INFO: [Train][Epoch 36/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08692961, top1: 0.84356, CELoss: 0.44655, loss: 0.44655, batch_cost: 0.61888s, reader_cost: 0.10644, ips: 103.41330 samples/s, eta: 7:46:34
[2022/06/18 22:29:33] ppcls INFO: [Train][Epoch 36/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08691960, top1: 0.84341, CELoss: 0.44905, loss: 0.44905, batch_cost: 0.62237s, reader_cost: 0.10489, ips: 102.83306 samples/s, eta: 7:49:06
[2022/06/18 22:29:40] ppcls INFO: [Train][Epoch 36/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08690957, top1: 0.84421, CELoss: 0.44800, loss: 0.44800, batch_cost: 0.62950s, reader_cost: 0.10340, ips: 101.66757 samples/s, eta: 7:54:22
[2022/06/18 22:29:46] ppcls INFO: [Train][Epoch 36/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08689952, top1: 0.84445, CELoss: 0.44984, loss: 0.44984, batch_cost: 0.61888s, reader_cost: 0.09381, ips: 103.41204 samples/s, eta: 7:46:16
[2022/06/18 22:29:52] ppcls INFO: [Train][Epoch 36/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08688946, top1: 0.84452, CELoss: 0.44662, loss: 0.44662, batch_cost: 0.61986s, reader_cost: 0.08588, ips: 103.24865 samples/s, eta: 7:46:54
[2022/06/18 22:29:58] ppcls INFO: [Train][Epoch 36/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08687939, top1: 0.84411, CELoss: 0.44820, loss: 0.44820, batch_cost: 0.61987s, reader_cost: 0.07973, ips: 103.24670 samples/s, eta: 7:46:49
[2022/06/18 22:30:05] ppcls INFO: [Train][Epoch 36/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08686930, top1: 0.84508, CELoss: 0.44443, loss: 0.44443, batch_cost: 0.62215s, reader_cost: 0.07466, ips: 102.86961 samples/s, eta: 7:48:25
[2022/06/18 22:30:11] ppcls INFO: [Train][Epoch 36/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08685919, top1: 0.84530, CELoss: 0.44517, loss: 0.44517, batch_cost: 0.62415s, reader_cost: 0.07031, ips: 102.53931 samples/s, eta: 7:49:49
[2022/06/18 22:30:16] ppcls INFO: [Train][Epoch 36/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08684907, top1: 0.84666, CELoss: 0.43957, loss: 0.43957, batch_cost: 0.61530s, reader_cost: 0.06636, ips: 104.01462 samples/s, eta: 7:43:03
[2022/06/18 22:30:18] ppcls INFO: [Train][Epoch 36/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08683893, top1: 0.84646, CELoss: 0.43872, loss: 0.43872, batch_cost: 0.59093s, reader_cost: 0.06240, ips: 82.91985 samples/s, eta: 7:24:37
[2022/06/18 22:30:19] ppcls INFO: [Train][Epoch 36/300][Avg]top1: 0.84646, CELoss: 0.43872, loss: 0.43872
[2022/06/18 22:30:19] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:30:26] ppcls INFO: [Train][Epoch 37/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08683791, top1: 0.79688, CELoss: 0.58583, loss: 0.58583, batch_cost: 0.62847s, reader_cost: 0.08865, ips: 101.83424 samples/s, eta: 7:52:51
[2022/06/18 22:30:32] ppcls INFO: [Train][Epoch 37/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08682776, top1: 0.84091, CELoss: 0.44409, loss: 0.44409, batch_cost: 0.63233s, reader_cost: 0.01720, ips: 101.21352 samples/s, eta: 7:55:39
[2022/06/18 22:30:39] ppcls INFO: [Train][Epoch 37/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08681759, top1: 0.84449, CELoss: 0.43690, loss: 0.43690, batch_cost: 0.67471s, reader_cost: 0.01339, ips: 94.85570 samples/s, eta: 8:27:25
[2022/06/18 22:30:45] ppcls INFO: [Train][Epoch 37/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08680740, top1: 0.84526, CELoss: 0.43265, loss: 0.43265, batch_cost: 0.63845s, reader_cost: 0.01234, ips: 100.24264 samples/s, eta: 8:00:03
[2022/06/18 22:30:51] ppcls INFO: [Train][Epoch 37/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08679720, top1: 0.84451, CELoss: 0.43302, loss: 0.43302, batch_cost: 0.62825s, reader_cost: 0.01077, ips: 101.87032 samples/s, eta: 7:52:16
[2022/06/18 22:30:57] ppcls INFO: [Train][Epoch 37/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08678698, top1: 0.84589, CELoss: 0.42885, loss: 0.42885, batch_cost: 0.61562s, reader_cost: 0.01261, ips: 103.96080 samples/s, eta: 7:42:40
[2022/06/18 22:31:02] ppcls INFO: [Train][Epoch 37/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08677674, top1: 0.84810, CELoss: 0.42485, loss: 0.42485, batch_cost: 0.60384s, reader_cost: 0.01381, ips: 105.98883 samples/s, eta: 7:33:43
[2022/06/18 22:31:08] ppcls INFO: [Train][Epoch 37/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08676649, top1: 0.84617, CELoss: 0.43008, loss: 0.43008, batch_cost: 0.61037s, reader_cost: 0.02590, ips: 104.85466 samples/s, eta: 7:38:31
[2022/06/18 22:31:15] ppcls INFO: [Train][Epoch 37/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08675623, top1: 0.84452, CELoss: 0.43589, loss: 0.43589, batch_cost: 0.61853s, reader_cost: 0.03378, ips: 103.47172 samples/s, eta: 7:44:33
[2022/06/18 22:31:21] ppcls INFO: [Train][Epoch 37/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08674595, top1: 0.84392, CELoss: 0.43742, loss: 0.43742, batch_cost: 0.61154s, reader_cost: 0.03809, ips: 104.65398 samples/s, eta: 7:39:12
[2022/06/18 22:31:26] ppcls INFO: [Train][Epoch 37/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08673565, top1: 0.84545, CELoss: 0.43584, loss: 0.43584, batch_cost: 0.60490s, reader_cost: 0.03517, ips: 105.80192 samples/s, eta: 7:34:07
[2022/06/18 22:31:32] ppcls INFO: [Train][Epoch 37/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08672534, top1: 0.84558, CELoss: 0.43815, loss: 0.43815, batch_cost: 0.60275s, reader_cost: 0.03279, ips: 106.18063 samples/s, eta: 7:32:24
[2022/06/18 22:31:39] ppcls INFO: [Train][Epoch 37/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08671501, top1: 0.84672, CELoss: 0.43672, loss: 0.43672, batch_cost: 0.61104s, reader_cost: 0.03259, ips: 104.73902 samples/s, eta: 7:38:31
[2022/06/18 22:31:44] ppcls INFO: [Train][Epoch 37/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08670467, top1: 0.84649, CELoss: 0.43798, loss: 0.43798, batch_cost: 0.60292s, reader_cost: 0.03060, ips: 106.15048 samples/s, eta: 7:32:19
[2022/06/18 22:31:50] ppcls INFO: [Train][Epoch 37/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08669431, top1: 0.84741, CELoss: 0.43513, loss: 0.43513, batch_cost: 0.59844s, reader_cost: 0.02935, ips: 106.94488 samples/s, eta: 7:28:52
[2022/06/18 22:31:56] ppcls INFO: [Train][Epoch 37/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08668393, top1: 0.84789, CELoss: 0.43308, loss: 0.43308, batch_cost: 0.60463s, reader_cost: 0.02774, ips: 105.85023 samples/s, eta: 7:33:24
[2022/06/18 22:32:02] ppcls INFO: [Train][Epoch 37/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08667354, top1: 0.84753, CELoss: 0.43546, loss: 0.43546, batch_cost: 0.60135s, reader_cost: 0.02716, ips: 106.42700 samples/s, eta: 7:30:51
[2022/06/18 22:32:04] ppcls INFO: [Train][Epoch 37/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08666314, top1: 0.84820, CELoss: 0.43495, loss: 0.43495, batch_cost: 0.57765s, reader_cost: 0.02553, ips: 84.82589 samples/s, eta: 7:12:59
[2022/06/18 22:32:05] ppcls INFO: [Train][Epoch 37/300][Avg]top1: 0.84820, CELoss: 0.43495, loss: 0.43495
[2022/06/18 22:32:05] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:32:11] ppcls INFO: [Train][Epoch 38/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08666209, top1: 0.87500, CELoss: 0.33708, loss: 0.33708, batch_cost: 0.61032s, reader_cost: 0.05073, ips: 104.86321 samples/s, eta: 7:37:27
[2022/06/18 22:32:17] ppcls INFO: [Train][Epoch 38/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08665167, top1: 0.86790, CELoss: 0.38547, loss: 0.38547, batch_cost: 0.65320s, reader_cost: 0.01798, ips: 97.97954 samples/s, eta: 8:09:29
[2022/06/18 22:32:24] ppcls INFO: [Train][Epoch 38/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08664123, top1: 0.87202, CELoss: 0.39002, loss: 0.39002, batch_cost: 0.65103s, reader_cost: 0.05695, ips: 98.30625 samples/s, eta: 8:07:45
[2022/06/18 22:32:30] ppcls INFO: [Train][Epoch 38/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08663078, top1: 0.86542, CELoss: 0.41032, loss: 0.41032, batch_cost: 0.64675s, reader_cost: 0.05490, ips: 98.95691 samples/s, eta: 8:04:26
[2022/06/18 22:32:36] ppcls INFO: [Train][Epoch 38/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08662031, top1: 0.86700, CELoss: 0.40136, loss: 0.40136, batch_cost: 0.62086s, reader_cost: 0.04323, ips: 103.08291 samples/s, eta: 7:44:57
[2022/06/18 22:32:42] ppcls INFO: [Train][Epoch 38/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08660982, top1: 0.86520, CELoss: 0.39719, loss: 0.39719, batch_cost: 0.60950s, reader_cost: 0.03809, ips: 105.00352 samples/s, eta: 7:36:20
[2022/06/18 22:32:48] ppcls INFO: [Train][Epoch 38/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08659932, top1: 0.86245, CELoss: 0.40524, loss: 0.40524, batch_cost: 0.60809s, reader_cost: 0.05965, ips: 105.24754 samples/s, eta: 7:35:11
[2022/06/18 22:32:53] ppcls INFO: [Train][Epoch 38/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08658880, top1: 0.85695, CELoss: 0.41315, loss: 0.41315, batch_cost: 0.59737s, reader_cost: 0.05227, ips: 107.13590 samples/s, eta: 7:27:03
[2022/06/18 22:32:59] ppcls INFO: [Train][Epoch 38/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08657827, top1: 0.85648, CELoss: 0.41547, loss: 0.41547, batch_cost: 0.59359s, reader_cost: 0.04692, ips: 107.81773 samples/s, eta: 7:24:08
[2022/06/18 22:33:06] ppcls INFO: [Train][Epoch 38/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08656772, top1: 0.85680, CELoss: 0.41327, loss: 0.41327, batch_cost: 0.60966s, reader_cost: 0.06997, ips: 104.97604 samples/s, eta: 7:36:03
[2022/06/18 22:33:11] ppcls INFO: [Train][Epoch 38/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08655716, top1: 0.85829, CELoss: 0.41038, loss: 0.41038, batch_cost: 0.60140s, reader_cost: 0.06819, ips: 106.41750 samples/s, eta: 7:29:46
[2022/06/18 22:33:18] ppcls INFO: [Train][Epoch 38/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08654658, top1: 0.85881, CELoss: 0.41061, loss: 0.41061, batch_cost: 0.60874s, reader_cost: 0.08097, ips: 105.13492 samples/s, eta: 7:35:09
[2022/06/18 22:33:24] ppcls INFO: [Train][Epoch 38/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08653598, top1: 0.85808, CELoss: 0.41271, loss: 0.41271, batch_cost: 0.60631s, reader_cost: 0.07812, ips: 105.55591 samples/s, eta: 7:33:14
[2022/06/18 22:33:30] ppcls INFO: [Train][Epoch 38/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08652537, top1: 0.85794, CELoss: 0.41611, loss: 0.41611, batch_cost: 0.60970s, reader_cost: 0.08388, ips: 104.96905 samples/s, eta: 7:35:40
[2022/06/18 22:33:36] ppcls INFO: [Train][Epoch 38/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08651475, top1: 0.86026, CELoss: 0.41144, loss: 0.41144, batch_cost: 0.60664s, reader_cost: 0.08180, ips: 105.49921 samples/s, eta: 7:33:17
[2022/06/18 22:33:42] ppcls INFO: [Train][Epoch 38/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08650410, top1: 0.86010, CELoss: 0.41161, loss: 0.41161, batch_cost: 0.60495s, reader_cost: 0.08307, ips: 105.79421 samples/s, eta: 7:31:55
[2022/06/18 22:33:47] ppcls INFO: [Train][Epoch 38/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08649345, top1: 0.85811, CELoss: 0.41601, loss: 0.41601, batch_cost: 0.60068s, reader_cost: 0.08743, ips: 106.54613 samples/s, eta: 7:28:38
[2022/06/18 22:33:49] ppcls INFO: [Train][Epoch 38/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08648277, top1: 0.85790, CELoss: 0.41582, loss: 0.41582, batch_cost: 0.57693s, reader_cost: 0.08219, ips: 84.93302 samples/s, eta: 7:10:47
[2022/06/18 22:33:50] ppcls INFO: [Train][Epoch 38/300][Avg]top1: 0.85790, CELoss: 0.41582, loss: 0.41582
[2022/06/18 22:33:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:33:56] ppcls INFO: [Train][Epoch 39/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08648171, top1: 0.87500, CELoss: 0.25153, loss: 0.25153, batch_cost: 0.60832s, reader_cost: 0.10997, ips: 105.20743 samples/s, eta: 7:34:14
[2022/06/18 22:34:03] ppcls INFO: [Train][Epoch 39/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08647102, top1: 0.86648, CELoss: 0.40468, loss: 0.40468, batch_cost: 0.60337s, reader_cost: 0.02963, ips: 106.07127 samples/s, eta: 7:30:26
[2022/06/18 22:34:09] ppcls INFO: [Train][Epoch 39/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08646031, top1: 0.86235, CELoss: 0.40281, loss: 0.40281, batch_cost: 0.60032s, reader_cost: 0.01987, ips: 106.60993 samples/s, eta: 7:28:03
[2022/06/18 22:34:15] ppcls INFO: [Train][Epoch 39/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08644959, top1: 0.86391, CELoss: 0.39969, loss: 0.39969, batch_cost: 0.61611s, reader_cost: 0.01791, ips: 103.87763 samples/s, eta: 7:39:44
[2022/06/18 22:34:21] ppcls INFO: [Train][Epoch 39/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08643885, top1: 0.86852, CELoss: 0.38423, loss: 0.38423, batch_cost: 0.60559s, reader_cost: 0.02048, ips: 105.68127 samples/s, eta: 7:31:47
[2022/06/18 22:34:27] ppcls INFO: [Train][Epoch 39/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08642810, top1: 0.85968, CELoss: 0.40415, loss: 0.40415, batch_cost: 0.61063s, reader_cost: 0.01705, ips: 104.80987 samples/s, eta: 7:35:26
[2022/06/18 22:34:33] ppcls INFO: [Train][Epoch 39/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08641733, top1: 0.85528, CELoss: 0.40940, loss: 0.40940, batch_cost: 0.61228s, reader_cost: 0.03900, ips: 104.52688 samples/s, eta: 7:36:34
[2022/06/18 22:34:40] ppcls INFO: [Train][Epoch 39/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08640655, top1: 0.86092, CELoss: 0.40070, loss: 0.40070, batch_cost: 0.61399s, reader_cost: 0.03809, ips: 104.23542 samples/s, eta: 7:37:45
[2022/06/18 22:34:46] ppcls INFO: [Train][Epoch 39/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08639575, top1: 0.85725, CELoss: 0.40739, loss: 0.40739, batch_cost: 0.61308s, reader_cost: 0.04105, ips: 104.39172 samples/s, eta: 7:36:57
[2022/06/18 22:34:52] ppcls INFO: [Train][Epoch 39/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08638494, top1: 0.85354, CELoss: 0.41523, loss: 0.41523, batch_cost: 0.61261s, reader_cost: 0.03769, ips: 104.47162 samples/s, eta: 7:36:30
[2022/06/18 22:34:58] ppcls INFO: [Train][Epoch 39/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08637411, top1: 0.85257, CELoss: 0.42025, loss: 0.42025, batch_cost: 0.61464s, reader_cost: 0.03477, ips: 104.12632 samples/s, eta: 7:37:55
[2022/06/18 22:35:05] ppcls INFO: [Train][Epoch 39/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08636326, top1: 0.85318, CELoss: 0.41778, loss: 0.41778, batch_cost: 0.61960s, reader_cost: 0.04229, ips: 103.29240 samples/s, eta: 7:41:31
[2022/06/18 22:35:11] ppcls INFO: [Train][Epoch 39/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08635240, top1: 0.85498, CELoss: 0.41531, loss: 0.41531, batch_cost: 0.62138s, reader_cost: 0.04592, ips: 102.99658 samples/s, eta: 7:42:44
[2022/06/18 22:35:18] ppcls INFO: [Train][Epoch 39/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08634152, top1: 0.85544, CELoss: 0.41473, loss: 0.41473, batch_cost: 0.62366s, reader_cost: 0.04277, ips: 102.62069 samples/s, eta: 7:44:19
[2022/06/18 22:35:23] ppcls INFO: [Train][Epoch 39/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08633063, top1: 0.85395, CELoss: 0.41898, loss: 0.41898, batch_cost: 0.61840s, reader_cost: 0.04104, ips: 103.49359 samples/s, eta: 7:40:18
[2022/06/18 22:35:29] ppcls INFO: [Train][Epoch 39/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08631972, top1: 0.85358, CELoss: 0.41842, loss: 0.41842, batch_cost: 0.61635s, reader_cost: 0.03872, ips: 103.83780 samples/s, eta: 7:38:41
[2022/06/18 22:35:34] ppcls INFO: [Train][Epoch 39/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08630880, top1: 0.85287, CELoss: 0.42042, loss: 0.42042, batch_cost: 0.60830s, reader_cost: 0.03699, ips: 105.21139 samples/s, eta: 7:32:35
[2022/06/18 22:35:37] ppcls INFO: [Train][Epoch 39/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08629786, top1: 0.85333, CELoss: 0.41950, loss: 0.41950, batch_cost: 0.58805s, reader_cost: 0.03481, ips: 83.32615 samples/s, eta: 7:17:25
[2022/06/18 22:35:37] ppcls INFO: [Train][Epoch 39/300][Avg]top1: 0.85333, CELoss: 0.41950, loss: 0.41950
[2022/06/18 22:35:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:35:44] ppcls INFO: [Train][Epoch 40/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08629677, top1: 0.90625, CELoss: 0.24871, loss: 0.24871, batch_cost: 0.62490s, reader_cost: 0.07138, ips: 102.41578 samples/s, eta: 7:44:50
[2022/06/18 22:35:50] ppcls INFO: [Train][Epoch 40/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08628581, top1: 0.87358, CELoss: 0.38964, loss: 0.38964, batch_cost: 0.63003s, reader_cost: 0.00418, ips: 101.58327 samples/s, eta: 7:48:32
[2022/06/18 22:35:56] ppcls INFO: [Train][Epoch 40/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08627484, top1: 0.86607, CELoss: 0.40786, loss: 0.40786, batch_cost: 0.61821s, reader_cost: 0.00818, ips: 103.52518 samples/s, eta: 7:39:38
[2022/06/18 22:36:02] ppcls INFO: [Train][Epoch 40/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08626386, top1: 0.87248, CELoss: 0.39879, loss: 0.39879, batch_cost: 0.60360s, reader_cost: 0.00652, ips: 106.02961 samples/s, eta: 7:28:41
[2022/06/18 22:36:09] ppcls INFO: [Train][Epoch 40/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08625285, top1: 0.87081, CELoss: 0.39254, loss: 0.39254, batch_cost: 0.61413s, reader_cost: 0.00793, ips: 104.21195 samples/s, eta: 7:36:24
[2022/06/18 22:36:15] ppcls INFO: [Train][Epoch 40/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08624184, top1: 0.86703, CELoss: 0.39771, loss: 0.39771, batch_cost: 0.62998s, reader_cost: 0.00975, ips: 101.59010 samples/s, eta: 7:48:05
[2022/06/18 22:36:22] ppcls INFO: [Train][Epoch 40/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08623080, top1: 0.86501, CELoss: 0.40153, loss: 0.40153, batch_cost: 0.62982s, reader_cost: 0.01012, ips: 101.61665 samples/s, eta: 7:47:51
[2022/06/18 22:36:27] ppcls INFO: [Train][Epoch 40/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08621976, top1: 0.86268, CELoss: 0.40475, loss: 0.40475, batch_cost: 0.62238s, reader_cost: 0.01107, ips: 102.83028 samples/s, eta: 7:42:14
[2022/06/18 22:36:33] ppcls INFO: [Train][Epoch 40/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08620869, top1: 0.86208, CELoss: 0.40793, loss: 0.40793, batch_cost: 0.61295s, reader_cost: 0.01203, ips: 104.41236 samples/s, eta: 7:35:07
[2022/06/18 22:36:40] ppcls INFO: [Train][Epoch 40/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08619761, top1: 0.86092, CELoss: 0.40829, loss: 0.40829, batch_cost: 0.62439s, reader_cost: 0.01163, ips: 102.49960 samples/s, eta: 7:43:31
[2022/06/18 22:36:46] ppcls INFO: [Train][Epoch 40/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08618652, top1: 0.86092, CELoss: 0.40698, loss: 0.40698, batch_cost: 0.61769s, reader_cost: 0.01192, ips: 103.61127 samples/s, eta: 7:38:26
[2022/06/18 22:36:52] ppcls INFO: [Train][Epoch 40/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08617541, top1: 0.85811, CELoss: 0.41012, loss: 0.41012, batch_cost: 0.61685s, reader_cost: 0.01142, ips: 103.75327 samples/s, eta: 7:37:42
[2022/06/18 22:36:57] ppcls INFO: [Train][Epoch 40/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08616428, top1: 0.85976, CELoss: 0.40782, loss: 0.40782, batch_cost: 0.61276s, reader_cost: 0.01236, ips: 104.44465 samples/s, eta: 7:34:34
[2022/06/18 22:37:04] ppcls INFO: [Train][Epoch 40/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08615314, top1: 0.85866, CELoss: 0.41035, loss: 0.41035, batch_cost: 0.61875s, reader_cost: 0.01254, ips: 103.43356 samples/s, eta: 7:38:55
[2022/06/18 22:37:10] ppcls INFO: [Train][Epoch 40/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08614199, top1: 0.85683, CELoss: 0.41676, loss: 0.41676, batch_cost: 0.61443s, reader_cost: 0.01215, ips: 104.16153 samples/s, eta: 7:35:36
[2022/06/18 22:37:15] ppcls INFO: [Train][Epoch 40/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08613081, top1: 0.85617, CELoss: 0.41622, loss: 0.41622, batch_cost: 0.60948s, reader_cost: 0.01312, ips: 105.00754 samples/s, eta: 7:31:50
[2022/06/18 22:37:21] ppcls INFO: [Train][Epoch 40/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08611963, top1: 0.85549, CELoss: 0.41474, loss: 0.41474, batch_cost: 0.60485s, reader_cost: 0.01286, ips: 105.81095 samples/s, eta: 7:28:18
[2022/06/18 22:37:23] ppcls INFO: [Train][Epoch 40/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08610842, top1: 0.85479, CELoss: 0.41475, loss: 0.41475, batch_cost: 0.58093s, reader_cost: 0.01215, ips: 84.34767 samples/s, eta: 7:10:28
[2022/06/18 22:37:23] ppcls INFO: [Train][Epoch 40/300][Avg]top1: 0.85479, CELoss: 0.41475, loss: 0.41475
[2022/06/18 22:37:30] ppcls INFO: [Eval][Epoch 40][Iter: 0/16]CELoss: 0.91392, loss: 0.91392, top1: 0.71680, batch_cost: 6.76232s, reader_cost: 3.49927, ips: 9.46421 images/sec
[2022/06/18 22:37:38] ppcls INFO: [Eval][Epoch 40][Iter: 10/16]CELoss: 0.70443, loss: 0.70443, top1: 0.73757, batch_cost: 0.64552s, reader_cost: 0.00612, ips: 99.14550 images/sec
[2022/06/18 22:37:40] ppcls INFO: [Eval][Epoch 40][Avg]CELoss: 0.68253, loss: 0.68253, top1: 0.74498
[2022/06/18 22:37:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 22:37:40] ppcls INFO: [Eval][Epoch 40][best metric: 0.7449755072593689]
[2022/06/18 22:37:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_40
[2022/06/18 22:37:41] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:37:47] ppcls INFO: [Train][Epoch 41/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08610730, top1: 0.87500, CELoss: 0.33154, loss: 0.33154, batch_cost: 0.61372s, reader_cost: 0.04258, ips: 104.28233 samples/s, eta: 7:34:45
[2022/06/18 22:37:54] ppcls INFO: [Train][Epoch 41/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08609608, top1: 0.86364, CELoss: 0.36909, loss: 0.36909, batch_cost: 0.72901s, reader_cost: 0.02824, ips: 87.78986 samples/s, eta: 9:00:04
[2022/06/18 22:38:00] ppcls INFO: [Train][Epoch 41/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08608485, top1: 0.86979, CELoss: 0.36237, loss: 0.36237, batch_cost: 0.67394s, reader_cost: 0.01885, ips: 94.96432 samples/s, eta: 8:19:09
[2022/06/18 22:38:06] ppcls INFO: [Train][Epoch 41/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08607360, top1: 0.86895, CELoss: 0.38397, loss: 0.38397, batch_cost: 0.64914s, reader_cost: 0.01397, ips: 98.59199 samples/s, eta: 8:00:41
[2022/06/18 22:38:12] ppcls INFO: [Train][Epoch 41/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08606233, top1: 0.86738, CELoss: 0.38922, loss: 0.38922, batch_cost: 0.62426s, reader_cost: 0.01160, ips: 102.52152 samples/s, eta: 7:42:09
[2022/06/18 22:38:18] ppcls INFO: [Train][Epoch 41/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08605105, top1: 0.86857, CELoss: 0.39148, loss: 0.39148, batch_cost: 0.63265s, reader_cost: 0.01825, ips: 101.16108 samples/s, eta: 7:48:16
[2022/06/18 22:38:24] ppcls INFO: [Train][Epoch 41/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08603976, top1: 0.86527, CELoss: 0.39784, loss: 0.39784, batch_cost: 0.62971s, reader_cost: 0.02229, ips: 101.63363 samples/s, eta: 7:45:59
[2022/06/18 22:38:31] ppcls INFO: [Train][Epoch 41/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08602844, top1: 0.86356, CELoss: 0.40381, loss: 0.40381, batch_cost: 0.62845s, reader_cost: 0.04115, ips: 101.83812 samples/s, eta: 7:44:56
[2022/06/18 22:38:37] ppcls INFO: [Train][Epoch 41/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08601712, top1: 0.86015, CELoss: 0.40924, loss: 0.40924, batch_cost: 0.63526s, reader_cost: 0.07336, ips: 100.74631 samples/s, eta: 7:49:52
[2022/06/18 22:38:43] ppcls INFO: [Train][Epoch 41/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08600577, top1: 0.85697, CELoss: 0.41376, loss: 0.41376, batch_cost: 0.62405s, reader_cost: 0.06628, ips: 102.55663 samples/s, eta: 7:41:28
[2022/06/18 22:38:49] ppcls INFO: [Train][Epoch 41/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08599441, top1: 0.85705, CELoss: 0.41291, loss: 0.41291, batch_cost: 0.62266s, reader_cost: 0.06787, ips: 102.78551 samples/s, eta: 7:40:21
[2022/06/18 22:38:55] ppcls INFO: [Train][Epoch 41/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08598304, top1: 0.85867, CELoss: 0.41226, loss: 0.41226, batch_cost: 0.61963s, reader_cost: 0.06948, ips: 103.28736 samples/s, eta: 7:38:00
[2022/06/18 22:39:01] ppcls INFO: [Train][Epoch 41/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08597165, top1: 0.85795, CELoss: 0.41451, loss: 0.41451, batch_cost: 0.62130s, reader_cost: 0.07840, ips: 103.00977 samples/s, eta: 7:39:08
[2022/06/18 22:39:07] ppcls INFO: [Train][Epoch 41/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08596025, top1: 0.85675, CELoss: 0.41573, loss: 0.41573, batch_cost: 0.61585s, reader_cost: 0.07635, ips: 103.92174 samples/s, eta: 7:35:00
[2022/06/18 22:39:13] ppcls INFO: [Train][Epoch 41/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08594883, top1: 0.85816, CELoss: 0.41184, loss: 0.41184, batch_cost: 0.61365s, reader_cost: 0.07309, ips: 104.29323 samples/s, eta: 7:33:17
[2022/06/18 22:39:20] ppcls INFO: [Train][Epoch 41/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08593739, top1: 0.85720, CELoss: 0.41556, loss: 0.41556, batch_cost: 0.62028s, reader_cost: 0.06837, ips: 103.17850 samples/s, eta: 7:38:04
[2022/06/18 22:39:24] ppcls INFO: [Train][Epoch 41/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08592594, top1: 0.85714, CELoss: 0.41567, loss: 0.41567, batch_cost: 0.60979s, reader_cost: 0.06420, ips: 104.95344 samples/s, eta: 7:30:13
[2022/06/18 22:39:28] ppcls INFO: [Train][Epoch 41/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08591448, top1: 0.85653, CELoss: 0.41612, loss: 0.41612, batch_cost: 0.59378s, reader_cost: 0.06048, ips: 82.52191 samples/s, eta: 7:18:18
[2022/06/18 22:39:28] ppcls INFO: [Train][Epoch 41/300][Avg]top1: 0.85653, CELoss: 0.41612, loss: 0.41612
[2022/06/18 22:39:28] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:39:34] ppcls INFO: [Train][Epoch 42/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08591333, top1: 0.89062, CELoss: 0.28109, loss: 0.28109, batch_cost: 0.62450s, reader_cost: 0.08290, ips: 102.48222 samples/s, eta: 7:40:58
[2022/06/18 22:39:41] ppcls INFO: [Train][Epoch 42/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08590185, top1: 0.86222, CELoss: 0.38345, loss: 0.38345, batch_cost: 0.64459s, reader_cost: 0.01451, ips: 99.28867 samples/s, eta: 7:55:41
[2022/06/18 22:39:48] ppcls INFO: [Train][Epoch 42/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08589035, top1: 0.85491, CELoss: 0.41494, loss: 0.41494, batch_cost: 0.64230s, reader_cost: 0.00921, ips: 99.64200 samples/s, eta: 7:53:53
[2022/06/18 22:39:53] ppcls INFO: [Train][Epoch 42/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08587884, top1: 0.85534, CELoss: 0.41488, loss: 0.41488, batch_cost: 0.60341s, reader_cost: 0.00714, ips: 106.06468 samples/s, eta: 7:25:06
[2022/06/18 22:40:00] ppcls INFO: [Train][Epoch 42/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08586731, top1: 0.85137, CELoss: 0.42460, loss: 0.42460, batch_cost: 0.62413s, reader_cost: 0.00623, ips: 102.54282 samples/s, eta: 7:40:17
[2022/06/18 22:40:05] ppcls INFO: [Train][Epoch 42/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08585576, top1: 0.85110, CELoss: 0.42528, loss: 0.42528, batch_cost: 0.60399s, reader_cost: 0.00676, ips: 105.96277 samples/s, eta: 7:25:19
[2022/06/18 22:40:12] ppcls INFO: [Train][Epoch 42/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08584421, top1: 0.85220, CELoss: 0.42485, loss: 0.42485, batch_cost: 0.60998s, reader_cost: 0.01087, ips: 104.92075 samples/s, eta: 7:29:38
[2022/06/18 22:40:19] ppcls INFO: [Train][Epoch 42/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08583263, top1: 0.85255, CELoss: 0.42101, loss: 0.42101, batch_cost: 0.61947s, reader_cost: 0.01142, ips: 103.31448 samples/s, eta: 7:36:32
[2022/06/18 22:40:24] ppcls INFO: [Train][Epoch 42/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08582104, top1: 0.85359, CELoss: 0.41779, loss: 0.41779, batch_cost: 0.61027s, reader_cost: 0.01341, ips: 104.87131 samples/s, eta: 7:29:39
[2022/06/18 22:40:30] ppcls INFO: [Train][Epoch 42/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08580944, top1: 0.85354, CELoss: 0.41534, loss: 0.41534, batch_cost: 0.61459s, reader_cost: 0.01416, ips: 104.13524 samples/s, eta: 7:32:44
[2022/06/18 22:40:37] ppcls INFO: [Train][Epoch 42/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08579782, top1: 0.85319, CELoss: 0.41743, loss: 0.41743, batch_cost: 0.61718s, reader_cost: 0.01386, ips: 103.69802 samples/s, eta: 7:34:32
[2022/06/18 22:40:43] ppcls INFO: [Train][Epoch 42/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08578618, top1: 0.85487, CELoss: 0.41380, loss: 0.41380, batch_cost: 0.61283s, reader_cost: 0.01376, ips: 104.43367 samples/s, eta: 7:31:14
[2022/06/18 22:40:49] ppcls INFO: [Train][Epoch 42/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08577453, top1: 0.85783, CELoss: 0.40738, loss: 0.40738, batch_cost: 0.61332s, reader_cost: 0.01464, ips: 104.35071 samples/s, eta: 7:31:29
[2022/06/18 22:40:56] ppcls INFO: [Train][Epoch 42/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08576286, top1: 0.85782, CELoss: 0.40762, loss: 0.40762, batch_cost: 0.62341s, reader_cost: 0.03604, ips: 102.66086 samples/s, eta: 7:38:49
[2022/06/18 22:41:01] ppcls INFO: [Train][Epoch 42/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08575118, top1: 0.85993, CELoss: 0.40629, loss: 0.40629, batch_cost: 0.61233s, reader_cost: 0.03393, ips: 104.51953 samples/s, eta: 7:30:33
[2022/06/18 22:41:07] ppcls INFO: [Train][Epoch 42/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08573948, top1: 0.85948, CELoss: 0.40723, loss: 0.40723, batch_cost: 0.60926s, reader_cost: 0.03391, ips: 105.04595 samples/s, eta: 7:28:12
[2022/06/18 22:41:11] ppcls INFO: [Train][Epoch 42/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08572777, top1: 0.86035, CELoss: 0.40512, loss: 0.40512, batch_cost: 0.60086s, reader_cost: 0.03297, ips: 106.51358 samples/s, eta: 7:21:55
[2022/06/18 22:41:14] ppcls INFO: [Train][Epoch 42/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08571604, top1: 0.86138, CELoss: 0.40184, loss: 0.40184, batch_cost: 0.57823s, reader_cost: 0.03106, ips: 84.74111 samples/s, eta: 7:05:11
[2022/06/18 22:41:14] ppcls INFO: [Train][Epoch 42/300][Avg]top1: 0.86138, CELoss: 0.40184, loss: 0.40184
[2022/06/18 22:41:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:41:21] ppcls INFO: [Train][Epoch 43/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08571487, top1: 0.85938, CELoss: 0.41615, loss: 0.41615, batch_cost: 0.61507s, reader_cost: 0.06692, ips: 104.05360 samples/s, eta: 7:32:15
[2022/06/18 22:41:27] ppcls INFO: [Train][Epoch 43/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08570313, top1: 0.84233, CELoss: 0.46050, loss: 0.46050, batch_cost: 0.64869s, reader_cost: 0.00300, ips: 98.66046 samples/s, eta: 7:56:52
[2022/06/18 22:41:34] ppcls INFO: [Train][Epoch 43/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08569137, top1: 0.85119, CELoss: 0.42871, loss: 0.42871, batch_cost: 0.64959s, reader_cost: 0.00874, ips: 98.52382 samples/s, eta: 7:57:25
[2022/06/18 22:41:40] ppcls INFO: [Train][Epoch 43/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08567959, top1: 0.85988, CELoss: 0.40858, loss: 0.40858, batch_cost: 0.63430s, reader_cost: 0.01022, ips: 100.89905 samples/s, eta: 7:46:04
[2022/06/18 22:41:46] ppcls INFO: [Train][Epoch 43/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08566780, top1: 0.85328, CELoss: 0.41501, loss: 0.41501, batch_cost: 0.63551s, reader_cost: 0.00849, ips: 100.70677 samples/s, eta: 7:46:51
[2022/06/18 22:41:52] ppcls INFO: [Train][Epoch 43/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08565600, top1: 0.85631, CELoss: 0.40304, loss: 0.40304, batch_cost: 0.61869s, reader_cost: 0.00881, ips: 103.44455 samples/s, eta: 7:34:24
[2022/06/18 22:41:58] ppcls INFO: [Train][Epoch 43/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08564418, top1: 0.85963, CELoss: 0.39502, loss: 0.39502, batch_cost: 0.61946s, reader_cost: 0.00919, ips: 103.31535 samples/s, eta: 7:34:52
[2022/06/18 22:42:05] ppcls INFO: [Train][Epoch 43/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08563234, top1: 0.85982, CELoss: 0.39638, loss: 0.39638, batch_cost: 0.62109s, reader_cost: 0.00846, ips: 103.04483 samples/s, eta: 7:35:57
[2022/06/18 22:42:11] ppcls INFO: [Train][Epoch 43/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08562049, top1: 0.86092, CELoss: 0.39427, loss: 0.39427, batch_cost: 0.61834s, reader_cost: 0.00828, ips: 103.50345 samples/s, eta: 7:33:50
[2022/06/18 22:42:18] ppcls INFO: [Train][Epoch 43/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08560862, top1: 0.86006, CELoss: 0.39831, loss: 0.39831, batch_cost: 0.63031s, reader_cost: 0.00897, ips: 101.53689 samples/s, eta: 7:42:31
[2022/06/18 22:42:23] ppcls INFO: [Train][Epoch 43/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08559674, top1: 0.86092, CELoss: 0.39790, loss: 0.39790, batch_cost: 0.61758s, reader_cost: 0.01023, ips: 103.62983 samples/s, eta: 7:33:04
[2022/06/18 22:42:29] ppcls INFO: [Train][Epoch 43/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08558485, top1: 0.86078, CELoss: 0.39643, loss: 0.39643, batch_cost: 0.61509s, reader_cost: 0.01157, ips: 104.05033 samples/s, eta: 7:31:08
[2022/06/18 22:42:34] ppcls INFO: [Train][Epoch 43/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08557293, top1: 0.86118, CELoss: 0.39777, loss: 0.39777, batch_cost: 0.60867s, reader_cost: 0.01114, ips: 105.14662 samples/s, eta: 7:26:20
[2022/06/18 22:42:41] ppcls INFO: [Train][Epoch 43/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08556101, top1: 0.86104, CELoss: 0.40060, loss: 0.40060, batch_cost: 0.61741s, reader_cost: 0.01245, ips: 103.65814 samples/s, eta: 7:32:38
[2022/06/18 22:42:47] ppcls INFO: [Train][Epoch 43/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08554906, top1: 0.86226, CELoss: 0.39901, loss: 0.39901, batch_cost: 0.61321s, reader_cost: 0.01177, ips: 104.36915 samples/s, eta: 7:29:27
[2022/06/18 22:42:55] ppcls INFO: [Train][Epoch 43/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08553711, top1: 0.86175, CELoss: 0.39787, loss: 0.39787, batch_cost: 0.62524s, reader_cost: 0.01108, ips: 102.36091 samples/s, eta: 7:38:10
[2022/06/18 22:42:59] ppcls INFO: [Train][Epoch 43/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08552513, top1: 0.85986, CELoss: 0.40232, loss: 0.40232, batch_cost: 0.61214s, reader_cost: 0.01060, ips: 104.55084 samples/s, eta: 7:28:28
[2022/06/18 22:43:01] ppcls INFO: [Train][Epoch 43/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08551315, top1: 0.86046, CELoss: 0.40156, loss: 0.40156, batch_cost: 0.58780s, reader_cost: 0.00997, ips: 83.36214 samples/s, eta: 7:10:32
[2022/06/18 22:43:02] ppcls INFO: [Train][Epoch 43/300][Avg]top1: 0.86046, CELoss: 0.40156, loss: 0.40156
[2022/06/18 22:43:02] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:43:09] ppcls INFO: [Train][Epoch 44/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08551195, top1: 0.85938, CELoss: 0.42863, loss: 0.42863, batch_cost: 0.62594s, reader_cost: 0.03774, ips: 102.24582 samples/s, eta: 7:38:28
[2022/06/18 22:43:15] ppcls INFO: [Train][Epoch 44/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08549994, top1: 0.86648, CELoss: 0.38367, loss: 0.38367, batch_cost: 0.56908s, reader_cost: 0.01607, ips: 112.46300 samples/s, eta: 6:56:43
[2022/06/18 22:43:21] ppcls INFO: [Train][Epoch 44/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08548792, top1: 0.86086, CELoss: 0.41083, loss: 0.41083, batch_cost: 0.63163s, reader_cost: 0.02288, ips: 101.32471 samples/s, eta: 7:42:25
[2022/06/18 22:43:28] ppcls INFO: [Train][Epoch 44/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08547589, top1: 0.86341, CELoss: 0.40956, loss: 0.40956, batch_cost: 0.62294s, reader_cost: 0.02223, ips: 102.73887 samples/s, eta: 7:35:57
[2022/06/18 22:43:34] ppcls INFO: [Train][Epoch 44/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08546384, top1: 0.86128, CELoss: 0.41011, loss: 0.41011, batch_cost: 0.61649s, reader_cost: 0.02347, ips: 103.81431 samples/s, eta: 7:31:08
[2022/06/18 22:43:39] ppcls INFO: [Train][Epoch 44/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08545177, top1: 0.85784, CELoss: 0.40875, loss: 0.40875, batch_cost: 0.60669s, reader_cost: 0.02339, ips: 105.48987 samples/s, eta: 7:23:52
[2022/06/18 22:43:46] ppcls INFO: [Train][Epoch 44/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08543969, top1: 0.85938, CELoss: 0.41090, loss: 0.41090, batch_cost: 0.61628s, reader_cost: 0.02261, ips: 103.84927 samples/s, eta: 7:30:46
[2022/06/18 22:43:52] ppcls INFO: [Train][Epoch 44/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08542759, top1: 0.85938, CELoss: 0.40908, loss: 0.40908, batch_cost: 0.60876s, reader_cost: 0.02232, ips: 105.13181 samples/s, eta: 7:25:10
[2022/06/18 22:43:58] ppcls INFO: [Train][Epoch 44/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08541548, top1: 0.85880, CELoss: 0.41395, loss: 0.41395, batch_cost: 0.61815s, reader_cost: 0.02003, ips: 103.53535 samples/s, eta: 7:31:56
[2022/06/18 22:44:04] ppcls INFO: [Train][Epoch 44/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08540336, top1: 0.86178, CELoss: 0.40818, loss: 0.40818, batch_cost: 0.60669s, reader_cost: 0.01909, ips: 105.49097 samples/s, eta: 7:23:27
[2022/06/18 22:44:10] ppcls INFO: [Train][Epoch 44/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08539122, top1: 0.86092, CELoss: 0.40795, loss: 0.40795, batch_cost: 0.61251s, reader_cost: 0.01834, ips: 104.48840 samples/s, eta: 7:27:36
[2022/06/18 22:44:16] ppcls INFO: [Train][Epoch 44/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08537906, top1: 0.86022, CELoss: 0.40951, loss: 0.40951, batch_cost: 0.60473s, reader_cost: 0.01852, ips: 105.83193 samples/s, eta: 7:21:49
[2022/06/18 22:44:22] ppcls INFO: [Train][Epoch 44/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08536689, top1: 0.85963, CELoss: 0.41044, loss: 0.41044, batch_cost: 0.60592s, reader_cost: 0.01867, ips: 105.62459 samples/s, eta: 7:22:35
[2022/06/18 22:44:28] ppcls INFO: [Train][Epoch 44/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08535470, top1: 0.85842, CELoss: 0.41375, loss: 0.41375, batch_cost: 0.61183s, reader_cost: 0.01774, ips: 104.60448 samples/s, eta: 7:26:48
[2022/06/18 22:44:34] ppcls INFO: [Train][Epoch 44/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08534250, top1: 0.85782, CELoss: 0.41472, loss: 0.41472, batch_cost: 0.60867s, reader_cost: 0.01662, ips: 105.14690 samples/s, eta: 7:24:24
[2022/06/18 22:44:40] ppcls INFO: [Train][Epoch 44/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08533028, top1: 0.85865, CELoss: 0.41077, loss: 0.41077, batch_cost: 0.60670s, reader_cost: 0.01550, ips: 105.48955 samples/s, eta: 7:22:51
[2022/06/18 22:44:45] ppcls INFO: [Train][Epoch 44/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08531805, top1: 0.85928, CELoss: 0.41238, loss: 0.41238, batch_cost: 0.59980s, reader_cost: 0.01454, ips: 106.70138 samples/s, eta: 7:17:43
[2022/06/18 22:44:47] ppcls INFO: [Train][Epoch 44/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08530580, top1: 0.85936, CELoss: 0.41007, loss: 0.41007, batch_cost: 0.57690s, reader_cost: 0.01371, ips: 84.93609 samples/s, eta: 7:00:55
[2022/06/18 22:44:48] ppcls INFO: [Train][Epoch 44/300][Avg]top1: 0.85936, CELoss: 0.41007, loss: 0.41007
[2022/06/18 22:44:48] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:44:56] ppcls INFO: [Train][Epoch 45/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08530458, top1: 0.89062, CELoss: 0.33821, loss: 0.33821, batch_cost: 0.62287s, reader_cost: 0.04088, ips: 102.75086 samples/s, eta: 7:34:26
[2022/06/18 22:45:01] ppcls INFO: [Train][Epoch 45/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08529231, top1: 0.84517, CELoss: 0.43321, loss: 0.43321, batch_cost: 0.50562s, reader_cost: 0.03536, ips: 126.57752 samples/s, eta: 6:08:48
[2022/06/18 22:45:07] ppcls INFO: [Train][Epoch 45/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08528004, top1: 0.85714, CELoss: 0.41149, loss: 0.41149, batch_cost: 0.57537s, reader_cost: 0.02800, ips: 111.23245 samples/s, eta: 6:59:35
[2022/06/18 22:45:14] ppcls INFO: [Train][Epoch 45/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08526774, top1: 0.85433, CELoss: 0.41444, loss: 0.41444, batch_cost: 0.63059s, reader_cost: 0.08027, ips: 101.49261 samples/s, eta: 7:39:45
[2022/06/18 22:45:20] ppcls INFO: [Train][Epoch 45/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08525543, top1: 0.85976, CELoss: 0.40396, loss: 0.40396, batch_cost: 0.61457s, reader_cost: 0.06184, ips: 104.13843 samples/s, eta: 7:27:58
[2022/06/18 22:45:26] ppcls INFO: [Train][Epoch 45/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08524311, top1: 0.86121, CELoss: 0.40199, loss: 0.40199, batch_cost: 0.61118s, reader_cost: 0.06835, ips: 104.71577 samples/s, eta: 7:25:24
[2022/06/18 22:45:33] ppcls INFO: [Train][Epoch 45/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08523077, top1: 0.85784, CELoss: 0.40202, loss: 0.40202, batch_cost: 0.62541s, reader_cost: 0.08820, ips: 102.33221 samples/s, eta: 7:35:40
[2022/06/18 22:45:38] ppcls INFO: [Train][Epoch 45/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08521841, top1: 0.85893, CELoss: 0.39780, loss: 0.39780, batch_cost: 0.61679s, reader_cost: 0.07677, ips: 103.76290 samples/s, eta: 7:29:17
[2022/06/18 22:45:45] ppcls INFO: [Train][Epoch 45/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08520605, top1: 0.85880, CELoss: 0.39668, loss: 0.39668, batch_cost: 0.61833s, reader_cost: 0.07914, ips: 103.50415 samples/s, eta: 7:30:18
[2022/06/18 22:45:51] ppcls INFO: [Train][Epoch 45/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08519366, top1: 0.85749, CELoss: 0.39970, loss: 0.39970, batch_cost: 0.61735s, reader_cost: 0.08281, ips: 103.66918 samples/s, eta: 7:29:29
[2022/06/18 22:45:57] ppcls INFO: [Train][Epoch 45/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08518126, top1: 0.85783, CELoss: 0.39885, loss: 0.39885, batch_cost: 0.61456s, reader_cost: 0.07810, ips: 104.14009 samples/s, eta: 7:27:21
[2022/06/18 22:46:03] ppcls INFO: [Train][Epoch 45/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08516885, top1: 0.85825, CELoss: 0.39967, loss: 0.39967, batch_cost: 0.61154s, reader_cost: 0.07805, ips: 104.65308 samples/s, eta: 7:25:03
[2022/06/18 22:46:09] ppcls INFO: [Train][Epoch 45/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08515642, top1: 0.85950, CELoss: 0.39880, loss: 0.39880, batch_cost: 0.61456s, reader_cost: 0.08128, ips: 104.13926 samples/s, eta: 7:27:09
[2022/06/18 22:46:15] ppcls INFO: [Train][Epoch 45/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08514397, top1: 0.85902, CELoss: 0.40141, loss: 0.40141, batch_cost: 0.61188s, reader_cost: 0.07504, ips: 104.59636 samples/s, eta: 7:25:05
[2022/06/18 22:46:23] ppcls INFO: [Train][Epoch 45/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08513151, top1: 0.86048, CELoss: 0.39753, loss: 0.39753, batch_cost: 0.62722s, reader_cost: 0.08849, ips: 102.03829 samples/s, eta: 7:36:09
[2022/06/18 22:46:27] ppcls INFO: [Train][Epoch 45/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08511904, top1: 0.86113, CELoss: 0.39581, loss: 0.39581, batch_cost: 0.61428s, reader_cost: 0.08323, ips: 104.18737 samples/s, eta: 7:26:38
[2022/06/18 22:46:32] ppcls INFO: [Train][Epoch 45/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08510655, top1: 0.86054, CELoss: 0.39594, loss: 0.39594, batch_cost: 0.60334s, reader_cost: 0.07825, ips: 106.07623 samples/s, eta: 7:18:35
[2022/06/18 22:46:34] ppcls INFO: [Train][Epoch 45/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08509404, top1: 0.86092, CELoss: 0.39491, loss: 0.39491, batch_cost: 0.58219s, reader_cost: 0.07499, ips: 84.16463 samples/s, eta: 7:03:07
[2022/06/18 22:46:35] ppcls INFO: [Train][Epoch 45/300][Avg]top1: 0.86092, CELoss: 0.39491, loss: 0.39491
[2022/06/18 22:46:42] ppcls INFO: [Eval][Epoch 45][Iter: 0/16]CELoss: 0.85561, loss: 0.85561, top1: 0.69141, batch_cost: 6.70252s, reader_cost: 3.46608, ips: 9.54864 images/sec
[2022/06/18 22:46:50] ppcls INFO: [Eval][Epoch 45][Iter: 10/16]CELoss: 0.69361, loss: 0.69361, top1: 0.73686, batch_cost: 0.59233s, reader_cost: 0.00347, ips: 108.04776 images/sec
[2022/06/18 22:46:52] ppcls INFO: [Eval][Epoch 45][Avg]CELoss: 0.67953, loss: 0.67953, top1: 0.74792
[2022/06/18 22:46:52] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 22:46:52] ppcls INFO: [Eval][Epoch 45][best metric: 0.7479166984558105]
[2022/06/18 22:46:52] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:47:01] ppcls INFO: [Train][Epoch 46/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08509279, top1: 0.87500, CELoss: 0.40901, loss: 0.40901, batch_cost: 0.63142s, reader_cost: 0.09855, ips: 101.35810 samples/s, eta: 7:38:53
[2022/06/18 22:47:06] ppcls INFO: [Train][Epoch 46/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08508027, top1: 0.86364, CELoss: 0.38780, loss: 0.38780, batch_cost: 0.58665s, reader_cost: 0.01958, ips: 109.09397 samples/s, eta: 7:06:15
[2022/06/18 22:47:11] ppcls INFO: [Train][Epoch 46/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08506773, top1: 0.85193, CELoss: 0.40087, loss: 0.40087, batch_cost: 0.57457s, reader_cost: 0.01129, ips: 111.38674 samples/s, eta: 6:57:22
[2022/06/18 22:47:17] ppcls INFO: [Train][Epoch 46/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08505518, top1: 0.85282, CELoss: 0.39090, loss: 0.39090, batch_cost: 0.57334s, reader_cost: 0.01762, ips: 111.62566 samples/s, eta: 6:56:23
[2022/06/18 22:47:23] ppcls INFO: [Train][Epoch 46/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08504262, top1: 0.85823, CELoss: 0.38512, loss: 0.38512, batch_cost: 0.56927s, reader_cost: 0.01656, ips: 112.42461 samples/s, eta: 6:53:20
[2022/06/18 22:47:29] ppcls INFO: [Train][Epoch 46/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08503003, top1: 0.85876, CELoss: 0.38576, loss: 0.38576, batch_cost: 0.59352s, reader_cost: 0.04269, ips: 107.83153 samples/s, eta: 7:10:50
[2022/06/18 22:47:36] ppcls INFO: [Train][Epoch 46/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08501744, top1: 0.86168, CELoss: 0.38247, loss: 0.38247, batch_cost: 0.60381s, reader_cost: 0.03632, ips: 105.99447 samples/s, eta: 7:18:12
[2022/06/18 22:47:43] ppcls INFO: [Train][Epoch 46/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08500483, top1: 0.86026, CELoss: 0.38533, loss: 0.38533, batch_cost: 0.62407s, reader_cost: 0.03210, ips: 102.55201 samples/s, eta: 7:32:49
[2022/06/18 22:47:49] ppcls INFO: [Train][Epoch 46/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08499220, top1: 0.86343, CELoss: 0.38354, loss: 0.38354, batch_cost: 0.61561s, reader_cost: 0.03045, ips: 103.96226 samples/s, eta: 7:26:34
[2022/06/18 22:47:55] ppcls INFO: [Train][Epoch 46/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08497956, top1: 0.86195, CELoss: 0.38561, loss: 0.38561, batch_cost: 0.61063s, reader_cost: 0.02739, ips: 104.80932 samples/s, eta: 7:22:51
[2022/06/18 22:48:02] ppcls INFO: [Train][Epoch 46/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08496690, top1: 0.86262, CELoss: 0.38658, loss: 0.38658, batch_cost: 0.62181s, reader_cost: 0.02481, ips: 102.92573 samples/s, eta: 7:30:51
[2022/06/18 22:48:08] ppcls INFO: [Train][Epoch 46/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08495423, top1: 0.86219, CELoss: 0.38949, loss: 0.38949, batch_cost: 0.61793s, reader_cost: 0.02337, ips: 103.57156 samples/s, eta: 7:27:56
[2022/06/18 22:48:14] ppcls INFO: [Train][Epoch 46/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08494154, top1: 0.86428, CELoss: 0.38424, loss: 0.38424, batch_cost: 0.61707s, reader_cost: 0.02371, ips: 103.71538 samples/s, eta: 7:27:13
[2022/06/18 22:48:19] ppcls INFO: [Train][Epoch 46/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08492884, top1: 0.86248, CELoss: 0.38953, loss: 0.38953, batch_cost: 0.61261s, reader_cost: 0.02268, ips: 104.47157 samples/s, eta: 7:23:53
[2022/06/18 22:48:26] ppcls INFO: [Train][Epoch 46/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08491612, top1: 0.86370, CELoss: 0.38774, loss: 0.38774, batch_cost: 0.61528s, reader_cost: 0.02149, ips: 104.01696 samples/s, eta: 7:25:43
[2022/06/18 22:48:32] ppcls INFO: [Train][Epoch 46/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08490339, top1: 0.86320, CELoss: 0.38863, loss: 0.38863, batch_cost: 0.61783s, reader_cost: 0.02137, ips: 103.58888 samples/s, eta: 7:27:27
[2022/06/18 22:48:37] ppcls INFO: [Train][Epoch 46/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08489065, top1: 0.86122, CELoss: 0.39408, loss: 0.39408, batch_cost: 0.61099s, reader_cost: 0.02034, ips: 104.74807 samples/s, eta: 7:22:24
[2022/06/18 22:48:39] ppcls INFO: [Train][Epoch 46/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08487788, top1: 0.86257, CELoss: 0.39161, loss: 0.39161, batch_cost: 0.58674s, reader_cost: 0.01912, ips: 83.51250 samples/s, eta: 7:04:44
[2022/06/18 22:48:40] ppcls INFO: [Train][Epoch 46/300][Avg]top1: 0.86257, CELoss: 0.39161, loss: 0.39161
[2022/06/18 22:48:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:48:47] ppcls INFO: [Train][Epoch 47/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08487661, top1: 0.85938, CELoss: 0.37872, loss: 0.37872, batch_cost: 0.62350s, reader_cost: 0.05008, ips: 102.64609 samples/s, eta: 7:31:21
[2022/06/18 22:48:55] ppcls INFO: [Train][Epoch 47/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08486383, top1: 0.87642, CELoss: 0.36645, loss: 0.36645, batch_cost: 0.83708s, reader_cost: 0.01582, ips: 76.45594 samples/s, eta: 10:05:49
[2022/06/18 22:49:01] ppcls INFO: [Train][Epoch 47/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08485104, top1: 0.86607, CELoss: 0.36939, loss: 0.36939, batch_cost: 0.72417s, reader_cost: 0.01691, ips: 88.37709 samples/s, eta: 8:43:59
[2022/06/18 22:49:06] ppcls INFO: [Train][Epoch 47/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08483823, top1: 0.86190, CELoss: 0.37440, loss: 0.37440, batch_cost: 0.65005s, reader_cost: 0.01746, ips: 98.45380 samples/s, eta: 7:50:14
[2022/06/18 22:49:13] ppcls INFO: [Train][Epoch 47/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08482541, top1: 0.86395, CELoss: 0.36997, loss: 0.36997, batch_cost: 0.64137s, reader_cost: 0.01646, ips: 99.78640 samples/s, eta: 7:43:51
[2022/06/18 22:49:20] ppcls INFO: [Train][Epoch 47/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08481257, top1: 0.85876, CELoss: 0.38278, loss: 0.38278, batch_cost: 0.67383s, reader_cost: 0.01570, ips: 94.97959 samples/s, eta: 8:07:13
[2022/06/18 22:49:26] ppcls INFO: [Train][Epoch 47/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08479972, top1: 0.86117, CELoss: 0.38512, loss: 0.38512, batch_cost: 0.64988s, reader_cost: 0.01456, ips: 98.47917 samples/s, eta: 7:49:48
[2022/06/18 22:49:32] ppcls INFO: [Train][Epoch 47/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08478685, top1: 0.86092, CELoss: 0.38896, loss: 0.38896, batch_cost: 0.64231s, reader_cost: 0.01449, ips: 99.63970 samples/s, eta: 7:44:13
[2022/06/18 22:49:37] ppcls INFO: [Train][Epoch 47/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08477397, top1: 0.86304, CELoss: 0.38773, loss: 0.38773, batch_cost: 0.63146s, reader_cost: 0.01373, ips: 101.35278 samples/s, eta: 7:36:16
[2022/06/18 22:49:44] ppcls INFO: [Train][Epoch 47/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08476107, top1: 0.86041, CELoss: 0.39209, loss: 0.39209, batch_cost: 0.63115s, reader_cost: 0.01374, ips: 101.40280 samples/s, eta: 7:35:56
[2022/06/18 22:49:50] ppcls INFO: [Train][Epoch 47/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08474816, top1: 0.85860, CELoss: 0.39606, loss: 0.39606, batch_cost: 0.63007s, reader_cost: 0.01551, ips: 101.57540 samples/s, eta: 7:35:03
[2022/06/18 22:49:56] ppcls INFO: [Train][Epoch 47/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08473523, top1: 0.85628, CELoss: 0.40187, loss: 0.40187, batch_cost: 0.62724s, reader_cost: 0.01536, ips: 102.03453 samples/s, eta: 7:32:54
[2022/06/18 22:50:02] ppcls INFO: [Train][Epoch 47/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08472229, top1: 0.85537, CELoss: 0.40444, loss: 0.40444, batch_cost: 0.62247s, reader_cost: 0.01522, ips: 102.81564 samples/s, eta: 7:29:21
[2022/06/18 22:50:07] ppcls INFO: [Train][Epoch 47/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08470933, top1: 0.85615, CELoss: 0.40230, loss: 0.40230, batch_cost: 0.61656s, reader_cost: 0.01539, ips: 103.80090 samples/s, eta: 7:24:59
[2022/06/18 22:50:14] ppcls INFO: [Train][Epoch 47/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08469636, top1: 0.85505, CELoss: 0.40388, loss: 0.40388, batch_cost: 0.62349s, reader_cost: 0.01540, ips: 102.64749 samples/s, eta: 7:29:53
[2022/06/18 22:50:20] ppcls INFO: [Train][Epoch 47/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08468337, top1: 0.85596, CELoss: 0.40217, loss: 0.40217, batch_cost: 0.61777s, reader_cost: 0.01560, ips: 103.59919 samples/s, eta: 7:25:39
[2022/06/18 22:50:25] ppcls INFO: [Train][Epoch 47/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08467037, top1: 0.85578, CELoss: 0.40270, loss: 0.40270, batch_cost: 0.61285s, reader_cost: 0.01573, ips: 104.43056 samples/s, eta: 7:22:00
[2022/06/18 22:50:27] ppcls INFO: [Train][Epoch 47/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08465735, top1: 0.85571, CELoss: 0.40358, loss: 0.40358, batch_cost: 0.58845s, reader_cost: 0.01479, ips: 83.26961 samples/s, eta: 7:04:18
[2022/06/18 22:50:28] ppcls INFO: [Train][Epoch 47/300][Avg]top1: 0.85571, CELoss: 0.40358, loss: 0.40358
[2022/06/18 22:50:28] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:50:35] ppcls INFO: [Train][Epoch 48/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08465605, top1: 0.85938, CELoss: 0.42299, loss: 0.42299, batch_cost: 0.62719s, reader_cost: 0.04399, ips: 102.04282 samples/s, eta: 7:32:14
[2022/06/18 22:50:41] ppcls INFO: [Train][Epoch 48/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08464302, top1: 0.88494, CELoss: 0.36140, loss: 0.36140, batch_cost: 0.60177s, reader_cost: 0.01768, ips: 106.35252 samples/s, eta: 7:13:48
[2022/06/18 22:50:47] ppcls INFO: [Train][Epoch 48/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08462997, top1: 0.87946, CELoss: 0.36520, loss: 0.36520, batch_cost: 0.63173s, reader_cost: 0.01554, ips: 101.30955 samples/s, eta: 7:35:17
[2022/06/18 22:50:53] ppcls INFO: [Train][Epoch 48/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08461691, top1: 0.87399, CELoss: 0.36869, loss: 0.36869, batch_cost: 0.62237s, reader_cost: 0.01442, ips: 102.83222 samples/s, eta: 7:28:27
[2022/06/18 22:51:00] ppcls INFO: [Train][Epoch 48/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08460383, top1: 0.87424, CELoss: 0.36640, loss: 0.36640, batch_cost: 0.62693s, reader_cost: 0.01364, ips: 102.08556 samples/s, eta: 7:31:37
[2022/06/18 22:51:06] ppcls INFO: [Train][Epoch 48/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08459074, top1: 0.86550, CELoss: 0.37954, loss: 0.37954, batch_cost: 0.61942s, reader_cost: 0.01334, ips: 103.32281 samples/s, eta: 7:26:06
[2022/06/18 22:51:12] ppcls INFO: [Train][Epoch 48/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08457763, top1: 0.86117, CELoss: 0.39019, loss: 0.39019, batch_cost: 0.62148s, reader_cost: 0.01357, ips: 102.98049 samples/s, eta: 7:27:29
[2022/06/18 22:51:18] ppcls INFO: [Train][Epoch 48/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08456451, top1: 0.86004, CELoss: 0.39410, loss: 0.39410, batch_cost: 0.61790s, reader_cost: 0.01265, ips: 103.57692 samples/s, eta: 7:24:48
[2022/06/18 22:51:25] ppcls INFO: [Train][Epoch 48/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08455137, top1: 0.85860, CELoss: 0.39776, loss: 0.39776, batch_cost: 0.62498s, reader_cost: 0.01284, ips: 102.40362 samples/s, eta: 7:29:48
[2022/06/18 22:51:30] ppcls INFO: [Train][Epoch 48/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08453822, top1: 0.85852, CELoss: 0.39947, loss: 0.39947, batch_cost: 0.61481s, reader_cost: 0.01292, ips: 104.09751 samples/s, eta: 7:22:23
[2022/06/18 22:51:36] ppcls INFO: [Train][Epoch 48/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08452505, top1: 0.85922, CELoss: 0.39654, loss: 0.39654, batch_cost: 0.61127s, reader_cost: 0.01385, ips: 104.70004 samples/s, eta: 7:19:44
[2022/06/18 22:51:43] ppcls INFO: [Train][Epoch 48/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08451187, top1: 0.86106, CELoss: 0.39710, loss: 0.39710, batch_cost: 0.61884s, reader_cost: 0.01396, ips: 103.41893 samples/s, eta: 7:25:04
[2022/06/18 22:51:48] ppcls INFO: [Train][Epoch 48/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08449868, top1: 0.85938, CELoss: 0.40146, loss: 0.40146, batch_cost: 0.61368s, reader_cost: 0.01318, ips: 104.28895 samples/s, eta: 7:21:15
[2022/06/18 22:51:54] ppcls INFO: [Train][Epoch 48/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08448546, top1: 0.85938, CELoss: 0.40222, loss: 0.40222, batch_cost: 0.60699s, reader_cost: 0.01325, ips: 105.43835 samples/s, eta: 7:16:21
[2022/06/18 22:52:00] ppcls INFO: [Train][Epoch 48/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08447224, top1: 0.85949, CELoss: 0.40625, loss: 0.40625, batch_cost: 0.61166s, reader_cost: 0.01236, ips: 104.63332 samples/s, eta: 7:19:36
[2022/06/18 22:52:07] ppcls INFO: [Train][Epoch 48/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08445900, top1: 0.85927, CELoss: 0.40708, loss: 0.40708, batch_cost: 0.61762s, reader_cost: 0.01234, ips: 103.62371 samples/s, eta: 7:23:47
[2022/06/18 22:52:12] ppcls INFO: [Train][Epoch 48/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08444574, top1: 0.85908, CELoss: 0.40670, loss: 0.40670, batch_cost: 0.60496s, reader_cost: 0.01171, ips: 105.79257 samples/s, eta: 7:14:35
[2022/06/18 22:52:14] ppcls INFO: [Train][Epoch 48/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08443247, top1: 0.85946, CELoss: 0.40602, loss: 0.40602, batch_cost: 0.58100s, reader_cost: 0.01105, ips: 84.33783 samples/s, eta: 6:57:16
[2022/06/18 22:52:14] ppcls INFO: [Train][Epoch 48/300][Avg]top1: 0.85946, CELoss: 0.40602, loss: 0.40602
[2022/06/18 22:52:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:52:21] ppcls INFO: [Train][Epoch 49/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08443115, top1: 0.87500, CELoss: 0.32812, loss: 0.32812, batch_cost: 0.61516s, reader_cost: 0.03653, ips: 104.03766 samples/s, eta: 7:21:48
[2022/06/18 22:52:28] ppcls INFO: [Train][Epoch 49/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08441786, top1: 0.85795, CELoss: 0.40279, loss: 0.40279, batch_cost: 0.69704s, reader_cost: 0.08820, ips: 91.81661 samples/s, eta: 8:20:29
[2022/06/18 22:52:34] ppcls INFO: [Train][Epoch 49/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08440456, top1: 0.85491, CELoss: 0.41017, loss: 0.41017, batch_cost: 0.64770s, reader_cost: 0.04586, ips: 98.81060 samples/s, eta: 7:44:57
[2022/06/18 22:52:40] ppcls INFO: [Train][Epoch 49/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08439124, top1: 0.85938, CELoss: 0.40109, loss: 0.40109, batch_cost: 0.63423s, reader_cost: 0.03718, ips: 100.91046 samples/s, eta: 7:35:11
[2022/06/18 22:52:47] ppcls INFO: [Train][Epoch 49/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08437791, top1: 0.85899, CELoss: 0.39560, loss: 0.39560, batch_cost: 0.63898s, reader_cost: 0.02874, ips: 100.15981 samples/s, eta: 7:38:29
[2022/06/18 22:52:52] ppcls INFO: [Train][Epoch 49/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08436457, top1: 0.86029, CELoss: 0.39370, loss: 0.39370, batch_cost: 0.62741s, reader_cost: 0.02758, ips: 102.00621 samples/s, eta: 7:30:05
[2022/06/18 22:52:59] ppcls INFO: [Train][Epoch 49/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08435120, top1: 0.85758, CELoss: 0.39978, loss: 0.39978, batch_cost: 0.62781s, reader_cost: 0.02369, ips: 101.94161 samples/s, eta: 7:30:15
[2022/06/18 22:53:05] ppcls INFO: [Train][Epoch 49/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08433783, top1: 0.85893, CELoss: 0.39945, loss: 0.39945, batch_cost: 0.62234s, reader_cost: 0.02183, ips: 102.83772 samples/s, eta: 7:26:14
[2022/06/18 22:53:12] ppcls INFO: [Train][Epoch 49/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08432444, top1: 0.86169, CELoss: 0.39731, loss: 0.39731, batch_cost: 0.63375s, reader_cost: 0.01993, ips: 100.98559 samples/s, eta: 7:34:19
[2022/06/18 22:53:18] ppcls INFO: [Train][Epoch 49/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08431104, top1: 0.86195, CELoss: 0.39619, loss: 0.39619, batch_cost: 0.63084s, reader_cost: 0.01905, ips: 101.45203 samples/s, eta: 7:32:07
[2022/06/18 22:53:24] ppcls INFO: [Train][Epoch 49/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08429762, top1: 0.86510, CELoss: 0.38978, loss: 0.38978, batch_cost: 0.62692s, reader_cost: 0.01829, ips: 102.08614 samples/s, eta: 7:29:12
[2022/06/18 22:53:29] ppcls INFO: [Train][Epoch 49/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08428418, top1: 0.86557, CELoss: 0.38775, loss: 0.38775, batch_cost: 0.62231s, reader_cost: 0.01780, ips: 102.84292 samples/s, eta: 7:25:48
[2022/06/18 22:53:36] ppcls INFO: [Train][Epoch 49/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08427073, top1: 0.86738, CELoss: 0.38263, loss: 0.38263, batch_cost: 0.62369s, reader_cost: 0.01684, ips: 102.61473 samples/s, eta: 7:26:41
[2022/06/18 22:53:42] ppcls INFO: [Train][Epoch 49/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08425727, top1: 0.86737, CELoss: 0.38443, loss: 0.38443, batch_cost: 0.61963s, reader_cost: 0.01773, ips: 103.28776 samples/s, eta: 7:23:40
[2022/06/18 22:53:47] ppcls INFO: [Train][Epoch 49/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08424379, top1: 0.86835, CELoss: 0.38249, loss: 0.38249, batch_cost: 0.61669s, reader_cost: 0.01665, ips: 103.77933 samples/s, eta: 7:21:28
[2022/06/18 22:53:53] ppcls INFO: [Train][Epoch 49/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08423030, top1: 0.86693, CELoss: 0.38489, loss: 0.38489, batch_cost: 0.61616s, reader_cost: 0.01623, ips: 103.86895 samples/s, eta: 7:20:59
[2022/06/18 22:53:59] ppcls INFO: [Train][Epoch 49/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08421679, top1: 0.86607, CELoss: 0.38795, loss: 0.38795, batch_cost: 0.61167s, reader_cost: 0.01545, ips: 104.63106 samples/s, eta: 7:17:40
[2022/06/18 22:54:01] ppcls INFO: [Train][Epoch 49/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08420327, top1: 0.86540, CELoss: 0.39030, loss: 0.39030, batch_cost: 0.58759s, reader_cost: 0.01456, ips: 83.39144 samples/s, eta: 7:00:20
[2022/06/18 22:54:02] ppcls INFO: [Train][Epoch 49/300][Avg]top1: 0.86540, CELoss: 0.39030, loss: 0.39030
[2022/06/18 22:54:02] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:54:07] ppcls INFO: [Train][Epoch 50/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08420192, top1: 0.84375, CELoss: 0.58633, loss: 0.58633, batch_cost: 0.61812s, reader_cost: 0.04245, ips: 103.53957 samples/s, eta: 7:22:10
[2022/06/18 22:54:13] ppcls INFO: [Train][Epoch 50/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08418838, top1: 0.86932, CELoss: 0.34877, loss: 0.34877, batch_cost: 0.62155s, reader_cost: 0.00448, ips: 102.96767 samples/s, eta: 7:24:31
[2022/06/18 22:54:20] ppcls INFO: [Train][Epoch 50/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08417482, top1: 0.86310, CELoss: 0.36814, loss: 0.36814, batch_cost: 0.65962s, reader_cost: 0.07116, ips: 97.02573 samples/s, eta: 7:51:38
[2022/06/18 22:54:26] ppcls INFO: [Train][Epoch 50/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08416126, top1: 0.87198, CELoss: 0.34998, loss: 0.34998, batch_cost: 0.64051s, reader_cost: 0.05605, ips: 99.92100 samples/s, eta: 7:37:51
[2022/06/18 22:54:34] ppcls INFO: [Train][Epoch 50/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08414767, top1: 0.86662, CELoss: 0.36054, loss: 0.36054, batch_cost: 0.67856s, reader_cost: 0.04131, ips: 94.31700 samples/s, eta: 8:04:57
[2022/06/18 22:54:40] ppcls INFO: [Train][Epoch 50/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08413408, top1: 0.86366, CELoss: 0.37470, loss: 0.37470, batch_cost: 0.65128s, reader_cost: 0.03247, ips: 98.26814 samples/s, eta: 7:45:20
[2022/06/18 22:54:46] ppcls INFO: [Train][Epoch 50/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08412046, top1: 0.86475, CELoss: 0.37857, loss: 0.37857, batch_cost: 0.64891s, reader_cost: 0.02818, ips: 98.62682 samples/s, eta: 7:43:32
[2022/06/18 22:54:52] ppcls INFO: [Train][Epoch 50/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08410684, top1: 0.86752, CELoss: 0.37139, loss: 0.37139, batch_cost: 0.63380s, reader_cost: 0.02645, ips: 100.97770 samples/s, eta: 7:32:39
[2022/06/18 22:54:58] ppcls INFO: [Train][Epoch 50/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08409320, top1: 0.86439, CELoss: 0.37891, loss: 0.37891, batch_cost: 0.63494s, reader_cost: 0.02474, ips: 100.79709 samples/s, eta: 7:33:21
[2022/06/18 22:55:04] ppcls INFO: [Train][Epoch 50/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08407954, top1: 0.86538, CELoss: 0.37911, loss: 0.37911, batch_cost: 0.62969s, reader_cost: 0.02424, ips: 101.63726 samples/s, eta: 7:29:30
[2022/06/18 22:55:10] ppcls INFO: [Train][Epoch 50/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08406587, top1: 0.86494, CELoss: 0.38000, loss: 0.38000, batch_cost: 0.62952s, reader_cost: 0.02316, ips: 101.66492 samples/s, eta: 7:29:16
[2022/06/18 22:55:15] ppcls INFO: [Train][Epoch 50/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08405218, top1: 0.86726, CELoss: 0.37420, loss: 0.37420, batch_cost: 0.61821s, reader_cost: 0.02479, ips: 103.52535 samples/s, eta: 7:21:06
[2022/06/18 22:55:21] ppcls INFO: [Train][Epoch 50/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08403848, top1: 0.86699, CELoss: 0.37386, loss: 0.37386, batch_cost: 0.61229s, reader_cost: 0.02391, ips: 104.52539 samples/s, eta: 7:16:46
[2022/06/18 22:55:27] ppcls INFO: [Train][Epoch 50/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08402477, top1: 0.86749, CELoss: 0.37355, loss: 0.37355, batch_cost: 0.61395s, reader_cost: 0.02897, ips: 104.24278 samples/s, eta: 7:17:51
[2022/06/18 22:55:33] ppcls INFO: [Train][Epoch 50/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08401104, top1: 0.86746, CELoss: 0.37387, loss: 0.37387, batch_cost: 0.61420s, reader_cost: 0.03554, ips: 104.20027 samples/s, eta: 7:17:56
[2022/06/18 22:55:40] ppcls INFO: [Train][Epoch 50/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08399730, top1: 0.86755, CELoss: 0.37244, loss: 0.37244, batch_cost: 0.62069s, reader_cost: 0.03614, ips: 103.11107 samples/s, eta: 7:22:27
[2022/06/18 22:55:45] ppcls INFO: [Train][Epoch 50/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08398354, top1: 0.86627, CELoss: 0.37641, loss: 0.37641, batch_cost: 0.60884s, reader_cost: 0.03485, ips: 105.11724 samples/s, eta: 7:13:54
[2022/06/18 22:55:47] ppcls INFO: [Train][Epoch 50/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08396977, top1: 0.86586, CELoss: 0.37501, loss: 0.37501, batch_cost: 0.58474s, reader_cost: 0.03278, ips: 83.79783 samples/s, eta: 6:56:38
[2022/06/18 22:55:47] ppcls INFO: [Train][Epoch 50/300][Avg]top1: 0.86586, CELoss: 0.37501, loss: 0.37501
[2022/06/18 22:55:54] ppcls INFO: [Eval][Epoch 50][Iter: 0/16]CELoss: 0.72481, loss: 0.72481, top1: 0.75000, batch_cost: 6.87733s, reader_cost: 3.57523, ips: 9.30594 images/sec
[2022/06/18 22:56:02] ppcls INFO: [Eval][Epoch 50][Iter: 10/16]CELoss: 0.78129, loss: 0.78129, top1: 0.74077, batch_cost: 0.62415s, reader_cost: 0.00173, ips: 102.53890 images/sec
[2022/06/18 22:56:04] ppcls INFO: [Eval][Epoch 50][Avg]CELoss: 0.70962, loss: 0.70962, top1: 0.75306
[2022/06/18 22:56:04] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 22:56:04] ppcls INFO: [Eval][Epoch 50][best metric: 0.7530637979507446]
[2022/06/18 22:56:04] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_50
[2022/06/18 22:56:04] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:56:10] ppcls INFO: [Train][Epoch 51/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08396839, top1: 0.93750, CELoss: 0.28007, loss: 0.28007, batch_cost: 0.61710s, reader_cost: 0.06541, ips: 103.71029 samples/s, eta: 7:19:41
[2022/06/18 22:56:17] ppcls INFO: [Train][Epoch 51/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08395460, top1: 0.88210, CELoss: 0.36334, loss: 0.36334, batch_cost: 0.79938s, reader_cost: 0.01426, ips: 80.06203 samples/s, eta: 9:29:25
[2022/06/18 22:56:23] ppcls INFO: [Train][Epoch 51/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08394079, top1: 0.87574, CELoss: 0.38093, loss: 0.38093, batch_cost: 0.64944s, reader_cost: 0.00750, ips: 98.54694 samples/s, eta: 7:42:30
[2022/06/18 22:56:30] ppcls INFO: [Train][Epoch 51/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08392698, top1: 0.87853, CELoss: 0.36529, loss: 0.36529, batch_cost: 0.65779s, reader_cost: 0.02891, ips: 97.29524 samples/s, eta: 7:48:20
[2022/06/18 22:56:36] ppcls INFO: [Train][Epoch 51/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08391314, top1: 0.87500, CELoss: 0.36705, loss: 0.36705, batch_cost: 0.64696s, reader_cost: 0.02160, ips: 98.92436 samples/s, eta: 7:40:31
[2022/06/18 22:56:42] ppcls INFO: [Train][Epoch 51/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08389930, top1: 0.87163, CELoss: 0.37363, loss: 0.37363, batch_cost: 0.64746s, reader_cost: 0.01725, ips: 98.84709 samples/s, eta: 7:40:46
[2022/06/18 22:56:49] ppcls INFO: [Train][Epoch 51/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08388543, top1: 0.87141, CELoss: 0.37821, loss: 0.37821, batch_cost: 0.65050s, reader_cost: 0.01592, ips: 98.38534 samples/s, eta: 7:42:49
[2022/06/18 22:56:54] ppcls INFO: [Train][Epoch 51/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08387156, top1: 0.86906, CELoss: 0.38268, loss: 0.38268, batch_cost: 0.62873s, reader_cost: 0.01400, ips: 101.79274 samples/s, eta: 7:27:14
[2022/06/18 22:57:01] ppcls INFO: [Train][Epoch 51/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08385767, top1: 0.86806, CELoss: 0.38326, loss: 0.38326, batch_cost: 0.63044s, reader_cost: 0.01285, ips: 101.51687 samples/s, eta: 7:28:20
[2022/06/18 22:57:06] ppcls INFO: [Train][Epoch 51/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08384376, top1: 0.86779, CELoss: 0.38528, loss: 0.38528, batch_cost: 0.61951s, reader_cost: 0.01325, ips: 103.30765 samples/s, eta: 7:20:28
[2022/06/18 22:57:11] ppcls INFO: [Train][Epoch 51/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08382984, top1: 0.87020, CELoss: 0.37932, loss: 0.37932, batch_cost: 0.61048s, reader_cost: 0.01348, ips: 104.83609 samples/s, eta: 7:13:56
[2022/06/18 22:57:18] ppcls INFO: [Train][Epoch 51/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08381590, top1: 0.86909, CELoss: 0.37820, loss: 0.37820, batch_cost: 0.61591s, reader_cost: 0.01224, ips: 103.91188 samples/s, eta: 7:17:42
[2022/06/18 22:57:24] ppcls INFO: [Train][Epoch 51/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08380195, top1: 0.86841, CELoss: 0.37931, loss: 0.37931, batch_cost: 0.61100s, reader_cost: 0.01269, ips: 104.74559 samples/s, eta: 7:14:07
[2022/06/18 22:57:30] ppcls INFO: [Train][Epoch 51/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08378799, top1: 0.86951, CELoss: 0.37653, loss: 0.37653, batch_cost: 0.61350s, reader_cost: 0.01178, ips: 104.31928 samples/s, eta: 7:15:47
[2022/06/18 22:57:37] ppcls INFO: [Train][Epoch 51/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08377401, top1: 0.86968, CELoss: 0.37454, loss: 0.37454, batch_cost: 0.61685s, reader_cost: 0.01610, ips: 103.75322 samples/s, eta: 7:18:03
[2022/06/18 22:57:42] ppcls INFO: [Train][Epoch 51/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08376002, top1: 0.86869, CELoss: 0.37535, loss: 0.37535, batch_cost: 0.61435s, reader_cost: 0.01605, ips: 104.17477 samples/s, eta: 7:16:11
[2022/06/18 22:57:48] ppcls INFO: [Train][Epoch 51/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08374601, top1: 0.86685, CELoss: 0.37929, loss: 0.37929, batch_cost: 0.60842s, reader_cost: 0.01661, ips: 105.19081 samples/s, eta: 7:11:52
[2022/06/18 22:57:50] ppcls INFO: [Train][Epoch 51/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08373199, top1: 0.86678, CELoss: 0.38026, loss: 0.38026, batch_cost: 0.58413s, reader_cost: 0.01561, ips: 83.88608 samples/s, eta: 6:54:32
[2022/06/18 22:57:50] ppcls INFO: [Train][Epoch 51/300][Avg]top1: 0.86678, CELoss: 0.38026, loss: 0.38026
[2022/06/18 22:57:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:57:57] ppcls INFO: [Train][Epoch 52/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08373059, top1: 0.87500, CELoss: 0.28841, loss: 0.28841, batch_cost: 0.61868s, reader_cost: 0.04998, ips: 103.44543 samples/s, eta: 7:19:02
[2022/06/18 22:58:04] ppcls INFO: [Train][Epoch 52/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08371655, top1: 0.86080, CELoss: 0.39300, loss: 0.39300, batch_cost: 0.71534s, reader_cost: 0.14551, ips: 89.46747 samples/s, eta: 8:27:31
[2022/06/18 22:58:10] ppcls INFO: [Train][Epoch 52/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08370249, top1: 0.87128, CELoss: 0.37589, loss: 0.37589, batch_cost: 0.67292s, reader_cost: 0.13791, ips: 95.10753 samples/s, eta: 7:57:18
[2022/06/18 22:58:16] ppcls INFO: [Train][Epoch 52/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08368843, top1: 0.86542, CELoss: 0.38758, loss: 0.38758, batch_cost: 0.63376s, reader_cost: 0.08748, ips: 100.98410 samples/s, eta: 7:29:25
[2022/06/18 22:58:22] ppcls INFO: [Train][Epoch 52/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08367435, top1: 0.86319, CELoss: 0.38540, loss: 0.38540, batch_cost: 0.62183s, reader_cost: 0.06933, ips: 102.92232 samples/s, eta: 7:20:51
[2022/06/18 22:58:28] ppcls INFO: [Train][Epoch 52/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08366025, top1: 0.86183, CELoss: 0.38823, loss: 0.38823, batch_cost: 0.62763s, reader_cost: 0.08213, ips: 101.97110 samples/s, eta: 7:24:52
[2022/06/18 22:58:35] ppcls INFO: [Train][Epoch 52/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08364614, top1: 0.86603, CELoss: 0.38247, loss: 0.38247, batch_cost: 0.63503s, reader_cost: 0.07038, ips: 100.78230 samples/s, eta: 7:30:00
[2022/06/18 22:58:40] ppcls INFO: [Train][Epoch 52/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08363201, top1: 0.86180, CELoss: 0.39279, loss: 0.39279, batch_cost: 0.61622s, reader_cost: 0.06181, ips: 103.85984 samples/s, eta: 7:16:34
[2022/06/18 22:58:46] ppcls INFO: [Train][Epoch 52/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08361787, top1: 0.86400, CELoss: 0.38926, loss: 0.38926, batch_cost: 0.61572s, reader_cost: 0.05645, ips: 103.94347 samples/s, eta: 7:16:07
[2022/06/18 22:58:52] ppcls INFO: [Train][Epoch 52/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08360372, top1: 0.86384, CELoss: 0.38763, loss: 0.38763, batch_cost: 0.60909s, reader_cost: 0.05059, ips: 105.07562 samples/s, eta: 7:11:19
[2022/06/18 22:58:59] ppcls INFO: [Train][Epoch 52/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08358955, top1: 0.86479, CELoss: 0.38609, loss: 0.38609, batch_cost: 0.62146s, reader_cost: 0.06192, ips: 102.98284 samples/s, eta: 7:19:59
[2022/06/18 22:59:06] ppcls INFO: [Train][Epoch 52/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08357537, top1: 0.86515, CELoss: 0.38589, loss: 0.38589, batch_cost: 0.62608s, reader_cost: 0.07091, ips: 102.22350 samples/s, eta: 7:23:08
[2022/06/18 22:59:11] ppcls INFO: [Train][Epoch 52/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08356117, top1: 0.86764, CELoss: 0.38264, loss: 0.38264, batch_cost: 0.62111s, reader_cost: 0.06826, ips: 103.04123 samples/s, eta: 7:19:31
[2022/06/18 22:59:17] ppcls INFO: [Train][Epoch 52/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08354696, top1: 0.86605, CELoss: 0.38632, loss: 0.38632, batch_cost: 0.61709s, reader_cost: 0.06396, ips: 103.71338 samples/s, eta: 7:16:34
[2022/06/18 22:59:23] ppcls INFO: [Train][Epoch 52/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08353273, top1: 0.86536, CELoss: 0.38868, loss: 0.38868, batch_cost: 0.61808s, reader_cost: 0.05958, ips: 103.54682 samples/s, eta: 7:17:10
[2022/06/18 22:59:29] ppcls INFO: [Train][Epoch 52/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08351849, top1: 0.86651, CELoss: 0.38551, loss: 0.38551, batch_cost: 0.61470s, reader_cost: 0.05805, ips: 104.11559 samples/s, eta: 7:14:41
[2022/06/18 22:59:34] ppcls INFO: [Train][Epoch 52/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08350423, top1: 0.86646, CELoss: 0.38552, loss: 0.38552, batch_cost: 0.61032s, reader_cost: 0.05783, ips: 104.86345 samples/s, eta: 7:11:29
[2022/06/18 22:59:36] ppcls INFO: [Train][Epoch 52/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08348996, top1: 0.86678, CELoss: 0.38457, loss: 0.38457, batch_cost: 0.58588s, reader_cost: 0.05444, ips: 83.63467 samples/s, eta: 6:54:06
[2022/06/18 22:59:37] ppcls INFO: [Train][Epoch 52/300][Avg]top1: 0.86678, CELoss: 0.38457, loss: 0.38457
[2022/06/18 22:59:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 22:59:43] ppcls INFO: [Train][Epoch 53/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08348854, top1: 0.87500, CELoss: 0.48092, loss: 0.48092, batch_cost: 0.61760s, reader_cost: 0.08448, ips: 103.62725 samples/s, eta: 7:16:31
[2022/06/18 22:59:51] ppcls INFO: [Train][Epoch 53/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08347425, top1: 0.87500, CELoss: 0.34271, loss: 0.34271, batch_cost: 0.85165s, reader_cost: 0.35431, ips: 75.14792 samples/s, eta: 10:01:48
[2022/06/18 22:59:58] ppcls INFO: [Train][Epoch 53/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08345995, top1: 0.86905, CELoss: 0.37198, loss: 0.37198, batch_cost: 0.73295s, reader_cost: 0.14520, ips: 87.31888 samples/s, eta: 8:37:48
[2022/06/18 23:00:03] ppcls INFO: [Train][Epoch 53/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08344564, top1: 0.86542, CELoss: 0.38060, loss: 0.38060, batch_cost: 0.67662s, reader_cost: 0.09892, ips: 94.58839 samples/s, eta: 7:57:53
[2022/06/18 23:00:10] ppcls INFO: [Train][Epoch 53/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08343131, top1: 0.86662, CELoss: 0.38014, loss: 0.38014, batch_cost: 0.66365s, reader_cost: 0.07895, ips: 96.43658 samples/s, eta: 7:48:37
[2022/06/18 23:00:16] ppcls INFO: [Train][Epoch 53/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08341696, top1: 0.86979, CELoss: 0.37510, loss: 0.37510, batch_cost: 0.65431s, reader_cost: 0.06572, ips: 97.81359 samples/s, eta: 7:41:55
[2022/06/18 23:00:21] ppcls INFO: [Train][Epoch 53/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08340261, top1: 0.87065, CELoss: 0.37068, loss: 0.37068, batch_cost: 0.63203s, reader_cost: 0.05752, ips: 101.26100 samples/s, eta: 7:26:05
[2022/06/18 23:00:28] ppcls INFO: [Train][Epoch 53/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08338823, top1: 0.87082, CELoss: 0.37169, loss: 0.37169, batch_cost: 0.63202s, reader_cost: 0.05117, ips: 101.26301 samples/s, eta: 7:25:58
[2022/06/18 23:00:34] ppcls INFO: [Train][Epoch 53/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08337385, top1: 0.86863, CELoss: 0.38169, loss: 0.38169, batch_cost: 0.62880s, reader_cost: 0.04638, ips: 101.78111 samples/s, eta: 7:23:35
[2022/06/18 23:00:40] ppcls INFO: [Train][Epoch 53/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08335945, top1: 0.86573, CELoss: 0.38433, loss: 0.38433, batch_cost: 0.63347s, reader_cost: 0.04454, ips: 101.03032 samples/s, eta: 7:26:47
[2022/06/18 23:00:46] ppcls INFO: [Train][Epoch 53/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08334503, top1: 0.86634, CELoss: 0.38579, loss: 0.38579, batch_cost: 0.62996s, reader_cost: 0.04134, ips: 101.59374 samples/s, eta: 7:24:12
[2022/06/18 23:00:52] ppcls INFO: [Train][Epoch 53/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08333060, top1: 0.86346, CELoss: 0.39051, loss: 0.39051, batch_cost: 0.62074s, reader_cost: 0.03876, ips: 103.10241 samples/s, eta: 7:17:36
[2022/06/18 23:00:58] ppcls INFO: [Train][Epoch 53/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08331616, top1: 0.86454, CELoss: 0.38814, loss: 0.38814, batch_cost: 0.62151s, reader_cost: 0.03636, ips: 102.97439 samples/s, eta: 7:18:02
[2022/06/18 23:01:03] ppcls INFO: [Train][Epoch 53/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08330170, top1: 0.86546, CELoss: 0.38652, loss: 0.38652, batch_cost: 0.61349s, reader_cost: 0.03509, ips: 104.32167 samples/s, eta: 7:12:17
[2022/06/18 23:01:11] ppcls INFO: [Train][Epoch 53/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08328722, top1: 0.86547, CELoss: 0.38648, loss: 0.38648, batch_cost: 0.62209s, reader_cost: 0.03316, ips: 102.87933 samples/s, eta: 7:18:14
[2022/06/18 23:01:17] ppcls INFO: [Train][Epoch 53/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08327274, top1: 0.86403, CELoss: 0.38949, loss: 0.38949, batch_cost: 0.62188s, reader_cost: 0.03193, ips: 102.91355 samples/s, eta: 7:17:59
[2022/06/18 23:01:21] ppcls INFO: [Train][Epoch 53/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08325824, top1: 0.86510, CELoss: 0.38668, loss: 0.38668, batch_cost: 0.61237s, reader_cost: 0.03034, ips: 104.51124 samples/s, eta: 7:11:11
[2022/06/18 23:01:24] ppcls INFO: [Train][Epoch 53/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08324372, top1: 0.86421, CELoss: 0.38912, loss: 0.38912, batch_cost: 0.58818s, reader_cost: 0.02852, ips: 83.30760 samples/s, eta: 6:54:03
[2022/06/18 23:01:24] ppcls INFO: [Train][Epoch 53/300][Avg]top1: 0.86421, CELoss: 0.38912, loss: 0.38912
[2022/06/18 23:01:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:01:30] ppcls INFO: [Train][Epoch 54/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08324227, top1: 0.82812, CELoss: 0.48655, loss: 0.48655, batch_cost: 0.62066s, reader_cost: 0.05955, ips: 103.11552 samples/s, eta: 7:16:54
[2022/06/18 23:01:36] ppcls INFO: [Train][Epoch 54/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08322773, top1: 0.86080, CELoss: 0.39855, loss: 0.39855, batch_cost: 0.56444s, reader_cost: 0.02483, ips: 113.38711 samples/s, eta: 6:37:14
[2022/06/18 23:01:43] ppcls INFO: [Train][Epoch 54/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08321319, top1: 0.86905, CELoss: 0.37116, loss: 0.37116, batch_cost: 0.61140s, reader_cost: 0.01488, ips: 104.67727 samples/s, eta: 7:10:11
[2022/06/18 23:01:50] ppcls INFO: [Train][Epoch 54/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08319863, top1: 0.87097, CELoss: 0.37080, loss: 0.37080, batch_cost: 0.64938s, reader_cost: 0.01603, ips: 98.55508 samples/s, eta: 7:36:48
[2022/06/18 23:01:56] ppcls INFO: [Train][Epoch 54/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08318405, top1: 0.86776, CELoss: 0.38242, loss: 0.38242, batch_cost: 0.64129s, reader_cost: 0.01395, ips: 99.79878 samples/s, eta: 7:31:00
[2022/06/18 23:02:02] ppcls INFO: [Train][Epoch 54/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08316946, top1: 0.86887, CELoss: 0.37231, loss: 0.37231, batch_cost: 0.62801s, reader_cost: 0.01219, ips: 101.90925 samples/s, eta: 7:21:33
[2022/06/18 23:02:08] ppcls INFO: [Train][Epoch 54/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08315486, top1: 0.87295, CELoss: 0.36333, loss: 0.36333, batch_cost: 0.63154s, reader_cost: 0.01127, ips: 101.33958 samples/s, eta: 7:23:56
[2022/06/18 23:02:14] ppcls INFO: [Train][Epoch 54/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08314024, top1: 0.87346, CELoss: 0.36370, loss: 0.36370, batch_cost: 0.62564s, reader_cost: 0.01480, ips: 102.29485 samples/s, eta: 7:19:41
[2022/06/18 23:02:20] ppcls INFO: [Train][Epoch 54/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08312561, top1: 0.87172, CELoss: 0.36326, loss: 0.36326, batch_cost: 0.61564s, reader_cost: 0.01577, ips: 103.95747 samples/s, eta: 7:12:33
[2022/06/18 23:02:25] ppcls INFO: [Train][Epoch 54/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08311096, top1: 0.87191, CELoss: 0.36605, loss: 0.36605, batch_cost: 0.61010s, reader_cost: 0.01649, ips: 104.90148 samples/s, eta: 7:08:33
[2022/06/18 23:02:30] ppcls INFO: [Train][Epoch 54/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08309630, top1: 0.87082, CELoss: 0.36966, loss: 0.36966, batch_cost: 0.59868s, reader_cost: 0.01550, ips: 106.90119 samples/s, eta: 7:00:26
[2022/06/18 23:02:37] ppcls INFO: [Train][Epoch 54/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08308163, top1: 0.87148, CELoss: 0.36886, loss: 0.36886, batch_cost: 0.60726s, reader_cost: 0.01496, ips: 105.39067 samples/s, eta: 7:06:22
[2022/06/18 23:02:43] ppcls INFO: [Train][Epoch 54/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08306694, top1: 0.87242, CELoss: 0.36906, loss: 0.36906, batch_cost: 0.60241s, reader_cost: 0.01478, ips: 106.23972 samples/s, eta: 7:02:51
[2022/06/18 23:02:49] ppcls INFO: [Train][Epoch 54/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08305224, top1: 0.87333, CELoss: 0.36834, loss: 0.36834, batch_cost: 0.60303s, reader_cost: 0.01497, ips: 106.13067 samples/s, eta: 7:03:11
[2022/06/18 23:02:57] ppcls INFO: [Train][Epoch 54/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08303752, top1: 0.87345, CELoss: 0.36881, loss: 0.36881, batch_cost: 0.61659s, reader_cost: 0.01425, ips: 103.79712 samples/s, eta: 7:12:36
[2022/06/18 23:03:02] ppcls INFO: [Train][Epoch 54/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08302279, top1: 0.87179, CELoss: 0.37195, loss: 0.37195, batch_cost: 0.61065s, reader_cost: 0.01371, ips: 104.80561 samples/s, eta: 7:08:20
[2022/06/18 23:03:07] ppcls INFO: [Train][Epoch 54/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08300804, top1: 0.87102, CELoss: 0.37281, loss: 0.37281, batch_cost: 0.60401s, reader_cost: 0.01314, ips: 105.95828 samples/s, eta: 7:03:34
[2022/06/18 23:03:09] ppcls INFO: [Train][Epoch 54/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08299328, top1: 0.87144, CELoss: 0.37197, loss: 0.37197, batch_cost: 0.57994s, reader_cost: 0.01237, ips: 84.49129 samples/s, eta: 6:46:36
[2022/06/18 23:03:10] ppcls INFO: [Train][Epoch 54/300][Avg]top1: 0.87144, CELoss: 0.37197, loss: 0.37197
[2022/06/18 23:03:10] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:03:15] ppcls INFO: [Train][Epoch 55/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08299180, top1: 0.90625, CELoss: 0.31795, loss: 0.31795, batch_cost: 0.61099s, reader_cost: 0.04143, ips: 104.74868 samples/s, eta: 7:08:21
[2022/06/18 23:03:23] ppcls INFO: [Train][Epoch 55/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08297703, top1: 0.86790, CELoss: 0.38702, loss: 0.38702, batch_cost: 0.66749s, reader_cost: 0.01534, ips: 95.88122 samples/s, eta: 7:47:52
[2022/06/18 23:03:29] ppcls INFO: [Train][Epoch 55/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08296224, top1: 0.87500, CELoss: 0.37263, loss: 0.37263, batch_cost: 0.61920s, reader_cost: 0.00952, ips: 103.35922 samples/s, eta: 7:13:54
[2022/06/18 23:03:34] ppcls INFO: [Train][Epoch 55/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08294743, top1: 0.86694, CELoss: 0.37348, loss: 0.37348, batch_cost: 0.58552s, reader_cost: 0.01444, ips: 109.30485 samples/s, eta: 6:50:12
[2022/06/18 23:03:41] ppcls INFO: [Train][Epoch 55/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08293261, top1: 0.86509, CELoss: 0.37270, loss: 0.37270, batch_cost: 0.62017s, reader_cost: 0.01759, ips: 103.19821 samples/s, eta: 7:14:23
[2022/06/18 23:03:47] ppcls INFO: [Train][Epoch 55/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08291778, top1: 0.86703, CELoss: 0.36590, loss: 0.36590, batch_cost: 0.61109s, reader_cost: 0.01924, ips: 104.73137 samples/s, eta: 7:07:55
[2022/06/18 23:03:53] ppcls INFO: [Train][Epoch 55/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08290293, top1: 0.87141, CELoss: 0.35598, loss: 0.35598, batch_cost: 0.60395s, reader_cost: 0.01948, ips: 105.96889 samples/s, eta: 7:02:49
[2022/06/18 23:03:59] ppcls INFO: [Train][Epoch 55/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08288807, top1: 0.87170, CELoss: 0.35348, loss: 0.35348, batch_cost: 0.60162s, reader_cost: 0.02022, ips: 106.38013 samples/s, eta: 7:01:05
[2022/06/18 23:04:05] ppcls INFO: [Train][Epoch 55/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08287320, top1: 0.87056, CELoss: 0.36030, loss: 0.36030, batch_cost: 0.60420s, reader_cost: 0.01946, ips: 105.92583 samples/s, eta: 7:02:47
[2022/06/18 23:04:10] ppcls INFO: [Train][Epoch 55/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08285831, top1: 0.87054, CELoss: 0.36162, loss: 0.36162, batch_cost: 0.59992s, reader_cost: 0.02005, ips: 106.68073 samples/s, eta: 6:59:42
[2022/06/18 23:04:17] ppcls INFO: [Train][Epoch 55/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08284340, top1: 0.86943, CELoss: 0.36413, loss: 0.36413, batch_cost: 0.60214s, reader_cost: 0.01993, ips: 106.28813 samples/s, eta: 7:01:09
[2022/06/18 23:04:25] ppcls INFO: [Train][Epoch 55/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08282848, top1: 0.86782, CELoss: 0.36925, loss: 0.36925, batch_cost: 0.62147s, reader_cost: 0.01948, ips: 102.98127 samples/s, eta: 7:14:34
[2022/06/18 23:04:29] ppcls INFO: [Train][Epoch 55/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08281355, top1: 0.86686, CELoss: 0.37236, loss: 0.37236, batch_cost: 0.60855s, reader_cost: 0.01907, ips: 105.16746 samples/s, eta: 7:05:26
[2022/06/18 23:04:34] ppcls INFO: [Train][Epoch 55/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08279860, top1: 0.86856, CELoss: 0.36889, loss: 0.36889, batch_cost: 0.59851s, reader_cost: 0.01818, ips: 106.93147 samples/s, eta: 6:58:19
[2022/06/18 23:04:41] ppcls INFO: [Train][Epoch 55/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08278364, top1: 0.86879, CELoss: 0.36731, loss: 0.36731, batch_cost: 0.60443s, reader_cost: 0.01817, ips: 105.88482 samples/s, eta: 7:02:21
[2022/06/18 23:04:47] ppcls INFO: [Train][Epoch 55/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08276867, top1: 0.86838, CELoss: 0.37008, loss: 0.37008, batch_cost: 0.60340s, reader_cost: 0.02027, ips: 106.06524 samples/s, eta: 7:01:32
[2022/06/18 23:04:52] ppcls INFO: [Train][Epoch 55/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08275368, top1: 0.86830, CELoss: 0.37001, loss: 0.37001, batch_cost: 0.59859s, reader_cost: 0.02153, ips: 106.91827 samples/s, eta: 6:58:04
[2022/06/18 23:04:55] ppcls INFO: [Train][Epoch 55/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08273867, top1: 0.86769, CELoss: 0.37074, loss: 0.37074, batch_cost: 0.57534s, reader_cost: 0.02024, ips: 85.16716 samples/s, eta: 6:41:44
[2022/06/18 23:04:55] ppcls INFO: [Train][Epoch 55/300][Avg]top1: 0.86769, CELoss: 0.37074, loss: 0.37074
[2022/06/18 23:05:02] ppcls INFO: [Eval][Epoch 55][Iter: 0/16]CELoss: 0.94588, loss: 0.94588, top1: 0.73438, batch_cost: 7.15197s, reader_cost: 3.60748, ips: 8.94858 images/sec
[2022/06/18 23:05:10] ppcls INFO: [Eval][Epoch 55][Iter: 10/16]CELoss: 0.75677, loss: 0.75677, top1: 0.75178, batch_cost: 0.57039s, reader_cost: 0.01096, ips: 112.20404 images/sec
[2022/06/18 23:05:12] ppcls INFO: [Eval][Epoch 55][Avg]CELoss: 0.71108, loss: 0.71108, top1: 0.76140
[2022/06/18 23:05:12] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 23:05:12] ppcls INFO: [Eval][Epoch 55][best metric: 0.761397123336792]
[2022/06/18 23:05:12] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:05:18] ppcls INFO: [Train][Epoch 56/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08273717, top1: 0.89062, CELoss: 0.24019, loss: 0.24019, batch_cost: 0.60813s, reader_cost: 0.04687, ips: 105.24095 samples/s, eta: 7:04:37
[2022/06/18 23:05:25] ppcls INFO: [Train][Epoch 56/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08272215, top1: 0.86222, CELoss: 0.39412, loss: 0.39412, batch_cost: 0.71965s, reader_cost: 0.01150, ips: 88.93169 samples/s, eta: 8:22:22
[2022/06/18 23:05:31] ppcls INFO: [Train][Epoch 56/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08270712, top1: 0.86458, CELoss: 0.38643, loss: 0.38643, batch_cost: 0.61987s, reader_cost: 0.00629, ips: 103.24736 samples/s, eta: 7:12:37
[2022/06/18 23:05:37] ppcls INFO: [Train][Epoch 56/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08269207, top1: 0.86643, CELoss: 0.38327, loss: 0.38327, batch_cost: 0.62444s, reader_cost: 0.00420, ips: 102.49176 samples/s, eta: 7:15:42
[2022/06/18 23:05:43] ppcls INFO: [Train][Epoch 56/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08267701, top1: 0.86700, CELoss: 0.37813, loss: 0.37813, batch_cost: 0.61697s, reader_cost: 0.00496, ips: 103.73203 samples/s, eta: 7:10:23
[2022/06/18 23:05:50] ppcls INFO: [Train][Epoch 56/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08266194, top1: 0.86765, CELoss: 0.37574, loss: 0.37574, batch_cost: 0.63045s, reader_cost: 0.00562, ips: 101.51520 samples/s, eta: 7:19:41
[2022/06/18 23:05:56] ppcls INFO: [Train][Epoch 56/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08264685, top1: 0.87295, CELoss: 0.36576, loss: 0.36576, batch_cost: 0.62340s, reader_cost: 0.00701, ips: 102.66323 samples/s, eta: 7:14:39
[2022/06/18 23:06:01] ppcls INFO: [Train][Epoch 56/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08263174, top1: 0.87148, CELoss: 0.36510, loss: 0.36510, batch_cost: 0.60799s, reader_cost: 0.00843, ips: 105.26528 samples/s, eta: 7:03:49
[2022/06/18 23:06:08] ppcls INFO: [Train][Epoch 56/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08261663, top1: 0.86998, CELoss: 0.36798, loss: 0.36798, batch_cost: 0.61080s, reader_cost: 0.01044, ips: 104.78105 samples/s, eta: 7:05:40
[2022/06/18 23:06:14] ppcls INFO: [Train][Epoch 56/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08260149, top1: 0.87019, CELoss: 0.36627, loss: 0.36627, batch_cost: 0.61619s, reader_cost: 0.00959, ips: 103.86485 samples/s, eta: 7:09:19
[2022/06/18 23:06:20] ppcls INFO: [Train][Epoch 56/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08258635, top1: 0.87191, CELoss: 0.36493, loss: 0.36493, batch_cost: 0.61158s, reader_cost: 0.00862, ips: 104.64719 samples/s, eta: 7:06:00
[2022/06/18 23:06:25] ppcls INFO: [Train][Epoch 56/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08257119, top1: 0.87176, CELoss: 0.36524, loss: 0.36524, batch_cost: 0.60654s, reader_cost: 0.00791, ips: 105.51585 samples/s, eta: 7:02:24
[2022/06/18 23:06:32] ppcls INFO: [Train][Epoch 56/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08255601, top1: 0.87242, CELoss: 0.36542, loss: 0.36542, batch_cost: 0.60780s, reader_cost: 0.00765, ips: 105.29848 samples/s, eta: 7:03:10
[2022/06/18 23:06:37] ppcls INFO: [Train][Epoch 56/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08254083, top1: 0.87369, CELoss: 0.36476, loss: 0.36476, batch_cost: 0.59934s, reader_cost: 0.00767, ips: 106.78399 samples/s, eta: 6:57:11
[2022/06/18 23:06:43] ppcls INFO: [Train][Epoch 56/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08252562, top1: 0.87445, CELoss: 0.36220, loss: 0.36220, batch_cost: 0.60311s, reader_cost: 0.00833, ips: 106.11615 samples/s, eta: 6:59:42
[2022/06/18 23:06:49] ppcls INFO: [Train][Epoch 56/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08251041, top1: 0.87459, CELoss: 0.36115, loss: 0.36115, batch_cost: 0.60555s, reader_cost: 0.00889, ips: 105.68887 samples/s, eta: 7:01:18
[2022/06/18 23:06:55] ppcls INFO: [Train][Epoch 56/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08249518, top1: 0.87257, CELoss: 0.36595, loss: 0.36595, batch_cost: 0.60104s, reader_cost: 0.00854, ips: 106.48289 samples/s, eta: 6:58:04
[2022/06/18 23:06:57] ppcls INFO: [Train][Epoch 56/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08247993, top1: 0.87254, CELoss: 0.36451, loss: 0.36451, batch_cost: 0.57761s, reader_cost: 0.00807, ips: 84.83230 samples/s, eta: 6:41:40
[2022/06/18 23:06:57] ppcls INFO: [Train][Epoch 56/300][Avg]top1: 0.87254, CELoss: 0.36451, loss: 0.36451
[2022/06/18 23:06:58] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:07:04] ppcls INFO: [Train][Epoch 57/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08247841, top1: 0.85938, CELoss: 0.48934, loss: 0.48934, batch_cost: 0.61007s, reader_cost: 0.03090, ips: 104.90626 samples/s, eta: 7:04:14
[2022/06/18 23:07:11] ppcls INFO: [Train][Epoch 57/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08246315, top1: 0.85511, CELoss: 0.41118, loss: 0.41118, batch_cost: 0.67956s, reader_cost: 0.01513, ips: 94.17928 samples/s, eta: 7:52:26
[2022/06/18 23:07:17] ppcls INFO: [Train][Epoch 57/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08244787, top1: 0.86905, CELoss: 0.38848, loss: 0.38848, batch_cost: 0.67408s, reader_cost: 0.01253, ips: 94.94475 samples/s, eta: 7:48:31
[2022/06/18 23:07:23] ppcls INFO: [Train][Epoch 57/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08243258, top1: 0.87550, CELoss: 0.37777, loss: 0.37777, batch_cost: 0.64471s, reader_cost: 0.01686, ips: 99.27018 samples/s, eta: 7:28:00
[2022/06/18 23:07:30] ppcls INFO: [Train][Epoch 57/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08241728, top1: 0.87652, CELoss: 0.36641, loss: 0.36641, batch_cost: 0.64743s, reader_cost: 0.01350, ips: 98.85229 samples/s, eta: 7:29:47
[2022/06/18 23:07:35] ppcls INFO: [Train][Epoch 57/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08240196, top1: 0.87745, CELoss: 0.36371, loss: 0.36371, batch_cost: 0.61951s, reader_cost: 0.01153, ips: 103.30696 samples/s, eta: 7:10:17
[2022/06/18 23:07:42] ppcls INFO: [Train][Epoch 57/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08238663, top1: 0.87859, CELoss: 0.35719, loss: 0.35719, batch_cost: 0.62819s, reader_cost: 0.01267, ips: 101.87992 samples/s, eta: 7:16:12
[2022/06/18 23:07:48] ppcls INFO: [Train][Epoch 57/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08237129, top1: 0.87214, CELoss: 0.36963, loss: 0.36963, batch_cost: 0.62835s, reader_cost: 0.01168, ips: 101.85435 samples/s, eta: 7:16:13
[2022/06/18 23:07:54] ppcls INFO: [Train][Epoch 57/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08235593, top1: 0.87751, CELoss: 0.35913, loss: 0.35913, batch_cost: 0.62579s, reader_cost: 0.01158, ips: 102.27121 samples/s, eta: 7:14:20
[2022/06/18 23:08:00] ppcls INFO: [Train][Epoch 57/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08234056, top1: 0.87912, CELoss: 0.35542, loss: 0.35542, batch_cost: 0.62391s, reader_cost: 0.01178, ips: 102.57887 samples/s, eta: 7:12:55
[2022/06/18 23:08:07] ppcls INFO: [Train][Epoch 57/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08232517, top1: 0.88072, CELoss: 0.35138, loss: 0.35138, batch_cost: 0.63093s, reader_cost: 0.01365, ips: 101.43799 samples/s, eta: 7:17:41
[2022/06/18 23:08:14] ppcls INFO: [Train][Epoch 57/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08230977, top1: 0.88091, CELoss: 0.35179, loss: 0.35179, batch_cost: 0.63378s, reader_cost: 0.01322, ips: 100.98155 samples/s, eta: 7:19:34
[2022/06/18 23:08:19] ppcls INFO: [Train][Epoch 57/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08229436, top1: 0.88249, CELoss: 0.34938, loss: 0.34938, batch_cost: 0.62814s, reader_cost: 0.01244, ips: 101.88832 samples/s, eta: 7:15:33
[2022/06/18 23:08:25] ppcls INFO: [Train][Epoch 57/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08227893, top1: 0.88240, CELoss: 0.34833, loss: 0.34833, batch_cost: 0.62035s, reader_cost: 0.01174, ips: 103.16739 samples/s, eta: 7:10:02
[2022/06/18 23:08:32] ppcls INFO: [Train][Epoch 57/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08226349, top1: 0.88010, CELoss: 0.35300, loss: 0.35300, batch_cost: 0.62687s, reader_cost: 0.01120, ips: 102.09519 samples/s, eta: 7:14:27
[2022/06/18 23:08:37] ppcls INFO: [Train][Epoch 57/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08224803, top1: 0.88007, CELoss: 0.35273, loss: 0.35273, batch_cost: 0.62305s, reader_cost: 0.01098, ips: 102.72040 samples/s, eta: 7:11:42
[2022/06/18 23:08:42] ppcls INFO: [Train][Epoch 57/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08223256, top1: 0.88092, CELoss: 0.35253, loss: 0.35253, batch_cost: 0.61399s, reader_cost: 0.01059, ips: 104.23581 samples/s, eta: 7:05:19
[2022/06/18 23:08:44] ppcls INFO: [Train][Epoch 57/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08221708, top1: 0.88169, CELoss: 0.35152, loss: 0.35152, batch_cost: 0.58946s, reader_cost: 0.00995, ips: 83.12645 samples/s, eta: 6:48:14
[2022/06/18 23:08:45] ppcls INFO: [Train][Epoch 57/300][Avg]top1: 0.88169, CELoss: 0.35152, loss: 0.35152
[2022/06/18 23:08:45] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:08:52] ppcls INFO: [Train][Epoch 58/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08221553, top1: 0.85938, CELoss: 0.40159, loss: 0.40159, batch_cost: 0.62567s, reader_cost: 0.04446, ips: 102.28974 samples/s, eta: 7:13:18
[2022/06/18 23:08:58] ppcls INFO: [Train][Epoch 58/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08220003, top1: 0.87784, CELoss: 0.33542, loss: 0.33542, batch_cost: 0.65384s, reader_cost: 0.01229, ips: 97.88365 samples/s, eta: 7:32:42
[2022/06/18 23:09:04] ppcls INFO: [Train][Epoch 58/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08218451, top1: 0.87723, CELoss: 0.35231, loss: 0.35231, batch_cost: 0.61250s, reader_cost: 0.00693, ips: 104.48966 samples/s, eta: 7:03:58
[2022/06/18 23:09:10] ppcls INFO: [Train][Epoch 58/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08216899, top1: 0.87651, CELoss: 0.35904, loss: 0.35904, batch_cost: 0.62397s, reader_cost: 0.00438, ips: 102.56918 samples/s, eta: 7:11:49
[2022/06/18 23:09:16] ppcls INFO: [Train][Epoch 58/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08215345, top1: 0.87652, CELoss: 0.35738, loss: 0.35738, batch_cost: 0.61121s, reader_cost: 0.00560, ips: 104.71089 samples/s, eta: 7:02:53
[2022/06/18 23:09:22] ppcls INFO: [Train][Epoch 58/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08213789, top1: 0.87531, CELoss: 0.36127, loss: 0.36127, batch_cost: 0.61502s, reader_cost: 0.00808, ips: 104.06177 samples/s, eta: 7:05:25
[2022/06/18 23:09:28] ppcls INFO: [Train][Epoch 58/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08212232, top1: 0.87449, CELoss: 0.36104, loss: 0.36104, batch_cost: 0.60725s, reader_cost: 0.00795, ips: 105.39234 samples/s, eta: 6:59:56
[2022/06/18 23:09:35] ppcls INFO: [Train][Epoch 58/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08210674, top1: 0.87808, CELoss: 0.35394, loss: 0.35394, batch_cost: 0.61351s, reader_cost: 0.00832, ips: 104.31756 samples/s, eta: 7:04:10
[2022/06/18 23:09:41] ppcls INFO: [Train][Epoch 58/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08209114, top1: 0.87751, CELoss: 0.35657, loss: 0.35657, batch_cost: 0.61570s, reader_cost: 0.00834, ips: 103.94737 samples/s, eta: 7:05:34
[2022/06/18 23:09:47] ppcls INFO: [Train][Epoch 58/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08207553, top1: 0.87637, CELoss: 0.35919, loss: 0.35919, batch_cost: 0.61034s, reader_cost: 0.00869, ips: 104.85925 samples/s, eta: 7:01:46
[2022/06/18 23:09:52] ppcls INFO: [Train][Epoch 58/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08205990, top1: 0.87717, CELoss: 0.35496, loss: 0.35496, batch_cost: 0.60622s, reader_cost: 0.00990, ips: 105.57181 samples/s, eta: 6:58:49
[2022/06/18 23:09:58] ppcls INFO: [Train][Epoch 58/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08204427, top1: 0.87810, CELoss: 0.35254, loss: 0.35254, batch_cost: 0.60206s, reader_cost: 0.00970, ips: 106.30136 samples/s, eta: 6:55:51
[2022/06/18 23:10:04] ppcls INFO: [Train][Epoch 58/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08202861, top1: 0.87797, CELoss: 0.35324, loss: 0.35324, batch_cost: 0.59928s, reader_cost: 0.01176, ips: 106.79464 samples/s, eta: 6:53:50
[2022/06/18 23:10:11] ppcls INFO: [Train][Epoch 58/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08201295, top1: 0.87750, CELoss: 0.35499, loss: 0.35499, batch_cost: 0.61097s, reader_cost: 0.01219, ips: 104.75182 samples/s, eta: 7:01:48
[2022/06/18 23:10:16] ppcls INFO: [Train][Epoch 58/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08199727, top1: 0.87677, CELoss: 0.35602, loss: 0.35602, batch_cost: 0.60441s, reader_cost: 0.01171, ips: 105.88836 samples/s, eta: 6:57:10
[2022/06/18 23:10:22] ppcls INFO: [Train][Epoch 58/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08198157, top1: 0.87748, CELoss: 0.35213, loss: 0.35213, batch_cost: 0.60143s, reader_cost: 0.01187, ips: 106.41218 samples/s, eta: 6:55:01
[2022/06/18 23:10:27] ppcls INFO: [Train][Epoch 58/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08196586, top1: 0.87568, CELoss: 0.35490, loss: 0.35490, batch_cost: 0.59847s, reader_cost: 0.01176, ips: 106.93979 samples/s, eta: 6:52:52
[2022/06/18 23:10:30] ppcls INFO: [Train][Epoch 58/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08195014, top1: 0.87620, CELoss: 0.35401, loss: 0.35401, batch_cost: 0.57741s, reader_cost: 0.01105, ips: 84.86225 samples/s, eta: 6:38:14
[2022/06/18 23:10:30] ppcls INFO: [Train][Epoch 58/300][Avg]top1: 0.87620, CELoss: 0.35401, loss: 0.35401
[2022/06/18 23:10:31] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:10:36] ppcls INFO: [Train][Epoch 59/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08194857, top1: 0.95312, CELoss: 0.27353, loss: 0.27353, batch_cost: 0.60949s, reader_cost: 0.03820, ips: 105.00642 samples/s, eta: 7:00:21
[2022/06/18 23:10:43] ppcls INFO: [Train][Epoch 59/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08193283, top1: 0.87074, CELoss: 0.40623, loss: 0.40623, batch_cost: 0.65091s, reader_cost: 0.00683, ips: 98.32342 samples/s, eta: 7:28:49
[2022/06/18 23:10:50] ppcls INFO: [Train][Epoch 59/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08191708, top1: 0.87277, CELoss: 0.38356, loss: 0.38356, batch_cost: 0.64479s, reader_cost: 0.02041, ips: 99.25645 samples/s, eta: 7:24:29
[2022/06/18 23:10:56] ppcls INFO: [Train][Epoch 59/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08190132, top1: 0.87298, CELoss: 0.37048, loss: 0.37048, batch_cost: 0.63467s, reader_cost: 0.01711, ips: 100.84018 samples/s, eta: 7:17:24
[2022/06/18 23:11:02] ppcls INFO: [Train][Epoch 59/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08188554, top1: 0.87309, CELoss: 0.37498, loss: 0.37498, batch_cost: 0.63390s, reader_cost: 0.01601, ips: 100.96188 samples/s, eta: 7:16:46
[2022/06/18 23:11:09] ppcls INFO: [Train][Epoch 59/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08186974, top1: 0.87224, CELoss: 0.37487, loss: 0.37487, batch_cost: 0.64588s, reader_cost: 0.01465, ips: 99.08888 samples/s, eta: 7:24:55
[2022/06/18 23:11:15] ppcls INFO: [Train][Epoch 59/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08185394, top1: 0.87474, CELoss: 0.36751, loss: 0.36751, batch_cost: 0.63596s, reader_cost: 0.01318, ips: 100.63490 samples/s, eta: 7:17:59
[2022/06/18 23:11:22] ppcls INFO: [Train][Epoch 59/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08183812, top1: 0.87500, CELoss: 0.36239, loss: 0.36239, batch_cost: 0.64691s, reader_cost: 0.01242, ips: 98.93176 samples/s, eta: 7:25:25
[2022/06/18 23:11:28] ppcls INFO: [Train][Epoch 59/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08182228, top1: 0.87596, CELoss: 0.36300, loss: 0.36300, batch_cost: 0.64320s, reader_cost: 0.01437, ips: 99.50262 samples/s, eta: 7:22:45
[2022/06/18 23:11:34] ppcls INFO: [Train][Epoch 59/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08180643, top1: 0.87586, CELoss: 0.36253, loss: 0.36253, batch_cost: 0.63857s, reader_cost: 0.01392, ips: 100.22348 samples/s, eta: 7:19:27
[2022/06/18 23:11:40] ppcls INFO: [Train][Epoch 59/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08179057, top1: 0.87515, CELoss: 0.36485, loss: 0.36485, batch_cost: 0.62913s, reader_cost: 0.01432, ips: 101.72796 samples/s, eta: 7:12:51
[2022/06/18 23:11:46] ppcls INFO: [Train][Epoch 59/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08177470, top1: 0.87528, CELoss: 0.36389, loss: 0.36389, batch_cost: 0.62941s, reader_cost: 0.01364, ips: 101.68283 samples/s, eta: 7:12:56
[2022/06/18 23:11:52] ppcls INFO: [Train][Epoch 59/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08175881, top1: 0.87397, CELoss: 0.36747, loss: 0.36747, batch_cost: 0.62492s, reader_cost: 0.01303, ips: 102.41366 samples/s, eta: 7:09:45
[2022/06/18 23:11:59] ppcls INFO: [Train][Epoch 59/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08174290, top1: 0.87464, CELoss: 0.36685, loss: 0.36685, batch_cost: 0.63236s, reader_cost: 0.01292, ips: 101.20796 samples/s, eta: 7:14:46
[2022/06/18 23:12:05] ppcls INFO: [Train][Epoch 59/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08172699, top1: 0.87533, CELoss: 0.36360, loss: 0.36360, batch_cost: 0.63082s, reader_cost: 0.01352, ips: 101.45468 samples/s, eta: 7:13:36
[2022/06/18 23:12:10] ppcls INFO: [Train][Epoch 59/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08171106, top1: 0.87614, CELoss: 0.36225, loss: 0.36225, batch_cost: 0.62244s, reader_cost: 0.01292, ips: 102.82089 samples/s, eta: 7:07:44
[2022/06/18 23:12:16] ppcls INFO: [Train][Epoch 59/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08169511, top1: 0.87519, CELoss: 0.36562, loss: 0.36562, batch_cost: 0.61928s, reader_cost: 0.01249, ips: 103.34617 samples/s, eta: 7:05:27
[2022/06/18 23:12:19] ppcls INFO: [Train][Epoch 59/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08167915, top1: 0.87538, CELoss: 0.36458, loss: 0.36458, batch_cost: 0.59681s, reader_cost: 0.01175, ips: 82.10384 samples/s, eta: 6:49:55
[2022/06/18 23:12:19] ppcls INFO: [Train][Epoch 59/300][Avg]top1: 0.87538, CELoss: 0.36458, loss: 0.36458
[2022/06/18 23:12:19] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:12:25] ppcls INFO: [Train][Epoch 60/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08167756, top1: 0.87500, CELoss: 0.34689, loss: 0.34689, batch_cost: 0.63005s, reader_cost: 0.04189, ips: 101.57886 samples/s, eta: 7:12:45
[2022/06/18 23:12:33] ppcls INFO: [Train][Epoch 60/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08166158, top1: 0.87216, CELoss: 0.35650, loss: 0.35650, batch_cost: 0.46607s, reader_cost: 0.01142, ips: 137.31856 samples/s, eta: 5:20:02
[2022/06/18 23:12:39] ppcls INFO: [Train][Epoch 60/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08164560, top1: 0.86905, CELoss: 0.35953, loss: 0.35953, batch_cost: 0.53000s, reader_cost: 0.01017, ips: 120.75446 samples/s, eta: 6:03:51
[2022/06/18 23:12:45] ppcls INFO: [Train][Epoch 60/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08162960, top1: 0.87198, CELoss: 0.35111, loss: 0.35111, batch_cost: 0.58078s, reader_cost: 0.01613, ips: 110.19617 samples/s, eta: 6:38:37
[2022/06/18 23:12:52] ppcls INFO: [Train][Epoch 60/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08161358, top1: 0.87538, CELoss: 0.35073, loss: 0.35073, batch_cost: 0.60278s, reader_cost: 0.01669, ips: 106.17542 samples/s, eta: 6:53:36
[2022/06/18 23:12:58] ppcls INFO: [Train][Epoch 60/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08159755, top1: 0.87224, CELoss: 0.35575, loss: 0.35575, batch_cost: 0.60660s, reader_cost: 0.01454, ips: 105.50692 samples/s, eta: 6:56:08
[2022/06/18 23:13:04] ppcls INFO: [Train][Epoch 60/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08158151, top1: 0.87090, CELoss: 0.35988, loss: 0.35988, batch_cost: 0.60715s, reader_cost: 0.01685, ips: 105.41103 samples/s, eta: 6:56:24
[2022/06/18 23:13:10] ppcls INFO: [Train][Epoch 60/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08156546, top1: 0.87368, CELoss: 0.35297, loss: 0.35297, batch_cost: 0.59849s, reader_cost: 0.01505, ips: 106.93498 samples/s, eta: 6:50:22
[2022/06/18 23:13:17] ppcls INFO: [Train][Epoch 60/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08154939, top1: 0.86902, CELoss: 0.36299, loss: 0.36299, batch_cost: 0.61185s, reader_cost: 0.01569, ips: 104.60086 samples/s, eta: 6:59:25
[2022/06/18 23:13:22] ppcls INFO: [Train][Epoch 60/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08153330, top1: 0.86933, CELoss: 0.36281, loss: 0.36281, batch_cost: 0.60551s, reader_cost: 0.01725, ips: 105.69584 samples/s, eta: 6:54:59
[2022/06/18 23:13:29] ppcls INFO: [Train][Epoch 60/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08151721, top1: 0.86928, CELoss: 0.36081, loss: 0.36081, batch_cost: 0.60826s, reader_cost: 0.01763, ips: 105.21748 samples/s, eta: 6:56:46
[2022/06/18 23:13:34] ppcls INFO: [Train][Epoch 60/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08150110, top1: 0.86993, CELoss: 0.36220, loss: 0.36220, batch_cost: 0.60273s, reader_cost: 0.01656, ips: 106.18275 samples/s, eta: 6:52:52
[2022/06/18 23:13:40] ppcls INFO: [Train][Epoch 60/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08148497, top1: 0.86893, CELoss: 0.36327, loss: 0.36327, batch_cost: 0.59976s, reader_cost: 0.01640, ips: 106.70958 samples/s, eta: 6:50:44
[2022/06/18 23:13:46] ppcls INFO: [Train][Epoch 60/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08146883, top1: 0.87059, CELoss: 0.36109, loss: 0.36109, batch_cost: 0.60320s, reader_cost: 0.01586, ips: 106.10085 samples/s, eta: 6:53:00
[2022/06/18 23:13:52] ppcls INFO: [Train][Epoch 60/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08145268, top1: 0.86957, CELoss: 0.36344, loss: 0.36344, batch_cost: 0.60161s, reader_cost: 0.01485, ips: 106.38154 samples/s, eta: 6:51:48
[2022/06/18 23:13:58] ppcls INFO: [Train][Epoch 60/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08143652, top1: 0.87159, CELoss: 0.35818, loss: 0.35818, batch_cost: 0.60312s, reader_cost: 0.01418, ips: 106.11554 samples/s, eta: 6:52:44
[2022/06/18 23:14:04] ppcls INFO: [Train][Epoch 60/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08142034, top1: 0.87238, CELoss: 0.35981, loss: 0.35981, batch_cost: 0.60022s, reader_cost: 0.01366, ips: 106.62677 samples/s, eta: 6:50:39
[2022/06/18 23:14:06] ppcls INFO: [Train][Epoch 60/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08140415, top1: 0.87217, CELoss: 0.35948, loss: 0.35948, batch_cost: 0.57672s, reader_cost: 0.01284, ips: 84.96384 samples/s, eta: 6:34:28
[2022/06/18 23:14:07] ppcls INFO: [Train][Epoch 60/300][Avg]top1: 0.87217, CELoss: 0.35948, loss: 0.35948
[2022/06/18 23:14:14] ppcls INFO: [Eval][Epoch 60][Iter: 0/16]CELoss: 0.81612, loss: 0.81612, top1: 0.72266, batch_cost: 7.00341s, reader_cost: 3.80689, ips: 9.13841 images/sec
[2022/06/18 23:14:22] ppcls INFO: [Eval][Epoch 60][Iter: 10/16]CELoss: 0.81169, loss: 0.81169, top1: 0.74183, batch_cost: 0.56196s, reader_cost: 0.00421, ips: 113.88653 images/sec
[2022/06/18 23:14:23] ppcls INFO: [Eval][Epoch 60][Avg]CELoss: 0.67284, loss: 0.67284, top1: 0.75233
[2022/06/18 23:14:23] ppcls INFO: [Eval][Epoch 60][best metric: 0.761397123336792]
[2022/06/18 23:14:23] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_60
[2022/06/18 23:14:23] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:14:32] ppcls INFO: [Train][Epoch 61/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08140253, top1: 0.87500, CELoss: 0.33014, loss: 0.33014, batch_cost: 0.62486s, reader_cost: 0.06119, ips: 102.42234 samples/s, eta: 7:07:24
[2022/06/18 23:14:37] ppcls INFO: [Train][Epoch 61/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08138632, top1: 0.88636, CELoss: 0.33290, loss: 0.33290, batch_cost: 0.51785s, reader_cost: 0.01737, ips: 123.58805 samples/s, eta: 5:54:07
[2022/06/18 23:14:42] ppcls INFO: [Train][Epoch 61/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08137010, top1: 0.88988, CELoss: 0.32447, loss: 0.32447, batch_cost: 0.54478s, reader_cost: 0.02404, ips: 117.47864 samples/s, eta: 6:12:26
[2022/06/18 23:14:50] ppcls INFO: [Train][Epoch 61/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08135386, top1: 0.88760, CELoss: 0.33300, loss: 0.33300, batch_cost: 0.63969s, reader_cost: 0.01875, ips: 100.04811 samples/s, eta: 7:17:13
[2022/06/18 23:14:55] ppcls INFO: [Train][Epoch 61/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08133761, top1: 0.88605, CELoss: 0.33566, loss: 0.33566, batch_cost: 0.59544s, reader_cost: 0.01640, ips: 107.48320 samples/s, eta: 6:46:53
[2022/06/18 23:15:01] ppcls INFO: [Train][Epoch 61/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08132135, top1: 0.88572, CELoss: 0.33905, loss: 0.33905, batch_cost: 0.60075s, reader_cost: 0.01542, ips: 106.53363 samples/s, eta: 6:50:24
[2022/06/18 23:15:08] ppcls INFO: [Train][Epoch 61/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08130507, top1: 0.88371, CELoss: 0.34627, loss: 0.34627, batch_cost: 0.60798s, reader_cost: 0.01402, ips: 105.26677 samples/s, eta: 6:55:14
[2022/06/18 23:15:13] ppcls INFO: [Train][Epoch 61/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08128879, top1: 0.88270, CELoss: 0.34852, loss: 0.34852, batch_cost: 0.60079s, reader_cost: 0.01501, ips: 106.52711 samples/s, eta: 6:50:14
[2022/06/18 23:15:21] ppcls INFO: [Train][Epoch 61/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08127248, top1: 0.88465, CELoss: 0.34658, loss: 0.34658, batch_cost: 0.61748s, reader_cost: 0.01416, ips: 103.64792 samples/s, eta: 7:01:31
[2022/06/18 23:15:27] ppcls INFO: [Train][Epoch 61/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08125617, top1: 0.88427, CELoss: 0.34500, loss: 0.34500, batch_cost: 0.61425s, reader_cost: 0.01410, ips: 104.19222 samples/s, eta: 6:59:13
[2022/06/18 23:15:32] ppcls INFO: [Train][Epoch 61/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08123984, top1: 0.88212, CELoss: 0.34678, loss: 0.34678, batch_cost: 0.61173s, reader_cost: 0.01350, ips: 104.62096 samples/s, eta: 6:57:24
[2022/06/18 23:15:38] ppcls INFO: [Train][Epoch 61/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08122349, top1: 0.88119, CELoss: 0.34983, loss: 0.34983, batch_cost: 0.60903s, reader_cost: 0.01303, ips: 105.08582 samples/s, eta: 6:55:27
[2022/06/18 23:15:45] ppcls INFO: [Train][Epoch 61/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08120713, top1: 0.88004, CELoss: 0.35136, loss: 0.35136, batch_cost: 0.61491s, reader_cost: 0.01542, ips: 104.07963 samples/s, eta: 6:59:22
[2022/06/18 23:15:51] ppcls INFO: [Train][Epoch 61/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08119076, top1: 0.87870, CELoss: 0.35354, loss: 0.35354, batch_cost: 0.60981s, reader_cost: 0.01473, ips: 104.95109 samples/s, eta: 6:55:47
[2022/06/18 23:15:57] ppcls INFO: [Train][Epoch 61/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08117438, top1: 0.87977, CELoss: 0.35169, loss: 0.35169, batch_cost: 0.61055s, reader_cost: 0.01470, ips: 104.82302 samples/s, eta: 6:56:11
[2022/06/18 23:16:03] ppcls INFO: [Train][Epoch 61/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08115798, top1: 0.87841, CELoss: 0.35489, loss: 0.35489, batch_cost: 0.61042s, reader_cost: 0.01449, ips: 104.84629 samples/s, eta: 6:55:59
[2022/06/18 23:16:08] ppcls INFO: [Train][Epoch 61/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08114157, top1: 0.87772, CELoss: 0.35502, loss: 0.35502, batch_cost: 0.60521s, reader_cost: 0.01436, ips: 105.74904 samples/s, eta: 6:52:20
[2022/06/18 23:16:10] ppcls INFO: [Train][Epoch 61/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08112514, top1: 0.87702, CELoss: 0.35563, loss: 0.35563, batch_cost: 0.58116s, reader_cost: 0.01352, ips: 84.31348 samples/s, eta: 6:35:52
[2022/06/18 23:16:11] ppcls INFO: [Train][Epoch 61/300][Avg]top1: 0.87702, CELoss: 0.35563, loss: 0.35563
[2022/06/18 23:16:11] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:16:17] ppcls INFO: [Train][Epoch 62/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08112350, top1: 0.89062, CELoss: 0.33657, loss: 0.33657, batch_cost: 0.61650s, reader_cost: 0.04864, ips: 103.81212 samples/s, eta: 6:59:55
[2022/06/18 23:16:24] ppcls INFO: [Train][Epoch 62/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08110706, top1: 0.88068, CELoss: 0.33878, loss: 0.33878, batch_cost: 0.66655s, reader_cost: 0.01525, ips: 96.01727 samples/s, eta: 7:33:54
[2022/06/18 23:16:30] ppcls INFO: [Train][Epoch 62/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08109061, top1: 0.87128, CELoss: 0.35549, loss: 0.35549, batch_cost: 0.65669s, reader_cost: 0.02165, ips: 97.45849 samples/s, eta: 7:27:05
[2022/06/18 23:16:37] ppcls INFO: [Train][Epoch 62/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08107414, top1: 0.87954, CELoss: 0.33605, loss: 0.33605, batch_cost: 0.66191s, reader_cost: 0.01856, ips: 96.68946 samples/s, eta: 7:30:31
[2022/06/18 23:16:43] ppcls INFO: [Train][Epoch 62/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08105766, top1: 0.87691, CELoss: 0.34312, loss: 0.34312, batch_cost: 0.63679s, reader_cost: 0.01839, ips: 100.50357 samples/s, eta: 7:13:19
[2022/06/18 23:16:48] ppcls INFO: [Train][Epoch 62/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08104116, top1: 0.87684, CELoss: 0.34245, loss: 0.34245, batch_cost: 0.61835s, reader_cost: 0.01785, ips: 103.50131 samples/s, eta: 7:00:40
[2022/06/18 23:16:54] ppcls INFO: [Train][Epoch 62/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08102466, top1: 0.87423, CELoss: 0.34512, loss: 0.34512, batch_cost: 0.61306s, reader_cost: 0.01915, ips: 104.39434 samples/s, eta: 6:56:58
[2022/06/18 23:17:00] ppcls INFO: [Train][Epoch 62/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08100813, top1: 0.87412, CELoss: 0.34788, loss: 0.34788, batch_cost: 0.61366s, reader_cost: 0.01856, ips: 104.29159 samples/s, eta: 6:57:16
[2022/06/18 23:17:06] ppcls INFO: [Train][Epoch 62/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08099160, top1: 0.87461, CELoss: 0.34232, loss: 0.34232, batch_cost: 0.61332s, reader_cost: 0.01829, ips: 104.34967 samples/s, eta: 6:56:56
[2022/06/18 23:17:13] ppcls INFO: [Train][Epoch 62/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08097505, top1: 0.87242, CELoss: 0.34532, loss: 0.34532, batch_cost: 0.62205s, reader_cost: 0.01845, ips: 102.88581 samples/s, eta: 7:02:46
[2022/06/18 23:17:19] ppcls INFO: [Train][Epoch 62/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08095849, top1: 0.87129, CELoss: 0.34781, loss: 0.34781, batch_cost: 0.61872s, reader_cost: 0.01804, ips: 103.43987 samples/s, eta: 7:00:24
[2022/06/18 23:17:25] ppcls INFO: [Train][Epoch 62/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08094191, top1: 0.87106, CELoss: 0.35042, loss: 0.35042, batch_cost: 0.61799s, reader_cost: 0.01762, ips: 103.56089 samples/s, eta: 6:59:48
[2022/06/18 23:17:31] ppcls INFO: [Train][Epoch 62/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08092533, top1: 0.87126, CELoss: 0.34972, loss: 0.34972, batch_cost: 0.61549s, reader_cost: 0.01689, ips: 103.98245 samples/s, eta: 6:58:00
[2022/06/18 23:17:36] ppcls INFO: [Train][Epoch 62/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08090872, top1: 0.87118, CELoss: 0.35288, loss: 0.35288, batch_cost: 0.60802s, reader_cost: 0.01615, ips: 105.25913 samples/s, eta: 6:52:50
[2022/06/18 23:17:43] ppcls INFO: [Train][Epoch 62/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08089211, top1: 0.87179, CELoss: 0.35278, loss: 0.35278, batch_cost: 0.61114s, reader_cost: 0.01526, ips: 104.72151 samples/s, eta: 6:54:51
[2022/06/18 23:17:48] ppcls INFO: [Train][Epoch 62/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08087548, top1: 0.87303, CELoss: 0.35080, loss: 0.35080, batch_cost: 0.60815s, reader_cost: 0.01467, ips: 105.23641 samples/s, eta: 6:52:43
[2022/06/18 23:17:53] ppcls INFO: [Train][Epoch 62/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08085884, top1: 0.87257, CELoss: 0.35405, loss: 0.35405, batch_cost: 0.59927s, reader_cost: 0.01443, ips: 106.79735 samples/s, eta: 6:46:35
[2022/06/18 23:17:55] ppcls INFO: [Train][Epoch 62/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08084218, top1: 0.87217, CELoss: 0.35645, loss: 0.35645, batch_cost: 0.57603s, reader_cost: 0.01358, ips: 85.06477 samples/s, eta: 6:30:43
[2022/06/18 23:17:56] ppcls INFO: [Train][Epoch 62/300][Avg]top1: 0.87217, CELoss: 0.35645, loss: 0.35645
[2022/06/18 23:17:56] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:18:01] ppcls INFO: [Train][Epoch 63/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08084051, top1: 0.92188, CELoss: 0.31529, loss: 0.31529, batch_cost: 0.60515s, reader_cost: 0.04192, ips: 105.75829 samples/s, eta: 6:50:28
[2022/06/18 23:18:08] ppcls INFO: [Train][Epoch 63/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08082384, top1: 0.88352, CELoss: 0.36513, loss: 0.36513, batch_cost: 0.67067s, reader_cost: 0.00184, ips: 95.42688 samples/s, eta: 7:34:48
[2022/06/18 23:18:15] ppcls INFO: [Train][Epoch 63/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08080716, top1: 0.88393, CELoss: 0.35498, loss: 0.35498, batch_cost: 0.72416s, reader_cost: 0.00804, ips: 88.37821 samples/s, eta: 8:10:57
[2022/06/18 23:18:21] ppcls INFO: [Train][Epoch 63/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08079046, top1: 0.88357, CELoss: 0.36613, loss: 0.36613, batch_cost: 0.66245s, reader_cost: 0.01208, ips: 96.61078 samples/s, eta: 7:29:00
[2022/06/18 23:18:28] ppcls INFO: [Train][Epoch 63/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08077375, top1: 0.88262, CELoss: 0.35836, loss: 0.35836, batch_cost: 0.67211s, reader_cost: 0.01588, ips: 95.22219 samples/s, eta: 7:35:26
[2022/06/18 23:18:34] ppcls INFO: [Train][Epoch 63/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08075703, top1: 0.88021, CELoss: 0.36136, loss: 0.36136, batch_cost: 0.66732s, reader_cost: 0.01487, ips: 95.90632 samples/s, eta: 7:32:05
[2022/06/18 23:18:40] ppcls INFO: [Train][Epoch 63/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08074029, top1: 0.88089, CELoss: 0.35932, loss: 0.35932, batch_cost: 0.65206s, reader_cost: 0.01458, ips: 98.15038 samples/s, eta: 7:21:38
[2022/06/18 23:18:46] ppcls INFO: [Train][Epoch 63/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08072354, top1: 0.88050, CELoss: 0.35353, loss: 0.35353, batch_cost: 0.64404s, reader_cost: 0.01306, ips: 99.37236 samples/s, eta: 7:16:06
[2022/06/18 23:18:52] ppcls INFO: [Train][Epoch 63/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08070677, top1: 0.88233, CELoss: 0.34719, loss: 0.34719, batch_cost: 0.63276s, reader_cost: 0.01463, ips: 101.14436 samples/s, eta: 7:08:21
[2022/06/18 23:18:58] ppcls INFO: [Train][Epoch 63/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08068999, top1: 0.88152, CELoss: 0.34756, loss: 0.34756, batch_cost: 0.63370s, reader_cost: 0.01420, ips: 100.99440 samples/s, eta: 7:08:53
[2022/06/18 23:19:05] ppcls INFO: [Train][Epoch 63/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08067320, top1: 0.88134, CELoss: 0.34968, loss: 0.34968, batch_cost: 0.64148s, reader_cost: 0.01387, ips: 99.76860 samples/s, eta: 7:14:02
[2022/06/18 23:19:11] ppcls INFO: [Train][Epoch 63/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08065640, top1: 0.88021, CELoss: 0.35127, loss: 0.35127, batch_cost: 0.63212s, reader_cost: 0.01320, ips: 101.24649 samples/s, eta: 7:07:36
[2022/06/18 23:19:16] ppcls INFO: [Train][Epoch 63/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08063958, top1: 0.88055, CELoss: 0.35092, loss: 0.35092, batch_cost: 0.62568s, reader_cost: 0.01317, ips: 102.28882 samples/s, eta: 7:03:08
[2022/06/18 23:19:24] ppcls INFO: [Train][Epoch 63/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08062275, top1: 0.88132, CELoss: 0.34807, loss: 0.34807, batch_cost: 0.63487s, reader_cost: 0.01334, ips: 100.80850 samples/s, eta: 7:09:15
[2022/06/18 23:19:29] ppcls INFO: [Train][Epoch 63/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08060590, top1: 0.88231, CELoss: 0.34649, loss: 0.34649, batch_cost: 0.62726s, reader_cost: 0.01313, ips: 102.03186 samples/s, eta: 7:04:00
[2022/06/18 23:19:34] ppcls INFO: [Train][Epoch 63/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08058904, top1: 0.88235, CELoss: 0.34584, loss: 0.34584, batch_cost: 0.62112s, reader_cost: 0.01258, ips: 103.04033 samples/s, eta: 6:59:45
[2022/06/18 23:19:41] ppcls INFO: [Train][Epoch 63/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08057217, top1: 0.88111, CELoss: 0.35001, loss: 0.35001, batch_cost: 0.62383s, reader_cost: 0.01248, ips: 102.59221 samples/s, eta: 7:01:28
[2022/06/18 23:19:43] ppcls INFO: [Train][Epoch 63/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08055529, top1: 0.87968, CELoss: 0.35419, loss: 0.35419, batch_cost: 0.59903s, reader_cost: 0.01173, ips: 81.79918 samples/s, eta: 6:44:37
[2022/06/18 23:19:44] ppcls INFO: [Train][Epoch 63/300][Avg]top1: 0.87968, CELoss: 0.35419, loss: 0.35419
[2022/06/18 23:19:44] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:19:51] ppcls INFO: [Train][Epoch 64/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08055360, top1: 0.82812, CELoss: 0.45884, loss: 0.45884, batch_cost: 0.63800s, reader_cost: 0.04473, ips: 100.31392 samples/s, eta: 7:10:56
[2022/06/18 23:19:57] ppcls INFO: [Train][Epoch 64/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08053670, top1: 0.86932, CELoss: 0.37186, loss: 0.37186, batch_cost: 0.66797s, reader_cost: 0.00048, ips: 95.81316 samples/s, eta: 7:31:04
[2022/06/18 23:20:03] ppcls INFO: [Train][Epoch 64/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08051978, top1: 0.86979, CELoss: 0.36058, loss: 0.36058, batch_cost: 0.63143s, reader_cost: 0.00224, ips: 101.35647 samples/s, eta: 7:06:17
[2022/06/18 23:20:10] ppcls INFO: [Train][Epoch 64/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08050286, top1: 0.86442, CELoss: 0.35940, loss: 0.35940, batch_cost: 0.63443s, reader_cost: 0.00753, ips: 100.87809 samples/s, eta: 7:08:12
[2022/06/18 23:20:16] ppcls INFO: [Train][Epoch 64/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08048592, top1: 0.86966, CELoss: 0.35300, loss: 0.35300, batch_cost: 0.63323s, reader_cost: 0.00564, ips: 101.06912 samples/s, eta: 7:07:17
[2022/06/18 23:20:23] ppcls INFO: [Train][Epoch 64/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08046897, top1: 0.86918, CELoss: 0.35263, loss: 0.35263, batch_cost: 0.64131s, reader_cost: 0.00651, ips: 99.79636 samples/s, eta: 7:12:38
[2022/06/18 23:20:30] ppcls INFO: [Train][Epoch 64/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08045200, top1: 0.86706, CELoss: 0.36185, loss: 0.36185, batch_cost: 0.64694s, reader_cost: 0.00540, ips: 98.92698 samples/s, eta: 7:16:19
[2022/06/18 23:20:35] ppcls INFO: [Train][Epoch 64/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08043502, top1: 0.86972, CELoss: 0.36055, loss: 0.36055, batch_cost: 0.63052s, reader_cost: 0.00606, ips: 101.50414 samples/s, eta: 7:05:08
[2022/06/18 23:20:41] ppcls INFO: [Train][Epoch 64/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08041803, top1: 0.87095, CELoss: 0.35881, loss: 0.35881, batch_cost: 0.62376s, reader_cost: 0.00593, ips: 102.60404 samples/s, eta: 7:00:29
[2022/06/18 23:20:46] ppcls INFO: [Train][Epoch 64/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08040102, top1: 0.87139, CELoss: 0.35967, loss: 0.35967, batch_cost: 0.61867s, reader_cost: 0.00600, ips: 103.44799 samples/s, eta: 6:56:57
[2022/06/18 23:20:53] ppcls INFO: [Train][Epoch 64/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08038400, top1: 0.87268, CELoss: 0.35786, loss: 0.35786, batch_cost: 0.61975s, reader_cost: 0.00988, ips: 103.26800 samples/s, eta: 6:57:34
[2022/06/18 23:20:58] ppcls INFO: [Train][Epoch 64/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08036697, top1: 0.87275, CELoss: 0.36052, loss: 0.36052, batch_cost: 0.61211s, reader_cost: 0.01087, ips: 104.55692 samples/s, eta: 6:52:19
[2022/06/18 23:21:04] ppcls INFO: [Train][Epoch 64/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08034992, top1: 0.87177, CELoss: 0.36253, loss: 0.36253, batch_cost: 0.61366s, reader_cost: 0.01023, ips: 104.29176 samples/s, eta: 6:53:16
[2022/06/18 23:21:12] ppcls INFO: [Train][Epoch 64/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08033286, top1: 0.87190, CELoss: 0.36126, loss: 0.36126, batch_cost: 0.62369s, reader_cost: 0.01003, ips: 102.61550 samples/s, eta: 6:59:55
[2022/06/18 23:21:19] ppcls INFO: [Train][Epoch 64/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08031579, top1: 0.87145, CELoss: 0.36064, loss: 0.36064, batch_cost: 0.63160s, reader_cost: 0.01110, ips: 101.33040 samples/s, eta: 7:05:08
[2022/06/18 23:21:26] ppcls INFO: [Train][Epoch 64/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08029871, top1: 0.87200, CELoss: 0.36173, loss: 0.36173, batch_cost: 0.63416s, reader_cost: 0.01050, ips: 100.92020 samples/s, eta: 7:06:45
[2022/06/18 23:21:31] ppcls INFO: [Train][Epoch 64/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.08028161, top1: 0.87219, CELoss: 0.36068, loss: 0.36068, batch_cost: 0.62338s, reader_cost: 0.01015, ips: 102.66641 samples/s, eta: 6:59:23
[2022/06/18 23:21:33] ppcls INFO: [Train][Epoch 64/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.08026449, top1: 0.87117, CELoss: 0.36403, loss: 0.36403, batch_cost: 0.59841s, reader_cost: 0.00955, ips: 81.88424 samples/s, eta: 6:42:29
[2022/06/18 23:21:33] ppcls INFO: [Train][Epoch 64/300][Avg]top1: 0.87117, CELoss: 0.36403, loss: 0.36403
[2022/06/18 23:21:33] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:21:40] ppcls INFO: [Train][Epoch 65/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.08026278, top1: 0.93750, CELoss: 0.19524, loss: 0.19524, batch_cost: 0.63319s, reader_cost: 0.03401, ips: 101.07545 samples/s, eta: 7:05:53
[2022/06/18 23:21:46] ppcls INFO: [Train][Epoch 65/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.08024566, top1: 0.91051, CELoss: 0.27028, loss: 0.27028, batch_cost: 0.66539s, reader_cost: 0.01791, ips: 96.18490 samples/s, eta: 7:27:25
[2022/06/18 23:21:52] ppcls INFO: [Train][Epoch 65/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.08022852, top1: 0.89062, CELoss: 0.30545, loss: 0.30545, batch_cost: 0.59992s, reader_cost: 0.02326, ips: 106.68118 samples/s, eta: 6:43:18
[2022/06/18 23:21:58] ppcls INFO: [Train][Epoch 65/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.08021136, top1: 0.89264, CELoss: 0.31321, loss: 0.31321, batch_cost: 0.61026s, reader_cost: 0.02501, ips: 104.87278 samples/s, eta: 6:50:09
[2022/06/18 23:22:04] ppcls INFO: [Train][Epoch 65/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.08019420, top1: 0.89444, CELoss: 0.31100, loss: 0.31100, batch_cost: 0.61331s, reader_cost: 0.02057, ips: 104.35241 samples/s, eta: 6:52:06
[2022/06/18 23:22:10] ppcls INFO: [Train][Epoch 65/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.08017702, top1: 0.89154, CELoss: 0.32551, loss: 0.32551, batch_cost: 0.60359s, reader_cost: 0.01948, ips: 106.03176 samples/s, eta: 6:45:28
[2022/06/18 23:22:16] ppcls INFO: [Train][Epoch 65/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.08015982, top1: 0.88986, CELoss: 0.32845, loss: 0.32845, batch_cost: 0.60292s, reader_cost: 0.01839, ips: 106.14930 samples/s, eta: 6:44:55
[2022/06/18 23:22:22] ppcls INFO: [Train][Epoch 65/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.08014262, top1: 0.88754, CELoss: 0.32982, loss: 0.32982, batch_cost: 0.60136s, reader_cost: 0.01913, ips: 106.42502 samples/s, eta: 6:43:46
[2022/06/18 23:22:28] ppcls INFO: [Train][Epoch 65/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.08012540, top1: 0.88715, CELoss: 0.32936, loss: 0.32936, batch_cost: 0.60227s, reader_cost: 0.01844, ips: 106.26432 samples/s, eta: 6:44:17
[2022/06/18 23:22:35] ppcls INFO: [Train][Epoch 65/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.08010817, top1: 0.88547, CELoss: 0.33431, loss: 0.33431, batch_cost: 0.61370s, reader_cost: 0.01858, ips: 104.28611 samples/s, eta: 6:51:51
[2022/06/18 23:22:42] ppcls INFO: [Train][Epoch 65/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.08009092, top1: 0.88506, CELoss: 0.33402, loss: 0.33402, batch_cost: 0.61556s, reader_cost: 0.01799, ips: 103.97098 samples/s, eta: 6:52:59
[2022/06/18 23:22:47] ppcls INFO: [Train][Epoch 65/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.08007366, top1: 0.88387, CELoss: 0.33752, loss: 0.33752, batch_cost: 0.60914s, reader_cost: 0.01740, ips: 105.06619 samples/s, eta: 6:48:35
[2022/06/18 23:22:53] ppcls INFO: [Train][Epoch 65/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.08005639, top1: 0.88326, CELoss: 0.33873, loss: 0.33873, batch_cost: 0.61177s, reader_cost: 0.01705, ips: 104.61442 samples/s, eta: 6:50:15
[2022/06/18 23:22:59] ppcls INFO: [Train][Epoch 65/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.08003911, top1: 0.88144, CELoss: 0.34078, loss: 0.34078, batch_cost: 0.60762s, reader_cost: 0.01667, ips: 105.32836 samples/s, eta: 6:47:22
[2022/06/18 23:23:05] ppcls INFO: [Train][Epoch 65/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.08002181, top1: 0.88187, CELoss: 0.34063, loss: 0.34063, batch_cost: 0.60844s, reader_cost: 0.01626, ips: 105.18723 samples/s, eta: 6:47:48
[2022/06/18 23:23:10] ppcls INFO: [Train][Epoch 65/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.08000450, top1: 0.88111, CELoss: 0.34181, loss: 0.34181, batch_cost: 0.60123s, reader_cost: 0.01526, ips: 106.44795 samples/s, eta: 6:42:53
[2022/06/18 23:23:16] ppcls INFO: [Train][Epoch 65/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07998717, top1: 0.88063, CELoss: 0.34063, loss: 0.34063, batch_cost: 0.60297s, reader_cost: 0.01476, ips: 106.14113 samples/s, eta: 6:43:57
[2022/06/18 23:23:19] ppcls INFO: [Train][Epoch 65/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07996983, top1: 0.88114, CELoss: 0.33956, loss: 0.33956, batch_cost: 0.57916s, reader_cost: 0.01391, ips: 84.60471 samples/s, eta: 6:27:54
[2022/06/18 23:23:19] ppcls INFO: [Train][Epoch 65/300][Avg]top1: 0.88114, CELoss: 0.33956, loss: 0.33956
[2022/06/18 23:23:26] ppcls INFO: [Eval][Epoch 65][Iter: 0/16]CELoss: 0.81269, loss: 0.81269, top1: 0.75586, batch_cost: 7.25334s, reader_cost: 3.39033, ips: 8.82352 images/sec
[2022/06/18 23:23:34] ppcls INFO: [Eval][Epoch 65][Iter: 10/16]CELoss: 0.79074, loss: 0.79074, top1: 0.74432, batch_cost: 0.56622s, reader_cost: 0.00120, ips: 113.03070 images/sec
[2022/06/18 23:23:36] ppcls INFO: [Eval][Epoch 65][Avg]CELoss: 0.70543, loss: 0.70543, top1: 0.75441
[2022/06/18 23:23:36] ppcls INFO: [Eval][Epoch 65][best metric: 0.761397123336792]
[2022/06/18 23:23:36] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:23:42] ppcls INFO: [Train][Epoch 66/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07996810, top1: 0.90625, CELoss: 0.23305, loss: 0.23305, batch_cost: 0.61025s, reader_cost: 0.04240, ips: 104.87448 samples/s, eta: 6:48:43
[2022/06/18 23:23:49] ppcls INFO: [Train][Epoch 66/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07995075, top1: 0.88068, CELoss: 0.33314, loss: 0.33314, batch_cost: 0.62899s, reader_cost: 0.01516, ips: 101.75065 samples/s, eta: 7:01:09
[2022/06/18 23:23:55] ppcls INFO: [Train][Epoch 66/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07993338, top1: 0.87500, CELoss: 0.34637, loss: 0.34637, batch_cost: 0.63011s, reader_cost: 0.01729, ips: 101.56998 samples/s, eta: 7:01:48
[2022/06/18 23:24:02] ppcls INFO: [Train][Epoch 66/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07991600, top1: 0.86794, CELoss: 0.36057, loss: 0.36057, batch_cost: 0.64242s, reader_cost: 0.01303, ips: 99.62382 samples/s, eta: 7:09:56
[2022/06/18 23:24:07] ppcls INFO: [Train][Epoch 66/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07989861, top1: 0.86509, CELoss: 0.37049, loss: 0.37049, batch_cost: 0.61611s, reader_cost: 0.01341, ips: 103.87823 samples/s, eta: 6:52:13
[2022/06/18 23:24:14] ppcls INFO: [Train][Epoch 66/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07988121, top1: 0.86765, CELoss: 0.36662, loss: 0.36662, batch_cost: 0.61951s, reader_cost: 0.01129, ips: 103.30743 samples/s, eta: 6:54:24
[2022/06/18 23:24:19] ppcls INFO: [Train][Epoch 66/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07986379, top1: 0.87013, CELoss: 0.36383, loss: 0.36383, batch_cost: 0.61391s, reader_cost: 0.01109, ips: 104.25046 samples/s, eta: 6:50:32
[2022/06/18 23:24:25] ppcls INFO: [Train][Epoch 66/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07984636, top1: 0.87104, CELoss: 0.36515, loss: 0.36515, batch_cost: 0.60133s, reader_cost: 0.01170, ips: 106.42989 samples/s, eta: 6:42:02
[2022/06/18 23:24:31] ppcls INFO: [Train][Epoch 66/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07982892, top1: 0.87249, CELoss: 0.36706, loss: 0.36706, batch_cost: 0.60476s, reader_cost: 0.01183, ips: 105.82765 samples/s, eta: 6:44:13
[2022/06/18 23:24:38] ppcls INFO: [Train][Epoch 66/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07981146, top1: 0.87157, CELoss: 0.36432, loss: 0.36432, batch_cost: 0.61022s, reader_cost: 0.01279, ips: 104.88036 samples/s, eta: 6:47:46
[2022/06/18 23:24:43] ppcls INFO: [Train][Epoch 66/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07979399, top1: 0.87531, CELoss: 0.35766, loss: 0.35766, batch_cost: 0.59969s, reader_cost: 0.01150, ips: 106.72219 samples/s, eta: 6:40:38
[2022/06/18 23:24:49] ppcls INFO: [Train][Epoch 66/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07977651, top1: 0.87655, CELoss: 0.35607, loss: 0.35607, batch_cost: 0.60623s, reader_cost: 0.01044, ips: 105.56991 samples/s, eta: 6:44:54
[2022/06/18 23:24:55] ppcls INFO: [Train][Epoch 66/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07975901, top1: 0.87720, CELoss: 0.35442, loss: 0.35442, batch_cost: 0.60580s, reader_cost: 0.01023, ips: 105.64597 samples/s, eta: 6:44:31
[2022/06/18 23:25:00] ppcls INFO: [Train][Epoch 66/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07974150, top1: 0.87739, CELoss: 0.35278, loss: 0.35278, batch_cost: 0.59816s, reader_cost: 0.00985, ips: 106.99529 samples/s, eta: 6:39:19
[2022/06/18 23:25:07] ppcls INFO: [Train][Epoch 66/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07972398, top1: 0.87655, CELoss: 0.35424, loss: 0.35424, batch_cost: 0.60416s, reader_cost: 0.00977, ips: 105.93145 samples/s, eta: 6:43:13
[2022/06/18 23:25:13] ppcls INFO: [Train][Epoch 66/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07970645, top1: 0.87748, CELoss: 0.35289, loss: 0.35289, batch_cost: 0.60530s, reader_cost: 0.00947, ips: 105.73296 samples/s, eta: 6:43:53
[2022/06/18 23:25:18] ppcls INFO: [Train][Epoch 66/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07968890, top1: 0.87849, CELoss: 0.35025, loss: 0.35025, batch_cost: 0.59543s, reader_cost: 0.00951, ips: 107.48508 samples/s, eta: 6:37:12
[2022/06/18 23:25:21] ppcls INFO: [Train][Epoch 66/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07967134, top1: 0.87949, CELoss: 0.34690, loss: 0.34690, batch_cost: 0.57467s, reader_cost: 0.00896, ips: 85.26654 samples/s, eta: 6:23:15
[2022/06/18 23:25:21] ppcls INFO: [Train][Epoch 66/300][Avg]top1: 0.87949, CELoss: 0.34690, loss: 0.34690
[2022/06/18 23:25:21] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:25:27] ppcls INFO: [Train][Epoch 67/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07966958, top1: 0.92188, CELoss: 0.23757, loss: 0.23757, batch_cost: 0.60759s, reader_cost: 0.03644, ips: 105.33496 samples/s, eta: 6:45:11
[2022/06/18 23:25:35] ppcls INFO: [Train][Epoch 67/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07965201, top1: 0.88494, CELoss: 0.33716, loss: 0.33716, batch_cost: 0.78763s, reader_cost: 0.00258, ips: 81.25659 samples/s, eta: 8:45:08
[2022/06/18 23:25:41] ppcls INFO: [Train][Epoch 67/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07963442, top1: 0.88393, CELoss: 0.33733, loss: 0.33733, batch_cost: 0.69401s, reader_cost: 0.00182, ips: 92.21835 samples/s, eta: 7:42:36
[2022/06/18 23:25:48] ppcls INFO: [Train][Epoch 67/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07961682, top1: 0.88306, CELoss: 0.33904, loss: 0.33904, batch_cost: 0.67680s, reader_cost: 0.00126, ips: 94.56198 samples/s, eta: 7:31:01
[2022/06/18 23:25:54] ppcls INFO: [Train][Epoch 67/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07959920, top1: 0.87805, CELoss: 0.35350, loss: 0.35350, batch_cost: 0.65876s, reader_cost: 0.00498, ips: 97.15180 samples/s, eta: 7:18:53
[2022/06/18 23:26:00] ppcls INFO: [Train][Epoch 67/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07958158, top1: 0.88021, CELoss: 0.34484, loss: 0.34484, batch_cost: 0.64155s, reader_cost: 0.00819, ips: 99.75781 samples/s, eta: 7:07:19
[2022/06/18 23:26:05] ppcls INFO: [Train][Epoch 67/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07956394, top1: 0.88243, CELoss: 0.33636, loss: 0.33636, batch_cost: 0.62307s, reader_cost: 0.00764, ips: 102.71677 samples/s, eta: 6:54:54
[2022/06/18 23:26:11] ppcls INFO: [Train][Epoch 67/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07954628, top1: 0.88402, CELoss: 0.33581, loss: 0.33581, batch_cost: 0.62427s, reader_cost: 0.01035, ips: 102.51941 samples/s, eta: 6:55:35
[2022/06/18 23:26:18] ppcls INFO: [Train][Epoch 67/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07952862, top1: 0.88272, CELoss: 0.34292, loss: 0.34292, batch_cost: 0.63560s, reader_cost: 0.01196, ips: 100.69251 samples/s, eta: 7:03:01
[2022/06/18 23:26:24] ppcls INFO: [Train][Epoch 67/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07951094, top1: 0.88032, CELoss: 0.34762, loss: 0.34762, batch_cost: 0.63028s, reader_cost: 0.01366, ips: 101.54202 samples/s, eta: 6:59:23
[2022/06/18 23:26:30] ppcls INFO: [Train][Epoch 67/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07949325, top1: 0.87794, CELoss: 0.34910, loss: 0.34910, batch_cost: 0.62296s, reader_cost: 0.01341, ips: 102.73474 samples/s, eta: 6:54:24
[2022/06/18 23:26:36] ppcls INFO: [Train][Epoch 67/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07947554, top1: 0.87866, CELoss: 0.34815, loss: 0.34815, batch_cost: 0.62625s, reader_cost: 0.01236, ips: 102.19586 samples/s, eta: 6:56:29
[2022/06/18 23:26:42] ppcls INFO: [Train][Epoch 67/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07945782, top1: 0.87771, CELoss: 0.35106, loss: 0.35106, batch_cost: 0.62242s, reader_cost: 0.01252, ips: 102.82382 samples/s, eta: 6:53:50
[2022/06/18 23:26:48] ppcls INFO: [Train][Epoch 67/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07944009, top1: 0.87989, CELoss: 0.34635, loss: 0.34635, batch_cost: 0.61637s, reader_cost: 0.01261, ips: 103.83296 samples/s, eta: 6:49:43
[2022/06/18 23:26:54] ppcls INFO: [Train][Epoch 67/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07942235, top1: 0.88087, CELoss: 0.34491, loss: 0.34491, batch_cost: 0.61978s, reader_cost: 0.01331, ips: 103.26280 samples/s, eta: 6:51:53
[2022/06/18 23:27:01] ppcls INFO: [Train][Epoch 67/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07940459, top1: 0.88142, CELoss: 0.34582, loss: 0.34582, batch_cost: 0.62046s, reader_cost: 0.01375, ips: 103.14955 samples/s, eta: 6:52:13
[2022/06/18 23:27:06] ppcls INFO: [Train][Epoch 67/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07938682, top1: 0.88082, CELoss: 0.34618, loss: 0.34618, batch_cost: 0.61514s, reader_cost: 0.01384, ips: 104.04134 samples/s, eta: 6:48:35
[2022/06/18 23:27:08] ppcls INFO: [Train][Epoch 67/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07936904, top1: 0.88059, CELoss: 0.34722, loss: 0.34722, batch_cost: 0.59078s, reader_cost: 0.01308, ips: 82.94108 samples/s, eta: 6:32:19
[2022/06/18 23:27:09] ppcls INFO: [Train][Epoch 67/300][Avg]top1: 0.88059, CELoss: 0.34722, loss: 0.34722
[2022/06/18 23:27:09] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:27:15] ppcls INFO: [Train][Epoch 68/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07936726, top1: 0.90625, CELoss: 0.30014, loss: 0.30014, batch_cost: 0.62571s, reader_cost: 0.03880, ips: 102.28455 samples/s, eta: 6:55:29
[2022/06/18 23:27:22] ppcls INFO: [Train][Epoch 68/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07934947, top1: 0.86790, CELoss: 0.39617, loss: 0.39617, batch_cost: 0.76280s, reader_cost: 0.02491, ips: 83.90126 samples/s, eta: 8:26:24
[2022/06/18 23:27:29] ppcls INFO: [Train][Epoch 68/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07933166, top1: 0.86830, CELoss: 0.37786, loss: 0.37786, batch_cost: 0.69974s, reader_cost: 0.01500, ips: 91.46307 samples/s, eta: 7:44:25
[2022/06/18 23:27:35] ppcls INFO: [Train][Epoch 68/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07931384, top1: 0.87550, CELoss: 0.35586, loss: 0.35586, batch_cost: 0.65741s, reader_cost: 0.01480, ips: 97.35163 samples/s, eta: 7:16:13
[2022/06/18 23:27:41] ppcls INFO: [Train][Epoch 68/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07929600, top1: 0.87995, CELoss: 0.34460, loss: 0.34460, batch_cost: 0.64457s, reader_cost: 0.01885, ips: 99.29169 samples/s, eta: 7:07:35
[2022/06/18 23:27:47] ppcls INFO: [Train][Epoch 68/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07927815, top1: 0.87898, CELoss: 0.35095, loss: 0.35095, batch_cost: 0.64789s, reader_cost: 0.02261, ips: 98.78163 samples/s, eta: 7:09:41
[2022/06/18 23:27:54] ppcls INFO: [Train][Epoch 68/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07926029, top1: 0.87910, CELoss: 0.35103, loss: 0.35103, batch_cost: 0.63985s, reader_cost: 0.01982, ips: 100.02353 samples/s, eta: 7:04:15
[2022/06/18 23:27:59] ppcls INFO: [Train][Epoch 68/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07924242, top1: 0.88226, CELoss: 0.34674, loss: 0.34674, batch_cost: 0.63034s, reader_cost: 0.01780, ips: 101.53290 samples/s, eta: 6:57:50
[2022/06/18 23:28:05] ppcls INFO: [Train][Epoch 68/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07922453, top1: 0.88002, CELoss: 0.34778, loss: 0.34778, batch_cost: 0.62128s, reader_cost: 0.01745, ips: 103.01335 samples/s, eta: 6:51:43
[2022/06/18 23:28:11] ppcls INFO: [Train][Epoch 68/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07920663, top1: 0.88084, CELoss: 0.34733, loss: 0.34733, batch_cost: 0.62347s, reader_cost: 0.01693, ips: 102.65084 samples/s, eta: 6:53:04
[2022/06/18 23:28:18] ppcls INFO: [Train][Epoch 68/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07918872, top1: 0.88506, CELoss: 0.33739, loss: 0.33739, batch_cost: 0.62616s, reader_cost: 0.01598, ips: 102.21093 samples/s, eta: 6:54:45
[2022/06/18 23:28:23] ppcls INFO: [Train][Epoch 68/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07917080, top1: 0.88514, CELoss: 0.33969, loss: 0.33969, batch_cost: 0.62092s, reader_cost: 0.01500, ips: 103.07305 samples/s, eta: 6:51:10
[2022/06/18 23:28:30] ppcls INFO: [Train][Epoch 68/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07915286, top1: 0.88546, CELoss: 0.33819, loss: 0.33819, batch_cost: 0.61923s, reader_cost: 0.01555, ips: 103.35409 samples/s, eta: 6:49:57
[2022/06/18 23:28:36] ppcls INFO: [Train][Epoch 68/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07913491, top1: 0.88406, CELoss: 0.33986, loss: 0.33986, batch_cost: 0.62470s, reader_cost: 0.01593, ips: 102.44990 samples/s, eta: 6:53:28
[2022/06/18 23:28:41] ppcls INFO: [Train][Epoch 68/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07911694, top1: 0.88420, CELoss: 0.33996, loss: 0.33996, batch_cost: 0.61624s, reader_cost: 0.01548, ips: 103.85545 samples/s, eta: 6:47:46
[2022/06/18 23:28:48] ppcls INFO: [Train][Epoch 68/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07909897, top1: 0.88349, CELoss: 0.34126, loss: 0.34126, batch_cost: 0.62131s, reader_cost: 0.01457, ips: 103.00818 samples/s, eta: 6:51:01
[2022/06/18 23:28:53] ppcls INFO: [Train][Epoch 68/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07908098, top1: 0.88306, CELoss: 0.34320, loss: 0.34320, batch_cost: 0.61051s, reader_cost: 0.01399, ips: 104.83053 samples/s, eta: 6:43:46
[2022/06/18 23:28:55] ppcls INFO: [Train][Epoch 68/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07906298, top1: 0.88398, CELoss: 0.34119, loss: 0.34119, batch_cost: 0.58737s, reader_cost: 0.01315, ips: 83.42226 samples/s, eta: 6:28:22
[2022/06/18 23:28:56] ppcls INFO: [Train][Epoch 68/300][Avg]top1: 0.88398, CELoss: 0.34119, loss: 0.34119
[2022/06/18 23:28:56] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:29:03] ppcls INFO: [Train][Epoch 69/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07906118, top1: 0.90625, CELoss: 0.35625, loss: 0.35625, batch_cost: 0.62493s, reader_cost: 0.04388, ips: 102.41079 samples/s, eta: 6:53:12
[2022/06/18 23:29:09] ppcls INFO: [Train][Epoch 69/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07904316, top1: 0.87216, CELoss: 0.35237, loss: 0.35237, batch_cost: 0.58439s, reader_cost: 0.00030, ips: 109.51647 samples/s, eta: 6:26:17
[2022/06/18 23:29:15] ppcls INFO: [Train][Epoch 69/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07902513, top1: 0.87649, CELoss: 0.34751, loss: 0.34751, batch_cost: 0.57691s, reader_cost: 0.01873, ips: 110.93658 samples/s, eta: 6:21:15
[2022/06/18 23:29:21] ppcls INFO: [Train][Epoch 69/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07900709, top1: 0.87349, CELoss: 0.34655, loss: 0.34655, batch_cost: 0.62025s, reader_cost: 0.01844, ips: 103.18437 samples/s, eta: 6:49:47
[2022/06/18 23:29:27] ppcls INFO: [Train][Epoch 69/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07898904, top1: 0.87691, CELoss: 0.34209, loss: 0.34209, batch_cost: 0.61093s, reader_cost: 0.01850, ips: 104.75849 samples/s, eta: 6:43:32
[2022/06/18 23:29:33] ppcls INFO: [Train][Epoch 69/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07897097, top1: 0.87592, CELoss: 0.33898, loss: 0.33898, batch_cost: 0.61095s, reader_cost: 0.01598, ips: 104.75466 samples/s, eta: 6:43:27
[2022/06/18 23:29:39] ppcls INFO: [Train][Epoch 69/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07895289, top1: 0.87372, CELoss: 0.34376, loss: 0.34376, batch_cost: 0.60392s, reader_cost: 0.01567, ips: 105.97401 samples/s, eta: 6:38:42
[2022/06/18 23:29:46] ppcls INFO: [Train][Epoch 69/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07893480, top1: 0.87764, CELoss: 0.34024, loss: 0.34024, batch_cost: 0.61966s, reader_cost: 0.01503, ips: 103.28277 samples/s, eta: 6:48:59
[2022/06/18 23:29:52] ppcls INFO: [Train][Epoch 69/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07891669, top1: 0.87982, CELoss: 0.33551, loss: 0.33551, batch_cost: 0.61330s, reader_cost: 0.01496, ips: 104.35380 samples/s, eta: 6:44:41
[2022/06/18 23:29:58] ppcls INFO: [Train][Epoch 69/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07889857, top1: 0.87740, CELoss: 0.33919, loss: 0.33919, batch_cost: 0.61872s, reader_cost: 0.01452, ips: 103.43922 samples/s, eta: 6:48:10
[2022/06/18 23:30:05] ppcls INFO: [Train][Epoch 69/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07888044, top1: 0.87949, CELoss: 0.33367, loss: 0.33367, batch_cost: 0.62293s, reader_cost: 0.01423, ips: 102.74090 samples/s, eta: 6:50:50
[2022/06/18 23:30:11] ppcls INFO: [Train][Epoch 69/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07886230, top1: 0.87936, CELoss: 0.33680, loss: 0.33680, batch_cost: 0.61873s, reader_cost: 0.01364, ips: 103.43731 samples/s, eta: 6:47:58
[2022/06/18 23:30:16] ppcls INFO: [Train][Epoch 69/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07884415, top1: 0.87991, CELoss: 0.33634, loss: 0.33634, batch_cost: 0.60864s, reader_cost: 0.01502, ips: 105.15269 samples/s, eta: 6:41:12
[2022/06/18 23:30:22] ppcls INFO: [Train][Epoch 69/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07882598, top1: 0.87977, CELoss: 0.33555, loss: 0.33555, batch_cost: 0.61117s, reader_cost: 0.01539, ips: 104.71641 samples/s, eta: 6:42:47
[2022/06/18 23:30:29] ppcls INFO: [Train][Epoch 69/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07880780, top1: 0.87777, CELoss: 0.33970, loss: 0.33970, batch_cost: 0.61248s, reader_cost: 0.01445, ips: 104.49249 samples/s, eta: 6:43:32
[2022/06/18 23:30:34] ppcls INFO: [Train][Epoch 69/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07878960, top1: 0.87935, CELoss: 0.33804, loss: 0.33804, batch_cost: 0.60687s, reader_cost: 0.01441, ips: 105.45932 samples/s, eta: 6:39:44
[2022/06/18 23:30:39] ppcls INFO: [Train][Epoch 69/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07877140, top1: 0.87995, CELoss: 0.33784, loss: 0.33784, batch_cost: 0.60312s, reader_cost: 0.01380, ips: 106.11539 samples/s, eta: 6:37:10
[2022/06/18 23:30:41] ppcls INFO: [Train][Epoch 69/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07875318, top1: 0.88123, CELoss: 0.33469, loss: 0.33469, batch_cost: 0.57942s, reader_cost: 0.01298, ips: 84.56768 samples/s, eta: 6:21:28
[2022/06/18 23:30:42] ppcls INFO: [Train][Epoch 69/300][Avg]top1: 0.88123, CELoss: 0.33469, loss: 0.33469
[2022/06/18 23:30:42] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:30:48] ppcls INFO: [Train][Epoch 70/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07875135, top1: 0.90625, CELoss: 0.24821, loss: 0.24821, batch_cost: 0.61033s, reader_cost: 0.04179, ips: 104.86114 samples/s, eta: 6:41:48
[2022/06/18 23:30:55] ppcls INFO: [Train][Epoch 70/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07873312, top1: 0.88778, CELoss: 0.29873, loss: 0.29873, batch_cost: 0.68305s, reader_cost: 0.02526, ips: 93.69747 samples/s, eta: 7:29:34
[2022/06/18 23:31:01] ppcls INFO: [Train][Epoch 70/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07871487, top1: 0.88839, CELoss: 0.32078, loss: 0.32078, batch_cost: 0.62999s, reader_cost: 0.01844, ips: 101.58941 samples/s, eta: 6:54:32
[2022/06/18 23:31:07] ppcls INFO: [Train][Epoch 70/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07869662, top1: 0.89163, CELoss: 0.31499, loss: 0.31499, batch_cost: 0.61119s, reader_cost: 0.01330, ips: 104.71393 samples/s, eta: 6:42:04
[2022/06/18 23:31:13] ppcls INFO: [Train][Epoch 70/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07867834, top1: 0.88796, CELoss: 0.32029, loss: 0.32029, batch_cost: 0.61348s, reader_cost: 0.00969, ips: 104.32320 samples/s, eta: 6:43:28
[2022/06/18 23:31:19] ppcls INFO: [Train][Epoch 70/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07866006, top1: 0.88603, CELoss: 0.32233, loss: 0.32233, batch_cost: 0.59561s, reader_cost: 0.00798, ips: 107.45267 samples/s, eta: 6:31:37
[2022/06/18 23:31:25] ppcls INFO: [Train][Epoch 70/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07864176, top1: 0.88704, CELoss: 0.31758, loss: 0.31758, batch_cost: 0.60517s, reader_cost: 0.00732, ips: 105.75509 samples/s, eta: 6:37:48
[2022/06/18 23:31:31] ppcls INFO: [Train][Epoch 70/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07862346, top1: 0.88424, CELoss: 0.32268, loss: 0.32268, batch_cost: 0.60869s, reader_cost: 0.00694, ips: 105.14463 samples/s, eta: 6:40:01
[2022/06/18 23:31:38] ppcls INFO: [Train][Epoch 70/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07860513, top1: 0.88329, CELoss: 0.32547, loss: 0.32547, batch_cost: 0.61153s, reader_cost: 0.00974, ips: 104.65545 samples/s, eta: 6:41:47
[2022/06/18 23:31:43] ppcls INFO: [Train][Epoch 70/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07858680, top1: 0.88067, CELoss: 0.33469, loss: 0.33469, batch_cost: 0.60773s, reader_cost: 0.00921, ips: 105.30938 samples/s, eta: 6:39:11
[2022/06/18 23:31:49] ppcls INFO: [Train][Epoch 70/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07856845, top1: 0.88103, CELoss: 0.33253, loss: 0.33253, batch_cost: 0.60494s, reader_cost: 0.01354, ips: 105.79590 samples/s, eta: 6:37:15
[2022/06/18 23:31:55] ppcls INFO: [Train][Epoch 70/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07855009, top1: 0.88190, CELoss: 0.33287, loss: 0.33287, batch_cost: 0.60337s, reader_cost: 0.01516, ips: 106.07068 samples/s, eta: 6:36:07
[2022/06/18 23:32:00] ppcls INFO: [Train][Epoch 70/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07853172, top1: 0.88314, CELoss: 0.32707, loss: 0.32707, batch_cost: 0.59545s, reader_cost: 0.01496, ips: 107.48200 samples/s, eta: 6:30:49
[2022/06/18 23:32:07] ppcls INFO: [Train][Epoch 70/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07851334, top1: 0.88323, CELoss: 0.32475, loss: 0.32475, batch_cost: 0.60056s, reader_cost: 0.01987, ips: 106.56760 samples/s, eta: 6:34:04
[2022/06/18 23:32:14] ppcls INFO: [Train][Epoch 70/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07849494, top1: 0.88287, CELoss: 0.32637, loss: 0.32637, batch_cost: 0.61070s, reader_cost: 0.01860, ips: 104.79804 samples/s, eta: 6:40:37
[2022/06/18 23:32:20] ppcls INFO: [Train][Epoch 70/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07847653, top1: 0.88307, CELoss: 0.32560, loss: 0.32560, batch_cost: 0.60509s, reader_cost: 0.01768, ips: 105.76989 samples/s, eta: 6:36:50
[2022/06/18 23:32:25] ppcls INFO: [Train][Epoch 70/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07845811, top1: 0.88189, CELoss: 0.32874, loss: 0.32874, batch_cost: 0.60032s, reader_cost: 0.01724, ips: 106.61035 samples/s, eta: 6:33:37
[2022/06/18 23:32:27] ppcls INFO: [Train][Epoch 70/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07843967, top1: 0.88288, CELoss: 0.32676, loss: 0.32676, batch_cost: 0.57821s, reader_cost: 0.01626, ips: 84.74435 samples/s, eta: 6:19:01
[2022/06/18 23:32:28] ppcls INFO: [Train][Epoch 70/300][Avg]top1: 0.88288, CELoss: 0.32676, loss: 0.32676
[2022/06/18 23:32:34] ppcls INFO: [Eval][Epoch 70][Iter: 0/16]CELoss: 0.90346, loss: 0.90346, top1: 0.74805, batch_cost: 6.57362s, reader_cost: 3.59268, ips: 9.73589 images/sec
[2022/06/18 23:32:43] ppcls INFO: [Eval][Epoch 70][Iter: 10/16]CELoss: 0.76957, loss: 0.76957, top1: 0.74911, batch_cost: 0.61988s, reader_cost: 0.00529, ips: 103.24595 images/sec
[2022/06/18 23:32:44] ppcls INFO: [Eval][Epoch 70][Avg]CELoss: 0.70794, loss: 0.70794, top1: 0.75956
[2022/06/18 23:32:44] ppcls INFO: [Eval][Epoch 70][best metric: 0.761397123336792]
[2022/06/18 23:32:44] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_70
[2022/06/18 23:32:44] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:32:52] ppcls INFO: [Train][Epoch 71/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07843783, top1: 0.90625, CELoss: 0.29029, loss: 0.29029, batch_cost: 0.62104s, reader_cost: 0.04642, ips: 103.05316 samples/s, eta: 6:47:05
[2022/06/18 23:32:58] ppcls INFO: [Train][Epoch 71/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07841938, top1: 0.89631, CELoss: 0.29472, loss: 0.29472, batch_cost: 0.58426s, reader_cost: 0.02237, ips: 109.54074 samples/s, eta: 6:22:53
[2022/06/18 23:33:04] ppcls INFO: [Train][Epoch 71/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07840092, top1: 0.88765, CELoss: 0.32509, loss: 0.32509, batch_cost: 0.60180s, reader_cost: 0.02173, ips: 106.34846 samples/s, eta: 6:34:16
[2022/06/18 23:33:10] ppcls INFO: [Train][Epoch 71/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07838245, top1: 0.88710, CELoss: 0.33001, loss: 0.33001, batch_cost: 0.60453s, reader_cost: 0.01965, ips: 105.86676 samples/s, eta: 6:35:58
[2022/06/18 23:33:16] ppcls INFO: [Train][Epoch 71/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07836396, top1: 0.88605, CELoss: 0.33324, loss: 0.33324, batch_cost: 0.60896s, reader_cost: 0.01775, ips: 105.09694 samples/s, eta: 6:38:46
[2022/06/18 23:33:22] ppcls INFO: [Train][Epoch 71/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07834546, top1: 0.88695, CELoss: 0.32744, loss: 0.32744, batch_cost: 0.60227s, reader_cost: 0.01661, ips: 106.26539 samples/s, eta: 6:34:16
[2022/06/18 23:33:28] ppcls INFO: [Train][Epoch 71/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07832695, top1: 0.88781, CELoss: 0.32919, loss: 0.32919, batch_cost: 0.59829s, reader_cost: 0.01633, ips: 106.97087 samples/s, eta: 6:31:34
[2022/06/18 23:33:34] ppcls INFO: [Train][Epoch 71/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07830843, top1: 0.88622, CELoss: 0.33268, loss: 0.33268, batch_cost: 0.61053s, reader_cost: 0.05650, ips: 104.82753 samples/s, eta: 6:39:29
[2022/06/18 23:33:40] ppcls INFO: [Train][Epoch 71/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07828989, top1: 0.88465, CELoss: 0.33289, loss: 0.33289, batch_cost: 0.60539s, reader_cost: 0.05021, ips: 105.71646 samples/s, eta: 6:36:01
[2022/06/18 23:33:46] ppcls INFO: [Train][Epoch 71/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07827134, top1: 0.88462, CELoss: 0.33155, loss: 0.33155, batch_cost: 0.60824s, reader_cost: 0.04650, ips: 105.22232 samples/s, eta: 6:37:47
[2022/06/18 23:33:52] ppcls INFO: [Train][Epoch 71/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07825278, top1: 0.88552, CELoss: 0.33076, loss: 0.33076, batch_cost: 0.60113s, reader_cost: 0.04455, ips: 106.46578 samples/s, eta: 6:33:02
[2022/06/18 23:33:57] ppcls INFO: [Train][Epoch 71/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07823421, top1: 0.88260, CELoss: 0.33297, loss: 0.33297, batch_cost: 0.59453s, reader_cost: 0.04144, ips: 107.64811 samples/s, eta: 6:28:37
[2022/06/18 23:34:03] ppcls INFO: [Train][Epoch 71/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07821562, top1: 0.88326, CELoss: 0.33087, loss: 0.33087, batch_cost: 0.59232s, reader_cost: 0.04487, ips: 108.04994 samples/s, eta: 6:27:04
[2022/06/18 23:34:11] ppcls INFO: [Train][Epoch 71/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07819702, top1: 0.88299, CELoss: 0.33448, loss: 0.33448, batch_cost: 0.60962s, reader_cost: 0.06298, ips: 104.98282 samples/s, eta: 6:38:17
[2022/06/18 23:34:17] ppcls INFO: [Train][Epoch 71/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07817841, top1: 0.88398, CELoss: 0.33363, loss: 0.33363, batch_cost: 0.60887s, reader_cost: 0.06395, ips: 105.11332 samples/s, eta: 6:37:41
[2022/06/18 23:34:24] ppcls INFO: [Train][Epoch 71/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07815979, top1: 0.88266, CELoss: 0.33543, loss: 0.33543, batch_cost: 0.61715s, reader_cost: 0.07634, ips: 103.70224 samples/s, eta: 6:42:59
[2022/06/18 23:34:29] ppcls INFO: [Train][Epoch 71/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07814115, top1: 0.88257, CELoss: 0.33400, loss: 0.33400, batch_cost: 0.60958s, reader_cost: 0.07795, ips: 104.99012 samples/s, eta: 6:37:57
[2022/06/18 23:34:31] ppcls INFO: [Train][Epoch 71/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07812250, top1: 0.88251, CELoss: 0.33559, loss: 0.33559, batch_cost: 0.58545s, reader_cost: 0.07326, ips: 83.69588 samples/s, eta: 6:22:06
[2022/06/18 23:34:32] ppcls INFO: [Train][Epoch 71/300][Avg]top1: 0.88251, CELoss: 0.33559, loss: 0.33559
[2022/06/18 23:34:32] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:34:40] ppcls INFO: [Train][Epoch 72/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07812064, top1: 0.90625, CELoss: 0.25624, loss: 0.25624, batch_cost: 0.63022s, reader_cost: 0.10130, ips: 101.55130 samples/s, eta: 6:51:18
[2022/06/18 23:34:46] ppcls INFO: [Train][Epoch 72/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07810198, top1: 0.88352, CELoss: 0.32655, loss: 0.32655, batch_cost: 0.69390s, reader_cost: 0.00519, ips: 92.23278 samples/s, eta: 7:32:45
[2022/06/18 23:34:52] ppcls INFO: [Train][Epoch 72/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07808330, top1: 0.88690, CELoss: 0.31813, loss: 0.31813, batch_cost: 0.61752s, reader_cost: 0.01852, ips: 103.64080 samples/s, eta: 6:42:49
[2022/06/18 23:34:58] ppcls INFO: [Train][Epoch 72/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07806462, top1: 0.88155, CELoss: 0.33689, loss: 0.33689, batch_cost: 0.60732s, reader_cost: 0.01600, ips: 105.38058 samples/s, eta: 6:36:03
[2022/06/18 23:35:04] ppcls INFO: [Train][Epoch 72/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07804592, top1: 0.88110, CELoss: 0.34346, loss: 0.34346, batch_cost: 0.60256s, reader_cost: 0.02146, ips: 106.21298 samples/s, eta: 6:32:51
[2022/06/18 23:35:09] ppcls INFO: [Train][Epoch 72/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07802720, top1: 0.88021, CELoss: 0.34480, loss: 0.34480, batch_cost: 0.59091s, reader_cost: 0.01961, ips: 108.30710 samples/s, eta: 6:25:09
[2022/06/18 23:35:14] ppcls INFO: [Train][Epoch 72/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07800848, top1: 0.88397, CELoss: 0.33888, loss: 0.33888, batch_cost: 0.57814s, reader_cost: 0.01856, ips: 110.70064 samples/s, eta: 6:16:44
[2022/06/18 23:35:20] ppcls INFO: [Train][Epoch 72/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07798974, top1: 0.88336, CELoss: 0.33893, loss: 0.33893, batch_cost: 0.57246s, reader_cost: 0.01798, ips: 111.79765 samples/s, eta: 6:12:56
[2022/06/18 23:35:26] ppcls INFO: [Train][Epoch 72/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07797100, top1: 0.88291, CELoss: 0.33723, loss: 0.33723, batch_cost: 0.57745s, reader_cost: 0.01631, ips: 110.83122 samples/s, eta: 6:16:06
[2022/06/18 23:35:34] ppcls INFO: [Train][Epoch 72/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07795223, top1: 0.88273, CELoss: 0.33550, loss: 0.33550, batch_cost: 0.59866s, reader_cost: 0.01507, ips: 106.90549 samples/s, eta: 6:29:49
[2022/06/18 23:35:39] ppcls INFO: [Train][Epoch 72/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07793346, top1: 0.88274, CELoss: 0.33610, loss: 0.33610, batch_cost: 0.59764s, reader_cost: 0.01489, ips: 107.08736 samples/s, eta: 6:29:03
[2022/06/18 23:35:45] ppcls INFO: [Train][Epoch 72/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07791468, top1: 0.88331, CELoss: 0.33438, loss: 0.33438, batch_cost: 0.59604s, reader_cost: 0.01484, ips: 107.37558 samples/s, eta: 6:27:54
[2022/06/18 23:35:51] ppcls INFO: [Train][Epoch 72/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07789588, top1: 0.88391, CELoss: 0.33380, loss: 0.33380, batch_cost: 0.59272s, reader_cost: 0.01452, ips: 107.97623 samples/s, eta: 6:25:39
[2022/06/18 23:35:57] ppcls INFO: [Train][Epoch 72/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07787707, top1: 0.88478, CELoss: 0.33011, loss: 0.33011, batch_cost: 0.59663s, reader_cost: 0.01521, ips: 107.26990 samples/s, eta: 6:28:05
[2022/06/18 23:36:05] ppcls INFO: [Train][Epoch 72/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07785824, top1: 0.88276, CELoss: 0.33724, loss: 0.33724, batch_cost: 0.60946s, reader_cost: 0.01496, ips: 105.01090 samples/s, eta: 6:36:20
[2022/06/18 23:36:11] ppcls INFO: [Train][Epoch 72/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07783941, top1: 0.88224, CELoss: 0.33947, loss: 0.33947, batch_cost: 0.60926s, reader_cost: 0.01484, ips: 105.04619 samples/s, eta: 6:36:06
[2022/06/18 23:36:15] ppcls INFO: [Train][Epoch 72/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07782056, top1: 0.88257, CELoss: 0.33890, loss: 0.33890, batch_cost: 0.59568s, reader_cost: 0.01409, ips: 107.44110 samples/s, eta: 6:27:10
[2022/06/18 23:36:17] ppcls INFO: [Train][Epoch 72/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07780170, top1: 0.88123, CELoss: 0.34067, loss: 0.34067, batch_cost: 0.57237s, reader_cost: 0.01329, ips: 85.60850 samples/s, eta: 6:11:56
[2022/06/18 23:36:18] ppcls INFO: [Train][Epoch 72/300][Avg]top1: 0.88123, CELoss: 0.34067, loss: 0.34067
[2022/06/18 23:36:18] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:36:25] ppcls INFO: [Train][Epoch 73/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07779982, top1: 0.93750, CELoss: 0.18664, loss: 0.18664, batch_cost: 0.61167s, reader_cost: 0.03862, ips: 104.63238 samples/s, eta: 6:37:27
[2022/06/18 23:36:31] ppcls INFO: [Train][Epoch 73/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07778094, top1: 0.85938, CELoss: 0.37646, loss: 0.37646, batch_cost: 0.61880s, reader_cost: 0.00040, ips: 103.42517 samples/s, eta: 6:41:59
[2022/06/18 23:36:38] ppcls INFO: [Train][Epoch 73/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07776206, top1: 0.87054, CELoss: 0.34378, loss: 0.34378, batch_cost: 0.66150s, reader_cost: 0.00036, ips: 96.74914 samples/s, eta: 7:09:37
[2022/06/18 23:36:44] ppcls INFO: [Train][Epoch 73/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07774316, top1: 0.87450, CELoss: 0.34190, loss: 0.34190, batch_cost: 0.62751s, reader_cost: 0.00034, ips: 101.99112 samples/s, eta: 6:47:26
[2022/06/18 23:36:50] ppcls INFO: [Train][Epoch 73/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07772425, top1: 0.87767, CELoss: 0.34016, loss: 0.34016, batch_cost: 0.61967s, reader_cost: 0.00382, ips: 103.28017 samples/s, eta: 6:42:15
[2022/06/18 23:36:56] ppcls INFO: [Train][Epoch 73/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07770533, top1: 0.87714, CELoss: 0.33974, loss: 0.33974, batch_cost: 0.62619s, reader_cost: 0.00306, ips: 102.20567 samples/s, eta: 6:46:22
[2022/06/18 23:37:02] ppcls INFO: [Train][Epoch 73/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07768639, top1: 0.87807, CELoss: 0.33793, loss: 0.33793, batch_cost: 0.61415s, reader_cost: 0.00602, ips: 104.20926 samples/s, eta: 6:38:27
[2022/06/18 23:37:07] ppcls INFO: [Train][Epoch 73/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07766744, top1: 0.88094, CELoss: 0.33564, loss: 0.33564, batch_cost: 0.60767s, reader_cost: 0.00848, ips: 105.32011 samples/s, eta: 6:34:09
[2022/06/18 23:37:13] ppcls INFO: [Train][Epoch 73/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07764849, top1: 0.88117, CELoss: 0.33317, loss: 0.33317, batch_cost: 0.60493s, reader_cost: 0.01689, ips: 105.79728 samples/s, eta: 6:32:16
[2022/06/18 23:37:19] ppcls INFO: [Train][Epoch 73/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07762951, top1: 0.88032, CELoss: 0.33567, loss: 0.33567, batch_cost: 0.60208s, reader_cost: 0.01619, ips: 106.29748 samples/s, eta: 6:30:19
[2022/06/18 23:37:25] ppcls INFO: [Train][Epoch 73/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07761053, top1: 0.88088, CELoss: 0.33379, loss: 0.33379, batch_cost: 0.60410s, reader_cost: 0.01515, ips: 105.94325 samples/s, eta: 6:31:32
[2022/06/18 23:37:31] ppcls INFO: [Train][Epoch 73/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07759153, top1: 0.88359, CELoss: 0.32888, loss: 0.32888, batch_cost: 0.60462s, reader_cost: 0.01395, ips: 105.85087 samples/s, eta: 6:31:46
[2022/06/18 23:37:37] ppcls INFO: [Train][Epoch 73/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07757253, top1: 0.88326, CELoss: 0.33024, loss: 0.33024, batch_cost: 0.60157s, reader_cost: 0.01436, ips: 106.38785 samples/s, eta: 6:29:41
[2022/06/18 23:37:43] ppcls INFO: [Train][Epoch 73/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07755351, top1: 0.88180, CELoss: 0.33432, loss: 0.33432, batch_cost: 0.60227s, reader_cost: 0.01463, ips: 106.26426 samples/s, eta: 6:30:03
[2022/06/18 23:37:49] ppcls INFO: [Train][Epoch 73/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07753447, top1: 0.88143, CELoss: 0.33310, loss: 0.33310, batch_cost: 0.60131s, reader_cost: 0.01389, ips: 106.43391 samples/s, eta: 6:29:19
[2022/06/18 23:37:55] ppcls INFO: [Train][Epoch 73/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07751543, top1: 0.88193, CELoss: 0.33011, loss: 0.33011, batch_cost: 0.59990s, reader_cost: 0.01297, ips: 106.68521 samples/s, eta: 6:28:18
[2022/06/18 23:38:00] ppcls INFO: [Train][Epoch 73/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07749637, top1: 0.88228, CELoss: 0.32906, loss: 0.32906, batch_cost: 0.59337s, reader_cost: 0.01230, ips: 107.85853 samples/s, eta: 6:23:59
[2022/06/18 23:38:02] ppcls INFO: [Train][Epoch 73/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07747730, top1: 0.88251, CELoss: 0.32584, loss: 0.32584, batch_cost: 0.57290s, reader_cost: 0.01248, ips: 85.52940 samples/s, eta: 6:10:38
[2022/06/18 23:38:03] ppcls INFO: [Train][Epoch 73/300][Avg]top1: 0.88251, CELoss: 0.32584, loss: 0.32584
[2022/06/18 23:38:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:38:09] ppcls INFO: [Train][Epoch 74/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07747540, top1: 0.90625, CELoss: 0.22965, loss: 0.22965, batch_cost: 0.60725s, reader_cost: 0.04477, ips: 105.39361 samples/s, eta: 6:32:51
[2022/06/18 23:38:15] ppcls INFO: [Train][Epoch 74/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07745631, top1: 0.85511, CELoss: 0.37945, loss: 0.37945, batch_cost: 0.58071s, reader_cost: 0.00039, ips: 110.20911 samples/s, eta: 6:15:35
[2022/06/18 23:38:21] ppcls INFO: [Train][Epoch 74/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07743722, top1: 0.85938, CELoss: 0.36462, loss: 0.36462, batch_cost: 0.61837s, reader_cost: 0.05022, ips: 103.49716 samples/s, eta: 6:39:51
[2022/06/18 23:38:28] ppcls INFO: [Train][Epoch 74/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07741811, top1: 0.86593, CELoss: 0.36273, loss: 0.36273, batch_cost: 0.63483s, reader_cost: 0.08827, ips: 100.81455 samples/s, eta: 6:50:23
[2022/06/18 23:38:34] ppcls INFO: [Train][Epoch 74/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07739899, top1: 0.87005, CELoss: 0.35217, loss: 0.35217, batch_cost: 0.63018s, reader_cost: 0.06818, ips: 101.55807 samples/s, eta: 6:47:16
[2022/06/18 23:38:40] ppcls INFO: [Train][Epoch 74/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07737986, top1: 0.87071, CELoss: 0.35195, loss: 0.35195, batch_cost: 0.62586s, reader_cost: 0.07093, ips: 102.25980 samples/s, eta: 6:44:22
[2022/06/18 23:38:46] ppcls INFO: [Train][Epoch 74/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07736072, top1: 0.86988, CELoss: 0.35423, loss: 0.35423, batch_cost: 0.62089s, reader_cost: 0.07112, ips: 103.07712 samples/s, eta: 6:41:04
[2022/06/18 23:38:52] ppcls INFO: [Train][Epoch 74/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07734156, top1: 0.86994, CELoss: 0.36061, loss: 0.36061, batch_cost: 0.61318s, reader_cost: 0.06904, ips: 104.37347 samples/s, eta: 6:35:58
[2022/06/18 23:38:57] ppcls INFO: [Train][Epoch 74/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07732240, top1: 0.87423, CELoss: 0.35599, loss: 0.35599, batch_cost: 0.60495s, reader_cost: 0.06133, ips: 105.79421 samples/s, eta: 6:30:33
[2022/06/18 23:39:03] ppcls INFO: [Train][Epoch 74/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07730322, top1: 0.87448, CELoss: 0.35642, loss: 0.35642, batch_cost: 0.60211s, reader_cost: 0.06141, ips: 106.29304 samples/s, eta: 6:28:37
[2022/06/18 23:39:09] ppcls INFO: [Train][Epoch 74/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07728402, top1: 0.87701, CELoss: 0.35145, loss: 0.35145, batch_cost: 0.60077s, reader_cost: 0.05759, ips: 106.53039 samples/s, eta: 6:27:39
[2022/06/18 23:39:15] ppcls INFO: [Train][Epoch 74/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07726482, top1: 0.87669, CELoss: 0.35213, loss: 0.35213, batch_cost: 0.60260s, reader_cost: 0.06526, ips: 106.20613 samples/s, eta: 6:28:44
[2022/06/18 23:39:21] ppcls INFO: [Train][Epoch 74/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07724560, top1: 0.87681, CELoss: 0.34836, loss: 0.34836, batch_cost: 0.60157s, reader_cost: 0.06059, ips: 106.38848 samples/s, eta: 6:27:58
[2022/06/18 23:39:27] ppcls INFO: [Train][Epoch 74/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07722638, top1: 0.87762, CELoss: 0.34484, loss: 0.34484, batch_cost: 0.60213s, reader_cost: 0.05608, ips: 106.29003 samples/s, eta: 6:28:14
[2022/06/18 23:39:33] ppcls INFO: [Train][Epoch 74/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07720714, top1: 0.87777, CELoss: 0.34406, loss: 0.34406, batch_cost: 0.60132s, reader_cost: 0.05265, ips: 106.43210 samples/s, eta: 6:27:37
[2022/06/18 23:39:40] ppcls INFO: [Train][Epoch 74/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07718788, top1: 0.87841, CELoss: 0.34093, loss: 0.34093, batch_cost: 0.60379s, reader_cost: 0.04962, ips: 105.99640 samples/s, eta: 6:29:06
[2022/06/18 23:39:44] ppcls INFO: [Train][Epoch 74/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07716862, top1: 0.87849, CELoss: 0.34116, loss: 0.34116, batch_cost: 0.59288s, reader_cost: 0.04676, ips: 107.94769 samples/s, eta: 6:21:58
[2022/06/18 23:39:46] ppcls INFO: [Train][Epoch 74/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07714934, top1: 0.87959, CELoss: 0.33888, loss: 0.33888, batch_cost: 0.56960s, reader_cost: 0.04396, ips: 86.02509 samples/s, eta: 6:06:53
[2022/06/18 23:39:47] ppcls INFO: [Train][Epoch 74/300][Avg]top1: 0.87959, CELoss: 0.33888, loss: 0.33888
[2022/06/18 23:39:47] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:39:53] ppcls INFO: [Train][Epoch 75/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07714741, top1: 0.92188, CELoss: 0.37661, loss: 0.37661, batch_cost: 0.60539s, reader_cost: 0.07035, ips: 105.71761 samples/s, eta: 6:29:55
[2022/06/18 23:40:00] ppcls INFO: [Train][Epoch 75/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07712812, top1: 0.89489, CELoss: 0.32036, loss: 0.32036, batch_cost: 0.65421s, reader_cost: 0.02218, ips: 97.82731 samples/s, eta: 7:01:16
[2022/06/18 23:40:06] ppcls INFO: [Train][Epoch 75/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07710882, top1: 0.89509, CELoss: 0.31045, loss: 0.31045, batch_cost: 0.63251s, reader_cost: 0.01867, ips: 101.18444 samples/s, eta: 6:47:11
[2022/06/18 23:40:12] ppcls INFO: [Train][Epoch 75/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07708951, top1: 0.89567, CELoss: 0.30431, loss: 0.30431, batch_cost: 0.63123s, reader_cost: 0.01708, ips: 101.39015 samples/s, eta: 6:46:15
[2022/06/18 23:40:19] ppcls INFO: [Train][Epoch 75/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07707018, top1: 0.89139, CELoss: 0.30960, loss: 0.30960, batch_cost: 0.63347s, reader_cost: 0.01920, ips: 101.03115 samples/s, eta: 6:47:35
[2022/06/18 23:40:24] ppcls INFO: [Train][Epoch 75/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07705085, top1: 0.88817, CELoss: 0.31871, loss: 0.31871, batch_cost: 0.61079s, reader_cost: 0.01847, ips: 104.78289 samples/s, eta: 6:32:53
[2022/06/18 23:40:30] ppcls INFO: [Train][Epoch 75/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07703150, top1: 0.88601, CELoss: 0.31993, loss: 0.31993, batch_cost: 0.60348s, reader_cost: 0.01948, ips: 106.05104 samples/s, eta: 6:28:05
[2022/06/18 23:40:38] ppcls INFO: [Train][Epoch 75/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07701213, top1: 0.88314, CELoss: 0.32704, loss: 0.32704, batch_cost: 0.63454s, reader_cost: 0.01791, ips: 100.85978 samples/s, eta: 6:47:58
[2022/06/18 23:40:43] ppcls INFO: [Train][Epoch 75/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07699276, top1: 0.88368, CELoss: 0.32923, loss: 0.32923, batch_cost: 0.61974s, reader_cost: 0.01639, ips: 103.26956 samples/s, eta: 6:38:20
[2022/06/18 23:40:49] ppcls INFO: [Train][Epoch 75/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07697337, top1: 0.88238, CELoss: 0.33171, loss: 0.33171, batch_cost: 0.61609s, reader_cost: 0.01596, ips: 103.88059 samples/s, eta: 6:35:54
[2022/06/18 23:40:55] ppcls INFO: [Train][Epoch 75/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07695398, top1: 0.88103, CELoss: 0.33609, loss: 0.33609, batch_cost: 0.61654s, reader_cost: 0.01590, ips: 103.80557 samples/s, eta: 6:36:05
[2022/06/18 23:41:01] ppcls INFO: [Train][Epoch 75/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07693457, top1: 0.87852, CELoss: 0.33917, loss: 0.33917, batch_cost: 0.61592s, reader_cost: 0.01516, ips: 103.91015 samples/s, eta: 6:35:34
[2022/06/18 23:41:07] ppcls INFO: [Train][Epoch 75/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07691514, top1: 0.88081, CELoss: 0.33408, loss: 0.33408, batch_cost: 0.61701s, reader_cost: 0.01530, ips: 103.72612 samples/s, eta: 6:36:10
[2022/06/18 23:41:13] ppcls INFO: [Train][Epoch 75/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07689571, top1: 0.88216, CELoss: 0.33282, loss: 0.33282, batch_cost: 0.61118s, reader_cost: 0.01563, ips: 104.71489 samples/s, eta: 6:32:20
[2022/06/18 23:41:19] ppcls INFO: [Train][Epoch 75/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07687627, top1: 0.88187, CELoss: 0.33262, loss: 0.33262, batch_cost: 0.61095s, reader_cost: 0.01474, ips: 104.75415 samples/s, eta: 6:32:05
[2022/06/18 23:41:24] ppcls INFO: [Train][Epoch 75/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07685681, top1: 0.88152, CELoss: 0.33387, loss: 0.33387, batch_cost: 0.60268s, reader_cost: 0.01414, ips: 106.19169 samples/s, eta: 6:26:40
[2022/06/18 23:41:31] ppcls INFO: [Train][Epoch 75/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07683734, top1: 0.88043, CELoss: 0.33830, loss: 0.33830, batch_cost: 0.60869s, reader_cost: 0.01345, ips: 105.14413 samples/s, eta: 6:30:25
[2022/06/18 23:41:33] ppcls INFO: [Train][Epoch 75/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07681786, top1: 0.88123, CELoss: 0.33724, loss: 0.33724, batch_cost: 0.58431s, reader_cost: 0.01267, ips: 83.85915 samples/s, eta: 6:14:42
[2022/06/18 23:41:33] ppcls INFO: [Train][Epoch 75/300][Avg]top1: 0.88123, CELoss: 0.33724, loss: 0.33724
[2022/06/18 23:41:40] ppcls INFO: [Eval][Epoch 75][Iter: 0/16]CELoss: 0.77450, loss: 0.77450, top1: 0.74805, batch_cost: 7.08838s, reader_cost: 3.48220, ips: 9.02886 images/sec
[2022/06/18 23:41:49] ppcls INFO: [Eval][Epoch 75][Iter: 10/16]CELoss: 0.72241, loss: 0.72241, top1: 0.75692, batch_cost: 0.58283s, reader_cost: 0.00172, ips: 109.80883 images/sec
[2022/06/18 23:41:50] ppcls INFO: [Eval][Epoch 75][Avg]CELoss: 0.67137, loss: 0.67137, top1: 0.76752
[2022/06/18 23:41:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/18 23:41:50] ppcls INFO: [Eval][Epoch 75][best metric: 0.7675245404243469]
[2022/06/18 23:41:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:41:56] ppcls INFO: [Train][Epoch 76/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07681591, top1: 0.96875, CELoss: 0.12883, loss: 0.12883, batch_cost: 0.61550s, reader_cost: 0.04144, ips: 103.98038 samples/s, eta: 6:34:41
[2022/06/18 23:42:04] ppcls INFO: [Train][Epoch 76/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07679641, top1: 0.89773, CELoss: 0.32389, loss: 0.32389, batch_cost: 0.91435s, reader_cost: 0.33112, ips: 69.99506 samples/s, eta: 9:46:10
[2022/06/18 23:42:10] ppcls INFO: [Train][Epoch 76/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07677691, top1: 0.89955, CELoss: 0.31248, loss: 0.31248, batch_cost: 0.72448s, reader_cost: 0.15489, ips: 88.33925 samples/s, eta: 7:44:19
[2022/06/18 23:42:17] ppcls INFO: [Train][Epoch 76/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07675739, top1: 0.89617, CELoss: 0.31258, loss: 0.31258, batch_cost: 0.69270s, reader_cost: 0.15566, ips: 92.39247 samples/s, eta: 7:23:50
[2022/06/18 23:42:22] ppcls INFO: [Train][Epoch 76/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07673786, top1: 0.89748, CELoss: 0.31344, loss: 0.31344, batch_cost: 0.65515s, reader_cost: 0.13986, ips: 97.68717 samples/s, eta: 6:59:40
[2022/06/18 23:42:29] ppcls INFO: [Train][Epoch 76/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07671832, top1: 0.89890, CELoss: 0.30554, loss: 0.30554, batch_cost: 0.66494s, reader_cost: 0.15856, ips: 96.24936 samples/s, eta: 7:05:50
[2022/06/18 23:42:35] ppcls INFO: [Train][Epoch 76/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07669876, top1: 0.89498, CELoss: 0.31822, loss: 0.31822, batch_cost: 0.64829s, reader_cost: 0.14213, ips: 98.72058 samples/s, eta: 6:55:04
[2022/06/18 23:42:41] ppcls INFO: [Train][Epoch 76/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07667919, top1: 0.89459, CELoss: 0.32491, loss: 0.32491, batch_cost: 0.63937s, reader_cost: 0.13408, ips: 100.09833 samples/s, eta: 6:49:15
[2022/06/18 23:42:46] ppcls INFO: [Train][Epoch 76/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07665962, top1: 0.88966, CELoss: 0.32826, loss: 0.32826, batch_cost: 0.63010s, reader_cost: 0.12524, ips: 101.57155 samples/s, eta: 6:43:12
[2022/06/18 23:42:53] ppcls INFO: [Train][Epoch 76/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07664003, top1: 0.88891, CELoss: 0.32770, loss: 0.32770, batch_cost: 0.62774s, reader_cost: 0.11923, ips: 101.95314 samples/s, eta: 6:41:35
[2022/06/18 23:42:58] ppcls INFO: [Train][Epoch 76/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07662043, top1: 0.88583, CELoss: 0.33189, loss: 0.33189, batch_cost: 0.62278s, reader_cost: 0.11065, ips: 102.76583 samples/s, eta: 6:38:18
[2022/06/18 23:43:04] ppcls INFO: [Train][Epoch 76/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07660081, top1: 0.88725, CELoss: 0.32924, loss: 0.32924, batch_cost: 0.61511s, reader_cost: 0.10977, ips: 104.04587 samples/s, eta: 6:33:18
[2022/06/18 23:43:10] ppcls INFO: [Train][Epoch 76/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07658119, top1: 0.88727, CELoss: 0.32922, loss: 0.32922, batch_cost: 0.61708s, reader_cost: 0.11366, ips: 103.71347 samples/s, eta: 6:34:28
[2022/06/18 23:43:17] ppcls INFO: [Train][Epoch 76/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07656155, top1: 0.88573, CELoss: 0.32992, loss: 0.32992, batch_cost: 0.62125s, reader_cost: 0.12114, ips: 103.01788 samples/s, eta: 6:37:01
[2022/06/18 23:43:24] ppcls INFO: [Train][Epoch 76/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07654190, top1: 0.88508, CELoss: 0.33020, loss: 0.33020, batch_cost: 0.62641s, reader_cost: 0.11266, ips: 102.16980 samples/s, eta: 6:40:13
[2022/06/18 23:43:29] ppcls INFO: [Train][Epoch 76/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07652224, top1: 0.88566, CELoss: 0.32962, loss: 0.32962, batch_cost: 0.62053s, reader_cost: 0.10546, ips: 103.13791 samples/s, eta: 6:36:21
[2022/06/18 23:43:35] ppcls INFO: [Train][Epoch 76/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07650257, top1: 0.88606, CELoss: 0.32753, loss: 0.32753, batch_cost: 0.61631s, reader_cost: 0.09890, ips: 103.84396 samples/s, eta: 6:33:33
[2022/06/18 23:43:37] ppcls INFO: [Train][Epoch 76/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07648288, top1: 0.88617, CELoss: 0.32836, loss: 0.32836, batch_cost: 0.59171s, reader_cost: 0.09309, ips: 82.81045 samples/s, eta: 6:17:45
[2022/06/18 23:43:37] ppcls INFO: [Train][Epoch 76/300][Avg]top1: 0.88617, CELoss: 0.32836, loss: 0.32836
[2022/06/18 23:43:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:43:46] ppcls INFO: [Train][Epoch 77/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07648091, top1: 0.89062, CELoss: 0.26160, loss: 0.26160, batch_cost: 0.63638s, reader_cost: 0.12383, ips: 100.56958 samples/s, eta: 6:46:15
[2022/06/18 23:43:51] ppcls INFO: [Train][Epoch 77/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07646121, top1: 0.88920, CELoss: 0.31191, loss: 0.31191, batch_cost: 0.61231s, reader_cost: 0.00727, ips: 104.52172 samples/s, eta: 6:30:47
[2022/06/18 23:43:57] ppcls INFO: [Train][Epoch 77/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07644151, top1: 0.88988, CELoss: 0.31209, loss: 0.31209, batch_cost: 0.60364s, reader_cost: 0.00884, ips: 106.02386 samples/s, eta: 6:25:09
[2022/06/18 23:44:03] ppcls INFO: [Train][Epoch 77/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07642178, top1: 0.88911, CELoss: 0.31008, loss: 0.31008, batch_cost: 0.60333s, reader_cost: 0.00567, ips: 106.07743 samples/s, eta: 6:24:51
[2022/06/18 23:44:09] ppcls INFO: [Train][Epoch 77/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07640205, top1: 0.88872, CELoss: 0.31010, loss: 0.31010, batch_cost: 0.61043s, reader_cost: 0.00759, ips: 104.84470 samples/s, eta: 6:29:17
[2022/06/18 23:44:15] ppcls INFO: [Train][Epoch 77/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07638231, top1: 0.88971, CELoss: 0.31191, loss: 0.31191, batch_cost: 0.61004s, reader_cost: 0.00739, ips: 104.91056 samples/s, eta: 6:28:56
[2022/06/18 23:44:21] ppcls INFO: [Train][Epoch 77/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07636255, top1: 0.88781, CELoss: 0.31731, loss: 0.31731, batch_cost: 0.59423s, reader_cost: 0.01083, ips: 107.70255 samples/s, eta: 6:18:45
[2022/06/18 23:44:27] ppcls INFO: [Train][Epoch 77/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07634278, top1: 0.88754, CELoss: 0.31692, loss: 0.31692, batch_cost: 0.59334s, reader_cost: 0.01253, ips: 107.86332 samples/s, eta: 6:18:05
[2022/06/18 23:44:33] ppcls INFO: [Train][Epoch 77/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07632300, top1: 0.88600, CELoss: 0.32186, loss: 0.32186, batch_cost: 0.59805s, reader_cost: 0.01360, ips: 107.01506 samples/s, eta: 6:20:59
[2022/06/18 23:44:39] ppcls INFO: [Train][Epoch 77/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07630321, top1: 0.88685, CELoss: 0.32115, loss: 0.32115, batch_cost: 0.59500s, reader_cost: 0.01514, ips: 107.56241 samples/s, eta: 6:18:57
[2022/06/18 23:44:44] ppcls INFO: [Train][Epoch 77/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07628341, top1: 0.88614, CELoss: 0.32405, loss: 0.32405, batch_cost: 0.59438s, reader_cost: 0.01455, ips: 107.67528 samples/s, eta: 6:18:27
[2022/06/18 23:44:50] ppcls INFO: [Train][Epoch 77/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07626359, top1: 0.88739, CELoss: 0.32078, loss: 0.32078, batch_cost: 0.58945s, reader_cost: 0.01528, ips: 108.57535 samples/s, eta: 6:15:13
[2022/06/18 23:44:55] ppcls INFO: [Train][Epoch 77/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07624376, top1: 0.88714, CELoss: 0.32332, loss: 0.32332, batch_cost: 0.58593s, reader_cost: 0.01507, ips: 109.22721 samples/s, eta: 6:12:53
[2022/06/18 23:45:02] ppcls INFO: [Train][Epoch 77/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07622393, top1: 0.88764, CELoss: 0.32062, loss: 0.32062, batch_cost: 0.59165s, reader_cost: 0.01478, ips: 108.17260 samples/s, eta: 6:16:25
[2022/06/18 23:45:09] ppcls INFO: [Train][Epoch 77/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07620408, top1: 0.88785, CELoss: 0.32017, loss: 0.32017, batch_cost: 0.59680s, reader_cost: 0.01451, ips: 107.23808 samples/s, eta: 6:19:36
[2022/06/18 23:45:15] ppcls INFO: [Train][Epoch 77/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07618421, top1: 0.88845, CELoss: 0.31948, loss: 0.31948, batch_cost: 0.60113s, reader_cost: 0.01442, ips: 106.46588 samples/s, eta: 6:22:15
[2022/06/18 23:45:21] ppcls INFO: [Train][Epoch 77/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07616434, top1: 0.88742, CELoss: 0.32049, loss: 0.32049, batch_cost: 0.59769s, reader_cost: 0.01407, ips: 107.07969 samples/s, eta: 6:19:58
[2022/06/18 23:45:23] ppcls INFO: [Train][Epoch 77/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07614445, top1: 0.88672, CELoss: 0.32127, loss: 0.32127, batch_cost: 0.57421s, reader_cost: 0.01330, ips: 85.33403 samples/s, eta: 6:04:57
[2022/06/18 23:45:23] ppcls INFO: [Train][Epoch 77/300][Avg]top1: 0.88672, CELoss: 0.32127, loss: 0.32127
[2022/06/18 23:45:23] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:45:29] ppcls INFO: [Train][Epoch 78/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07614246, top1: 0.79688, CELoss: 0.62370, loss: 0.62370, batch_cost: 0.60456s, reader_cost: 0.03971, ips: 105.86289 samples/s, eta: 6:24:13
[2022/06/18 23:45:37] ppcls INFO: [Train][Epoch 78/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07612257, top1: 0.88210, CELoss: 0.32089, loss: 0.32089, batch_cost: 0.99989s, reader_cost: 0.40540, ips: 64.00726 samples/s, eta: 10:35:18
[2022/06/18 23:45:43] ppcls INFO: [Train][Epoch 78/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07610266, top1: 0.88616, CELoss: 0.30519, loss: 0.30519, batch_cost: 0.74880s, reader_cost: 0.16315, ips: 85.47025 samples/s, eta: 7:55:38
[2022/06/18 23:45:50] ppcls INFO: [Train][Epoch 78/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07608273, top1: 0.87853, CELoss: 0.33176, loss: 0.33176, batch_cost: 0.71057s, reader_cost: 0.10302, ips: 90.06899 samples/s, eta: 7:31:14
[2022/06/18 23:45:56] ppcls INFO: [Train][Epoch 78/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07606280, top1: 0.88110, CELoss: 0.32824, loss: 0.32824, batch_cost: 0.67774s, reader_cost: 0.08202, ips: 94.43128 samples/s, eta: 7:10:17
[2022/06/18 23:46:02] ppcls INFO: [Train][Epoch 78/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07604286, top1: 0.88205, CELoss: 0.32889, loss: 0.32889, batch_cost: 0.66740s, reader_cost: 0.06932, ips: 95.89504 samples/s, eta: 7:03:36
[2022/06/18 23:46:08] ppcls INFO: [Train][Epoch 78/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07602290, top1: 0.88243, CELoss: 0.32604, loss: 0.32604, batch_cost: 0.65849s, reader_cost: 0.06196, ips: 97.19217 samples/s, eta: 6:57:50
[2022/06/18 23:46:14] ppcls INFO: [Train][Epoch 78/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07600293, top1: 0.88468, CELoss: 0.32300, loss: 0.32300, batch_cost: 0.64841s, reader_cost: 0.05504, ips: 98.70318 samples/s, eta: 6:51:20
[2022/06/18 23:46:20] ppcls INFO: [Train][Epoch 78/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07598295, top1: 0.88349, CELoss: 0.32697, loss: 0.32697, batch_cost: 0.64610s, reader_cost: 0.04846, ips: 99.05559 samples/s, eta: 6:49:46
[2022/06/18 23:46:26] ppcls INFO: [Train][Epoch 78/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07596296, top1: 0.88462, CELoss: 0.32459, loss: 0.32459, batch_cost: 0.63101s, reader_cost: 0.04533, ips: 101.42395 samples/s, eta: 6:40:05
[2022/06/18 23:46:31] ppcls INFO: [Train][Epoch 78/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07594296, top1: 0.88243, CELoss: 0.33079, loss: 0.33079, batch_cost: 0.61734s, reader_cost: 0.04160, ips: 103.67065 samples/s, eta: 6:31:19
[2022/06/18 23:46:37] ppcls INFO: [Train][Epoch 78/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07592294, top1: 0.88359, CELoss: 0.32817, loss: 0.32817, batch_cost: 0.61680s, reader_cost: 0.03840, ips: 103.76201 samples/s, eta: 6:30:52
[2022/06/18 23:46:43] ppcls INFO: [Train][Epoch 78/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07590292, top1: 0.88417, CELoss: 0.32816, loss: 0.32816, batch_cost: 0.61862s, reader_cost: 0.03685, ips: 103.45593 samples/s, eta: 6:31:55
[2022/06/18 23:46:50] ppcls INFO: [Train][Epoch 78/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07588288, top1: 0.88347, CELoss: 0.32793, loss: 0.32793, batch_cost: 0.62698s, reader_cost: 0.03471, ips: 102.07646 samples/s, eta: 6:37:07
[2022/06/18 23:46:56] ppcls INFO: [Train][Epoch 78/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07586283, top1: 0.88276, CELoss: 0.32806, loss: 0.32806, batch_cost: 0.61907s, reader_cost: 0.03263, ips: 103.38006 samples/s, eta: 6:32:00
[2022/06/18 23:47:03] ppcls INFO: [Train][Epoch 78/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07584277, top1: 0.88421, CELoss: 0.32243, loss: 0.32243, batch_cost: 0.62586s, reader_cost: 0.03059, ips: 102.25936 samples/s, eta: 6:36:12
[2022/06/18 23:47:07] ppcls INFO: [Train][Epoch 78/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07582270, top1: 0.88451, CELoss: 0.32345, loss: 0.32345, batch_cost: 0.61618s, reader_cost: 0.02916, ips: 103.86541 samples/s, eta: 6:29:58
[2022/06/18 23:47:10] ppcls INFO: [Train][Epoch 78/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07580261, top1: 0.88517, CELoss: 0.32345, loss: 0.32345, batch_cost: 0.59153s, reader_cost: 0.02741, ips: 82.83620 samples/s, eta: 6:14:16
[2022/06/18 23:47:10] ppcls INFO: [Train][Epoch 78/300][Avg]top1: 0.88517, CELoss: 0.32345, loss: 0.32345
[2022/06/18 23:47:10] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:47:17] ppcls INFO: [Train][Epoch 79/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07580060, top1: 0.92188, CELoss: 0.28423, loss: 0.28423, batch_cost: 0.62967s, reader_cost: 0.05813, ips: 101.64088 samples/s, eta: 6:38:23
[2022/06/18 23:47:23] ppcls INFO: [Train][Epoch 79/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07578051, top1: 0.89205, CELoss: 0.28728, loss: 0.28728, batch_cost: 0.59796s, reader_cost: 0.05247, ips: 107.03029 samples/s, eta: 6:18:13
[2022/06/18 23:47:29] ppcls INFO: [Train][Epoch 79/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07576040, top1: 0.90253, CELoss: 0.26924, loss: 0.26924, batch_cost: 0.60540s, reader_cost: 0.02884, ips: 105.71604 samples/s, eta: 6:22:49
[2022/06/18 23:47:35] ppcls INFO: [Train][Epoch 79/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07574028, top1: 0.89365, CELoss: 0.29818, loss: 0.29818, batch_cost: 0.60821s, reader_cost: 0.02726, ips: 105.22627 samples/s, eta: 6:24:30
[2022/06/18 23:47:42] ppcls INFO: [Train][Epoch 79/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07572015, top1: 0.89291, CELoss: 0.30138, loss: 0.30138, batch_cost: 0.60810s, reader_cost: 0.05225, ips: 105.24507 samples/s, eta: 6:24:20
[2022/06/18 23:47:48] ppcls INFO: [Train][Epoch 79/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07570000, top1: 0.89032, CELoss: 0.31069, loss: 0.31069, batch_cost: 0.62584s, reader_cost: 0.07362, ips: 102.26326 samples/s, eta: 6:35:26
[2022/06/18 23:47:54] ppcls INFO: [Train][Epoch 79/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07567985, top1: 0.88986, CELoss: 0.31381, loss: 0.31381, batch_cost: 0.61903s, reader_cost: 0.07775, ips: 103.38817 samples/s, eta: 6:31:02
[2022/06/18 23:48:00] ppcls INFO: [Train][Epoch 79/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07565968, top1: 0.89195, CELoss: 0.31051, loss: 0.31051, batch_cost: 0.61763s, reader_cost: 0.09164, ips: 103.62137 samples/s, eta: 6:30:03
[2022/06/18 23:48:06] ppcls INFO: [Train][Epoch 79/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07563950, top1: 0.89313, CELoss: 0.30820, loss: 0.30820, batch_cost: 0.60773s, reader_cost: 0.08129, ips: 105.31024 samples/s, eta: 6:23:41
[2022/06/18 23:48:12] ppcls INFO: [Train][Epoch 79/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07561932, top1: 0.89166, CELoss: 0.31195, loss: 0.31195, batch_cost: 0.61045s, reader_cost: 0.07433, ips: 104.83985 samples/s, eta: 6:25:19
[2022/06/18 23:48:18] ppcls INFO: [Train][Epoch 79/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07559911, top1: 0.88861, CELoss: 0.31867, loss: 0.31867, batch_cost: 0.60919s, reader_cost: 0.06809, ips: 105.05793 samples/s, eta: 6:24:25
[2022/06/18 23:48:24] ppcls INFO: [Train][Epoch 79/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07557890, top1: 0.88837, CELoss: 0.31968, loss: 0.31968, batch_cost: 0.60936s, reader_cost: 0.06846, ips: 105.02855 samples/s, eta: 6:24:25
[2022/06/18 23:48:30] ppcls INFO: [Train][Epoch 79/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07555868, top1: 0.88830, CELoss: 0.32147, loss: 0.32147, batch_cost: 0.60679s, reader_cost: 0.06366, ips: 105.47231 samples/s, eta: 6:22:42
[2022/06/18 23:48:36] ppcls INFO: [Train][Epoch 79/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07553844, top1: 0.88717, CELoss: 0.32471, loss: 0.32471, batch_cost: 0.60850s, reader_cost: 0.06084, ips: 105.17597 samples/s, eta: 6:23:40
[2022/06/18 23:48:42] ppcls INFO: [Train][Epoch 79/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07551820, top1: 0.88697, CELoss: 0.32472, loss: 0.32472, batch_cost: 0.60719s, reader_cost: 0.05655, ips: 105.40421 samples/s, eta: 6:22:45
[2022/06/18 23:48:48] ppcls INFO: [Train][Epoch 79/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07549794, top1: 0.88721, CELoss: 0.32590, loss: 0.32590, batch_cost: 0.60726s, reader_cost: 0.05286, ips: 105.39155 samples/s, eta: 6:22:41
[2022/06/18 23:48:54] ppcls INFO: [Train][Epoch 79/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07547767, top1: 0.88713, CELoss: 0.32691, loss: 0.32691, batch_cost: 0.60444s, reader_cost: 0.04960, ips: 105.88332 samples/s, eta: 6:20:48
[2022/06/18 23:48:56] ppcls INFO: [Train][Epoch 79/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07545739, top1: 0.88672, CELoss: 0.32798, loss: 0.32798, batch_cost: 0.58148s, reader_cost: 0.04737, ips: 84.26710 samples/s, eta: 6:06:15
[2022/06/18 23:48:57] ppcls INFO: [Train][Epoch 79/300][Avg]top1: 0.88672, CELoss: 0.32798, loss: 0.32798
[2022/06/18 23:48:57] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:49:04] ppcls INFO: [Train][Epoch 80/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07545536, top1: 0.89062, CELoss: 0.43808, loss: 0.43808, batch_cost: 0.62319s, reader_cost: 0.08688, ips: 102.69717 samples/s, eta: 6:32:31
[2022/06/18 23:49:10] ppcls INFO: [Train][Epoch 80/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07543507, top1: 0.90199, CELoss: 0.30391, loss: 0.30391, batch_cost: 0.65347s, reader_cost: 0.00340, ips: 97.93884 samples/s, eta: 6:51:28
[2022/06/18 23:49:16] ppcls INFO: [Train][Epoch 80/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07541476, top1: 0.90179, CELoss: 0.29530, loss: 0.29530, batch_cost: 0.60660s, reader_cost: 0.01575, ips: 105.50562 samples/s, eta: 6:21:51
[2022/06/18 23:49:23] ppcls INFO: [Train][Epoch 80/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07539445, top1: 0.89365, CELoss: 0.30391, loss: 0.30391, batch_cost: 0.62269s, reader_cost: 0.01127, ips: 102.77947 samples/s, eta: 6:31:53
[2022/06/18 23:49:28] ppcls INFO: [Train][Epoch 80/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07537412, top1: 0.88872, CELoss: 0.32115, loss: 0.32115, batch_cost: 0.59985s, reader_cost: 0.01738, ips: 106.69278 samples/s, eta: 6:17:25
[2022/06/18 23:49:34] ppcls INFO: [Train][Epoch 80/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07535378, top1: 0.88817, CELoss: 0.32335, loss: 0.32335, batch_cost: 0.59976s, reader_cost: 0.01857, ips: 106.70985 samples/s, eta: 6:17:15
[2022/06/18 23:49:40] ppcls INFO: [Train][Epoch 80/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07533343, top1: 0.88806, CELoss: 0.31753, loss: 0.31753, batch_cost: 0.59973s, reader_cost: 0.01651, ips: 106.71492 samples/s, eta: 6:17:08
[2022/06/18 23:49:46] ppcls INFO: [Train][Epoch 80/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07531307, top1: 0.88864, CELoss: 0.31871, loss: 0.31871, batch_cost: 0.59527s, reader_cost: 0.01729, ips: 107.51396 samples/s, eta: 6:14:14
[2022/06/18 23:49:52] ppcls INFO: [Train][Epoch 80/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07529270, top1: 0.88715, CELoss: 0.32528, loss: 0.32528, batch_cost: 0.59999s, reader_cost: 0.01717, ips: 106.66836 samples/s, eta: 6:17:06
[2022/06/18 23:49:58] ppcls INFO: [Train][Epoch 80/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07527231, top1: 0.88719, CELoss: 0.32701, loss: 0.32701, batch_cost: 0.59642s, reader_cost: 0.01696, ips: 107.30679 samples/s, eta: 6:14:45
[2022/06/18 23:50:05] ppcls INFO: [Train][Epoch 80/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07525192, top1: 0.88722, CELoss: 0.32525, loss: 0.32525, batch_cost: 0.61442s, reader_cost: 0.01680, ips: 104.16359 samples/s, eta: 6:25:58
[2022/06/18 23:50:11] ppcls INFO: [Train][Epoch 80/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07523151, top1: 0.88711, CELoss: 0.32960, loss: 0.32960, batch_cost: 0.60568s, reader_cost: 0.01671, ips: 105.66554 samples/s, eta: 6:20:22
[2022/06/18 23:50:16] ppcls INFO: [Train][Epoch 80/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07521109, top1: 0.88843, CELoss: 0.32582, loss: 0.32582, batch_cost: 0.59980s, reader_cost: 0.01752, ips: 106.70172 samples/s, eta: 6:16:35
[2022/06/18 23:50:23] ppcls INFO: [Train][Epoch 80/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07519066, top1: 0.88896, CELoss: 0.32654, loss: 0.32654, batch_cost: 0.60388s, reader_cost: 0.01711, ips: 105.98083 samples/s, eta: 6:19:02
[2022/06/18 23:50:28] ppcls INFO: [Train][Epoch 80/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07517022, top1: 0.88741, CELoss: 0.32907, loss: 0.32907, batch_cost: 0.60079s, reader_cost: 0.01614, ips: 106.52698 samples/s, eta: 6:17:00
[2022/06/18 23:50:34] ppcls INFO: [Train][Epoch 80/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07514977, top1: 0.88752, CELoss: 0.32849, loss: 0.32849, batch_cost: 0.60198s, reader_cost: 0.01922, ips: 106.31540 samples/s, eta: 6:17:39
[2022/06/18 23:50:39] ppcls INFO: [Train][Epoch 80/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07512930, top1: 0.88597, CELoss: 0.33048, loss: 0.33048, batch_cost: 0.59497s, reader_cost: 0.02378, ips: 107.56896 samples/s, eta: 6:13:09
[2022/06/18 23:50:41] ppcls INFO: [Train][Epoch 80/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07510883, top1: 0.88599, CELoss: 0.33170, loss: 0.33170, batch_cost: 0.57163s, reader_cost: 0.02237, ips: 85.72051 samples/s, eta: 5:58:25
[2022/06/18 23:50:42] ppcls INFO: [Train][Epoch 80/300][Avg]top1: 0.88599, CELoss: 0.33170, loss: 0.33170
[2022/06/18 23:50:49] ppcls INFO: [Eval][Epoch 80][Iter: 0/16]CELoss: 0.74585, loss: 0.74585, top1: 0.75781, batch_cost: 6.97901s, reader_cost: 3.97597, ips: 9.17036 images/sec
[2022/06/18 23:50:57] ppcls INFO: [Eval][Epoch 80][Iter: 10/16]CELoss: 0.73859, loss: 0.73859, top1: 0.75337, batch_cost: 0.57144s, reader_cost: 0.00939, ips: 111.99709 images/sec
[2022/06/18 23:50:58] ppcls INFO: [Eval][Epoch 80][Avg]CELoss: 0.69967, loss: 0.69967, top1: 0.76360
[2022/06/18 23:50:58] ppcls INFO: [Eval][Epoch 80][best metric: 0.7675245404243469]
[2022/06/18 23:50:58] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_80
[2022/06/18 23:50:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:51:05] ppcls INFO: [Train][Epoch 81/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07510678, top1: 0.76562, CELoss: 0.52687, loss: 0.52687, batch_cost: 0.60455s, reader_cost: 0.05315, ips: 105.86419 samples/s, eta: 6:19:03
[2022/06/18 23:51:12] ppcls INFO: [Train][Epoch 81/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07508629, top1: 0.88494, CELoss: 0.35264, loss: 0.35264, batch_cost: 0.63287s, reader_cost: 0.07205, ips: 101.12675 samples/s, eta: 6:36:42
[2022/06/18 23:51:18] ppcls INFO: [Train][Epoch 81/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07506580, top1: 0.89360, CELoss: 0.31564, loss: 0.31564, batch_cost: 0.61853s, reader_cost: 0.03043, ips: 103.47075 samples/s, eta: 6:27:36
[2022/06/18 23:51:24] ppcls INFO: [Train][Epoch 81/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07504529, top1: 0.89264, CELoss: 0.31972, loss: 0.31972, batch_cost: 0.62644s, reader_cost: 0.02384, ips: 102.16443 samples/s, eta: 6:32:27
[2022/06/18 23:51:30] ppcls INFO: [Train][Epoch 81/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07502476, top1: 0.88872, CELoss: 0.32287, loss: 0.32287, batch_cost: 0.61904s, reader_cost: 0.02104, ips: 103.38507 samples/s, eta: 6:27:43
[2022/06/18 23:51:36] ppcls INFO: [Train][Epoch 81/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07500423, top1: 0.89062, CELoss: 0.32014, loss: 0.32014, batch_cost: 0.60440s, reader_cost: 0.02068, ips: 105.88957 samples/s, eta: 6:18:27
[2022/06/18 23:51:42] ppcls INFO: [Train][Epoch 81/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07498369, top1: 0.89421, CELoss: 0.31127, loss: 0.31127, batch_cost: 0.61390s, reader_cost: 0.02113, ips: 104.25211 samples/s, eta: 6:24:17
[2022/06/18 23:51:48] ppcls INFO: [Train][Epoch 81/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07496313, top1: 0.89151, CELoss: 0.31183, loss: 0.31183, batch_cost: 0.61332s, reader_cost: 0.02230, ips: 104.35041 samples/s, eta: 6:23:50
[2022/06/18 23:51:55] ppcls INFO: [Train][Epoch 81/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07494257, top1: 0.88735, CELoss: 0.31995, loss: 0.31995, batch_cost: 0.61434s, reader_cost: 0.02185, ips: 104.17750 samples/s, eta: 6:24:22
[2022/06/18 23:52:01] ppcls INFO: [Train][Epoch 81/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07492199, top1: 0.88582, CELoss: 0.32339, loss: 0.32339, batch_cost: 0.61609s, reader_cost: 0.02795, ips: 103.88012 samples/s, eta: 6:25:22
[2022/06/18 23:52:07] ppcls INFO: [Train][Epoch 81/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07490140, top1: 0.88506, CELoss: 0.32700, loss: 0.32700, batch_cost: 0.61841s, reader_cost: 0.03174, ips: 103.49175 samples/s, eta: 6:26:42
[2022/06/18 23:52:14] ppcls INFO: [Train][Epoch 81/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07488080, top1: 0.88429, CELoss: 0.32690, loss: 0.32690, batch_cost: 0.62073s, reader_cost: 0.04435, ips: 103.10456 samples/s, eta: 6:28:03
[2022/06/18 23:52:19] ppcls INFO: [Train][Epoch 81/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07486019, top1: 0.88404, CELoss: 0.32716, loss: 0.32716, batch_cost: 0.61545s, reader_cost: 0.05084, ips: 103.98972 samples/s, eta: 6:24:39
[2022/06/18 23:52:26] ppcls INFO: [Train][Epoch 81/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07483957, top1: 0.88478, CELoss: 0.32572, loss: 0.32572, batch_cost: 0.61888s, reader_cost: 0.06586, ips: 103.41262 samples/s, eta: 6:26:41
[2022/06/18 23:52:33] ppcls INFO: [Train][Epoch 81/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07481893, top1: 0.88464, CELoss: 0.32474, loss: 0.32474, batch_cost: 0.62767s, reader_cost: 0.07580, ips: 101.96411 samples/s, eta: 6:32:05
[2022/06/18 23:52:38] ppcls INFO: [Train][Epoch 81/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07479829, top1: 0.88338, CELoss: 0.32605, loss: 0.32605, batch_cost: 0.61511s, reader_cost: 0.07217, ips: 104.04642 samples/s, eta: 6:24:08
[2022/06/18 23:52:43] ppcls INFO: [Train][Epoch 81/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07477763, top1: 0.88393, CELoss: 0.32556, loss: 0.32556, batch_cost: 0.61193s, reader_cost: 0.06777, ips: 104.58712 samples/s, eta: 6:22:02
[2022/06/18 23:52:46] ppcls INFO: [Train][Epoch 81/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07475697, top1: 0.88462, CELoss: 0.32426, loss: 0.32426, batch_cost: 0.58764s, reader_cost: 0.06376, ips: 83.38413 samples/s, eta: 6:06:47
[2022/06/18 23:52:46] ppcls INFO: [Train][Epoch 81/300][Avg]top1: 0.88462, CELoss: 0.32426, loss: 0.32426
[2022/06/18 23:52:46] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:52:53] ppcls INFO: [Train][Epoch 82/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07475490, top1: 0.85938, CELoss: 0.39983, loss: 0.39983, batch_cost: 0.62685s, reader_cost: 0.09506, ips: 102.09840 samples/s, eta: 6:31:14
[2022/06/18 23:53:00] ppcls INFO: [Train][Epoch 82/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07473422, top1: 0.88494, CELoss: 0.32182, loss: 0.32182, batch_cost: 0.78292s, reader_cost: 0.19628, ips: 81.74573 samples/s, eta: 8:08:31
[2022/06/18 23:53:06] ppcls INFO: [Train][Epoch 82/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07471353, top1: 0.88914, CELoss: 0.32043, loss: 0.32043, batch_cost: 0.64268s, reader_cost: 0.10142, ips: 99.58361 samples/s, eta: 6:40:54
[2022/06/18 23:53:11] ppcls INFO: [Train][Epoch 82/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07469283, top1: 0.88609, CELoss: 0.32908, loss: 0.32908, batch_cost: 0.62331s, reader_cost: 0.07873, ips: 102.67700 samples/s, eta: 6:28:43
[2022/06/18 23:53:18] ppcls INFO: [Train][Epoch 82/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07467212, top1: 0.88681, CELoss: 0.32611, loss: 0.32611, batch_cost: 0.62447s, reader_cost: 0.06000, ips: 102.48690 samples/s, eta: 6:29:20
[2022/06/18 23:53:24] ppcls INFO: [Train][Epoch 82/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07465139, top1: 0.88848, CELoss: 0.31774, loss: 0.31774, batch_cost: 0.63218s, reader_cost: 0.05024, ips: 101.23625 samples/s, eta: 6:34:03
[2022/06/18 23:53:30] ppcls INFO: [Train][Epoch 82/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07463066, top1: 0.88806, CELoss: 0.31969, loss: 0.31969, batch_cost: 0.62287s, reader_cost: 0.04526, ips: 102.75037 samples/s, eta: 6:28:08
[2022/06/18 23:53:36] ppcls INFO: [Train][Epoch 82/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07460991, top1: 0.89040, CELoss: 0.31741, loss: 0.31741, batch_cost: 0.61071s, reader_cost: 0.04157, ips: 104.79593 samples/s, eta: 6:20:27
[2022/06/18 23:53:41] ppcls INFO: [Train][Epoch 82/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07458915, top1: 0.89198, CELoss: 0.31292, loss: 0.31292, batch_cost: 0.60388s, reader_cost: 0.03799, ips: 105.98123 samples/s, eta: 6:16:06
[2022/06/18 23:53:47] ppcls INFO: [Train][Epoch 82/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07456839, top1: 0.89183, CELoss: 0.31487, loss: 0.31487, batch_cost: 0.59654s, reader_cost: 0.03535, ips: 107.28592 samples/s, eta: 6:11:26
[2022/06/18 23:53:53] ppcls INFO: [Train][Epoch 82/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07454761, top1: 0.89295, CELoss: 0.31208, loss: 0.31208, batch_cost: 0.60410s, reader_cost: 0.03373, ips: 105.94241 samples/s, eta: 6:16:02
[2022/06/18 23:53:58] ppcls INFO: [Train][Epoch 82/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07452682, top1: 0.89372, CELoss: 0.31083, loss: 0.31083, batch_cost: 0.59616s, reader_cost: 0.03153, ips: 107.35400 samples/s, eta: 6:10:59
[2022/06/18 23:54:05] ppcls INFO: [Train][Epoch 82/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07450601, top1: 0.89398, CELoss: 0.31212, loss: 0.31212, batch_cost: 0.59745s, reader_cost: 0.02995, ips: 107.12212 samples/s, eta: 6:11:42
[2022/06/18 23:54:11] ppcls INFO: [Train][Epoch 82/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07448520, top1: 0.89420, CELoss: 0.31282, loss: 0.31282, batch_cost: 0.59750s, reader_cost: 0.02986, ips: 107.11379 samples/s, eta: 6:11:37
[2022/06/18 23:54:16] ppcls INFO: [Train][Epoch 82/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07446438, top1: 0.89473, CELoss: 0.30999, loss: 0.30999, batch_cost: 0.59626s, reader_cost: 0.02820, ips: 107.33556 samples/s, eta: 6:10:45
[2022/06/18 23:54:24] ppcls INFO: [Train][Epoch 82/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07444354, top1: 0.89466, CELoss: 0.31159, loss: 0.31159, batch_cost: 0.60530s, reader_cost: 0.03334, ips: 105.73345 samples/s, eta: 6:16:16
[2022/06/18 23:54:28] ppcls INFO: [Train][Epoch 82/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07442270, top1: 0.89334, CELoss: 0.31497, loss: 0.31497, batch_cost: 0.59322s, reader_cost: 0.03274, ips: 107.88647 samples/s, eta: 6:08:40
[2022/06/18 23:54:30] ppcls INFO: [Train][Epoch 82/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07440184, top1: 0.89368, CELoss: 0.31221, loss: 0.31221, batch_cost: 0.57010s, reader_cost: 0.03080, ips: 85.94961 samples/s, eta: 5:54:12
[2022/06/18 23:54:30] ppcls INFO: [Train][Epoch 82/300][Avg]top1: 0.89368, CELoss: 0.31221, loss: 0.31221
[2022/06/18 23:54:31] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:54:36] ppcls INFO: [Train][Epoch 83/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07439975, top1: 0.90625, CELoss: 0.29666, loss: 0.29666, batch_cost: 0.60013s, reader_cost: 0.06043, ips: 106.64273 samples/s, eta: 6:12:51
[2022/06/18 23:54:43] ppcls INFO: [Train][Epoch 83/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07437889, top1: 0.89915, CELoss: 0.30639, loss: 0.30639, batch_cost: 0.68193s, reader_cost: 0.00041, ips: 93.85089 samples/s, eta: 7:03:34
[2022/06/18 23:54:49] ppcls INFO: [Train][Epoch 83/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07435801, top1: 0.89435, CELoss: 0.31643, loss: 0.31643, batch_cost: 0.63219s, reader_cost: 0.00670, ips: 101.23539 samples/s, eta: 6:32:34
[2022/06/18 23:54:55] ppcls INFO: [Train][Epoch 83/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07433712, top1: 0.89315, CELoss: 0.32467, loss: 0.32467, batch_cost: 0.61451s, reader_cost: 0.00753, ips: 104.14867 samples/s, eta: 6:21:29
[2022/06/18 23:55:02] ppcls INFO: [Train][Epoch 83/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07431621, top1: 0.89215, CELoss: 0.31384, loss: 0.31384, batch_cost: 0.64381s, reader_cost: 0.00734, ips: 99.40797 samples/s, eta: 6:39:34
[2022/06/18 23:55:07] ppcls INFO: [Train][Epoch 83/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07429530, top1: 0.89216, CELoss: 0.31589, loss: 0.31589, batch_cost: 0.62812s, reader_cost: 0.00595, ips: 101.89098 samples/s, eta: 6:29:43
[2022/06/18 23:55:14] ppcls INFO: [Train][Epoch 83/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07427438, top1: 0.89319, CELoss: 0.31413, loss: 0.31413, batch_cost: 0.63219s, reader_cost: 0.00585, ips: 101.23498 samples/s, eta: 6:32:08
[2022/06/18 23:55:21] ppcls INFO: [Train][Epoch 83/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07425344, top1: 0.89591, CELoss: 0.31010, loss: 0.31010, batch_cost: 0.64260s, reader_cost: 0.00763, ips: 99.59493 samples/s, eta: 6:38:29
[2022/06/18 23:55:26] ppcls INFO: [Train][Epoch 83/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07423250, top1: 0.89564, CELoss: 0.30833, loss: 0.30833, batch_cost: 0.62609s, reader_cost: 0.00754, ips: 102.22161 samples/s, eta: 6:28:09
[2022/06/18 23:55:32] ppcls INFO: [Train][Epoch 83/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07421154, top1: 0.89595, CELoss: 0.30863, loss: 0.30863, batch_cost: 0.62203s, reader_cost: 0.00834, ips: 102.88814 samples/s, eta: 6:25:32
[2022/06/18 23:55:39] ppcls INFO: [Train][Epoch 83/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07419057, top1: 0.89480, CELoss: 0.30758, loss: 0.30758, batch_cost: 0.62599s, reader_cost: 0.00827, ips: 102.23861 samples/s, eta: 6:27:52
[2022/06/18 23:55:44] ppcls INFO: [Train][Epoch 83/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07416959, top1: 0.89569, CELoss: 0.30662, loss: 0.30662, batch_cost: 0.61878s, reader_cost: 0.00798, ips: 103.42922 samples/s, eta: 6:23:18
[2022/06/18 23:55:50] ppcls INFO: [Train][Epoch 83/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07414860, top1: 0.89514, CELoss: 0.30654, loss: 0.30654, batch_cost: 0.61624s, reader_cost: 0.00778, ips: 103.85639 samples/s, eta: 6:21:38
[2022/06/18 23:55:57] ppcls INFO: [Train][Epoch 83/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07412760, top1: 0.89468, CELoss: 0.30734, loss: 0.30734, batch_cost: 0.62527s, reader_cost: 0.00886, ips: 102.35519 samples/s, eta: 6:27:07
[2022/06/18 23:56:04] ppcls INFO: [Train][Epoch 83/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07410659, top1: 0.89406, CELoss: 0.30822, loss: 0.30822, batch_cost: 0.62638s, reader_cost: 0.00852, ips: 102.17446 samples/s, eta: 6:27:42
[2022/06/18 23:56:10] ppcls INFO: [Train][Epoch 83/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07408557, top1: 0.89414, CELoss: 0.30882, loss: 0.30882, batch_cost: 0.62543s, reader_cost: 0.00812, ips: 102.32918 samples/s, eta: 6:27:01
[2022/06/18 23:56:15] ppcls INFO: [Train][Epoch 83/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07406454, top1: 0.89451, CELoss: 0.30943, loss: 0.30943, batch_cost: 0.61516s, reader_cost: 0.00776, ips: 104.03770 samples/s, eta: 6:20:33
[2022/06/18 23:56:17] ppcls INFO: [Train][Epoch 83/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07404349, top1: 0.89441, CELoss: 0.31060, loss: 0.31060, batch_cost: 0.59507s, reader_cost: 0.00730, ips: 82.34309 samples/s, eta: 6:08:01
[2022/06/18 23:56:18] ppcls INFO: [Train][Epoch 83/300][Avg]top1: 0.89441, CELoss: 0.31060, loss: 0.31060
[2022/06/18 23:56:18] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:56:26] ppcls INFO: [Train][Epoch 84/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07404139, top1: 0.85938, CELoss: 0.33560, loss: 0.33560, batch_cost: 0.63981s, reader_cost: 0.04004, ips: 100.02940 samples/s, eta: 6:35:41
[2022/06/18 23:56:32] ppcls INFO: [Train][Epoch 84/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07402033, top1: 0.89631, CELoss: 0.30125, loss: 0.30125, batch_cost: 0.61671s, reader_cost: 0.02043, ips: 103.77716 samples/s, eta: 6:21:17
[2022/06/18 23:56:39] ppcls INFO: [Train][Epoch 84/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07399926, top1: 0.88690, CELoss: 0.31345, loss: 0.31345, batch_cost: 0.67501s, reader_cost: 0.01198, ips: 94.81313 samples/s, eta: 6:57:14
[2022/06/18 23:56:44] ppcls INFO: [Train][Epoch 84/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07397818, top1: 0.88558, CELoss: 0.31513, loss: 0.31513, batch_cost: 0.60084s, reader_cost: 0.01735, ips: 106.51749 samples/s, eta: 6:11:17
[2022/06/18 23:56:50] ppcls INFO: [Train][Epoch 84/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07395710, top1: 0.88758, CELoss: 0.31411, loss: 0.31411, batch_cost: 0.60031s, reader_cost: 0.01943, ips: 106.61144 samples/s, eta: 6:10:51
[2022/06/18 23:56:56] ppcls INFO: [Train][Epoch 84/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07393600, top1: 0.88603, CELoss: 0.32018, loss: 0.32018, batch_cost: 0.60486s, reader_cost: 0.01848, ips: 105.81013 samples/s, eta: 6:13:34
[2022/06/18 23:57:03] ppcls INFO: [Train][Epoch 84/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07391489, top1: 0.88397, CELoss: 0.32433, loss: 0.32433, batch_cost: 0.61281s, reader_cost: 0.01741, ips: 104.43614 samples/s, eta: 6:18:22
[2022/06/18 23:57:08] ppcls INFO: [Train][Epoch 84/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07389376, top1: 0.88292, CELoss: 0.32566, loss: 0.32566, batch_cost: 0.60916s, reader_cost: 0.01796, ips: 105.06332 samples/s, eta: 6:16:01
[2022/06/18 23:57:16] ppcls INFO: [Train][Epoch 84/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07387263, top1: 0.88272, CELoss: 0.32608, loss: 0.32608, batch_cost: 0.62513s, reader_cost: 0.01864, ips: 102.37829 samples/s, eta: 6:25:46
[2022/06/18 23:57:21] ppcls INFO: [Train][Epoch 84/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07385149, top1: 0.88221, CELoss: 0.32733, loss: 0.32733, batch_cost: 0.61868s, reader_cost: 0.01781, ips: 103.44666 samples/s, eta: 6:21:41
[2022/06/18 23:57:27] ppcls INFO: [Train][Epoch 84/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07383034, top1: 0.88459, CELoss: 0.32101, loss: 0.32101, batch_cost: 0.61127s, reader_cost: 0.01880, ips: 104.70053 samples/s, eta: 6:17:01
[2022/06/18 23:57:33] ppcls INFO: [Train][Epoch 84/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07380917, top1: 0.88514, CELoss: 0.32198, loss: 0.32198, batch_cost: 0.61228s, reader_cost: 0.01816, ips: 104.52707 samples/s, eta: 6:17:32
[2022/06/18 23:57:39] ppcls INFO: [Train][Epoch 84/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07378800, top1: 0.88572, CELoss: 0.32077, loss: 0.32077, batch_cost: 0.61120s, reader_cost: 0.01760, ips: 104.71284 samples/s, eta: 6:16:46
[2022/06/18 23:57:45] ppcls INFO: [Train][Epoch 84/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07376681, top1: 0.88705, CELoss: 0.31879, loss: 0.31879, batch_cost: 0.60876s, reader_cost: 0.01786, ips: 105.13113 samples/s, eta: 6:15:10
[2022/06/18 23:57:51] ppcls INFO: [Train][Epoch 84/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07374561, top1: 0.88641, CELoss: 0.32031, loss: 0.32031, batch_cost: 0.60526s, reader_cost: 0.01746, ips: 105.73883 samples/s, eta: 6:12:54
[2022/06/18 23:57:58] ppcls INFO: [Train][Epoch 84/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07372440, top1: 0.88762, CELoss: 0.31966, loss: 0.31966, batch_cost: 0.61514s, reader_cost: 0.01665, ips: 104.04087 samples/s, eta: 6:18:53
[2022/06/18 23:58:02] ppcls INFO: [Train][Epoch 84/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07370319, top1: 0.88684, CELoss: 0.31898, loss: 0.31898, batch_cost: 0.60241s, reader_cost: 0.01646, ips: 106.24044 samples/s, eta: 6:10:57
[2022/06/18 23:58:04] ppcls INFO: [Train][Epoch 84/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07368196, top1: 0.88663, CELoss: 0.31849, loss: 0.31849, batch_cost: 0.57915s, reader_cost: 0.01552, ips: 84.60635 samples/s, eta: 5:56:32
[2022/06/18 23:58:05] ppcls INFO: [Train][Epoch 84/300][Avg]top1: 0.88663, CELoss: 0.31849, loss: 0.31849
[2022/06/18 23:58:05] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/18 23:58:11] ppcls INFO: [Train][Epoch 85/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07367983, top1: 0.93750, CELoss: 0.20530, loss: 0.20530, batch_cost: 0.61101s, reader_cost: 0.03937, ips: 104.74422 samples/s, eta: 6:16:08
[2022/06/18 23:58:18] ppcls INFO: [Train][Epoch 85/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07365859, top1: 0.90909, CELoss: 0.27904, loss: 0.27904, batch_cost: 0.73853s, reader_cost: 0.01680, ips: 86.65829 samples/s, eta: 7:34:31
[2022/06/18 23:58:25] ppcls INFO: [Train][Epoch 85/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07363734, top1: 0.90104, CELoss: 0.28441, loss: 0.28441, batch_cost: 0.68744s, reader_cost: 0.01641, ips: 93.09840 samples/s, eta: 7:02:57
[2022/06/18 23:58:31] ppcls INFO: [Train][Epoch 85/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07361608, top1: 0.89617, CELoss: 0.30515, loss: 0.30515, batch_cost: 0.65801s, reader_cost: 0.01553, ips: 97.26249 samples/s, eta: 6:44:44
[2022/06/18 23:58:37] ppcls INFO: [Train][Epoch 85/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07359480, top1: 0.89329, CELoss: 0.30688, loss: 0.30688, batch_cost: 0.65824s, reader_cost: 0.01745, ips: 97.22900 samples/s, eta: 6:44:46
[2022/06/18 23:58:43] ppcls INFO: [Train][Epoch 85/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07357352, top1: 0.89246, CELoss: 0.31518, loss: 0.31518, batch_cost: 0.64973s, reader_cost: 0.01514, ips: 98.50203 samples/s, eta: 6:39:26
[2022/06/18 23:58:49] ppcls INFO: [Train][Epoch 85/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07355222, top1: 0.89114, CELoss: 0.31533, loss: 0.31533, batch_cost: 0.63406s, reader_cost: 0.01377, ips: 100.93655 samples/s, eta: 6:29:41
[2022/06/18 23:58:55] ppcls INFO: [Train][Epoch 85/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07353092, top1: 0.89217, CELoss: 0.31324, loss: 0.31324, batch_cost: 0.62278s, reader_cost: 0.01566, ips: 102.76541 samples/s, eta: 6:22:39
[2022/06/18 23:59:01] ppcls INFO: [Train][Epoch 85/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07350960, top1: 0.89024, CELoss: 0.31567, loss: 0.31567, batch_cost: 0.62245s, reader_cost: 0.01504, ips: 102.81920 samples/s, eta: 6:22:21
[2022/06/18 23:59:08] ppcls INFO: [Train][Epoch 85/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07348828, top1: 0.88822, CELoss: 0.31889, loss: 0.31889, batch_cost: 0.62914s, reader_cost: 0.01479, ips: 101.72549 samples/s, eta: 6:26:21
[2022/06/18 23:59:13] ppcls INFO: [Train][Epoch 85/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07346694, top1: 0.88660, CELoss: 0.32293, loss: 0.32293, batch_cost: 0.62059s, reader_cost: 0.01538, ips: 103.12702 samples/s, eta: 6:21:00
[2022/06/18 23:59:21] ppcls INFO: [Train][Epoch 85/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07344559, top1: 0.88584, CELoss: 0.32234, loss: 0.32234, batch_cost: 0.63484s, reader_cost: 0.01469, ips: 100.81241 samples/s, eta: 6:29:38
[2022/06/18 23:59:27] ppcls INFO: [Train][Epoch 85/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07342423, top1: 0.88649, CELoss: 0.32173, loss: 0.32173, batch_cost: 0.63273s, reader_cost: 0.01470, ips: 101.14919 samples/s, eta: 6:28:14
[2022/06/18 23:59:33] ppcls INFO: [Train][Epoch 85/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07340286, top1: 0.88860, CELoss: 0.31688, loss: 0.31688, batch_cost: 0.62837s, reader_cost: 0.01410, ips: 101.85019 samples/s, eta: 6:25:27
[2022/06/18 23:59:39] ppcls INFO: [Train][Epoch 85/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07338148, top1: 0.88885, CELoss: 0.31774, loss: 0.31774, batch_cost: 0.62424s, reader_cost: 0.01475, ips: 102.52416 samples/s, eta: 6:22:49
[2022/06/18 23:59:45] ppcls INFO: [Train][Epoch 85/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07336009, top1: 0.89083, CELoss: 0.31197, loss: 0.31197, batch_cost: 0.62394s, reader_cost: 0.01445, ips: 102.57407 samples/s, eta: 6:22:32
[2022/06/18 23:59:49] ppcls INFO: [Train][Epoch 85/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07333869, top1: 0.89150, CELoss: 0.30829, loss: 0.30829, batch_cost: 0.61421s, reader_cost: 0.01463, ips: 104.19923 samples/s, eta: 6:16:28
[2022/06/18 23:59:52] ppcls INFO: [Train][Epoch 85/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07331728, top1: 0.89148, CELoss: 0.30987, loss: 0.30987, batch_cost: 0.58976s, reader_cost: 0.01377, ips: 83.08477 samples/s, eta: 6:01:23
[2022/06/18 23:59:52] ppcls INFO: [Train][Epoch 85/300][Avg]top1: 0.89148, CELoss: 0.30987, loss: 0.30987
[2022/06/18 23:59:59] ppcls INFO: [Eval][Epoch 85][Iter: 0/16]CELoss: 0.77592, loss: 0.77592, top1: 0.77148, batch_cost: 6.72975s, reader_cost: 3.76081, ips: 9.51001 images/sec
[2022/06/19 00:00:07] ppcls INFO: [Eval][Epoch 85][Iter: 10/16]CELoss: 0.80589, loss: 0.80589, top1: 0.76829, batch_cost: 0.60191s, reader_cost: 0.01566, ips: 106.32747 images/sec
[2022/06/19 00:00:08] ppcls INFO: [Eval][Epoch 85][Avg]CELoss: 0.66599, loss: 0.66599, top1: 0.77512
[2022/06/19 00:00:08] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 00:00:08] ppcls INFO: [Eval][Epoch 85][best metric: 0.7751225829124451]
[2022/06/19 00:00:09] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:00:15] ppcls INFO: [Train][Epoch 86/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07331513, top1: 0.89062, CELoss: 0.22987, loss: 0.22987, batch_cost: 0.62741s, reader_cost: 0.05064, ips: 102.00668 samples/s, eta: 6:24:26
[2022/06/19 00:00:21] ppcls INFO: [Train][Epoch 86/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07329371, top1: 0.90341, CELoss: 0.28157, loss: 0.28157, batch_cost: 0.55179s, reader_cost: 0.02129, ips: 115.98565 samples/s, eta: 5:38:01
[2022/06/19 00:00:30] ppcls INFO: [Train][Epoch 86/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07327228, top1: 0.89211, CELoss: 0.30885, loss: 0.30885, batch_cost: 0.73749s, reader_cost: 0.01683, ips: 86.78068 samples/s, eta: 7:31:39
[2022/06/19 00:00:34] ppcls INFO: [Train][Epoch 86/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07325083, top1: 0.88861, CELoss: 0.31867, loss: 0.31867, batch_cost: 0.63967s, reader_cost: 0.01317, ips: 100.05083 samples/s, eta: 6:31:38
[2022/06/19 00:00:41] ppcls INFO: [Train][Epoch 86/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07322938, top1: 0.89329, CELoss: 0.30949, loss: 0.30949, batch_cost: 0.63612s, reader_cost: 0.01452, ips: 100.61016 samples/s, eta: 6:29:21
[2022/06/19 00:00:47] ppcls INFO: [Train][Epoch 86/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07320791, top1: 0.89767, CELoss: 0.29936, loss: 0.29936, batch_cost: 0.62865s, reader_cost: 0.01655, ips: 101.80563 samples/s, eta: 6:24:40
[2022/06/19 00:00:52] ppcls INFO: [Train][Epoch 86/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07318643, top1: 0.89703, CELoss: 0.29840, loss: 0.29840, batch_cost: 0.61944s, reader_cost: 0.01757, ips: 103.31951 samples/s, eta: 6:18:56
[2022/06/19 00:00:59] ppcls INFO: [Train][Epoch 86/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07316494, top1: 0.89679, CELoss: 0.29737, loss: 0.29737, batch_cost: 0.61835s, reader_cost: 0.01605, ips: 103.50071 samples/s, eta: 6:18:10
[2022/06/19 00:01:04] ppcls INFO: [Train][Epoch 86/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07314345, top1: 0.89506, CELoss: 0.30008, loss: 0.30008, batch_cost: 0.60782s, reader_cost: 0.01809, ips: 105.29352 samples/s, eta: 6:11:38
[2022/06/19 00:01:10] ppcls INFO: [Train][Epoch 86/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07312194, top1: 0.89560, CELoss: 0.29842, loss: 0.29842, batch_cost: 0.61274s, reader_cost: 0.01911, ips: 104.44863 samples/s, eta: 6:14:32
[2022/06/19 00:01:17] ppcls INFO: [Train][Epoch 86/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07310042, top1: 0.89356, CELoss: 0.30317, loss: 0.30317, batch_cost: 0.61355s, reader_cost: 0.01930, ips: 104.31063 samples/s, eta: 6:14:55
[2022/06/19 00:01:23] ppcls INFO: [Train][Epoch 86/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07307889, top1: 0.89231, CELoss: 0.30465, loss: 0.30465, batch_cost: 0.61205s, reader_cost: 0.01870, ips: 104.56623 samples/s, eta: 6:13:54
[2022/06/19 00:01:29] ppcls INFO: [Train][Epoch 86/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07305735, top1: 0.89114, CELoss: 0.30824, loss: 0.30824, batch_cost: 0.61627s, reader_cost: 0.02996, ips: 103.85129 samples/s, eta: 6:16:23
[2022/06/19 00:01:35] ppcls INFO: [Train][Epoch 86/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07303580, top1: 0.89134, CELoss: 0.30829, loss: 0.30829, batch_cost: 0.61248s, reader_cost: 0.03174, ips: 104.49364 samples/s, eta: 6:13:58
[2022/06/19 00:01:39] ppcls INFO: [Train][Epoch 86/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07301424, top1: 0.89317, CELoss: 0.30528, loss: 0.30528, batch_cost: 0.59975s, reader_cost: 0.03428, ips: 106.71140 samples/s, eta: 6:06:05
[2022/06/19 00:01:48] ppcls INFO: [Train][Epoch 86/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07299267, top1: 0.89207, CELoss: 0.30677, loss: 0.30677, batch_cost: 0.61822s, reader_cost: 0.05147, ips: 103.52221 samples/s, eta: 6:17:16
[2022/06/19 00:01:53] ppcls INFO: [Train][Epoch 86/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07297108, top1: 0.89208, CELoss: 0.30646, loss: 0.30646, batch_cost: 0.60996s, reader_cost: 0.05452, ips: 104.92439 samples/s, eta: 6:12:07
[2022/06/19 00:01:55] ppcls INFO: [Train][Epoch 86/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07294949, top1: 0.89322, CELoss: 0.30329, loss: 0.30329, batch_cost: 0.58578s, reader_cost: 0.05132, ips: 83.64981 samples/s, eta: 5:57:16
[2022/06/19 00:01:56] ppcls INFO: [Train][Epoch 86/300][Avg]top1: 0.89322, CELoss: 0.30329, loss: 0.30329
[2022/06/19 00:01:56] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:02:01] ppcls INFO: [Train][Epoch 87/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07294733, top1: 0.87500, CELoss: 0.33368, loss: 0.33368, batch_cost: 0.61602s, reader_cost: 0.08056, ips: 103.89243 samples/s, eta: 6:15:42
[2022/06/19 00:02:09] ppcls INFO: [Train][Epoch 87/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07292573, top1: 0.89773, CELoss: 0.30854, loss: 0.30854, batch_cost: 0.56757s, reader_cost: 0.01472, ips: 112.76135 samples/s, eta: 5:46:03
[2022/06/19 00:02:15] ppcls INFO: [Train][Epoch 87/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07290411, top1: 0.88690, CELoss: 0.32615, loss: 0.32615, batch_cost: 0.62552s, reader_cost: 0.02158, ips: 102.31491 samples/s, eta: 6:21:17
[2022/06/19 00:02:21] ppcls INFO: [Train][Epoch 87/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07288249, top1: 0.89415, CELoss: 0.31224, loss: 0.31224, batch_cost: 0.61249s, reader_cost: 0.03438, ips: 104.49113 samples/s, eta: 6:13:15
[2022/06/19 00:02:27] ppcls INFO: [Train][Epoch 87/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07286085, top1: 0.89329, CELoss: 0.31173, loss: 0.31173, batch_cost: 0.61136s, reader_cost: 0.02898, ips: 104.68460 samples/s, eta: 6:12:27
[2022/06/19 00:02:34] ppcls INFO: [Train][Epoch 87/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07283920, top1: 0.88909, CELoss: 0.31861, loss: 0.31861, batch_cost: 0.60915s, reader_cost: 0.02569, ips: 105.06465 samples/s, eta: 6:11:00
[2022/06/19 00:02:39] ppcls INFO: [Train][Epoch 87/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07281755, top1: 0.89011, CELoss: 0.31697, loss: 0.31697, batch_cost: 0.60564s, reader_cost: 0.02562, ips: 105.67354 samples/s, eta: 6:08:46
[2022/06/19 00:02:45] ppcls INFO: [Train][Epoch 87/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07279588, top1: 0.88776, CELoss: 0.32124, loss: 0.32124, batch_cost: 0.59869s, reader_cost: 0.02254, ips: 106.90085 samples/s, eta: 6:04:26
[2022/06/19 00:02:50] ppcls INFO: [Train][Epoch 87/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07277420, top1: 0.88850, CELoss: 0.31592, loss: 0.31592, batch_cost: 0.59113s, reader_cost: 0.02301, ips: 108.26683 samples/s, eta: 5:59:44
[2022/06/19 00:02:56] ppcls INFO: [Train][Epoch 87/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07275252, top1: 0.88736, CELoss: 0.31837, loss: 0.31837, batch_cost: 0.58848s, reader_cost: 0.02171, ips: 108.75408 samples/s, eta: 5:58:02
[2022/06/19 00:03:03] ppcls INFO: [Train][Epoch 87/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07273082, top1: 0.88800, CELoss: 0.31622, loss: 0.31622, batch_cost: 0.59390s, reader_cost: 0.02139, ips: 107.76206 samples/s, eta: 6:01:13
[2022/06/19 00:03:08] ppcls INFO: [Train][Epoch 87/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07270911, top1: 0.88978, CELoss: 0.31202, loss: 0.31202, batch_cost: 0.59343s, reader_cost: 0.02091, ips: 107.84805 samples/s, eta: 6:00:50
[2022/06/19 00:03:14] ppcls INFO: [Train][Epoch 87/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07268739, top1: 0.88972, CELoss: 0.31158, loss: 0.31158, batch_cost: 0.58957s, reader_cost: 0.02017, ips: 108.55319 samples/s, eta: 5:58:24
[2022/06/19 00:03:20] ppcls INFO: [Train][Epoch 87/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07266566, top1: 0.89098, CELoss: 0.30990, loss: 0.30990, batch_cost: 0.59442s, reader_cost: 0.02646, ips: 107.66879 samples/s, eta: 6:01:14
[2022/06/19 00:03:27] ppcls INFO: [Train][Epoch 87/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07264392, top1: 0.88918, CELoss: 0.31284, loss: 0.31284, batch_cost: 0.59630s, reader_cost: 0.02695, ips: 107.32906 samples/s, eta: 6:02:17
[2022/06/19 00:03:33] ppcls INFO: [Train][Epoch 87/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07262217, top1: 0.88907, CELoss: 0.31363, loss: 0.31363, batch_cost: 0.59604s, reader_cost: 0.02542, ips: 107.37475 samples/s, eta: 6:02:02
[2022/06/19 00:03:38] ppcls INFO: [Train][Epoch 87/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07260041, top1: 0.88898, CELoss: 0.31444, loss: 0.31444, batch_cost: 0.59094s, reader_cost: 0.02394, ips: 108.30203 samples/s, eta: 5:58:50
[2022/06/19 00:03:40] ppcls INFO: [Train][Epoch 87/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07257864, top1: 0.88837, CELoss: 0.31619, loss: 0.31619, batch_cost: 0.57039s, reader_cost: 0.02253, ips: 85.90663 samples/s, eta: 5:46:15
[2022/06/19 00:03:41] ppcls INFO: [Train][Epoch 87/300][Avg]top1: 0.88837, CELoss: 0.31619, loss: 0.31619
[2022/06/19 00:03:41] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:03:47] ppcls INFO: [Train][Epoch 88/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07257646, top1: 0.87500, CELoss: 0.27602, loss: 0.27602, batch_cost: 0.60515s, reader_cost: 0.05041, ips: 105.75936 samples/s, eta: 6:07:21
[2022/06/19 00:03:53] ppcls INFO: [Train][Epoch 88/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07255468, top1: 0.88636, CELoss: 0.30515, loss: 0.30515, batch_cost: 0.59515s, reader_cost: 0.00035, ips: 107.53562 samples/s, eta: 6:01:11
[2022/06/19 00:04:00] ppcls INFO: [Train][Epoch 88/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07253289, top1: 0.89658, CELoss: 0.29130, loss: 0.29130, batch_cost: 0.64207s, reader_cost: 0.01452, ips: 99.67819 samples/s, eta: 6:29:33
[2022/06/19 00:04:06] ppcls INFO: [Train][Epoch 88/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07251108, top1: 0.89970, CELoss: 0.28298, loss: 0.28298, batch_cost: 0.63700s, reader_cost: 0.01094, ips: 100.47039 samples/s, eta: 6:26:22
[2022/06/19 00:04:12] ppcls INFO: [Train][Epoch 88/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07248927, top1: 0.89939, CELoss: 0.27894, loss: 0.27894, batch_cost: 0.62987s, reader_cost: 0.01218, ips: 101.60875 samples/s, eta: 6:21:56
[2022/06/19 00:04:18] ppcls INFO: [Train][Epoch 88/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07246745, top1: 0.90257, CELoss: 0.27148, loss: 0.27148, batch_cost: 0.62722s, reader_cost: 0.01553, ips: 102.03779 samples/s, eta: 6:20:13
[2022/06/19 00:04:24] ppcls INFO: [Train][Epoch 88/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07244561, top1: 0.90215, CELoss: 0.27763, loss: 0.27763, batch_cost: 0.62220s, reader_cost: 0.01546, ips: 102.86074 samples/s, eta: 6:17:05
[2022/06/19 00:04:30] ppcls INFO: [Train][Epoch 88/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07242377, top1: 0.90053, CELoss: 0.28287, loss: 0.28287, batch_cost: 0.61755s, reader_cost: 0.01520, ips: 103.63601 samples/s, eta: 6:14:09
[2022/06/19 00:04:37] ppcls INFO: [Train][Epoch 88/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07240192, top1: 0.89815, CELoss: 0.29110, loss: 0.29110, batch_cost: 0.62174s, reader_cost: 0.01399, ips: 102.93754 samples/s, eta: 6:16:35
[2022/06/19 00:04:43] ppcls INFO: [Train][Epoch 88/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07238005, top1: 0.89766, CELoss: 0.29376, loss: 0.29376, batch_cost: 0.62535s, reader_cost: 0.01474, ips: 102.34293 samples/s, eta: 6:18:40
[2022/06/19 00:04:50] ppcls INFO: [Train][Epoch 88/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07235818, top1: 0.89774, CELoss: 0.29410, loss: 0.29410, batch_cost: 0.62650s, reader_cost: 0.01479, ips: 102.15470 samples/s, eta: 6:19:16
[2022/06/19 00:04:55] ppcls INFO: [Train][Epoch 88/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07233629, top1: 0.89724, CELoss: 0.29537, loss: 0.29537, batch_cost: 0.61568s, reader_cost: 0.01484, ips: 103.94984 samples/s, eta: 6:12:37
[2022/06/19 00:05:00] ppcls INFO: [Train][Epoch 88/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07231440, top1: 0.89669, CELoss: 0.29613, loss: 0.29613, batch_cost: 0.60826s, reader_cost: 0.01411, ips: 105.21813 samples/s, eta: 6:08:01
[2022/06/19 00:05:06] ppcls INFO: [Train][Epoch 88/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07229249, top1: 0.89778, CELoss: 0.29454, loss: 0.29454, batch_cost: 0.60349s, reader_cost: 0.01416, ips: 106.04950 samples/s, eta: 6:05:02
[2022/06/19 00:05:12] ppcls INFO: [Train][Epoch 88/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07227057, top1: 0.89794, CELoss: 0.29567, loss: 0.29567, batch_cost: 0.60625s, reader_cost: 0.01413, ips: 105.56690 samples/s, eta: 6:06:36
[2022/06/19 00:05:18] ppcls INFO: [Train][Epoch 88/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07224865, top1: 0.89880, CELoss: 0.29440, loss: 0.29440, batch_cost: 0.60647s, reader_cost: 0.01371, ips: 105.52882 samples/s, eta: 6:06:38
[2022/06/19 00:05:24] ppcls INFO: [Train][Epoch 88/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07222671, top1: 0.89907, CELoss: 0.29464, loss: 0.29464, batch_cost: 0.60466s, reader_cost: 0.01285, ips: 105.84382 samples/s, eta: 6:05:26
[2022/06/19 00:05:26] ppcls INFO: [Train][Epoch 88/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07220477, top1: 0.89853, CELoss: 0.29666, loss: 0.29666, batch_cost: 0.58094s, reader_cost: 0.01218, ips: 84.34600 samples/s, eta: 5:51:00
[2022/06/19 00:05:27] ppcls INFO: [Train][Epoch 88/300][Avg]top1: 0.89853, CELoss: 0.29666, loss: 0.29666
[2022/06/19 00:05:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:05:33] ppcls INFO: [Train][Epoch 89/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07220257, top1: 0.87500, CELoss: 0.35255, loss: 0.35255, batch_cost: 0.61797s, reader_cost: 0.04422, ips: 103.56498 samples/s, eta: 6:13:22
[2022/06/19 00:05:40] ppcls INFO: [Train][Epoch 89/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07218061, top1: 0.89773, CELoss: 0.27933, loss: 0.27933, batch_cost: 0.65006s, reader_cost: 0.00033, ips: 98.45182 samples/s, eta: 6:32:39
[2022/06/19 00:05:46] ppcls INFO: [Train][Epoch 89/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07215864, top1: 0.89509, CELoss: 0.29546, loss: 0.29546, batch_cost: 0.62557s, reader_cost: 0.00111, ips: 102.30678 samples/s, eta: 6:17:45
[2022/06/19 00:05:52] ppcls INFO: [Train][Epoch 89/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07213667, top1: 0.89415, CELoss: 0.30117, loss: 0.30117, batch_cost: 0.59993s, reader_cost: 0.00127, ips: 106.67921 samples/s, eta: 6:02:10
[2022/06/19 00:05:58] ppcls INFO: [Train][Epoch 89/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07211468, top1: 0.89367, CELoss: 0.30237, loss: 0.30237, batch_cost: 0.60337s, reader_cost: 0.00134, ips: 106.07148 samples/s, eta: 6:04:09
[2022/06/19 00:06:04] ppcls INFO: [Train][Epoch 89/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07209268, top1: 0.89154, CELoss: 0.30681, loss: 0.30681, batch_cost: 0.59572s, reader_cost: 0.00393, ips: 107.43221 samples/s, eta: 5:59:26
[2022/06/19 00:06:09] ppcls INFO: [Train][Epoch 89/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07207067, top1: 0.89370, CELoss: 0.30353, loss: 0.30353, batch_cost: 0.58773s, reader_cost: 0.01081, ips: 108.89420 samples/s, eta: 5:54:30
[2022/06/19 00:06:17] ppcls INFO: [Train][Epoch 89/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07204865, top1: 0.88908, CELoss: 0.31212, loss: 0.31212, batch_cost: 0.61380s, reader_cost: 0.02855, ips: 104.26814 samples/s, eta: 6:10:08
[2022/06/19 00:06:22] ppcls INFO: [Train][Epoch 89/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07202662, top1: 0.89082, CELoss: 0.31072, loss: 0.31072, batch_cost: 0.59860s, reader_cost: 0.02623, ips: 106.91633 samples/s, eta: 6:00:52
[2022/06/19 00:06:27] ppcls INFO: [Train][Epoch 89/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07200458, top1: 0.89028, CELoss: 0.31162, loss: 0.31162, batch_cost: 0.59643s, reader_cost: 0.02365, ips: 107.30561 samples/s, eta: 5:59:28
[2022/06/19 00:06:33] ppcls INFO: [Train][Epoch 89/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07198253, top1: 0.89109, CELoss: 0.30812, loss: 0.30812, batch_cost: 0.59381s, reader_cost: 0.02151, ips: 107.77909 samples/s, eta: 5:57:47
[2022/06/19 00:06:41] ppcls INFO: [Train][Epoch 89/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07196048, top1: 0.89203, CELoss: 0.30761, loss: 0.30761, batch_cost: 0.60738s, reader_cost: 0.02056, ips: 105.37141 samples/s, eta: 6:05:51
[2022/06/19 00:06:47] ppcls INFO: [Train][Epoch 89/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07193841, top1: 0.89192, CELoss: 0.30772, loss: 0.30772, batch_cost: 0.60692s, reader_cost: 0.01929, ips: 105.45007 samples/s, eta: 6:05:29
[2022/06/19 00:06:52] ppcls INFO: [Train][Epoch 89/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07191633, top1: 0.89253, CELoss: 0.30709, loss: 0.30709, batch_cost: 0.60130s, reader_cost: 0.01859, ips: 106.43606 samples/s, eta: 6:02:00
[2022/06/19 00:06:57] ppcls INFO: [Train][Epoch 89/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07189424, top1: 0.89284, CELoss: 0.30678, loss: 0.30678, batch_cost: 0.59546s, reader_cost: 0.01747, ips: 107.47935 samples/s, eta: 5:58:23
[2022/06/19 00:07:04] ppcls INFO: [Train][Epoch 89/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07187214, top1: 0.89197, CELoss: 0.30838, loss: 0.30838, batch_cost: 0.60115s, reader_cost: 0.01715, ips: 106.46293 samples/s, eta: 6:01:42
[2022/06/19 00:07:09] ppcls INFO: [Train][Epoch 89/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07185003, top1: 0.89334, CELoss: 0.30611, loss: 0.30611, batch_cost: 0.59557s, reader_cost: 0.01629, ips: 107.46004 samples/s, eta: 5:58:15
[2022/06/19 00:07:11] ppcls INFO: [Train][Epoch 89/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07182791, top1: 0.89221, CELoss: 0.30820, loss: 0.30820, batch_cost: 0.57220s, reader_cost: 0.01534, ips: 85.63416 samples/s, eta: 5:44:06
[2022/06/19 00:07:12] ppcls INFO: [Train][Epoch 89/300][Avg]top1: 0.89221, CELoss: 0.30820, loss: 0.30820
[2022/06/19 00:07:12] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:07:18] ppcls INFO: [Train][Epoch 90/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07182569, top1: 0.87500, CELoss: 0.29572, loss: 0.29572, batch_cost: 0.60579s, reader_cost: 0.04498, ips: 105.64739 samples/s, eta: 6:04:17
[2022/06/19 00:07:25] ppcls INFO: [Train][Epoch 90/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07180356, top1: 0.90483, CELoss: 0.29141, loss: 0.29141, batch_cost: 0.61653s, reader_cost: 0.00193, ips: 103.80627 samples/s, eta: 6:10:38
[2022/06/19 00:07:31] ppcls INFO: [Train][Epoch 90/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07178142, top1: 0.90179, CELoss: 0.29862, loss: 0.29862, batch_cost: 0.63163s, reader_cost: 0.00864, ips: 101.32490 samples/s, eta: 6:19:37
[2022/06/19 00:07:38] ppcls INFO: [Train][Epoch 90/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07175927, top1: 0.90323, CELoss: 0.28854, loss: 0.28854, batch_cost: 0.63815s, reader_cost: 0.02996, ips: 100.28947 samples/s, eta: 6:23:26
[2022/06/19 00:07:44] ppcls INFO: [Train][Epoch 90/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07173711, top1: 0.90587, CELoss: 0.28482, loss: 0.28482, batch_cost: 0.64907s, reader_cost: 0.02920, ips: 98.60250 samples/s, eta: 6:29:53
[2022/06/19 00:07:50] ppcls INFO: [Train][Epoch 90/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07171494, top1: 0.90656, CELoss: 0.28196, loss: 0.28196, batch_cost: 0.63398s, reader_cost: 0.02389, ips: 100.94904 samples/s, eta: 6:20:43
[2022/06/19 00:07:56] ppcls INFO: [Train][Epoch 90/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07169276, top1: 0.90446, CELoss: 0.28454, loss: 0.28454, batch_cost: 0.61602s, reader_cost: 0.02216, ips: 103.89333 samples/s, eta: 6:09:49
[2022/06/19 00:08:01] ppcls INFO: [Train][Epoch 90/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07167057, top1: 0.90185, CELoss: 0.28409, loss: 0.28409, batch_cost: 0.61205s, reader_cost: 0.02620, ips: 104.56721 samples/s, eta: 6:07:20
[2022/06/19 00:08:08] ppcls INFO: [Train][Epoch 90/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07164837, top1: 0.90220, CELoss: 0.28308, loss: 0.28308, batch_cost: 0.61432s, reader_cost: 0.04051, ips: 104.18070 samples/s, eta: 6:08:36
[2022/06/19 00:08:14] ppcls INFO: [Train][Epoch 90/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07162615, top1: 0.90196, CELoss: 0.28661, loss: 0.28661, batch_cost: 0.61716s, reader_cost: 0.05449, ips: 103.70119 samples/s, eta: 6:10:12
[2022/06/19 00:08:21] ppcls INFO: [Train][Epoch 90/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07160393, top1: 0.90037, CELoss: 0.28785, loss: 0.28785, batch_cost: 0.62247s, reader_cost: 0.07074, ips: 102.81608 samples/s, eta: 6:13:17
[2022/06/19 00:08:26] ppcls INFO: [Train][Epoch 90/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07158170, top1: 0.89992, CELoss: 0.28808, loss: 0.28808, batch_cost: 0.61008s, reader_cost: 0.06540, ips: 104.90506 samples/s, eta: 6:05:45
[2022/06/19 00:08:32] ppcls INFO: [Train][Epoch 90/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07155946, top1: 0.89992, CELoss: 0.28712, loss: 0.28712, batch_cost: 0.61346s, reader_cost: 0.07166, ips: 104.32624 samples/s, eta: 6:07:40
[2022/06/19 00:08:38] ppcls INFO: [Train][Epoch 90/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07153721, top1: 0.89921, CELoss: 0.28960, loss: 0.28960, batch_cost: 0.61404s, reader_cost: 0.07751, ips: 104.22829 samples/s, eta: 6:07:55
[2022/06/19 00:08:44] ppcls INFO: [Train][Epoch 90/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07151495, top1: 0.89883, CELoss: 0.28996, loss: 0.28996, batch_cost: 0.60923s, reader_cost: 0.07396, ips: 105.04984 samples/s, eta: 6:04:56
[2022/06/19 00:08:51] ppcls INFO: [Train][Epoch 90/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07149268, top1: 0.89828, CELoss: 0.29050, loss: 0.29050, batch_cost: 0.61541s, reader_cost: 0.06994, ips: 103.99557 samples/s, eta: 6:08:32
[2022/06/19 00:08:56] ppcls INFO: [Train][Epoch 90/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07147040, top1: 0.89684, CELoss: 0.29263, loss: 0.29263, batch_cost: 0.61105s, reader_cost: 0.06700, ips: 104.73735 samples/s, eta: 6:05:49
[2022/06/19 00:08:58] ppcls INFO: [Train][Epoch 90/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07144811, top1: 0.89642, CELoss: 0.29264, loss: 0.29264, batch_cost: 0.58679s, reader_cost: 0.06299, ips: 83.50494 samples/s, eta: 5:51:12
[2022/06/19 00:08:59] ppcls INFO: [Train][Epoch 90/300][Avg]top1: 0.89642, CELoss: 0.29264, loss: 0.29264
[2022/06/19 00:09:06] ppcls INFO: [Eval][Epoch 90][Iter: 0/16]CELoss: 0.89869, loss: 0.89869, top1: 0.73438, batch_cost: 7.30941s, reader_cost: 3.77091, ips: 8.75584 images/sec
[2022/06/19 00:09:14] ppcls INFO: [Eval][Epoch 90][Iter: 10/16]CELoss: 0.63439, loss: 0.63439, top1: 0.77770, batch_cost: 0.56348s, reader_cost: 0.00361, ips: 113.57994 images/sec
[2022/06/19 00:09:16] ppcls INFO: [Eval][Epoch 90][Avg]CELoss: 0.65797, loss: 0.65797, top1: 0.78456
[2022/06/19 00:09:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 00:09:16] ppcls INFO: [Eval][Epoch 90][best metric: 0.784558892250061]
[2022/06/19 00:09:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_90
[2022/06/19 00:09:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:09:24] ppcls INFO: [Train][Epoch 91/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07144588, top1: 0.89062, CELoss: 0.26168, loss: 0.26168, batch_cost: 0.63071s, reader_cost: 0.10681, ips: 101.47331 samples/s, eta: 6:17:28
[2022/06/19 00:09:30] ppcls INFO: [Train][Epoch 91/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07142358, top1: 0.90767, CELoss: 0.27934, loss: 0.27934, batch_cost: 0.66679s, reader_cost: 0.09687, ips: 95.98245 samples/s, eta: 6:38:57
[2022/06/19 00:09:36] ppcls INFO: [Train][Epoch 91/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07140126, top1: 0.89435, CELoss: 0.28955, loss: 0.28955, batch_cost: 0.61907s, reader_cost: 0.04034, ips: 103.38163 samples/s, eta: 6:10:18
[2022/06/19 00:09:42] ppcls INFO: [Train][Epoch 91/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07137894, top1: 0.89466, CELoss: 0.29544, loss: 0.29544, batch_cost: 0.62443s, reader_cost: 0.03001, ips: 102.49377 samples/s, eta: 6:13:24
[2022/06/19 00:09:48] ppcls INFO: [Train][Epoch 91/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07135661, top1: 0.89367, CELoss: 0.29605, loss: 0.29605, batch_cost: 0.60863s, reader_cost: 0.02312, ips: 105.15476 samples/s, eta: 6:03:51
[2022/06/19 00:09:55] ppcls INFO: [Train][Epoch 91/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07133427, top1: 0.89338, CELoss: 0.29638, loss: 0.29638, batch_cost: 0.63468s, reader_cost: 0.05637, ips: 100.83753 samples/s, eta: 6:19:19
[2022/06/19 00:10:01] ppcls INFO: [Train][Epoch 91/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07131192, top1: 0.89600, CELoss: 0.29311, loss: 0.29311, batch_cost: 0.62723s, reader_cost: 0.06780, ips: 102.03558 samples/s, eta: 6:14:46
[2022/06/19 00:10:07] ppcls INFO: [Train][Epoch 91/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07128956, top1: 0.89789, CELoss: 0.28971, loss: 0.28971, batch_cost: 0.61692s, reader_cost: 0.06313, ips: 103.74170 samples/s, eta: 6:08:30
[2022/06/19 00:10:13] ppcls INFO: [Train][Epoch 91/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07126719, top1: 0.89796, CELoss: 0.29350, loss: 0.29350, batch_cost: 0.62364s, reader_cost: 0.07733, ips: 102.62382 samples/s, eta: 6:12:24
[2022/06/19 00:10:19] ppcls INFO: [Train][Epoch 91/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07124481, top1: 0.89852, CELoss: 0.29224, loss: 0.29224, batch_cost: 0.61960s, reader_cost: 0.06988, ips: 103.29306 samples/s, eta: 6:09:53
[2022/06/19 00:10:25] ppcls INFO: [Train][Epoch 91/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07122242, top1: 0.89913, CELoss: 0.29337, loss: 0.29337, batch_cost: 0.61997s, reader_cost: 0.07431, ips: 103.23076 samples/s, eta: 6:10:01
[2022/06/19 00:10:31] ppcls INFO: [Train][Epoch 91/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07120002, top1: 0.89738, CELoss: 0.29676, loss: 0.29676, batch_cost: 0.61131s, reader_cost: 0.07107, ips: 104.69243 samples/s, eta: 6:04:45
[2022/06/19 00:10:39] ppcls INFO: [Train][Epoch 91/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07117760, top1: 0.89579, CELoss: 0.29997, loss: 0.29997, batch_cost: 0.63098s, reader_cost: 0.09384, ips: 101.42990 samples/s, eta: 6:16:22
[2022/06/19 00:10:44] ppcls INFO: [Train][Epoch 91/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07115518, top1: 0.89611, CELoss: 0.30145, loss: 0.30145, batch_cost: 0.61894s, reader_cost: 0.09226, ips: 103.40319 samples/s, eta: 6:09:05
[2022/06/19 00:10:49] ppcls INFO: [Train][Epoch 91/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07113275, top1: 0.89694, CELoss: 0.30073, loss: 0.30073, batch_cost: 0.61456s, reader_cost: 0.10462, ips: 104.14034 samples/s, eta: 6:06:22
[2022/06/19 00:10:55] ppcls INFO: [Train][Epoch 91/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07111032, top1: 0.89797, CELoss: 0.29803, loss: 0.29803, batch_cost: 0.60707s, reader_cost: 0.11127, ips: 105.42474 samples/s, eta: 6:01:48
[2022/06/19 00:11:05] ppcls INFO: [Train][Epoch 91/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07108787, top1: 0.89936, CELoss: 0.29508, loss: 0.29508, batch_cost: 0.63308s, reader_cost: 0.14952, ips: 101.09362 samples/s, eta: 6:17:12
[2022/06/19 00:11:07] ppcls INFO: [Train][Epoch 91/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07106541, top1: 0.89862, CELoss: 0.29812, loss: 0.29812, batch_cost: 0.60733s, reader_cost: 0.14052, ips: 80.68093 samples/s, eta: 6:01:45
[2022/06/19 00:11:07] ppcls INFO: [Train][Epoch 91/300][Avg]top1: 0.89862, CELoss: 0.29812, loss: 0.29812
[2022/06/19 00:11:07] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:11:14] ppcls INFO: [Train][Epoch 92/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07106316, top1: 0.93750, CELoss: 0.33330, loss: 0.33330, batch_cost: 0.64159s, reader_cost: 0.17080, ips: 99.75224 samples/s, eta: 6:22:09
[2022/06/19 00:11:20] ppcls INFO: [Train][Epoch 92/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07104069, top1: 0.90625, CELoss: 0.27004, loss: 0.27004, batch_cost: 0.58198s, reader_cost: 0.01309, ips: 109.96952 samples/s, eta: 5:46:33
[2022/06/19 00:11:26] ppcls INFO: [Train][Epoch 92/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07101821, top1: 0.90030, CELoss: 0.28287, loss: 0.28287, batch_cost: 0.64906s, reader_cost: 0.01532, ips: 98.60447 samples/s, eta: 6:26:23
[2022/06/19 00:11:33] ppcls INFO: [Train][Epoch 92/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07099572, top1: 0.89617, CELoss: 0.29143, loss: 0.29143, batch_cost: 0.63871s, reader_cost: 0.01762, ips: 100.20179 samples/s, eta: 6:20:07
[2022/06/19 00:11:40] ppcls INFO: [Train][Epoch 92/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07097322, top1: 0.89177, CELoss: 0.29585, loss: 0.29585, batch_cost: 0.65232s, reader_cost: 0.02052, ips: 98.11146 samples/s, eta: 6:28:07
[2022/06/19 00:11:46] ppcls INFO: [Train][Epoch 92/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07095071, top1: 0.89308, CELoss: 0.29462, loss: 0.29462, batch_cost: 0.64084s, reader_cost: 0.01914, ips: 99.86848 samples/s, eta: 6:21:11
[2022/06/19 00:11:51] ppcls INFO: [Train][Epoch 92/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07092819, top1: 0.89857, CELoss: 0.28642, loss: 0.28642, batch_cost: 0.63181s, reader_cost: 0.02021, ips: 101.29552 samples/s, eta: 6:15:42
[2022/06/19 00:11:57] ppcls INFO: [Train][Epoch 92/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07090567, top1: 0.89921, CELoss: 0.28618, loss: 0.28618, batch_cost: 0.61980s, reader_cost: 0.01845, ips: 103.25928 samples/s, eta: 6:08:27
[2022/06/19 00:12:02] ppcls INFO: [Train][Epoch 92/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07088313, top1: 0.90085, CELoss: 0.28462, loss: 0.28462, batch_cost: 0.60918s, reader_cost: 0.02016, ips: 105.05934 samples/s, eta: 6:02:02
[2022/06/19 00:12:09] ppcls INFO: [Train][Epoch 92/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07086058, top1: 0.90024, CELoss: 0.28532, loss: 0.28532, batch_cost: 0.61121s, reader_cost: 0.02000, ips: 104.71058 samples/s, eta: 6:03:08
[2022/06/19 00:12:14] ppcls INFO: [Train][Epoch 92/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07083802, top1: 0.89821, CELoss: 0.28991, loss: 0.28991, batch_cost: 0.60714s, reader_cost: 0.02017, ips: 105.41142 samples/s, eta: 6:00:38
[2022/06/19 00:12:20] ppcls INFO: [Train][Epoch 92/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07081545, top1: 0.89907, CELoss: 0.28830, loss: 0.28830, batch_cost: 0.60361s, reader_cost: 0.02053, ips: 106.02799 samples/s, eta: 5:58:26
[2022/06/19 00:12:26] ppcls INFO: [Train][Epoch 92/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07079288, top1: 0.89889, CELoss: 0.28780, loss: 0.28780, batch_cost: 0.60662s, reader_cost: 0.01949, ips: 105.50185 samples/s, eta: 6:00:07
[2022/06/19 00:12:32] ppcls INFO: [Train][Epoch 92/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07077029, top1: 0.89885, CELoss: 0.28960, loss: 0.28960, batch_cost: 0.60471s, reader_cost: 0.01860, ips: 105.83649 samples/s, eta: 5:58:52
[2022/06/19 00:12:38] ppcls INFO: [Train][Epoch 92/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07074769, top1: 0.89894, CELoss: 0.29202, loss: 0.29202, batch_cost: 0.60354s, reader_cost: 0.01848, ips: 106.04097 samples/s, eta: 5:58:05
[2022/06/19 00:12:44] ppcls INFO: [Train][Epoch 92/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07072509, top1: 0.89921, CELoss: 0.29034, loss: 0.29034, batch_cost: 0.59902s, reader_cost: 0.02356, ips: 106.84201 samples/s, eta: 5:55:18
[2022/06/19 00:12:50] ppcls INFO: [Train][Epoch 92/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07070247, top1: 0.89936, CELoss: 0.29053, loss: 0.29053, batch_cost: 0.60090s, reader_cost: 0.02427, ips: 106.50625 samples/s, eta: 5:56:19
[2022/06/19 00:12:52] ppcls INFO: [Train][Epoch 92/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07067985, top1: 0.89908, CELoss: 0.29210, loss: 0.29210, batch_cost: 0.57716s, reader_cost: 0.02284, ips: 84.89856 samples/s, eta: 5:42:08
[2022/06/19 00:12:52] ppcls INFO: [Train][Epoch 92/300][Avg]top1: 0.89908, CELoss: 0.29210, loss: 0.29210
[2022/06/19 00:12:53] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:12:58] ppcls INFO: [Train][Epoch 93/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07067758, top1: 0.92188, CELoss: 0.19719, loss: 0.19719, batch_cost: 0.60805s, reader_cost: 0.04870, ips: 105.25505 samples/s, eta: 6:00:27
[2022/06/19 00:13:05] ppcls INFO: [Train][Epoch 93/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07065495, top1: 0.90057, CELoss: 0.25591, loss: 0.25591, batch_cost: 0.63671s, reader_cost: 0.06303, ips: 100.51610 samples/s, eta: 6:17:20
[2022/06/19 00:13:12] ppcls INFO: [Train][Epoch 93/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07063230, top1: 0.90848, CELoss: 0.23418, loss: 0.23418, batch_cost: 0.71779s, reader_cost: 0.03704, ips: 89.16235 samples/s, eta: 7:05:16
[2022/06/19 00:13:18] ppcls INFO: [Train][Epoch 93/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07060965, top1: 0.90423, CELoss: 0.25870, loss: 0.25870, batch_cost: 0.65446s, reader_cost: 0.03457, ips: 97.79118 samples/s, eta: 6:27:38
[2022/06/19 00:13:24] ppcls INFO: [Train][Epoch 93/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07058698, top1: 0.90053, CELoss: 0.27053, loss: 0.27053, batch_cost: 0.64118s, reader_cost: 0.03102, ips: 99.81583 samples/s, eta: 6:19:39
[2022/06/19 00:13:30] ppcls INFO: [Train][Epoch 93/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07056431, top1: 0.89951, CELoss: 0.27134, loss: 0.27134, batch_cost: 0.63883s, reader_cost: 0.03334, ips: 100.18339 samples/s, eta: 6:18:09
[2022/06/19 00:13:37] ppcls INFO: [Train][Epoch 93/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07054163, top1: 0.89882, CELoss: 0.27244, loss: 0.27244, batch_cost: 0.63880s, reader_cost: 0.02852, ips: 100.18819 samples/s, eta: 6:18:02
[2022/06/19 00:13:42] ppcls INFO: [Train][Epoch 93/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07051893, top1: 0.90075, CELoss: 0.27089, loss: 0.27089, batch_cost: 0.62704s, reader_cost: 0.02532, ips: 102.06644 samples/s, eta: 6:10:58
[2022/06/19 00:13:48] ppcls INFO: [Train][Epoch 93/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07049623, top1: 0.90027, CELoss: 0.27242, loss: 0.27242, batch_cost: 0.62458s, reader_cost: 0.02481, ips: 102.46956 samples/s, eta: 6:09:24
[2022/06/19 00:13:55] ppcls INFO: [Train][Epoch 93/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07047352, top1: 0.90024, CELoss: 0.27350, loss: 0.27350, batch_cost: 0.63089s, reader_cost: 0.02351, ips: 101.44322 samples/s, eta: 6:13:02
[2022/06/19 00:14:01] ppcls INFO: [Train][Epoch 93/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07045079, top1: 0.90053, CELoss: 0.27404, loss: 0.27404, batch_cost: 0.62260s, reader_cost: 0.02387, ips: 102.79392 samples/s, eta: 6:08:02
[2022/06/19 00:14:07] ppcls INFO: [Train][Epoch 93/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07042806, top1: 0.89935, CELoss: 0.27831, loss: 0.27831, batch_cost: 0.62337s, reader_cost: 0.02340, ips: 102.66750 samples/s, eta: 6:08:23
[2022/06/19 00:14:14] ppcls INFO: [Train][Epoch 93/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07040532, top1: 0.89773, CELoss: 0.28338, loss: 0.28338, batch_cost: 0.62484s, reader_cost: 0.02215, ips: 102.42673 samples/s, eta: 6:09:09
[2022/06/19 00:14:19] ppcls INFO: [Train][Epoch 93/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.07038257, top1: 0.89766, CELoss: 0.28366, loss: 0.28366, batch_cost: 0.62125s, reader_cost: 0.02148, ips: 103.01734 samples/s, eta: 6:06:56
[2022/06/19 00:14:26] ppcls INFO: [Train][Epoch 93/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.07035981, top1: 0.89683, CELoss: 0.28583, loss: 0.28583, batch_cost: 0.62407s, reader_cost: 0.02022, ips: 102.55239 samples/s, eta: 6:08:29
[2022/06/19 00:14:33] ppcls INFO: [Train][Epoch 93/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.07033704, top1: 0.89652, CELoss: 0.28754, loss: 0.28754, batch_cost: 0.62728s, reader_cost: 0.01905, ips: 102.02780 samples/s, eta: 6:10:17
[2022/06/19 00:14:38] ppcls INFO: [Train][Epoch 93/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.07031426, top1: 0.89557, CELoss: 0.29182, loss: 0.29182, batch_cost: 0.62216s, reader_cost: 0.01798, ips: 102.86708 samples/s, eta: 6:07:09
[2022/06/19 00:14:40] ppcls INFO: [Train][Epoch 93/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.07029147, top1: 0.89569, CELoss: 0.29059, loss: 0.29059, batch_cost: 0.59719s, reader_cost: 0.01694, ips: 82.05038 samples/s, eta: 5:52:19
[2022/06/19 00:14:41] ppcls INFO: [Train][Epoch 93/300][Avg]top1: 0.89569, CELoss: 0.29059, loss: 0.29059
[2022/06/19 00:14:41] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:14:47] ppcls INFO: [Train][Epoch 94/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.07028919, top1: 0.85938, CELoss: 0.34815, loss: 0.34815, batch_cost: 0.62940s, reader_cost: 0.04474, ips: 101.68388 samples/s, eta: 6:11:18
[2022/06/19 00:14:54] ppcls INFO: [Train][Epoch 94/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.07026639, top1: 0.90057, CELoss: 0.29534, loss: 0.29534, batch_cost: 0.78327s, reader_cost: 0.02097, ips: 81.70906 samples/s, eta: 7:41:57
[2022/06/19 00:15:00] ppcls INFO: [Train][Epoch 94/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.07024359, top1: 0.89509, CELoss: 0.29314, loss: 0.29314, batch_cost: 0.66299s, reader_cost: 0.01273, ips: 96.53248 samples/s, eta: 6:30:54
[2022/06/19 00:15:06] ppcls INFO: [Train][Epoch 94/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.07022077, top1: 0.88911, CELoss: 0.31167, loss: 0.31167, batch_cost: 0.61985s, reader_cost: 0.01583, ips: 103.25098 samples/s, eta: 6:05:22
[2022/06/19 00:15:12] ppcls INFO: [Train][Epoch 94/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.07019794, top1: 0.88834, CELoss: 0.30670, loss: 0.30670, batch_cost: 0.63083s, reader_cost: 0.01669, ips: 101.45341 samples/s, eta: 6:11:44
[2022/06/19 00:15:18] ppcls INFO: [Train][Epoch 94/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.07017510, top1: 0.88664, CELoss: 0.30829, loss: 0.30829, batch_cost: 0.61312s, reader_cost: 0.01686, ips: 104.38487 samples/s, eta: 6:01:11
[2022/06/19 00:15:25] ppcls INFO: [Train][Epoch 94/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.07015226, top1: 0.88806, CELoss: 0.30522, loss: 0.30522, batch_cost: 0.62491s, reader_cost: 0.01491, ips: 102.41422 samples/s, eta: 6:08:02
[2022/06/19 00:15:30] ppcls INFO: [Train][Epoch 94/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.07012940, top1: 0.88974, CELoss: 0.30526, loss: 0.30526, batch_cost: 0.61222s, reader_cost: 0.01334, ips: 104.53843 samples/s, eta: 6:00:27
[2022/06/19 00:15:36] ppcls INFO: [Train][Epoch 94/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.07010654, top1: 0.88908, CELoss: 0.30719, loss: 0.30719, batch_cost: 0.60826s, reader_cost: 0.01330, ips: 105.21869 samples/s, eta: 5:58:01
[2022/06/19 00:15:43] ppcls INFO: [Train][Epoch 94/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.07008366, top1: 0.88771, CELoss: 0.30958, loss: 0.30958, batch_cost: 0.62099s, reader_cost: 0.01230, ips: 103.06041 samples/s, eta: 6:05:25
[2022/06/19 00:15:49] ppcls INFO: [Train][Epoch 94/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.07006078, top1: 0.88830, CELoss: 0.30921, loss: 0.30921, batch_cost: 0.61346s, reader_cost: 0.01215, ips: 104.32619 samples/s, eta: 6:00:53
[2022/06/19 00:15:55] ppcls INFO: [Train][Epoch 94/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.07003788, top1: 0.88865, CELoss: 0.30786, loss: 0.30786, batch_cost: 0.61146s, reader_cost: 0.02187, ips: 104.66789 samples/s, eta: 5:59:36
[2022/06/19 00:16:01] ppcls INFO: [Train][Epoch 94/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.07001498, top1: 0.88959, CELoss: 0.30467, loss: 0.30467, batch_cost: 0.61368s, reader_cost: 0.02980, ips: 104.28814 samples/s, eta: 6:00:48
[2022/06/19 00:16:06] ppcls INFO: [Train][Epoch 94/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06999207, top1: 0.88943, CELoss: 0.30705, loss: 0.30705, batch_cost: 0.60868s, reader_cost: 0.03249, ips: 105.14490 samples/s, eta: 5:57:46
[2022/06/19 00:16:12] ppcls INFO: [Train][Epoch 94/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06996915, top1: 0.88963, CELoss: 0.30590, loss: 0.30590, batch_cost: 0.60209s, reader_cost: 0.03151, ips: 106.29610 samples/s, eta: 5:53:47
[2022/06/19 00:16:19] ppcls INFO: [Train][Epoch 94/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06994621, top1: 0.88938, CELoss: 0.30676, loss: 0.30676, batch_cost: 0.60817s, reader_cost: 0.04545, ips: 105.23347 samples/s, eta: 5:57:16
[2022/06/19 00:16:23] ppcls INFO: [Train][Epoch 94/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06992327, top1: 0.89024, CELoss: 0.30454, loss: 0.30454, batch_cost: 0.59983s, reader_cost: 0.04600, ips: 106.69721 samples/s, eta: 5:52:16
[2022/06/19 00:16:25] ppcls INFO: [Train][Epoch 94/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06990032, top1: 0.88993, CELoss: 0.30492, loss: 0.30492, batch_cost: 0.57651s, reader_cost: 0.04326, ips: 84.99456 samples/s, eta: 5:38:28
[2022/06/19 00:16:26] ppcls INFO: [Train][Epoch 94/300][Avg]top1: 0.88993, CELoss: 0.30492, loss: 0.30492
[2022/06/19 00:16:26] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:16:33] ppcls INFO: [Train][Epoch 95/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06989803, top1: 0.92188, CELoss: 0.27688, loss: 0.27688, batch_cost: 0.61627s, reader_cost: 0.06762, ips: 103.85098 samples/s, eta: 6:01:48
[2022/06/19 00:16:40] ppcls INFO: [Train][Epoch 95/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06987507, top1: 0.89773, CELoss: 0.27789, loss: 0.27789, batch_cost: 0.69941s, reader_cost: 0.02298, ips: 91.50621 samples/s, eta: 6:50:30
[2022/06/19 00:16:46] ppcls INFO: [Train][Epoch 95/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06985210, top1: 0.90179, CELoss: 0.27192, loss: 0.27192, batch_cost: 0.63302s, reader_cost: 0.01144, ips: 101.10332 samples/s, eta: 6:11:25
[2022/06/19 00:16:52] ppcls INFO: [Train][Epoch 95/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06982912, top1: 0.89919, CELoss: 0.27672, loss: 0.27672, batch_cost: 0.62355s, reader_cost: 0.01637, ips: 102.63882 samples/s, eta: 6:05:46
[2022/06/19 00:16:58] ppcls INFO: [Train][Epoch 95/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06980613, top1: 0.90282, CELoss: 0.27012, loss: 0.27012, batch_cost: 0.62534s, reader_cost: 0.01675, ips: 102.34484 samples/s, eta: 6:06:43
[2022/06/19 00:17:04] ppcls INFO: [Train][Epoch 95/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06978314, top1: 0.90165, CELoss: 0.27810, loss: 0.27810, batch_cost: 0.61762s, reader_cost: 0.01471, ips: 103.62284 samples/s, eta: 6:02:05
[2022/06/19 00:17:09] ppcls INFO: [Train][Epoch 95/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06976013, top1: 0.90061, CELoss: 0.28402, loss: 0.28402, batch_cost: 0.60180s, reader_cost: 0.01408, ips: 106.34706 samples/s, eta: 5:52:43
[2022/06/19 00:17:15] ppcls INFO: [Train][Epoch 95/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06973711, top1: 0.89943, CELoss: 0.28430, loss: 0.28430, batch_cost: 0.59395s, reader_cost: 0.01262, ips: 107.75362 samples/s, eta: 5:48:00
[2022/06/19 00:17:22] ppcls INFO: [Train][Epoch 95/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06971409, top1: 0.89969, CELoss: 0.28102, loss: 0.28102, batch_cost: 0.60638s, reader_cost: 0.01352, ips: 105.54480 samples/s, eta: 5:55:11
[2022/06/19 00:17:27] ppcls INFO: [Train][Epoch 95/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06969105, top1: 0.90024, CELoss: 0.28040, loss: 0.28040, batch_cost: 0.59763s, reader_cost: 0.01429, ips: 107.08969 samples/s, eta: 5:49:58
[2022/06/19 00:17:33] ppcls INFO: [Train][Epoch 95/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06966801, top1: 0.89929, CELoss: 0.28525, loss: 0.28525, batch_cost: 0.59763s, reader_cost: 0.01476, ips: 107.08892 samples/s, eta: 5:49:52
[2022/06/19 00:17:39] ppcls INFO: [Train][Epoch 95/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06964496, top1: 0.90062, CELoss: 0.28286, loss: 0.28286, batch_cost: 0.59312s, reader_cost: 0.01530, ips: 107.90462 samples/s, eta: 5:47:07
[2022/06/19 00:17:46] ppcls INFO: [Train][Epoch 95/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06962189, top1: 0.89941, CELoss: 0.28298, loss: 0.28298, batch_cost: 0.60243s, reader_cost: 0.01499, ips: 106.23617 samples/s, eta: 5:52:28
[2022/06/19 00:17:51] ppcls INFO: [Train][Epoch 95/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06959882, top1: 0.89981, CELoss: 0.28195, loss: 0.28195, batch_cost: 0.60143s, reader_cost: 0.01505, ips: 106.41338 samples/s, eta: 5:51:47
[2022/06/19 00:17:59] ppcls INFO: [Train][Epoch 95/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06957574, top1: 0.89960, CELoss: 0.28172, loss: 0.28172, batch_cost: 0.60952s, reader_cost: 0.01456, ips: 105.00049 samples/s, eta: 5:56:25
[2022/06/19 00:18:04] ppcls INFO: [Train][Epoch 95/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06955265, top1: 0.89880, CELoss: 0.28340, loss: 0.28340, batch_cost: 0.60271s, reader_cost: 0.01358, ips: 106.18637 samples/s, eta: 5:52:20
[2022/06/19 00:18:08] ppcls INFO: [Train][Epoch 95/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06952955, top1: 0.89887, CELoss: 0.28317, loss: 0.28317, batch_cost: 0.59403s, reader_cost: 0.01304, ips: 107.73928 samples/s, eta: 5:47:10
[2022/06/19 00:18:11] ppcls INFO: [Train][Epoch 95/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06950645, top1: 0.89779, CELoss: 0.28654, loss: 0.28654, batch_cost: 0.57117s, reader_cost: 0.01231, ips: 85.78908 samples/s, eta: 5:33:42
[2022/06/19 00:18:11] ppcls INFO: [Train][Epoch 95/300][Avg]top1: 0.89779, CELoss: 0.28654, loss: 0.28654
[2022/06/19 00:18:18] ppcls INFO: [Eval][Epoch 95][Iter: 0/16]CELoss: 0.78259, loss: 0.78259, top1: 0.75391, batch_cost: 6.78047s, reader_cost: 3.51508, ips: 9.43887 images/sec
[2022/06/19 00:18:26] ppcls INFO: [Eval][Epoch 95][Iter: 10/16]CELoss: 0.82727, loss: 0.82727, top1: 0.75160, batch_cost: 0.57993s, reader_cost: 0.00210, ips: 110.35844 images/sec
[2022/06/19 00:18:27] ppcls INFO: [Eval][Epoch 95][Avg]CELoss: 0.71220, loss: 0.71220, top1: 0.76434
[2022/06/19 00:18:27] ppcls INFO: [Eval][Epoch 95][best metric: 0.784558892250061]
[2022/06/19 00:18:28] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:18:33] ppcls INFO: [Train][Epoch 96/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06950413, top1: 0.90625, CELoss: 0.20168, loss: 0.20168, batch_cost: 0.60238s, reader_cost: 0.04213, ips: 106.24564 samples/s, eta: 5:51:56
[2022/06/19 00:18:41] ppcls INFO: [Train][Epoch 96/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06948102, top1: 0.91051, CELoss: 0.24712, loss: 0.24712, batch_cost: 0.77063s, reader_cost: 0.00107, ips: 83.04860 samples/s, eta: 7:30:06
[2022/06/19 00:18:48] ppcls INFO: [Train][Epoch 96/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06945789, top1: 0.90997, CELoss: 0.25797, loss: 0.25797, batch_cost: 0.71260s, reader_cost: 0.01503, ips: 89.81251 samples/s, eta: 6:56:05
[2022/06/19 00:18:53] ppcls INFO: [Train][Epoch 96/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06943475, top1: 0.90423, CELoss: 0.26952, loss: 0.26952, batch_cost: 0.65495s, reader_cost: 0.01719, ips: 97.71800 samples/s, eta: 6:22:19
[2022/06/19 00:19:00] ppcls INFO: [Train][Epoch 96/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06941161, top1: 0.90434, CELoss: 0.27717, loss: 0.27717, batch_cost: 0.65589s, reader_cost: 0.01535, ips: 97.57750 samples/s, eta: 6:22:45
[2022/06/19 00:19:06] ppcls INFO: [Train][Epoch 96/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06938845, top1: 0.90686, CELoss: 0.27210, loss: 0.27210, batch_cost: 0.63757s, reader_cost: 0.01654, ips: 100.38192 samples/s, eta: 6:11:57
[2022/06/19 00:19:11] ppcls INFO: [Train][Epoch 96/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06936529, top1: 0.90727, CELoss: 0.27360, loss: 0.27360, batch_cost: 0.62527s, reader_cost: 0.01676, ips: 102.35532 samples/s, eta: 6:04:41
[2022/06/19 00:19:17] ppcls INFO: [Train][Epoch 96/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06934211, top1: 0.90625, CELoss: 0.27925, loss: 0.27925, batch_cost: 0.61847s, reader_cost: 0.01762, ips: 103.48045 samples/s, eta: 6:00:37
[2022/06/19 00:19:23] ppcls INFO: [Train][Epoch 96/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06931893, top1: 0.90316, CELoss: 0.28749, loss: 0.28749, batch_cost: 0.62000s, reader_cost: 0.01705, ips: 103.22607 samples/s, eta: 6:01:24
[2022/06/19 00:19:30] ppcls INFO: [Train][Epoch 96/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06929574, top1: 0.90402, CELoss: 0.28450, loss: 0.28450, batch_cost: 0.62099s, reader_cost: 0.01569, ips: 103.06144 samples/s, eta: 6:01:52
[2022/06/19 00:19:35] ppcls INFO: [Train][Epoch 96/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06927254, top1: 0.90486, CELoss: 0.28129, loss: 0.28129, batch_cost: 0.61179s, reader_cost: 0.01446, ips: 104.61049 samples/s, eta: 5:56:25
[2022/06/19 00:19:40] ppcls INFO: [Train][Epoch 96/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06924933, top1: 0.90343, CELoss: 0.28174, loss: 0.28174, batch_cost: 0.60383s, reader_cost: 0.01447, ips: 105.99089 samples/s, eta: 5:51:40
[2022/06/19 00:19:47] ppcls INFO: [Train][Epoch 96/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06922611, top1: 0.90199, CELoss: 0.28350, loss: 0.28350, batch_cost: 0.60889s, reader_cost: 0.01422, ips: 105.10961 samples/s, eta: 5:54:31
[2022/06/19 00:19:53] ppcls INFO: [Train][Epoch 96/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06920288, top1: 0.90196, CELoss: 0.28264, loss: 0.28264, batch_cost: 0.60508s, reader_cost: 0.01413, ips: 105.77138 samples/s, eta: 5:52:12
[2022/06/19 00:19:59] ppcls INFO: [Train][Epoch 96/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06917964, top1: 0.90226, CELoss: 0.28260, loss: 0.28260, batch_cost: 0.60692s, reader_cost: 0.01336, ips: 105.44977 samples/s, eta: 5:53:10
[2022/06/19 00:20:06] ppcls INFO: [Train][Epoch 96/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06915640, top1: 0.90242, CELoss: 0.28347, loss: 0.28347, batch_cost: 0.61130s, reader_cost: 0.01317, ips: 104.69525 samples/s, eta: 5:55:37
[2022/06/19 00:20:11] ppcls INFO: [Train][Epoch 96/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06913314, top1: 0.90295, CELoss: 0.28228, loss: 0.28228, batch_cost: 0.60684s, reader_cost: 0.01258, ips: 105.46505 samples/s, eta: 5:52:55
[2022/06/19 00:20:13] ppcls INFO: [Train][Epoch 96/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06910988, top1: 0.90338, CELoss: 0.28179, loss: 0.28179, batch_cost: 0.58285s, reader_cost: 0.01194, ips: 84.06917 samples/s, eta: 5:38:52
[2022/06/19 00:20:14] ppcls INFO: [Train][Epoch 96/300][Avg]top1: 0.90338, CELoss: 0.28179, loss: 0.28179
[2022/06/19 00:20:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:20:20] ppcls INFO: [Train][Epoch 97/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06910755, top1: 0.89062, CELoss: 0.25608, loss: 0.25608, batch_cost: 0.61618s, reader_cost: 0.04161, ips: 103.86602 samples/s, eta: 5:58:14
[2022/06/19 00:20:27] ppcls INFO: [Train][Epoch 97/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06908428, top1: 0.90909, CELoss: 0.26578, loss: 0.26578, batch_cost: 0.85064s, reader_cost: 0.04659, ips: 75.23710 samples/s, eta: 8:14:25
[2022/06/19 00:20:34] ppcls INFO: [Train][Epoch 97/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06906099, top1: 0.90551, CELoss: 0.27522, loss: 0.27522, batch_cost: 0.70709s, reader_cost: 0.02552, ips: 90.51171 samples/s, eta: 6:50:52
[2022/06/19 00:20:39] ppcls INFO: [Train][Epoch 97/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06903770, top1: 0.90423, CELoss: 0.27539, loss: 0.27539, batch_cost: 0.66478s, reader_cost: 0.02643, ips: 96.27205 samples/s, eta: 6:26:10
[2022/06/19 00:20:45] ppcls INFO: [Train][Epoch 97/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06901440, top1: 0.90130, CELoss: 0.28328, loss: 0.28328, batch_cost: 0.64387s, reader_cost: 0.02199, ips: 99.39883 samples/s, eta: 6:13:55
[2022/06/19 00:20:51] ppcls INFO: [Train][Epoch 97/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06899109, top1: 0.90196, CELoss: 0.27948, loss: 0.27948, batch_cost: 0.62994s, reader_cost: 0.02006, ips: 101.59761 samples/s, eta: 6:05:43
[2022/06/19 00:20:57] ppcls INFO: [Train][Epoch 97/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06896777, top1: 0.89933, CELoss: 0.28476, loss: 0.28476, batch_cost: 0.62155s, reader_cost: 0.02133, ips: 102.96819 samples/s, eta: 6:00:44
[2022/06/19 00:21:03] ppcls INFO: [Train][Epoch 97/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06894444, top1: 0.90075, CELoss: 0.27973, loss: 0.27973, batch_cost: 0.61654s, reader_cost: 0.01996, ips: 103.80482 samples/s, eta: 5:57:44
[2022/06/19 00:21:09] ppcls INFO: [Train][Epoch 97/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06892111, top1: 0.90008, CELoss: 0.27991, loss: 0.27991, batch_cost: 0.61152s, reader_cost: 0.02420, ips: 104.65712 samples/s, eta: 5:54:43
[2022/06/19 00:21:14] ppcls INFO: [Train][Epoch 97/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06889776, top1: 0.90024, CELoss: 0.28042, loss: 0.28042, batch_cost: 0.60426s, reader_cost: 0.02741, ips: 105.91453 samples/s, eta: 5:50:24
[2022/06/19 00:21:20] ppcls INFO: [Train][Epoch 97/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06887441, top1: 0.89960, CELoss: 0.28020, loss: 0.28020, batch_cost: 0.60276s, reader_cost: 0.03289, ips: 106.17740 samples/s, eta: 5:49:26
[2022/06/19 00:21:26] ppcls INFO: [Train][Epoch 97/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06885104, top1: 0.89963, CELoss: 0.28066, loss: 0.28066, batch_cost: 0.59783s, reader_cost: 0.03703, ips: 107.05382 samples/s, eta: 5:46:28
[2022/06/19 00:21:32] ppcls INFO: [Train][Epoch 97/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06882767, top1: 0.89850, CELoss: 0.28200, loss: 0.28200, batch_cost: 0.59884s, reader_cost: 0.04049, ips: 106.87293 samples/s, eta: 5:46:58
[2022/06/19 00:21:38] ppcls INFO: [Train][Epoch 97/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06880429, top1: 0.89850, CELoss: 0.28454, loss: 0.28454, batch_cost: 0.59820s, reader_cost: 0.04046, ips: 106.98676 samples/s, eta: 5:46:30
[2022/06/19 00:21:44] ppcls INFO: [Train][Epoch 97/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06878090, top1: 0.89871, CELoss: 0.28410, loss: 0.28410, batch_cost: 0.60426s, reader_cost: 0.04350, ips: 105.91413 samples/s, eta: 5:49:54
[2022/06/19 00:21:50] ppcls INFO: [Train][Epoch 97/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06875750, top1: 0.89880, CELoss: 0.28456, loss: 0.28456, batch_cost: 0.60457s, reader_cost: 0.04141, ips: 105.86001 samples/s, eta: 5:49:59
[2022/06/19 00:21:56] ppcls INFO: [Train][Epoch 97/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06873409, top1: 0.89868, CELoss: 0.28433, loss: 0.28433, batch_cost: 0.59922s, reader_cost: 0.03965, ips: 106.80549 samples/s, eta: 5:46:47
[2022/06/19 00:21:58] ppcls INFO: [Train][Epoch 97/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06871067, top1: 0.89962, CELoss: 0.28144, loss: 0.28144, batch_cost: 0.57548s, reader_cost: 0.03730, ips: 85.14630 samples/s, eta: 5:32:57
[2022/06/19 00:21:58] ppcls INFO: [Train][Epoch 97/300][Avg]top1: 0.89962, CELoss: 0.28144, loss: 0.28144
[2022/06/19 00:21:58] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:22:05] ppcls INFO: [Train][Epoch 98/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06870833, top1: 0.89062, CELoss: 0.35230, loss: 0.35230, batch_cost: 0.61051s, reader_cost: 0.06648, ips: 104.83076 samples/s, eta: 5:53:12
[2022/06/19 00:22:11] ppcls INFO: [Train][Epoch 98/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06868490, top1: 0.90341, CELoss: 0.28719, loss: 0.28719, batch_cost: 0.62749s, reader_cost: 0.01822, ips: 101.99418 samples/s, eta: 6:02:55
[2022/06/19 00:22:18] ppcls INFO: [Train][Epoch 98/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06866146, top1: 0.90551, CELoss: 0.29261, loss: 0.29261, batch_cost: 0.67211s, reader_cost: 0.01500, ips: 95.22276 samples/s, eta: 6:28:37
[2022/06/19 00:22:25] ppcls INFO: [Train][Epoch 98/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06863802, top1: 0.90625, CELoss: 0.28748, loss: 0.28748, batch_cost: 0.65330s, reader_cost: 0.01201, ips: 97.96387 samples/s, eta: 6:17:38
[2022/06/19 00:22:32] ppcls INFO: [Train][Epoch 98/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06861456, top1: 0.90473, CELoss: 0.29041, loss: 0.29041, batch_cost: 0.66918s, reader_cost: 0.07732, ips: 95.63886 samples/s, eta: 6:26:42
[2022/06/19 00:22:37] ppcls INFO: [Train][Epoch 98/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06859110, top1: 0.90349, CELoss: 0.28807, loss: 0.28807, batch_cost: 0.62931s, reader_cost: 0.06202, ips: 101.69838 samples/s, eta: 6:03:33
[2022/06/19 00:22:43] ppcls INFO: [Train][Epoch 98/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06856763, top1: 0.90061, CELoss: 0.29267, loss: 0.29267, batch_cost: 0.62785s, reader_cost: 0.06468, ips: 101.93452 samples/s, eta: 6:02:37
[2022/06/19 00:22:51] ppcls INFO: [Train][Epoch 98/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06854415, top1: 0.90053, CELoss: 0.29311, loss: 0.29311, batch_cost: 0.65363s, reader_cost: 0.09139, ips: 97.91478 samples/s, eta: 6:17:23
[2022/06/19 00:22:55] ppcls INFO: [Train][Epoch 98/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06852066, top1: 0.90201, CELoss: 0.28664, loss: 0.28664, batch_cost: 0.62841s, reader_cost: 0.08185, ips: 101.84394 samples/s, eta: 6:02:43
[2022/06/19 00:23:01] ppcls INFO: [Train][Epoch 98/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06849716, top1: 0.90179, CELoss: 0.28602, loss: 0.28602, batch_cost: 0.62371s, reader_cost: 0.07398, ips: 102.61169 samples/s, eta: 5:59:54
[2022/06/19 00:23:07] ppcls INFO: [Train][Epoch 98/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06847365, top1: 0.90192, CELoss: 0.28522, loss: 0.28522, batch_cost: 0.62030s, reader_cost: 0.06807, ips: 103.17637 samples/s, eta: 5:57:50
[2022/06/19 00:23:15] ppcls INFO: [Train][Epoch 98/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06845014, top1: 0.90160, CELoss: 0.28284, loss: 0.28284, batch_cost: 0.63900s, reader_cost: 0.09293, ips: 100.15691 samples/s, eta: 6:08:31
[2022/06/19 00:23:20] ppcls INFO: [Train][Epoch 98/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06842661, top1: 0.90134, CELoss: 0.28469, loss: 0.28469, batch_cost: 0.62723s, reader_cost: 0.08889, ips: 102.03564 samples/s, eta: 6:01:37
[2022/06/19 00:23:26] ppcls INFO: [Train][Epoch 98/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06840308, top1: 0.90052, CELoss: 0.28524, loss: 0.28524, batch_cost: 0.62179s, reader_cost: 0.08528, ips: 102.92819 samples/s, eta: 5:58:23
[2022/06/19 00:23:32] ppcls INFO: [Train][Epoch 98/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06837954, top1: 0.90093, CELoss: 0.28532, loss: 0.28532, batch_cost: 0.62164s, reader_cost: 0.08989, ips: 102.95269 samples/s, eta: 5:58:12
[2022/06/19 00:23:40] ppcls INFO: [Train][Epoch 98/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06835599, top1: 0.90159, CELoss: 0.28409, loss: 0.28409, batch_cost: 0.63048s, reader_cost: 0.10634, ips: 101.51053 samples/s, eta: 6:03:11
[2022/06/19 00:23:44] ppcls INFO: [Train][Epoch 98/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06833243, top1: 0.90159, CELoss: 0.28381, loss: 0.28381, batch_cost: 0.61662s, reader_cost: 0.10031, ips: 103.79165 samples/s, eta: 5:55:06
[2022/06/19 00:23:46] ppcls INFO: [Train][Epoch 98/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06830886, top1: 0.90173, CELoss: 0.28346, loss: 0.28346, batch_cost: 0.59199s, reader_cost: 0.09428, ips: 82.77204 samples/s, eta: 5:40:49
[2022/06/19 00:23:46] ppcls INFO: [Train][Epoch 98/300][Avg]top1: 0.90173, CELoss: 0.28346, loss: 0.28346
[2022/06/19 00:23:47] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:23:54] ppcls INFO: [Train][Epoch 99/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06830650, top1: 0.89062, CELoss: 0.33849, loss: 0.33849, batch_cost: 0.63000s, reader_cost: 0.12675, ips: 101.58651 samples/s, eta: 6:02:41
[2022/06/19 00:24:01] ppcls INFO: [Train][Epoch 99/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06828292, top1: 0.89347, CELoss: 0.31341, loss: 0.31341, batch_cost: 0.87937s, reader_cost: 0.38763, ips: 72.77972 samples/s, eta: 8:26:06
[2022/06/19 00:24:07] ppcls INFO: [Train][Epoch 99/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06825934, top1: 0.89211, CELoss: 0.28890, loss: 0.28890, batch_cost: 0.66822s, reader_cost: 0.16128, ips: 95.77662 samples/s, eta: 6:24:28
[2022/06/19 00:24:13] ppcls INFO: [Train][Epoch 99/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06823574, top1: 0.89163, CELoss: 0.29197, loss: 0.29197, batch_cost: 0.64548s, reader_cost: 0.10458, ips: 99.15026 samples/s, eta: 6:11:16
[2022/06/19 00:24:19] ppcls INFO: [Train][Epoch 99/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06821214, top1: 0.89139, CELoss: 0.29288, loss: 0.29288, batch_cost: 0.64713s, reader_cost: 0.07759, ips: 98.89795 samples/s, eta: 6:12:07
[2022/06/19 00:24:25] ppcls INFO: [Train][Epoch 99/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06818852, top1: 0.89062, CELoss: 0.29835, loss: 0.29835, batch_cost: 0.62532s, reader_cost: 0.06186, ips: 102.34713 samples/s, eta: 5:59:28
[2022/06/19 00:24:31] ppcls INFO: [Train][Epoch 99/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06816490, top1: 0.88832, CELoss: 0.30342, loss: 0.30342, batch_cost: 0.62808s, reader_cost: 0.06710, ips: 101.89817 samples/s, eta: 6:00:57
[2022/06/19 00:24:37] ppcls INFO: [Train][Epoch 99/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06814127, top1: 0.88974, CELoss: 0.29969, loss: 0.29969, batch_cost: 0.62386s, reader_cost: 0.07267, ips: 102.58770 samples/s, eta: 5:58:25
[2022/06/19 00:24:44] ppcls INFO: [Train][Epoch 99/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06811763, top1: 0.89429, CELoss: 0.29040, loss: 0.29040, batch_cost: 0.63229s, reader_cost: 0.08120, ips: 101.21946 samples/s, eta: 6:03:09
[2022/06/19 00:24:50] ppcls INFO: [Train][Epoch 99/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06809398, top1: 0.89578, CELoss: 0.28860, loss: 0.28860, batch_cost: 0.63089s, reader_cost: 0.07937, ips: 101.44320 samples/s, eta: 6:02:15
[2022/06/19 00:24:56] ppcls INFO: [Train][Epoch 99/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06807033, top1: 0.89588, CELoss: 0.28513, loss: 0.28513, batch_cost: 0.62672s, reader_cost: 0.07661, ips: 102.11887 samples/s, eta: 5:59:45
[2022/06/19 00:25:03] ppcls INFO: [Train][Epoch 99/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06804666, top1: 0.89809, CELoss: 0.28268, loss: 0.28268, batch_cost: 0.63102s, reader_cost: 0.08658, ips: 101.42230 samples/s, eta: 6:02:07
[2022/06/19 00:25:10] ppcls INFO: [Train][Epoch 99/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06802299, top1: 0.89928, CELoss: 0.28153, loss: 0.28153, batch_cost: 0.63251s, reader_cost: 0.09662, ips: 101.18361 samples/s, eta: 6:02:52
[2022/06/19 00:25:15] ppcls INFO: [Train][Epoch 99/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06799931, top1: 0.89885, CELoss: 0.28230, loss: 0.28230, batch_cost: 0.62843s, reader_cost: 0.09592, ips: 101.84037 samples/s, eta: 6:00:25
[2022/06/19 00:25:22] ppcls INFO: [Train][Epoch 99/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06797562, top1: 0.89971, CELoss: 0.28283, loss: 0.28283, batch_cost: 0.62778s, reader_cost: 0.09784, ips: 101.94655 samples/s, eta: 5:59:56
[2022/06/19 00:25:27] ppcls INFO: [Train][Epoch 99/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06795192, top1: 0.89849, CELoss: 0.28669, loss: 0.28669, batch_cost: 0.62174s, reader_cost: 0.09347, ips: 102.93697 samples/s, eta: 5:56:22
[2022/06/19 00:25:33] ppcls INFO: [Train][Epoch 99/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06792821, top1: 0.89897, CELoss: 0.28631, loss: 0.28631, batch_cost: 0.62212s, reader_cost: 0.10371, ips: 102.87352 samples/s, eta: 5:56:29
[2022/06/19 00:25:35] ppcls INFO: [Train][Epoch 99/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06790449, top1: 0.89853, CELoss: 0.28841, loss: 0.28841, batch_cost: 0.59719s, reader_cost: 0.09747, ips: 82.05101 samples/s, eta: 5:42:06
[2022/06/19 00:25:36] ppcls INFO: [Train][Epoch 99/300][Avg]top1: 0.89853, CELoss: 0.28841, loss: 0.28841
[2022/06/19 00:25:36] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:25:44] ppcls INFO: [Train][Epoch 100/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06790212, top1: 0.90625, CELoss: 0.20387, loss: 0.20387, batch_cost: 0.64177s, reader_cost: 0.14146, ips: 99.72406 samples/s, eta: 6:07:38
[2022/06/19 00:25:49] ppcls INFO: [Train][Epoch 100/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06787839, top1: 0.89915, CELoss: 0.26878, loss: 0.26878, batch_cost: 0.56774s, reader_cost: 0.03128, ips: 112.72746 samples/s, eta: 5:25:08
[2022/06/19 00:25:56] ppcls INFO: [Train][Epoch 100/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06785466, top1: 0.90848, CELoss: 0.24290, loss: 0.24290, batch_cost: 0.60588s, reader_cost: 0.03315, ips: 105.63191 samples/s, eta: 5:46:52
[2022/06/19 00:26:02] ppcls INFO: [Train][Epoch 100/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06783092, top1: 0.90373, CELoss: 0.26063, loss: 0.26063, batch_cost: 0.61142s, reader_cost: 0.03075, ips: 104.67519 samples/s, eta: 5:49:56
[2022/06/19 00:26:08] ppcls INFO: [Train][Epoch 100/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06780716, top1: 0.90396, CELoss: 0.26110, loss: 0.26110, batch_cost: 0.60864s, reader_cost: 0.02860, ips: 105.15248 samples/s, eta: 5:48:15
[2022/06/19 00:26:13] ppcls INFO: [Train][Epoch 100/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06778340, top1: 0.90319, CELoss: 0.26961, loss: 0.26961, batch_cost: 0.59747s, reader_cost: 0.02522, ips: 107.11889 samples/s, eta: 5:41:45
[2022/06/19 00:26:19] ppcls INFO: [Train][Epoch 100/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06775963, top1: 0.90010, CELoss: 0.27522, loss: 0.27522, batch_cost: 0.59613s, reader_cost: 0.02376, ips: 107.35998 samples/s, eta: 5:40:53
[2022/06/19 00:26:25] ppcls INFO: [Train][Epoch 100/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06773586, top1: 0.89965, CELoss: 0.27756, loss: 0.27756, batch_cost: 0.58922s, reader_cost: 0.02215, ips: 108.61776 samples/s, eta: 5:36:50
[2022/06/19 00:26:32] ppcls INFO: [Train][Epoch 100/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06771207, top1: 0.90201, CELoss: 0.27449, loss: 0.27449, batch_cost: 0.60078s, reader_cost: 0.04509, ips: 106.52771 samples/s, eta: 5:43:21
[2022/06/19 00:26:37] ppcls INFO: [Train][Epoch 100/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06768828, top1: 0.90367, CELoss: 0.27157, loss: 0.27157, batch_cost: 0.59608s, reader_cost: 0.04217, ips: 107.36795 samples/s, eta: 5:40:34
[2022/06/19 00:26:43] ppcls INFO: [Train][Epoch 100/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06766447, top1: 0.90300, CELoss: 0.27170, loss: 0.27170, batch_cost: 0.59219s, reader_cost: 0.03876, ips: 108.07258 samples/s, eta: 5:38:15
[2022/06/19 00:26:49] ppcls INFO: [Train][Epoch 100/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06764066, top1: 0.90400, CELoss: 0.26975, loss: 0.26975, batch_cost: 0.59601s, reader_cost: 0.04394, ips: 107.38019 samples/s, eta: 5:40:20
[2022/06/19 00:26:56] ppcls INFO: [Train][Epoch 100/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06761684, top1: 0.90367, CELoss: 0.26951, loss: 0.26951, batch_cost: 0.60644s, reader_cost: 0.04085, ips: 105.53378 samples/s, eta: 5:46:11
[2022/06/19 00:27:03] ppcls INFO: [Train][Epoch 100/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06759301, top1: 0.90327, CELoss: 0.27275, loss: 0.27275, batch_cost: 0.61007s, reader_cost: 0.03801, ips: 104.90576 samples/s, eta: 5:48:09
[2022/06/19 00:27:09] ppcls INFO: [Train][Epoch 100/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06756918, top1: 0.90171, CELoss: 0.27416, loss: 0.27416, batch_cost: 0.60782s, reader_cost: 0.03559, ips: 105.29357 samples/s, eta: 5:46:46
[2022/06/19 00:27:15] ppcls INFO: [Train][Epoch 100/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06754533, top1: 0.90056, CELoss: 0.27549, loss: 0.27549, batch_cost: 0.60918s, reader_cost: 0.03500, ips: 105.05999 samples/s, eta: 5:47:26
[2022/06/19 00:27:20] ppcls INFO: [Train][Epoch 100/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06752148, top1: 0.89946, CELoss: 0.27905, loss: 0.27905, batch_cost: 0.60169s, reader_cost: 0.03378, ips: 106.36736 samples/s, eta: 5:43:04
[2022/06/19 00:27:22] ppcls INFO: [Train][Epoch 100/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06749761, top1: 0.89972, CELoss: 0.27697, loss: 0.27697, batch_cost: 0.57804s, reader_cost: 0.03175, ips: 84.76933 samples/s, eta: 5:29:29
[2022/06/19 00:27:22] ppcls INFO: [Train][Epoch 100/300][Avg]top1: 0.89972, CELoss: 0.27697, loss: 0.27697
[2022/06/19 00:27:30] ppcls INFO: [Eval][Epoch 100][Iter: 0/16]CELoss: 0.70712, loss: 0.70712, top1: 0.78125, batch_cost: 7.23898s, reader_cost: 3.56123, ips: 8.84103 images/sec
[2022/06/19 00:27:37] ppcls INFO: [Eval][Epoch 100][Iter: 10/16]CELoss: 0.67618, loss: 0.67618, top1: 0.78072, batch_cost: 0.53926s, reader_cost: 0.00970, ips: 118.68145 images/sec
[2022/06/19 00:27:39] ppcls INFO: [Eval][Epoch 100][Avg]CELoss: 0.64595, loss: 0.64595, top1: 0.78909
[2022/06/19 00:27:39] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 00:27:39] ppcls INFO: [Eval][Epoch 100][best metric: 0.7890931963920593]
[2022/06/19 00:27:39] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_100
[2022/06/19 00:27:39] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:27:45] ppcls INFO: [Train][Epoch 101/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06749523, top1: 0.93750, CELoss: 0.23292, loss: 0.23292, batch_cost: 0.61120s, reader_cost: 0.06220, ips: 104.71157 samples/s, eta: 5:48:23
[2022/06/19 00:27:51] ppcls INFO: [Train][Epoch 101/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06747136, top1: 0.90057, CELoss: 0.28441, loss: 0.28441, batch_cost: 0.61615s, reader_cost: 0.03887, ips: 103.87144 samples/s, eta: 5:51:06
[2022/06/19 00:27:58] ppcls INFO: [Train][Epoch 101/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06744748, top1: 0.91146, CELoss: 0.27313, loss: 0.27313, batch_cost: 0.64977s, reader_cost: 0.02278, ips: 98.49632 samples/s, eta: 6:10:09
[2022/06/19 00:28:05] ppcls INFO: [Train][Epoch 101/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06742359, top1: 0.90675, CELoss: 0.27379, loss: 0.27379, batch_cost: 0.64606s, reader_cost: 0.02019, ips: 99.06212 samples/s, eta: 6:07:55
[2022/06/19 00:28:10] ppcls INFO: [Train][Epoch 101/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06739969, top1: 0.90434, CELoss: 0.27748, loss: 0.27748, batch_cost: 0.62765s, reader_cost: 0.01794, ips: 101.96778 samples/s, eta: 5:57:20
[2022/06/19 00:28:16] ppcls INFO: [Train][Epoch 101/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06737578, top1: 0.90380, CELoss: 0.27560, loss: 0.27560, batch_cost: 0.61676s, reader_cost: 0.02063, ips: 103.76767 samples/s, eta: 5:51:02
[2022/06/19 00:28:22] ppcls INFO: [Train][Epoch 101/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06735187, top1: 0.89703, CELoss: 0.29039, loss: 0.29039, batch_cost: 0.61423s, reader_cost: 0.02050, ips: 104.19516 samples/s, eta: 5:49:29
[2022/06/19 00:28:29] ppcls INFO: [Train][Epoch 101/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06732795, top1: 0.89547, CELoss: 0.29295, loss: 0.29295, batch_cost: 0.62082s, reader_cost: 0.01993, ips: 103.08865 samples/s, eta: 5:53:08
[2022/06/19 00:28:35] ppcls INFO: [Train][Epoch 101/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06730402, top1: 0.89680, CELoss: 0.28920, loss: 0.28920, batch_cost: 0.62188s, reader_cost: 0.01776, ips: 102.91409 samples/s, eta: 5:53:38
[2022/06/19 00:28:41] ppcls INFO: [Train][Epoch 101/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06728008, top1: 0.89698, CELoss: 0.28845, loss: 0.28845, batch_cost: 0.61489s, reader_cost: 0.01693, ips: 104.08350 samples/s, eta: 5:49:33
[2022/06/19 00:28:46] ppcls INFO: [Train][Epoch 101/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06725613, top1: 0.89527, CELoss: 0.29126, loss: 0.29126, batch_cost: 0.61118s, reader_cost: 0.01521, ips: 104.71553 samples/s, eta: 5:47:21
[2022/06/19 00:28:53] ppcls INFO: [Train][Epoch 101/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06723218, top1: 0.89583, CELoss: 0.28870, loss: 0.28870, batch_cost: 0.61206s, reader_cost: 0.01502, ips: 104.56476 samples/s, eta: 5:47:45
[2022/06/19 00:28:58] ppcls INFO: [Train][Epoch 101/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06720821, top1: 0.89618, CELoss: 0.28693, loss: 0.28693, batch_cost: 0.60661s, reader_cost: 0.01504, ips: 105.50433 samples/s, eta: 5:44:33
[2022/06/19 00:29:04] ppcls INFO: [Train][Epoch 101/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06718424, top1: 0.89695, CELoss: 0.28317, loss: 0.28317, batch_cost: 0.60612s, reader_cost: 0.01460, ips: 105.58962 samples/s, eta: 5:44:10
[2022/06/19 00:29:11] ppcls INFO: [Train][Epoch 101/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06716026, top1: 0.89672, CELoss: 0.28423, loss: 0.28423, batch_cost: 0.61009s, reader_cost: 0.01551, ips: 104.90215 samples/s, eta: 5:46:19
[2022/06/19 00:29:17] ppcls INFO: [Train][Epoch 101/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06713627, top1: 0.89828, CELoss: 0.28151, loss: 0.28151, batch_cost: 0.61223s, reader_cost: 0.01580, ips: 104.53587 samples/s, eta: 5:47:26
[2022/06/19 00:29:22] ppcls INFO: [Train][Epoch 101/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06711227, top1: 0.89887, CELoss: 0.28094, loss: 0.28094, batch_cost: 0.60163s, reader_cost: 0.01611, ips: 106.37809 samples/s, eta: 5:41:19
[2022/06/19 00:29:24] ppcls INFO: [Train][Epoch 101/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06708827, top1: 0.89844, CELoss: 0.28228, loss: 0.28228, batch_cost: 0.57809s, reader_cost: 0.01515, ips: 84.76171 samples/s, eta: 5:27:52
[2022/06/19 00:29:24] ppcls INFO: [Train][Epoch 101/300][Avg]top1: 0.89844, CELoss: 0.28228, loss: 0.28228
[2022/06/19 00:29:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:29:31] ppcls INFO: [Train][Epoch 102/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06708587, top1: 0.92188, CELoss: 0.19748, loss: 0.19748, batch_cost: 0.61619s, reader_cost: 0.04516, ips: 103.86364 samples/s, eta: 5:49:28
[2022/06/19 00:29:37] ppcls INFO: [Train][Epoch 102/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06706185, top1: 0.89631, CELoss: 0.26268, loss: 0.26268, batch_cost: 0.66891s, reader_cost: 0.00713, ips: 95.67786 samples/s, eta: 6:19:15
[2022/06/19 00:29:43] ppcls INFO: [Train][Epoch 102/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06703783, top1: 0.90179, CELoss: 0.26678, loss: 0.26678, batch_cost: 0.61854s, reader_cost: 0.00384, ips: 103.46973 samples/s, eta: 5:50:35
[2022/06/19 00:29:50] ppcls INFO: [Train][Epoch 102/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06701380, top1: 0.89919, CELoss: 0.26968, loss: 0.26968, batch_cost: 0.62795s, reader_cost: 0.00433, ips: 101.91839 samples/s, eta: 5:55:49
[2022/06/19 00:29:56] ppcls INFO: [Train][Epoch 102/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06698976, top1: 0.90091, CELoss: 0.26827, loss: 0.26827, batch_cost: 0.63667s, reader_cost: 0.00515, ips: 100.52258 samples/s, eta: 6:00:39
[2022/06/19 00:30:02] ppcls INFO: [Train][Epoch 102/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06696571, top1: 0.90074, CELoss: 0.27060, loss: 0.27060, batch_cost: 0.62451s, reader_cost: 0.00796, ips: 102.48020 samples/s, eta: 5:53:40
[2022/06/19 00:30:08] ppcls INFO: [Train][Epoch 102/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06694166, top1: 0.90446, CELoss: 0.26469, loss: 0.26469, batch_cost: 0.62164s, reader_cost: 0.01035, ips: 102.95380 samples/s, eta: 5:51:56
[2022/06/19 00:30:14] ppcls INFO: [Train][Epoch 102/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06691759, top1: 0.90317, CELoss: 0.26524, loss: 0.26524, batch_cost: 0.61971s, reader_cost: 0.01158, ips: 103.27377 samples/s, eta: 5:50:44
[2022/06/19 00:30:20] ppcls INFO: [Train][Epoch 102/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06689352, top1: 0.90471, CELoss: 0.26714, loss: 0.26714, batch_cost: 0.61182s, reader_cost: 0.01347, ips: 104.60556 samples/s, eta: 5:46:10
[2022/06/19 00:30:26] ppcls INFO: [Train][Epoch 102/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06686944, top1: 0.90058, CELoss: 0.27746, loss: 0.27746, batch_cost: 0.60731s, reader_cost: 0.01365, ips: 105.38223 samples/s, eta: 5:43:31
[2022/06/19 00:30:31] ppcls INFO: [Train][Epoch 102/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06684535, top1: 0.90176, CELoss: 0.27497, loss: 0.27497, batch_cost: 0.60045s, reader_cost: 0.01415, ips: 106.58737 samples/s, eta: 5:39:32
[2022/06/19 00:30:38] ppcls INFO: [Train][Epoch 102/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06682125, top1: 0.90104, CELoss: 0.27522, loss: 0.27522, batch_cost: 0.60406s, reader_cost: 0.01439, ips: 105.94938 samples/s, eta: 5:41:29
[2022/06/19 00:30:45] ppcls INFO: [Train][Epoch 102/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06679715, top1: 0.90147, CELoss: 0.27483, loss: 0.27483, batch_cost: 0.61139s, reader_cost: 0.01387, ips: 104.68005 samples/s, eta: 5:45:31
[2022/06/19 00:30:51] ppcls INFO: [Train][Epoch 102/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06677304, top1: 0.90196, CELoss: 0.27411, loss: 0.27411, batch_cost: 0.61138s, reader_cost: 0.01341, ips: 104.68143 samples/s, eta: 5:45:25
[2022/06/19 00:30:56] ppcls INFO: [Train][Epoch 102/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06674891, top1: 0.90060, CELoss: 0.27769, loss: 0.27769, batch_cost: 0.60698s, reader_cost: 0.01282, ips: 105.44067 samples/s, eta: 5:42:49
[2022/06/19 00:31:03] ppcls INFO: [Train][Epoch 102/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06672478, top1: 0.90014, CELoss: 0.27847, loss: 0.27847, batch_cost: 0.60974s, reader_cost: 0.01240, ips: 104.96295 samples/s, eta: 5:44:17
[2022/06/19 00:31:07] ppcls INFO: [Train][Epoch 102/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06670065, top1: 0.90179, CELoss: 0.27785, loss: 0.27785, batch_cost: 0.60072s, reader_cost: 0.01169, ips: 106.53961 samples/s, eta: 5:39:05
[2022/06/19 00:31:10] ppcls INFO: [Train][Epoch 102/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06667650, top1: 0.90155, CELoss: 0.27875, loss: 0.27875, batch_cost: 0.58180s, reader_cost: 0.01103, ips: 84.22102 samples/s, eta: 5:28:19
[2022/06/19 00:31:11] ppcls INFO: [Train][Epoch 102/300][Avg]top1: 0.90155, CELoss: 0.27875, loss: 0.27875
[2022/06/19 00:31:11] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:31:17] ppcls INFO: [Train][Epoch 103/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06667409, top1: 0.90625, CELoss: 0.32481, loss: 0.32481, batch_cost: 0.61514s, reader_cost: 0.04346, ips: 104.04098 samples/s, eta: 5:47:07
[2022/06/19 00:31:24] ppcls INFO: [Train][Epoch 103/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06664993, top1: 0.89773, CELoss: 0.28716, loss: 0.28716, batch_cost: 0.68462s, reader_cost: 0.02705, ips: 93.48261 samples/s, eta: 6:26:12
[2022/06/19 00:31:30] ppcls INFO: [Train][Epoch 103/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06662577, top1: 0.90104, CELoss: 0.28625, loss: 0.28625, batch_cost: 0.61912s, reader_cost: 0.02022, ips: 103.37237 samples/s, eta: 5:49:09
[2022/06/19 00:31:36] ppcls INFO: [Train][Epoch 103/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06660160, top1: 0.89919, CELoss: 0.29230, loss: 0.29230, batch_cost: 0.63042s, reader_cost: 0.01584, ips: 101.52037 samples/s, eta: 5:55:25
[2022/06/19 00:31:42] ppcls INFO: [Train][Epoch 103/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06657742, top1: 0.89558, CELoss: 0.29730, loss: 0.29730, batch_cost: 0.63096s, reader_cost: 0.01280, ips: 101.43321 samples/s, eta: 5:55:37
[2022/06/19 00:31:48] ppcls INFO: [Train][Epoch 103/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06655323, top1: 0.89583, CELoss: 0.29798, loss: 0.29798, batch_cost: 0.61528s, reader_cost: 0.01442, ips: 104.01808 samples/s, eta: 5:46:41
[2022/06/19 00:31:54] ppcls INFO: [Train][Epoch 103/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06652904, top1: 0.89754, CELoss: 0.29019, loss: 0.29019, batch_cost: 0.62302s, reader_cost: 0.01328, ips: 102.72475 samples/s, eta: 5:50:56
[2022/06/19 00:32:00] ppcls INFO: [Train][Epoch 103/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06650483, top1: 0.89811, CELoss: 0.28664, loss: 0.28664, batch_cost: 0.61807s, reader_cost: 0.01200, ips: 103.54882 samples/s, eta: 5:48:03
[2022/06/19 00:32:06] ppcls INFO: [Train][Epoch 103/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06648062, top1: 0.90258, CELoss: 0.27692, loss: 0.27692, batch_cost: 0.61696s, reader_cost: 0.01316, ips: 103.73480 samples/s, eta: 5:47:19
[2022/06/19 00:32:13] ppcls INFO: [Train][Epoch 103/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06645640, top1: 0.90350, CELoss: 0.27446, loss: 0.27446, batch_cost: 0.61830s, reader_cost: 0.01365, ips: 103.50883 samples/s, eta: 5:47:58
[2022/06/19 00:32:19] ppcls INFO: [Train][Epoch 103/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06643217, top1: 0.90470, CELoss: 0.27261, loss: 0.27261, batch_cost: 0.61665s, reader_cost: 0.01302, ips: 103.78690 samples/s, eta: 5:46:56
[2022/06/19 00:32:24] ppcls INFO: [Train][Epoch 103/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06640794, top1: 0.90329, CELoss: 0.27597, loss: 0.27597, batch_cost: 0.61009s, reader_cost: 0.01361, ips: 104.90341 samples/s, eta: 5:43:09
[2022/06/19 00:32:30] ppcls INFO: [Train][Epoch 103/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06638369, top1: 0.90405, CELoss: 0.27225, loss: 0.27225, batch_cost: 0.61023s, reader_cost: 0.01357, ips: 104.87806 samples/s, eta: 5:43:08
[2022/06/19 00:32:37] ppcls INFO: [Train][Epoch 103/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06635944, top1: 0.90482, CELoss: 0.26887, loss: 0.26887, batch_cost: 0.61413s, reader_cost: 0.01285, ips: 104.21267 samples/s, eta: 5:45:13
[2022/06/19 00:32:43] ppcls INFO: [Train][Epoch 103/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06633518, top1: 0.90392, CELoss: 0.27036, loss: 0.27036, batch_cost: 0.61313s, reader_cost: 0.01566, ips: 104.38251 samples/s, eta: 5:44:33
[2022/06/19 00:32:50] ppcls INFO: [Train][Epoch 103/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06631092, top1: 0.90459, CELoss: 0.26790, loss: 0.26790, batch_cost: 0.61987s, reader_cost: 0.01513, ips: 103.24747 samples/s, eta: 5:48:14
[2022/06/19 00:32:55] ppcls INFO: [Train][Epoch 103/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06628664, top1: 0.90518, CELoss: 0.26751, loss: 0.26751, batch_cost: 0.60835s, reader_cost: 0.01476, ips: 105.20267 samples/s, eta: 5:41:40
[2022/06/19 00:32:57] ppcls INFO: [Train][Epoch 103/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06626236, top1: 0.90447, CELoss: 0.26884, loss: 0.26884, batch_cost: 0.58469s, reader_cost: 0.01392, ips: 83.80514 samples/s, eta: 5:28:17
[2022/06/19 00:32:57] ppcls INFO: [Train][Epoch 103/300][Avg]top1: 0.90447, CELoss: 0.26884, loss: 0.26884
[2022/06/19 00:32:57] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:33:04] ppcls INFO: [Train][Epoch 104/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06625993, top1: 0.95312, CELoss: 0.19205, loss: 0.19205, batch_cost: 0.62098s, reader_cost: 0.04598, ips: 103.06221 samples/s, eta: 5:48:39
[2022/06/19 00:33:10] ppcls INFO: [Train][Epoch 104/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06623563, top1: 0.89631, CELoss: 0.26401, loss: 0.26401, batch_cost: 0.65182s, reader_cost: 0.01401, ips: 98.18640 samples/s, eta: 6:05:51
[2022/06/19 00:33:18] ppcls INFO: [Train][Epoch 104/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06621133, top1: 0.90104, CELoss: 0.28574, loss: 0.28574, batch_cost: 0.70732s, reader_cost: 0.14512, ips: 90.48279 samples/s, eta: 6:36:53
[2022/06/19 00:33:24] ppcls INFO: [Train][Epoch 104/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06618703, top1: 0.90474, CELoss: 0.27139, loss: 0.27139, batch_cost: 0.67285s, reader_cost: 0.09002, ips: 95.11731 samples/s, eta: 6:17:26
[2022/06/19 00:33:30] ppcls INFO: [Train][Epoch 104/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06616271, top1: 0.90206, CELoss: 0.27736, loss: 0.27736, batch_cost: 0.64924s, reader_cost: 0.06572, ips: 98.57605 samples/s, eta: 6:04:05
[2022/06/19 00:33:36] ppcls INFO: [Train][Epoch 104/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06613839, top1: 0.90502, CELoss: 0.27364, loss: 0.27364, batch_cost: 0.63677s, reader_cost: 0.05324, ips: 100.50699 samples/s, eta: 5:56:59
[2022/06/19 00:33:42] ppcls INFO: [Train][Epoch 104/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06611405, top1: 0.90702, CELoss: 0.27156, loss: 0.27156, batch_cost: 0.63015s, reader_cost: 0.04386, ips: 101.56240 samples/s, eta: 5:53:10
[2022/06/19 00:33:47] ppcls INFO: [Train][Epoch 104/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06608971, top1: 0.90691, CELoss: 0.27118, loss: 0.27118, batch_cost: 0.61950s, reader_cost: 0.03993, ips: 103.30843 samples/s, eta: 5:47:05
[2022/06/19 00:33:54] ppcls INFO: [Train][Epoch 104/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06606537, top1: 0.90625, CELoss: 0.27055, loss: 0.27055, batch_cost: 0.62071s, reader_cost: 0.04162, ips: 103.10738 samples/s, eta: 5:47:40
[2022/06/19 00:34:02] ppcls INFO: [Train][Epoch 104/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06604101, top1: 0.90608, CELoss: 0.27261, loss: 0.27261, batch_cost: 0.64387s, reader_cost: 0.07978, ips: 99.39822 samples/s, eta: 6:00:32
[2022/06/19 00:34:07] ppcls INFO: [Train][Epoch 104/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06601665, top1: 0.90548, CELoss: 0.27559, loss: 0.27559, batch_cost: 0.63099s, reader_cost: 0.07276, ips: 101.42867 samples/s, eta: 5:53:12
[2022/06/19 00:34:12] ppcls INFO: [Train][Epoch 104/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06599227, top1: 0.90315, CELoss: 0.27848, loss: 0.27848, batch_cost: 0.62243s, reader_cost: 0.06660, ips: 102.82295 samples/s, eta: 5:48:19
[2022/06/19 00:34:18] ppcls INFO: [Train][Epoch 104/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06596789, top1: 0.90276, CELoss: 0.27921, loss: 0.27921, batch_cost: 0.61701s, reader_cost: 0.06175, ips: 103.72613 samples/s, eta: 5:45:11
[2022/06/19 00:34:25] ppcls INFO: [Train][Epoch 104/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06594351, top1: 0.90160, CELoss: 0.28180, loss: 0.28180, batch_cost: 0.62450s, reader_cost: 0.07228, ips: 102.48189 samples/s, eta: 5:49:16
[2022/06/19 00:34:31] ppcls INFO: [Train][Epoch 104/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06591911, top1: 0.90215, CELoss: 0.27939, loss: 0.27939, batch_cost: 0.61883s, reader_cost: 0.06786, ips: 103.42027 samples/s, eta: 5:46:00
[2022/06/19 00:34:37] ppcls INFO: [Train][Epoch 104/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06589471, top1: 0.90232, CELoss: 0.27870, loss: 0.27870, batch_cost: 0.61668s, reader_cost: 0.06574, ips: 103.78094 samples/s, eta: 5:44:41
[2022/06/19 00:34:42] ppcls INFO: [Train][Epoch 104/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06587030, top1: 0.90179, CELoss: 0.27915, loss: 0.27915, batch_cost: 0.60917s, reader_cost: 0.06193, ips: 105.06123 samples/s, eta: 5:40:23
[2022/06/19 00:34:44] ppcls INFO: [Train][Epoch 104/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06584588, top1: 0.90127, CELoss: 0.27989, loss: 0.27989, batch_cost: 0.58536s, reader_cost: 0.05821, ips: 83.70949 samples/s, eta: 5:26:59
[2022/06/19 00:34:44] ppcls INFO: [Train][Epoch 104/300][Avg]top1: 0.90127, CELoss: 0.27989, loss: 0.27989
[2022/06/19 00:34:44] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:34:51] ppcls INFO: [Train][Epoch 105/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06584344, top1: 0.96875, CELoss: 0.16760, loss: 0.16760, batch_cost: 0.62237s, reader_cost: 0.08758, ips: 102.83316 samples/s, eta: 5:47:39
[2022/06/19 00:34:57] ppcls INFO: [Train][Epoch 105/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06581901, top1: 0.91051, CELoss: 0.24204, loss: 0.24204, batch_cost: 0.60521s, reader_cost: 0.00757, ips: 105.74762 samples/s, eta: 5:37:58
[2022/06/19 00:35:03] ppcls INFO: [Train][Epoch 105/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06579457, top1: 0.90402, CELoss: 0.25622, loss: 0.25622, batch_cost: 0.60942s, reader_cost: 0.00952, ips: 105.01723 samples/s, eta: 5:40:13
[2022/06/19 00:35:10] ppcls INFO: [Train][Epoch 105/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06577013, top1: 0.90222, CELoss: 0.26087, loss: 0.26087, batch_cost: 0.61326s, reader_cost: 0.01226, ips: 104.36105 samples/s, eta: 5:42:15
[2022/06/19 00:35:16] ppcls INFO: [Train][Epoch 105/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06574568, top1: 0.90396, CELoss: 0.26189, loss: 0.26189, batch_cost: 0.61750s, reader_cost: 0.01097, ips: 103.64397 samples/s, eta: 5:44:31
[2022/06/19 00:35:21] ppcls INFO: [Train][Epoch 105/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06572122, top1: 0.90564, CELoss: 0.25586, loss: 0.25586, batch_cost: 0.60097s, reader_cost: 0.01559, ips: 106.49516 samples/s, eta: 5:35:11
[2022/06/19 00:35:28] ppcls INFO: [Train][Epoch 105/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06569676, top1: 0.90394, CELoss: 0.26136, loss: 0.26136, batch_cost: 0.61309s, reader_cost: 0.01398, ips: 104.38895 samples/s, eta: 5:41:51
[2022/06/19 00:35:34] ppcls INFO: [Train][Epoch 105/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06567228, top1: 0.90405, CELoss: 0.26013, loss: 0.26013, batch_cost: 0.61096s, reader_cost: 0.01521, ips: 104.75291 samples/s, eta: 5:40:34
[2022/06/19 00:35:39] ppcls INFO: [Train][Epoch 105/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06564780, top1: 0.90451, CELoss: 0.26071, loss: 0.26071, batch_cost: 0.60056s, reader_cost: 0.01574, ips: 106.56674 samples/s, eta: 5:34:40
[2022/06/19 00:35:45] ppcls INFO: [Train][Epoch 105/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06562331, top1: 0.90419, CELoss: 0.26083, loss: 0.26083, batch_cost: 0.59576s, reader_cost: 0.01616, ips: 107.42593 samples/s, eta: 5:31:53
[2022/06/19 00:35:51] ppcls INFO: [Train][Epoch 105/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06559881, top1: 0.90254, CELoss: 0.26265, loss: 0.26265, batch_cost: 0.59729s, reader_cost: 0.01662, ips: 107.15145 samples/s, eta: 5:32:38
[2022/06/19 00:35:59] ppcls INFO: [Train][Epoch 105/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06557431, top1: 0.90160, CELoss: 0.26321, loss: 0.26321, batch_cost: 0.61473s, reader_cost: 0.01711, ips: 104.11138 samples/s, eta: 5:42:15
[2022/06/19 00:36:04] ppcls INFO: [Train][Epoch 105/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06554980, top1: 0.90225, CELoss: 0.26293, loss: 0.26293, batch_cost: 0.60196s, reader_cost: 0.01672, ips: 106.31932 samples/s, eta: 5:35:03
[2022/06/19 00:36:10] ppcls INFO: [Train][Epoch 105/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06552528, top1: 0.90315, CELoss: 0.26402, loss: 0.26402, batch_cost: 0.60268s, reader_cost: 0.01594, ips: 106.19230 samples/s, eta: 5:35:21
[2022/06/19 00:36:16] ppcls INFO: [Train][Epoch 105/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06550075, top1: 0.90160, CELoss: 0.26862, loss: 0.26862, batch_cost: 0.60763s, reader_cost: 0.01524, ips: 105.32650 samples/s, eta: 5:38:00
[2022/06/19 00:36:21] ppcls INFO: [Train][Epoch 105/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06547621, top1: 0.90077, CELoss: 0.27084, loss: 0.27084, batch_cost: 0.59610s, reader_cost: 0.01448, ips: 107.36414 samples/s, eta: 5:31:29
[2022/06/19 00:36:28] ppcls INFO: [Train][Epoch 105/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06545167, top1: 0.90159, CELoss: 0.27100, loss: 0.27100, batch_cost: 0.60094s, reader_cost: 0.01377, ips: 106.50005 samples/s, eta: 5:34:04
[2022/06/19 00:36:30] ppcls INFO: [Train][Epoch 105/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06542712, top1: 0.90155, CELoss: 0.27246, loss: 0.27246, batch_cost: 0.57744s, reader_cost: 0.01295, ips: 84.85754 samples/s, eta: 5:20:55
[2022/06/19 00:36:30] ppcls INFO: [Train][Epoch 105/300][Avg]top1: 0.90155, CELoss: 0.27246, loss: 0.27246
[2022/06/19 00:36:37] ppcls INFO: [Eval][Epoch 105][Iter: 0/16]CELoss: 1.00363, loss: 1.00363, top1: 0.74805, batch_cost: 7.09797s, reader_cost: 3.57190, ips: 9.01667 images/sec
[2022/06/19 00:36:45] ppcls INFO: [Eval][Epoch 105][Iter: 10/16]CELoss: 0.84091, loss: 0.84091, top1: 0.77184, batch_cost: 0.59628s, reader_cost: 0.00140, ips: 107.33154 images/sec
[2022/06/19 00:36:47] ppcls INFO: [Eval][Epoch 105][Avg]CELoss: 0.72905, loss: 0.72905, top1: 0.78260
[2022/06/19 00:36:47] ppcls INFO: [Eval][Epoch 105][best metric: 0.7890931963920593]
[2022/06/19 00:36:47] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:36:53] ppcls INFO: [Train][Epoch 106/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06542466, top1: 0.92188, CELoss: 0.19088, loss: 0.19088, batch_cost: 0.61123s, reader_cost: 0.03954, ips: 104.70752 samples/s, eta: 5:39:41
[2022/06/19 00:37:00] ppcls INFO: [Train][Epoch 106/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06540010, top1: 0.91335, CELoss: 0.24573, loss: 0.24573, batch_cost: 0.71210s, reader_cost: 0.06950, ips: 89.87548 samples/s, eta: 6:35:37
[2022/06/19 00:37:06] ppcls INFO: [Train][Epoch 106/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06537553, top1: 0.91295, CELoss: 0.26078, loss: 0.26078, batch_cost: 0.65482s, reader_cost: 0.03551, ips: 97.73701 samples/s, eta: 6:03:41
[2022/06/19 00:37:12] ppcls INFO: [Train][Epoch 106/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06535096, top1: 0.91230, CELoss: 0.25586, loss: 0.25586, batch_cost: 0.65252s, reader_cost: 0.02769, ips: 98.08198 samples/s, eta: 6:02:18
[2022/06/19 00:37:19] ppcls INFO: [Train][Epoch 106/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06532638, top1: 0.91387, CELoss: 0.24906, loss: 0.24906, batch_cost: 0.64151s, reader_cost: 0.02413, ips: 99.76387 samples/s, eta: 5:56:05
[2022/06/19 00:37:25] ppcls INFO: [Train][Epoch 106/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06530179, top1: 0.91268, CELoss: 0.25672, loss: 0.25672, batch_cost: 0.64317s, reader_cost: 0.02346, ips: 99.50676 samples/s, eta: 5:56:54
[2022/06/19 00:37:30] ppcls INFO: [Train][Epoch 106/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06527719, top1: 0.91393, CELoss: 0.25514, loss: 0.25514, batch_cost: 0.62471s, reader_cost: 0.02212, ips: 102.44782 samples/s, eta: 5:46:33
[2022/06/19 00:37:36] ppcls INFO: [Train][Epoch 106/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06525258, top1: 0.91131, CELoss: 0.26345, loss: 0.26345, batch_cost: 0.61951s, reader_cost: 0.02178, ips: 103.30722 samples/s, eta: 5:43:34
[2022/06/19 00:37:43] ppcls INFO: [Train][Epoch 106/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06522797, top1: 0.90934, CELoss: 0.26421, loss: 0.26421, batch_cost: 0.62210s, reader_cost: 0.02161, ips: 102.87779 samples/s, eta: 5:44:54
[2022/06/19 00:37:48] ppcls INFO: [Train][Epoch 106/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06520335, top1: 0.91071, CELoss: 0.26330, loss: 0.26330, batch_cost: 0.61620s, reader_cost: 0.01968, ips: 103.86302 samples/s, eta: 5:41:31
[2022/06/19 00:37:56] ppcls INFO: [Train][Epoch 106/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06517872, top1: 0.91166, CELoss: 0.25943, loss: 0.25943, batch_cost: 0.62975s, reader_cost: 0.01870, ips: 101.62718 samples/s, eta: 5:48:56
[2022/06/19 00:38:01] ppcls INFO: [Train][Epoch 106/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06515409, top1: 0.91146, CELoss: 0.26105, loss: 0.26105, batch_cost: 0.62135s, reader_cost: 0.01773, ips: 103.00094 samples/s, eta: 5:44:10
[2022/06/19 00:38:08] ppcls INFO: [Train][Epoch 106/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06512944, top1: 0.90922, CELoss: 0.26396, loss: 0.26396, batch_cost: 0.62981s, reader_cost: 0.01723, ips: 101.61818 samples/s, eta: 5:48:45
[2022/06/19 00:38:14] ppcls INFO: [Train][Epoch 106/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06510479, top1: 0.90840, CELoss: 0.26778, loss: 0.26778, batch_cost: 0.62267s, reader_cost: 0.01684, ips: 102.78282 samples/s, eta: 5:44:42
[2022/06/19 00:38:22] ppcls INFO: [Train][Epoch 106/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06508013, top1: 0.90780, CELoss: 0.26700, loss: 0.26700, batch_cost: 0.63566s, reader_cost: 0.01702, ips: 100.68199 samples/s, eta: 5:51:47
[2022/06/19 00:38:28] ppcls INFO: [Train][Epoch 106/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06505547, top1: 0.90749, CELoss: 0.26743, loss: 0.26743, batch_cost: 0.63065s, reader_cost: 0.01687, ips: 101.48294 samples/s, eta: 5:48:54
[2022/06/19 00:38:33] ppcls INFO: [Train][Epoch 106/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06503080, top1: 0.90761, CELoss: 0.26573, loss: 0.26573, batch_cost: 0.62317s, reader_cost: 0.01622, ips: 102.70101 samples/s, eta: 5:44:39
[2022/06/19 00:38:35] ppcls INFO: [Train][Epoch 106/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06500611, top1: 0.90777, CELoss: 0.26536, loss: 0.26536, batch_cost: 0.59814s, reader_cost: 0.01535, ips: 81.92098 samples/s, eta: 5:30:43
[2022/06/19 00:38:35] ppcls INFO: [Train][Epoch 106/300][Avg]top1: 0.90777, CELoss: 0.26536, loss: 0.26536
[2022/06/19 00:38:35] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:38:41] ppcls INFO: [Train][Epoch 107/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06500365, top1: 0.95312, CELoss: 0.18244, loss: 0.18244, batch_cost: 0.62612s, reader_cost: 0.04148, ips: 102.21687 samples/s, eta: 5:46:10
[2022/06/19 00:38:49] ppcls INFO: [Train][Epoch 107/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06497896, top1: 0.93040, CELoss: 0.24184, loss: 0.24184, batch_cost: 0.56871s, reader_cost: 0.00034, ips: 112.53483 samples/s, eta: 5:14:20
[2022/06/19 00:38:55] ppcls INFO: [Train][Epoch 107/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06495426, top1: 0.92336, CELoss: 0.24674, loss: 0.24674, batch_cost: 0.58249s, reader_cost: 0.00216, ips: 109.87347 samples/s, eta: 5:21:51
[2022/06/19 00:39:01] ppcls INFO: [Train][Epoch 107/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06492956, top1: 0.91683, CELoss: 0.26182, loss: 0.26182, batch_cost: 0.58511s, reader_cost: 0.00250, ips: 109.38180 samples/s, eta: 5:23:12
[2022/06/19 00:39:07] ppcls INFO: [Train][Epoch 107/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06490484, top1: 0.91349, CELoss: 0.26609, loss: 0.26609, batch_cost: 0.59504s, reader_cost: 0.01404, ips: 107.55598 samples/s, eta: 5:28:36
[2022/06/19 00:39:14] ppcls INFO: [Train][Epoch 107/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06488013, top1: 0.91238, CELoss: 0.25642, loss: 0.25642, batch_cost: 0.61767s, reader_cost: 0.03420, ips: 103.61557 samples/s, eta: 5:40:59
[2022/06/19 00:39:20] ppcls INFO: [Train][Epoch 107/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06485540, top1: 0.91214, CELoss: 0.25940, loss: 0.25940, batch_cost: 0.61230s, reader_cost: 0.02915, ips: 104.52364 samples/s, eta: 5:37:55
[2022/06/19 00:39:26] ppcls INFO: [Train][Epoch 107/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06483067, top1: 0.91175, CELoss: 0.26133, loss: 0.26133, batch_cost: 0.60911s, reader_cost: 0.02659, ips: 105.07136 samples/s, eta: 5:36:03
[2022/06/19 00:39:32] ppcls INFO: [Train][Epoch 107/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06480592, top1: 0.91069, CELoss: 0.26213, loss: 0.26213, batch_cost: 0.61328s, reader_cost: 0.02644, ips: 104.35609 samples/s, eta: 5:38:16
[2022/06/19 00:39:39] ppcls INFO: [Train][Epoch 107/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06478118, top1: 0.91106, CELoss: 0.25952, loss: 0.25952, batch_cost: 0.62670s, reader_cost: 0.02494, ips: 102.12169 samples/s, eta: 5:45:33
[2022/06/19 00:39:45] ppcls INFO: [Train][Epoch 107/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06475642, top1: 0.91306, CELoss: 0.25441, loss: 0.25441, batch_cost: 0.61685s, reader_cost: 0.02302, ips: 103.75351 samples/s, eta: 5:40:01
[2022/06/19 00:39:50] ppcls INFO: [Train][Epoch 107/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06473166, top1: 0.91273, CELoss: 0.25655, loss: 0.25655, batch_cost: 0.60481s, reader_cost: 0.02256, ips: 105.81840 samples/s, eta: 5:33:17
[2022/06/19 00:39:55] ppcls INFO: [Train][Epoch 107/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06470688, top1: 0.91271, CELoss: 0.25537, loss: 0.25537, batch_cost: 0.59909s, reader_cost: 0.02155, ips: 106.82923 samples/s, eta: 5:30:02
[2022/06/19 00:40:04] ppcls INFO: [Train][Epoch 107/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06468211, top1: 0.91174, CELoss: 0.25656, loss: 0.25656, batch_cost: 0.62367s, reader_cost: 0.02133, ips: 102.61811 samples/s, eta: 5:43:28
[2022/06/19 00:40:09] ppcls INFO: [Train][Epoch 107/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06465732, top1: 0.90946, CELoss: 0.25832, loss: 0.25832, batch_cost: 0.61396s, reader_cost: 0.02077, ips: 104.24095 samples/s, eta: 5:38:01
[2022/06/19 00:40:15] ppcls INFO: [Train][Epoch 107/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06463253, top1: 0.90863, CELoss: 0.26063, loss: 0.26063, batch_cost: 0.61578s, reader_cost: 0.01974, ips: 103.93338 samples/s, eta: 5:38:55
[2022/06/19 00:40:20] ppcls INFO: [Train][Epoch 107/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06460773, top1: 0.90984, CELoss: 0.25822, loss: 0.25822, batch_cost: 0.60693s, reader_cost: 0.01942, ips: 105.44947 samples/s, eta: 5:33:57
[2022/06/19 00:40:23] ppcls INFO: [Train][Epoch 107/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06458292, top1: 0.90832, CELoss: 0.26147, loss: 0.26147, batch_cost: 0.58565s, reader_cost: 0.01832, ips: 83.66768 samples/s, eta: 5:22:08
[2022/06/19 00:40:23] ppcls INFO: [Train][Epoch 107/300][Avg]top1: 0.90832, CELoss: 0.26147, loss: 0.26147
[2022/06/19 00:40:23] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:40:29] ppcls INFO: [Train][Epoch 108/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06458044, top1: 0.95312, CELoss: 0.14463, loss: 0.14463, batch_cost: 0.61819s, reader_cost: 0.05002, ips: 103.52748 samples/s, eta: 5:40:02
[2022/06/19 00:40:36] ppcls INFO: [Train][Epoch 108/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06455562, top1: 0.90909, CELoss: 0.24457, loss: 0.24457, batch_cost: 0.64957s, reader_cost: 0.00345, ips: 98.52741 samples/s, eta: 5:57:11
[2022/06/19 00:40:42] ppcls INFO: [Train][Epoch 108/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06453080, top1: 0.90774, CELoss: 0.25845, loss: 0.25845, batch_cost: 0.61269s, reader_cost: 0.01009, ips: 104.45791 samples/s, eta: 5:36:48
[2022/06/19 00:40:48] ppcls INFO: [Train][Epoch 108/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06450597, top1: 0.90575, CELoss: 0.26125, loss: 0.26125, batch_cost: 0.61597s, reader_cost: 0.01145, ips: 103.90105 samples/s, eta: 5:38:30
[2022/06/19 00:40:54] ppcls INFO: [Train][Epoch 108/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06448113, top1: 0.90168, CELoss: 0.27270, loss: 0.27270, batch_cost: 0.61376s, reader_cost: 0.00896, ips: 104.27579 samples/s, eta: 5:37:11
[2022/06/19 00:41:01] ppcls INFO: [Train][Epoch 108/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06445628, top1: 0.90594, CELoss: 0.26194, loss: 0.26194, batch_cost: 0.61523s, reader_cost: 0.00849, ips: 104.02634 samples/s, eta: 5:37:53
[2022/06/19 00:41:07] ppcls INFO: [Train][Epoch 108/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06443143, top1: 0.90471, CELoss: 0.26121, loss: 0.26121, batch_cost: 0.61414s, reader_cost: 0.00952, ips: 104.21125 samples/s, eta: 5:37:11
[2022/06/19 00:41:14] ppcls INFO: [Train][Epoch 108/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06440657, top1: 0.90493, CELoss: 0.25829, loss: 0.25829, batch_cost: 0.62875s, reader_cost: 0.02712, ips: 101.78913 samples/s, eta: 5:45:06
[2022/06/19 00:41:20] ppcls INFO: [Train][Epoch 108/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06438170, top1: 0.90779, CELoss: 0.25504, loss: 0.25504, batch_cost: 0.62349s, reader_cost: 0.02727, ips: 102.64849 samples/s, eta: 5:42:07
[2022/06/19 00:41:26] ppcls INFO: [Train][Epoch 108/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06435683, top1: 0.90848, CELoss: 0.25180, loss: 0.25180, batch_cost: 0.61963s, reader_cost: 0.02499, ips: 103.28670 samples/s, eta: 5:39:54
[2022/06/19 00:41:32] ppcls INFO: [Train][Epoch 108/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06433195, top1: 0.90811, CELoss: 0.25440, loss: 0.25440, batch_cost: 0.61979s, reader_cost: 0.02292, ips: 103.26044 samples/s, eta: 5:39:53
[2022/06/19 00:41:39] ppcls INFO: [Train][Epoch 108/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06430706, top1: 0.90780, CELoss: 0.25429, loss: 0.25429, batch_cost: 0.62818s, reader_cost: 0.02227, ips: 101.88151 samples/s, eta: 5:44:22
[2022/06/19 00:41:44] ppcls INFO: [Train][Epoch 108/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06428216, top1: 0.90845, CELoss: 0.25301, loss: 0.25301, batch_cost: 0.61978s, reader_cost: 0.02142, ips: 103.26197 samples/s, eta: 5:39:40
[2022/06/19 00:41:51] ppcls INFO: [Train][Epoch 108/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06425726, top1: 0.90828, CELoss: 0.25431, loss: 0.25431, batch_cost: 0.62450s, reader_cost: 0.02123, ips: 102.48148 samples/s, eta: 5:42:09
[2022/06/19 00:41:57] ppcls INFO: [Train][Epoch 108/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06423235, top1: 0.90847, CELoss: 0.25391, loss: 0.25391, batch_cost: 0.62202s, reader_cost: 0.02077, ips: 102.89078 samples/s, eta: 5:40:41
[2022/06/19 00:42:04] ppcls INFO: [Train][Epoch 108/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06420743, top1: 0.90853, CELoss: 0.25546, loss: 0.25546, batch_cost: 0.63003s, reader_cost: 0.01959, ips: 101.58303 samples/s, eta: 5:44:58
[2022/06/19 00:42:09] ppcls INFO: [Train][Epoch 108/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06418251, top1: 0.90693, CELoss: 0.26119, loss: 0.26119, batch_cost: 0.61827s, reader_cost: 0.01923, ips: 103.51422 samples/s, eta: 5:38:25
[2022/06/19 00:42:11] ppcls INFO: [Train][Epoch 108/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06415757, top1: 0.90786, CELoss: 0.25992, loss: 0.25992, batch_cost: 0.59365s, reader_cost: 0.01812, ips: 82.54028 samples/s, eta: 5:24:51
[2022/06/19 00:42:11] ppcls INFO: [Train][Epoch 108/300][Avg]top1: 0.90786, CELoss: 0.25992, loss: 0.25992
[2022/06/19 00:42:12] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:42:18] ppcls INFO: [Train][Epoch 109/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06415508, top1: 0.93750, CELoss: 0.29799, loss: 0.29799, batch_cost: 0.62730s, reader_cost: 0.04514, ips: 102.02405 samples/s, eta: 5:43:15
[2022/06/19 00:42:25] ppcls INFO: [Train][Epoch 109/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06413014, top1: 0.92472, CELoss: 0.22318, loss: 0.22318, batch_cost: 0.66868s, reader_cost: 0.02901, ips: 95.71054 samples/s, eta: 6:05:47
[2022/06/19 00:42:31] ppcls INFO: [Train][Epoch 109/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06410519, top1: 0.92262, CELoss: 0.22928, loss: 0.22928, batch_cost: 0.62524s, reader_cost: 0.02246, ips: 102.36091 samples/s, eta: 5:41:55
[2022/06/19 00:42:38] ppcls INFO: [Train][Epoch 109/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06408024, top1: 0.91583, CELoss: 0.25239, loss: 0.25239, batch_cost: 0.62256s, reader_cost: 0.01983, ips: 102.80099 samples/s, eta: 5:40:21
[2022/06/19 00:42:44] ppcls INFO: [Train][Epoch 109/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06405528, top1: 0.91311, CELoss: 0.25211, loss: 0.25211, batch_cost: 0.62169s, reader_cost: 0.01586, ips: 102.94503 samples/s, eta: 5:39:46
[2022/06/19 00:42:50] ppcls INFO: [Train][Epoch 109/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06403031, top1: 0.91391, CELoss: 0.25007, loss: 0.25007, batch_cost: 0.61551s, reader_cost: 0.01700, ips: 103.97878 samples/s, eta: 5:36:17
[2022/06/19 00:42:55] ppcls INFO: [Train][Epoch 109/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06400533, top1: 0.91112, CELoss: 0.25631, loss: 0.25631, batch_cost: 0.60353s, reader_cost: 0.02072, ips: 106.04330 samples/s, eta: 5:29:38
[2022/06/19 00:43:01] ppcls INFO: [Train][Epoch 109/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06398035, top1: 0.91153, CELoss: 0.25439, loss: 0.25439, batch_cost: 0.59719s, reader_cost: 0.01888, ips: 107.16812 samples/s, eta: 5:26:05
[2022/06/19 00:43:09] ppcls INFO: [Train][Epoch 109/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06395536, top1: 0.91069, CELoss: 0.25463, loss: 0.25463, batch_cost: 0.62254s, reader_cost: 0.01988, ips: 102.80506 samples/s, eta: 5:39:49
[2022/06/19 00:43:14] ppcls INFO: [Train][Epoch 109/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06393036, top1: 0.91037, CELoss: 0.25879, loss: 0.25879, batch_cost: 0.61323s, reader_cost: 0.01835, ips: 104.36567 samples/s, eta: 5:34:38
[2022/06/19 00:43:20] ppcls INFO: [Train][Epoch 109/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06390536, top1: 0.91105, CELoss: 0.25623, loss: 0.25623, batch_cost: 0.61089s, reader_cost: 0.01699, ips: 104.76526 samples/s, eta: 5:33:15
[2022/06/19 00:43:27] ppcls INFO: [Train][Epoch 109/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06388035, top1: 0.91202, CELoss: 0.25389, loss: 0.25389, batch_cost: 0.61548s, reader_cost: 0.01735, ips: 103.98311 samples/s, eta: 5:35:39
[2022/06/19 00:43:32] ppcls INFO: [Train][Epoch 109/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06385533, top1: 0.91116, CELoss: 0.25451, loss: 0.25451, batch_cost: 0.60615s, reader_cost: 0.01831, ips: 105.58442 samples/s, eta: 5:30:28
[2022/06/19 00:43:37] ppcls INFO: [Train][Epoch 109/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06383030, top1: 0.91066, CELoss: 0.25618, loss: 0.25618, batch_cost: 0.59932s, reader_cost: 0.01809, ips: 106.78740 samples/s, eta: 5:26:39
[2022/06/19 00:43:44] ppcls INFO: [Train][Epoch 109/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06380527, top1: 0.91079, CELoss: 0.25505, loss: 0.25505, batch_cost: 0.60529s, reader_cost: 0.01868, ips: 105.73432 samples/s, eta: 5:29:48
[2022/06/19 00:43:52] ppcls INFO: [Train][Epoch 109/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06378023, top1: 0.91018, CELoss: 0.25811, loss: 0.25811, batch_cost: 0.61706s, reader_cost: 0.03819, ips: 103.71843 samples/s, eta: 5:36:06
[2022/06/19 00:43:55] ppcls INFO: [Train][Epoch 109/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06375518, top1: 0.91013, CELoss: 0.25931, loss: 0.25931, batch_cost: 0.59997s, reader_cost: 0.03614, ips: 106.67163 samples/s, eta: 5:26:42
[2022/06/19 00:43:57] ppcls INFO: [Train][Epoch 109/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06373013, top1: 0.90987, CELoss: 0.25896, loss: 0.25896, batch_cost: 0.57629s, reader_cost: 0.03397, ips: 85.02711 samples/s, eta: 5:13:42
[2022/06/19 00:43:58] ppcls INFO: [Train][Epoch 109/300][Avg]top1: 0.90987, CELoss: 0.25896, loss: 0.25896
[2022/06/19 00:43:58] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:44:04] ppcls INFO: [Train][Epoch 110/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06372762, top1: 0.89062, CELoss: 0.25078, loss: 0.25078, batch_cost: 0.60926s, reader_cost: 0.06412, ips: 105.04496 samples/s, eta: 5:31:39
[2022/06/19 00:44:11] ppcls INFO: [Train][Epoch 110/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06370256, top1: 0.88068, CELoss: 0.27154, loss: 0.27154, batch_cost: 0.64498s, reader_cost: 0.02640, ips: 99.22780 samples/s, eta: 5:50:59
[2022/06/19 00:44:18] ppcls INFO: [Train][Epoch 110/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06367749, top1: 0.88914, CELoss: 0.27550, loss: 0.27550, batch_cost: 0.69763s, reader_cost: 0.01796, ips: 91.73948 samples/s, eta: 6:19:31
[2022/06/19 00:44:24] ppcls INFO: [Train][Epoch 110/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06365242, top1: 0.89365, CELoss: 0.27138, loss: 0.27138, batch_cost: 0.64589s, reader_cost: 0.01687, ips: 99.08736 samples/s, eta: 5:51:16
[2022/06/19 00:44:30] ppcls INFO: [Train][Epoch 110/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06362734, top1: 0.89558, CELoss: 0.26557, loss: 0.26557, batch_cost: 0.63867s, reader_cost: 0.01374, ips: 100.20771 samples/s, eta: 5:47:14
[2022/06/19 00:44:36] ppcls INFO: [Train][Epoch 110/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06360225, top1: 0.90319, CELoss: 0.25327, loss: 0.25327, batch_cost: 0.63439s, reader_cost: 0.01239, ips: 100.88393 samples/s, eta: 5:44:48
[2022/06/19 00:44:42] ppcls INFO: [Train][Epoch 110/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06357715, top1: 0.90497, CELoss: 0.25165, loss: 0.25165, batch_cost: 0.62632s, reader_cost: 0.01295, ips: 102.18366 samples/s, eta: 5:40:18
[2022/06/19 00:44:47] ppcls INFO: [Train][Epoch 110/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06355205, top1: 0.90911, CELoss: 0.24434, loss: 0.24434, batch_cost: 0.61332s, reader_cost: 0.01270, ips: 104.34993 samples/s, eta: 5:33:08
[2022/06/19 00:44:53] ppcls INFO: [Train][Epoch 110/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06352694, top1: 0.90992, CELoss: 0.24722, loss: 0.24722, batch_cost: 0.60619s, reader_cost: 0.01419, ips: 105.57778 samples/s, eta: 5:29:10
[2022/06/19 00:45:00] ppcls INFO: [Train][Epoch 110/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06350182, top1: 0.90745, CELoss: 0.25188, loss: 0.25188, batch_cost: 0.61845s, reader_cost: 0.01457, ips: 103.48414 samples/s, eta: 5:35:43
[2022/06/19 00:45:06] ppcls INFO: [Train][Epoch 110/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06347669, top1: 0.90919, CELoss: 0.24790, loss: 0.24790, batch_cost: 0.61636s, reader_cost: 0.01603, ips: 103.83492 samples/s, eta: 5:34:29
[2022/06/19 00:45:12] ppcls INFO: [Train][Epoch 110/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06345156, top1: 0.90921, CELoss: 0.24930, loss: 0.24930, batch_cost: 0.61102s, reader_cost: 0.01603, ips: 104.74252 samples/s, eta: 5:31:29
[2022/06/19 00:45:18] ppcls INFO: [Train][Epoch 110/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06342643, top1: 0.90935, CELoss: 0.25085, loss: 0.25085, batch_cost: 0.61434s, reader_cost: 0.01570, ips: 104.17683 samples/s, eta: 5:33:11
[2022/06/19 00:45:24] ppcls INFO: [Train][Epoch 110/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06340128, top1: 0.90935, CELoss: 0.25124, loss: 0.25124, batch_cost: 0.61500s, reader_cost: 0.01561, ips: 104.06429 samples/s, eta: 5:33:26
[2022/06/19 00:45:30] ppcls INFO: [Train][Epoch 110/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06337613, top1: 0.90935, CELoss: 0.25275, loss: 0.25275, batch_cost: 0.61000s, reader_cost: 0.01467, ips: 104.91794 samples/s, eta: 5:30:37
[2022/06/19 00:45:36] ppcls INFO: [Train][Epoch 110/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06335097, top1: 0.90925, CELoss: 0.25243, loss: 0.25243, batch_cost: 0.61191s, reader_cost: 0.03496, ips: 104.59026 samples/s, eta: 5:31:33
[2022/06/19 00:45:41] ppcls INFO: [Train][Epoch 110/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06332580, top1: 0.90809, CELoss: 0.25703, loss: 0.25703, batch_cost: 0.60215s, reader_cost: 0.04692, ips: 106.28536 samples/s, eta: 5:26:10
[2022/06/19 00:45:44] ppcls INFO: [Train][Epoch 110/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06330063, top1: 0.90630, CELoss: 0.26142, loss: 0.26142, batch_cost: 0.58418s, reader_cost: 0.04949, ips: 83.87887 samples/s, eta: 5:16:20
[2022/06/19 00:45:44] ppcls INFO: [Train][Epoch 110/300][Avg]top1: 0.90630, CELoss: 0.26142, loss: 0.26142
[2022/06/19 00:45:51] ppcls INFO: [Eval][Epoch 110][Iter: 0/16]CELoss: 0.78029, loss: 0.78029, top1: 0.76562, batch_cost: 6.94725s, reader_cost: 3.38014, ips: 9.21227 images/sec
[2022/06/19 00:46:00] ppcls INFO: [Eval][Epoch 110][Iter: 10/16]CELoss: 0.70996, loss: 0.70996, top1: 0.79386, batch_cost: 0.61478s, reader_cost: 0.00129, ips: 104.10195 images/sec
[2022/06/19 00:46:01] ppcls INFO: [Eval][Epoch 110][Avg]CELoss: 0.62083, loss: 0.62083, top1: 0.79902
[2022/06/19 00:46:01] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 00:46:01] ppcls INFO: [Eval][Epoch 110][best metric: 0.7990196347236633]
[2022/06/19 00:46:01] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_110
[2022/06/19 00:46:02] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:46:08] ppcls INFO: [Train][Epoch 111/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06329811, top1: 0.98438, CELoss: 0.09817, loss: 0.09817, batch_cost: 0.61709s, reader_cost: 0.08016, ips: 103.71253 samples/s, eta: 5:34:09
[2022/06/19 00:46:16] ppcls INFO: [Train][Epoch 111/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06327293, top1: 0.90625, CELoss: 0.28105, loss: 0.28105, batch_cost: 0.91694s, reader_cost: 0.35336, ips: 69.79725 samples/s, eta: 8:16:22
[2022/06/19 00:46:21] ppcls INFO: [Train][Epoch 111/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06324775, top1: 0.90551, CELoss: 0.28531, loss: 0.28531, batch_cost: 0.68812s, reader_cost: 0.15309, ips: 93.00699 samples/s, eta: 6:12:23
[2022/06/19 00:46:28] ppcls INFO: [Train][Epoch 111/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06322255, top1: 0.91028, CELoss: 0.26268, loss: 0.26268, batch_cost: 0.65499s, reader_cost: 0.09580, ips: 97.71107 samples/s, eta: 5:54:21
[2022/06/19 00:46:34] ppcls INFO: [Train][Epoch 111/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06319735, top1: 0.90892, CELoss: 0.26037, loss: 0.26037, batch_cost: 0.65312s, reader_cost: 0.07007, ips: 97.99185 samples/s, eta: 5:53:13
[2022/06/19 00:46:40] ppcls INFO: [Train][Epoch 111/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06317214, top1: 0.90993, CELoss: 0.25715, loss: 0.25715, batch_cost: 0.64347s, reader_cost: 0.05532, ips: 99.46034 samples/s, eta: 5:47:54
[2022/06/19 00:46:46] ppcls INFO: [Train][Epoch 111/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06314693, top1: 0.91060, CELoss: 0.25286, loss: 0.25286, batch_cost: 0.63792s, reader_cost: 0.04706, ips: 100.32600 samples/s, eta: 5:44:47
[2022/06/19 00:46:52] ppcls INFO: [Train][Epoch 111/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06312171, top1: 0.91241, CELoss: 0.24734, loss: 0.24734, batch_cost: 0.62302s, reader_cost: 0.04435, ips: 102.72535 samples/s, eta: 5:36:38
[2022/06/19 00:46:57] ppcls INFO: [Train][Epoch 111/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06309648, top1: 0.91146, CELoss: 0.24843, loss: 0.24843, batch_cost: 0.61721s, reader_cost: 0.04022, ips: 103.69216 samples/s, eta: 5:33:23
[2022/06/19 00:47:04] ppcls INFO: [Train][Epoch 111/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06307125, top1: 0.91140, CELoss: 0.24744, loss: 0.24744, batch_cost: 0.62312s, reader_cost: 0.04888, ips: 102.70862 samples/s, eta: 5:36:29
[2022/06/19 00:47:09] ppcls INFO: [Train][Epoch 111/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06304601, top1: 0.91012, CELoss: 0.25192, loss: 0.25192, batch_cost: 0.61233s, reader_cost: 0.04407, ips: 104.51924 samples/s, eta: 5:30:33
[2022/06/19 00:47:15] ppcls INFO: [Train][Epoch 111/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06302076, top1: 0.91090, CELoss: 0.25011, loss: 0.25011, batch_cost: 0.61039s, reader_cost: 0.04644, ips: 104.85078 samples/s, eta: 5:29:24
[2022/06/19 00:47:21] ppcls INFO: [Train][Epoch 111/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06299550, top1: 0.91219, CELoss: 0.24704, loss: 0.24704, batch_cost: 0.60860s, reader_cost: 0.04949, ips: 105.16008 samples/s, eta: 5:28:20
[2022/06/19 00:47:27] ppcls INFO: [Train][Epoch 111/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06297024, top1: 0.91102, CELoss: 0.25082, loss: 0.25082, batch_cost: 0.60634s, reader_cost: 0.05069, ips: 105.55098 samples/s, eta: 5:27:01
[2022/06/19 00:47:34] ppcls INFO: [Train][Epoch 111/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06294497, top1: 0.91146, CELoss: 0.24965, loss: 0.24965, batch_cost: 0.61278s, reader_cost: 0.05156, ips: 104.44243 samples/s, eta: 5:30:23
[2022/06/19 00:47:40] ppcls INFO: [Train][Epoch 111/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06291970, top1: 0.91018, CELoss: 0.25457, loss: 0.25457, batch_cost: 0.61198s, reader_cost: 0.05327, ips: 104.57891 samples/s, eta: 5:29:51
[2022/06/19 00:47:49] ppcls INFO: [Train][Epoch 111/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06289441, top1: 0.90916, CELoss: 0.25660, loss: 0.25660, batch_cost: 0.63065s, reader_cost: 0.06027, ips: 101.48222 samples/s, eta: 5:39:48
[2022/06/19 00:47:51] ppcls INFO: [Train][Epoch 111/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06286913, top1: 0.90905, CELoss: 0.25818, loss: 0.25818, batch_cost: 0.60668s, reader_cost: 0.05667, ips: 80.76700 samples/s, eta: 5:26:48
[2022/06/19 00:47:52] ppcls INFO: [Train][Epoch 111/300][Avg]top1: 0.90905, CELoss: 0.25818, loss: 0.25818
[2022/06/19 00:47:52] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:47:58] ppcls INFO: [Train][Epoch 112/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06286660, top1: 0.87500, CELoss: 0.43919, loss: 0.43919, batch_cost: 0.63846s, reader_cost: 0.08813, ips: 100.24130 samples/s, eta: 5:43:54
[2022/06/19 00:48:06] ppcls INFO: [Train][Epoch 112/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06284130, top1: 0.90483, CELoss: 0.27716, loss: 0.27716, batch_cost: 0.68118s, reader_cost: 0.13668, ips: 93.95468 samples/s, eta: 6:06:48
[2022/06/19 00:48:13] ppcls INFO: [Train][Epoch 112/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06281600, top1: 0.90923, CELoss: 0.26262, loss: 0.26262, batch_cost: 0.68781s, reader_cost: 0.19738, ips: 93.04947 samples/s, eta: 6:10:15
[2022/06/19 00:48:18] ppcls INFO: [Train][Epoch 112/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06279069, top1: 0.91079, CELoss: 0.26522, loss: 0.26522, batch_cost: 0.62992s, reader_cost: 0.12541, ips: 101.59986 samples/s, eta: 5:38:59
[2022/06/19 00:48:25] ppcls INFO: [Train][Epoch 112/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06276537, top1: 0.90816, CELoss: 0.26749, loss: 0.26749, batch_cost: 0.63023s, reader_cost: 0.09383, ips: 101.54953 samples/s, eta: 5:39:03
[2022/06/19 00:48:31] ppcls INFO: [Train][Epoch 112/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06274005, top1: 0.90962, CELoss: 0.26411, loss: 0.26411, batch_cost: 0.62360s, reader_cost: 0.07647, ips: 102.62940 samples/s, eta: 5:35:23
[2022/06/19 00:48:37] ppcls INFO: [Train][Epoch 112/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06271472, top1: 0.90599, CELoss: 0.27297, loss: 0.27297, batch_cost: 0.61757s, reader_cost: 0.06820, ips: 103.63252 samples/s, eta: 5:32:02
[2022/06/19 00:48:43] ppcls INFO: [Train][Epoch 112/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06268938, top1: 0.90603, CELoss: 0.27130, loss: 0.27130, batch_cost: 0.62358s, reader_cost: 0.05957, ips: 102.63276 samples/s, eta: 5:35:09
[2022/06/19 00:48:49] ppcls INFO: [Train][Epoch 112/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06266404, top1: 0.90644, CELoss: 0.27060, loss: 0.27060, batch_cost: 0.62353s, reader_cost: 0.05223, ips: 102.64164 samples/s, eta: 5:35:01
[2022/06/19 00:48:55] ppcls INFO: [Train][Epoch 112/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06263869, top1: 0.90642, CELoss: 0.26858, loss: 0.26858, batch_cost: 0.61713s, reader_cost: 0.04733, ips: 103.70578 samples/s, eta: 5:31:29
[2022/06/19 00:49:01] ppcls INFO: [Train][Epoch 112/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06261334, top1: 0.90532, CELoss: 0.26930, loss: 0.26930, batch_cost: 0.61621s, reader_cost: 0.05339, ips: 103.86142 samples/s, eta: 5:30:53
[2022/06/19 00:49:06] ppcls INFO: [Train][Epoch 112/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06258797, top1: 0.90555, CELoss: 0.26770, loss: 0.26770, batch_cost: 0.60661s, reader_cost: 0.05708, ips: 105.50428 samples/s, eta: 5:25:38
[2022/06/19 00:49:15] ppcls INFO: [Train][Epoch 112/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06256261, top1: 0.90522, CELoss: 0.27072, loss: 0.27072, batch_cost: 0.62795s, reader_cost: 0.07034, ips: 101.91846 samples/s, eta: 5:36:59
[2022/06/19 00:49:21] ppcls INFO: [Train][Epoch 112/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06253723, top1: 0.90637, CELoss: 0.26924, loss: 0.26924, batch_cost: 0.62675s, reader_cost: 0.07462, ips: 102.11431 samples/s, eta: 5:36:14
[2022/06/19 00:49:27] ppcls INFO: [Train][Epoch 112/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06251185, top1: 0.90680, CELoss: 0.26736, loss: 0.26736, batch_cost: 0.62748s, reader_cost: 0.07776, ips: 101.99511 samples/s, eta: 5:36:31
[2022/06/19 00:49:33] ppcls INFO: [Train][Epoch 112/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06248646, top1: 0.90656, CELoss: 0.26809, loss: 0.26809, batch_cost: 0.61966s, reader_cost: 0.07447, ips: 103.28270 samples/s, eta: 5:32:13
[2022/06/19 00:49:38] ppcls INFO: [Train][Epoch 112/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06246106, top1: 0.90567, CELoss: 0.26838, loss: 0.26838, batch_cost: 0.61809s, reader_cost: 0.08019, ips: 103.54438 samples/s, eta: 5:31:17
[2022/06/19 00:49:41] ppcls INFO: [Train][Epoch 112/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06243566, top1: 0.90566, CELoss: 0.26627, loss: 0.26627, batch_cost: 0.59360s, reader_cost: 0.07537, ips: 82.54705 samples/s, eta: 5:18:03
[2022/06/19 00:49:41] ppcls INFO: [Train][Epoch 112/300][Avg]top1: 0.90566, CELoss: 0.26627, loss: 0.26627
[2022/06/19 00:49:41] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:49:47] ppcls INFO: [Train][Epoch 113/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06243312, top1: 0.89062, CELoss: 0.22265, loss: 0.22265, batch_cost: 0.62616s, reader_cost: 0.10258, ips: 102.20963 samples/s, eta: 5:35:29
[2022/06/19 00:49:53] ppcls INFO: [Train][Epoch 113/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06240771, top1: 0.92898, CELoss: 0.21560, loss: 0.21560, batch_cost: 0.54002s, reader_cost: 0.01118, ips: 118.51353 samples/s, eta: 4:49:15
[2022/06/19 00:50:01] ppcls INFO: [Train][Epoch 113/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06238230, top1: 0.92411, CELoss: 0.22792, loss: 0.22792, batch_cost: 0.70632s, reader_cost: 0.02050, ips: 90.61081 samples/s, eta: 6:18:12
[2022/06/19 00:50:07] ppcls INFO: [Train][Epoch 113/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06235687, top1: 0.91331, CELoss: 0.23517, loss: 0.23517, batch_cost: 0.65037s, reader_cost: 0.01845, ips: 98.40584 samples/s, eta: 5:48:08
[2022/06/19 00:50:14] ppcls INFO: [Train][Epoch 113/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06233144, top1: 0.91159, CELoss: 0.24267, loss: 0.24267, batch_cost: 0.65337s, reader_cost: 0.01534, ips: 97.95369 samples/s, eta: 5:49:38
[2022/06/19 00:50:20] ppcls INFO: [Train][Epoch 113/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06230601, top1: 0.90993, CELoss: 0.25334, loss: 0.25334, batch_cost: 0.64564s, reader_cost: 0.01629, ips: 99.12714 samples/s, eta: 5:45:23
[2022/06/19 00:50:26] ppcls INFO: [Train][Epoch 113/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06228057, top1: 0.91265, CELoss: 0.24651, loss: 0.24651, batch_cost: 0.63790s, reader_cost: 0.01472, ips: 100.32876 samples/s, eta: 5:41:09
[2022/06/19 00:50:32] ppcls INFO: [Train][Epoch 113/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06225512, top1: 0.91351, CELoss: 0.24781, loss: 0.24781, batch_cost: 0.62775s, reader_cost: 0.01385, ips: 101.95073 samples/s, eta: 5:35:37
[2022/06/19 00:50:38] ppcls INFO: [Train][Epoch 113/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06222967, top1: 0.91204, CELoss: 0.25374, loss: 0.25374, batch_cost: 0.62923s, reader_cost: 0.01460, ips: 101.71125 samples/s, eta: 5:36:18
[2022/06/19 00:50:44] ppcls INFO: [Train][Epoch 113/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06220420, top1: 0.91346, CELoss: 0.25291, loss: 0.25291, batch_cost: 0.62327s, reader_cost: 0.01664, ips: 102.68437 samples/s, eta: 5:33:00
[2022/06/19 00:50:51] ppcls INFO: [Train][Epoch 113/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06217874, top1: 0.91445, CELoss: 0.25056, loss: 0.25056, batch_cost: 0.63427s, reader_cost: 0.01620, ips: 100.90316 samples/s, eta: 5:38:47
[2022/06/19 00:50:57] ppcls INFO: [Train][Epoch 113/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06215326, top1: 0.91512, CELoss: 0.24936, loss: 0.24936, batch_cost: 0.63230s, reader_cost: 0.01632, ips: 101.21801 samples/s, eta: 5:37:37
[2022/06/19 00:51:02] ppcls INFO: [Train][Epoch 113/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06212778, top1: 0.91593, CELoss: 0.24445, loss: 0.24445, batch_cost: 0.62159s, reader_cost: 0.01751, ips: 102.96182 samples/s, eta: 5:31:48
[2022/06/19 00:51:08] ppcls INFO: [Train][Epoch 113/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06210230, top1: 0.91579, CELoss: 0.24523, loss: 0.24523, batch_cost: 0.61760s, reader_cost: 0.01728, ips: 103.62744 samples/s, eta: 5:29:34
[2022/06/19 00:51:14] ppcls INFO: [Train][Epoch 113/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06207680, top1: 0.91478, CELoss: 0.24800, loss: 0.24800, batch_cost: 0.61388s, reader_cost: 0.01688, ips: 104.25533 samples/s, eta: 5:27:28
[2022/06/19 00:51:22] ppcls INFO: [Train][Epoch 113/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06205130, top1: 0.91474, CELoss: 0.24682, loss: 0.24682, batch_cost: 0.62677s, reader_cost: 0.01671, ips: 102.11051 samples/s, eta: 5:34:15
[2022/06/19 00:51:26] ppcls INFO: [Train][Epoch 113/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06202580, top1: 0.91431, CELoss: 0.24733, loss: 0.24733, batch_cost: 0.61435s, reader_cost: 0.01687, ips: 104.17441 samples/s, eta: 5:27:31
[2022/06/19 00:51:28] ppcls INFO: [Train][Epoch 113/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06200028, top1: 0.91445, CELoss: 0.24826, loss: 0.24826, batch_cost: 0.58978s, reader_cost: 0.01586, ips: 83.08126 samples/s, eta: 5:14:20
[2022/06/19 00:51:29] ppcls INFO: [Train][Epoch 113/300][Avg]top1: 0.91445, CELoss: 0.24826, loss: 0.24826
[2022/06/19 00:51:29] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:51:34] ppcls INFO: [Train][Epoch 114/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06199773, top1: 0.89062, CELoss: 0.25898, loss: 0.25898, batch_cost: 0.62045s, reader_cost: 0.04457, ips: 103.15085 samples/s, eta: 5:30:40
[2022/06/19 00:51:41] ppcls INFO: [Train][Epoch 114/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06197221, top1: 0.91335, CELoss: 0.25004, loss: 0.25004, batch_cost: 0.75566s, reader_cost: 0.03769, ips: 84.69431 samples/s, eta: 6:42:36
[2022/06/19 00:51:49] ppcls INFO: [Train][Epoch 114/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06194669, top1: 0.90551, CELoss: 0.25830, loss: 0.25830, batch_cost: 0.74363s, reader_cost: 0.01840, ips: 86.06488 samples/s, eta: 6:36:04
[2022/06/19 00:51:55] ppcls INFO: [Train][Epoch 114/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06192116, top1: 0.90171, CELoss: 0.26689, loss: 0.26689, batch_cost: 0.68514s, reader_cost: 0.01909, ips: 93.41154 samples/s, eta: 6:04:48
[2022/06/19 00:52:00] ppcls INFO: [Train][Epoch 114/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06189562, top1: 0.90244, CELoss: 0.27226, loss: 0.27226, batch_cost: 0.65312s, reader_cost: 0.02045, ips: 97.99090 samples/s, eta: 5:47:38
[2022/06/19 00:52:06] ppcls INFO: [Train][Epoch 114/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06187007, top1: 0.90993, CELoss: 0.25731, loss: 0.25731, batch_cost: 0.62624s, reader_cost: 0.01784, ips: 102.19668 samples/s, eta: 5:33:14
[2022/06/19 00:52:13] ppcls INFO: [Train][Epoch 114/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06184452, top1: 0.91060, CELoss: 0.25466, loss: 0.25466, batch_cost: 0.63946s, reader_cost: 0.01929, ips: 100.08453 samples/s, eta: 5:40:09
[2022/06/19 00:52:19] ppcls INFO: [Train][Epoch 114/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06181896, top1: 0.91131, CELoss: 0.25403, loss: 0.25403, batch_cost: 0.63191s, reader_cost: 0.02030, ips: 101.27986 samples/s, eta: 5:36:02
[2022/06/19 00:52:24] ppcls INFO: [Train][Epoch 114/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06179340, top1: 0.91184, CELoss: 0.24945, loss: 0.24945, batch_cost: 0.62650s, reader_cost: 0.01949, ips: 102.15438 samples/s, eta: 5:33:03
[2022/06/19 00:52:31] ppcls INFO: [Train][Epoch 114/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06176783, top1: 0.91054, CELoss: 0.25451, loss: 0.25451, batch_cost: 0.63032s, reader_cost: 0.02029, ips: 101.53521 samples/s, eta: 5:34:59
[2022/06/19 00:52:37] ppcls INFO: [Train][Epoch 114/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06174225, top1: 0.90981, CELoss: 0.25666, loss: 0.25666, batch_cost: 0.62721s, reader_cost: 0.01956, ips: 102.03998 samples/s, eta: 5:33:13
[2022/06/19 00:52:43] ppcls INFO: [Train][Epoch 114/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06171667, top1: 0.91174, CELoss: 0.25004, loss: 0.25004, batch_cost: 0.62654s, reader_cost: 0.01817, ips: 102.14891 samples/s, eta: 5:32:45
[2022/06/19 00:52:50] ppcls INFO: [Train][Epoch 114/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06169108, top1: 0.91064, CELoss: 0.25443, loss: 0.25443, batch_cost: 0.62846s, reader_cost: 0.01879, ips: 101.83621 samples/s, eta: 5:33:40
[2022/06/19 00:52:57] ppcls INFO: [Train][Epoch 114/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06166549, top1: 0.91126, CELoss: 0.25279, loss: 0.25279, batch_cost: 0.63932s, reader_cost: 0.01862, ips: 100.10602 samples/s, eta: 5:39:20
[2022/06/19 00:53:02] ppcls INFO: [Train][Epoch 114/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06163988, top1: 0.91013, CELoss: 0.25455, loss: 0.25455, batch_cost: 0.62506s, reader_cost: 0.01803, ips: 102.38959 samples/s, eta: 5:31:40
[2022/06/19 00:53:07] ppcls INFO: [Train][Epoch 114/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06161428, top1: 0.90863, CELoss: 0.25601, loss: 0.25601, batch_cost: 0.61516s, reader_cost: 0.01807, ips: 104.03789 samples/s, eta: 5:26:18
[2022/06/19 00:53:13] ppcls INFO: [Train][Epoch 114/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06158866, top1: 0.90877, CELoss: 0.25637, loss: 0.25637, batch_cost: 0.61401s, reader_cost: 0.02368, ips: 104.23343 samples/s, eta: 5:25:35
[2022/06/19 00:53:15] ppcls INFO: [Train][Epoch 114/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06156304, top1: 0.90951, CELoss: 0.25661, loss: 0.25661, batch_cost: 0.59019s, reader_cost: 0.02226, ips: 83.02348 samples/s, eta: 5:12:52
[2022/06/19 00:53:15] ppcls INFO: [Train][Epoch 114/300][Avg]top1: 0.90951, CELoss: 0.25661, loss: 0.25661
[2022/06/19 00:53:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:53:22] ppcls INFO: [Train][Epoch 115/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06156048, top1: 0.96875, CELoss: 0.14855, loss: 0.14855, batch_cost: 0.62291s, reader_cost: 0.04685, ips: 102.74284 samples/s, eta: 5:30:12
[2022/06/19 00:53:29] ppcls INFO: [Train][Epoch 115/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06153485, top1: 0.91335, CELoss: 0.27086, loss: 0.27086, batch_cost: 0.90031s, reader_cost: 0.02090, ips: 71.08635 samples/s, eta: 7:57:06
[2022/06/19 00:53:35] ppcls INFO: [Train][Epoch 115/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06150922, top1: 0.91071, CELoss: 0.25987, loss: 0.25987, batch_cost: 0.68781s, reader_cost: 0.02018, ips: 93.04853 samples/s, eta: 6:04:22
[2022/06/19 00:53:42] ppcls INFO: [Train][Epoch 115/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06148358, top1: 0.90776, CELoss: 0.25802, loss: 0.25802, batch_cost: 0.67406s, reader_cost: 0.01649, ips: 94.94705 samples/s, eta: 5:56:58
[2022/06/19 00:53:49] ppcls INFO: [Train][Epoch 115/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06145794, top1: 0.90930, CELoss: 0.25668, loss: 0.25668, batch_cost: 0.69439s, reader_cost: 0.01770, ips: 92.16735 samples/s, eta: 6:07:37
[2022/06/19 00:53:53] ppcls INFO: [Train][Epoch 115/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06143228, top1: 0.90809, CELoss: 0.25735, loss: 0.25735, batch_cost: 0.64124s, reader_cost: 0.01624, ips: 99.80593 samples/s, eta: 5:39:23
[2022/06/19 00:53:59] ppcls INFO: [Train][Epoch 115/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06140663, top1: 0.91342, CELoss: 0.24891, loss: 0.24891, batch_cost: 0.62316s, reader_cost: 0.01540, ips: 102.70208 samples/s, eta: 5:29:42
[2022/06/19 00:54:05] ppcls INFO: [Train][Epoch 115/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06138096, top1: 0.91087, CELoss: 0.25561, loss: 0.25561, batch_cost: 0.61964s, reader_cost: 0.01913, ips: 103.28656 samples/s, eta: 5:27:44
[2022/06/19 00:54:13] ppcls INFO: [Train][Epoch 115/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06135529, top1: 0.91030, CELoss: 0.26043, loss: 0.26043, batch_cost: 0.63939s, reader_cost: 0.02013, ips: 100.09589 samples/s, eta: 5:38:05
[2022/06/19 00:54:18] ppcls INFO: [Train][Epoch 115/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06132962, top1: 0.91106, CELoss: 0.26040, loss: 0.26040, batch_cost: 0.62911s, reader_cost: 0.01950, ips: 101.73120 samples/s, eta: 5:32:32
[2022/06/19 00:54:24] ppcls INFO: [Train][Epoch 115/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06130393, top1: 0.91058, CELoss: 0.26244, loss: 0.26244, batch_cost: 0.62512s, reader_cost: 0.01925, ips: 102.38110 samples/s, eta: 5:30:19
[2022/06/19 00:54:30] ppcls INFO: [Train][Epoch 115/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06127824, top1: 0.91019, CELoss: 0.26312, loss: 0.26312, batch_cost: 0.62658s, reader_cost: 0.01885, ips: 102.14190 samples/s, eta: 5:31:00
[2022/06/19 00:54:37] ppcls INFO: [Train][Epoch 115/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06125255, top1: 0.91077, CELoss: 0.26113, loss: 0.26113, batch_cost: 0.63268s, reader_cost: 0.01948, ips: 101.15696 samples/s, eta: 5:34:07
[2022/06/19 00:54:43] ppcls INFO: [Train][Epoch 115/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06122685, top1: 0.91054, CELoss: 0.26259, loss: 0.26259, batch_cost: 0.62776s, reader_cost: 0.01903, ips: 101.94937 samples/s, eta: 5:31:25
[2022/06/19 00:54:49] ppcls INFO: [Train][Epoch 115/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06120114, top1: 0.91068, CELoss: 0.26089, loss: 0.26089, batch_cost: 0.62331s, reader_cost: 0.01936, ips: 102.67816 samples/s, eta: 5:28:57
[2022/06/19 00:54:55] ppcls INFO: [Train][Epoch 115/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06117543, top1: 0.91070, CELoss: 0.26026, loss: 0.26026, batch_cost: 0.62325s, reader_cost: 0.01820, ips: 102.68714 samples/s, eta: 5:28:49
[2022/06/19 00:55:00] ppcls INFO: [Train][Epoch 115/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06114971, top1: 0.91062, CELoss: 0.25975, loss: 0.25975, batch_cost: 0.61413s, reader_cost: 0.01718, ips: 104.21217 samples/s, eta: 5:23:54
[2022/06/19 00:55:02] ppcls INFO: [Train][Epoch 115/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06112399, top1: 0.91015, CELoss: 0.26091, loss: 0.26091, batch_cost: 0.58968s, reader_cost: 0.01619, ips: 83.09573 samples/s, eta: 5:10:55
[2022/06/19 00:55:02] ppcls INFO: [Train][Epoch 115/300][Avg]top1: 0.91015, CELoss: 0.26091, loss: 0.26091
[2022/06/19 00:55:09] ppcls INFO: [Eval][Epoch 115][Iter: 0/16]CELoss: 0.93499, loss: 0.93499, top1: 0.76367, batch_cost: 6.99188s, reader_cost: 3.76030, ips: 9.15348 images/sec
[2022/06/19 00:55:17] ppcls INFO: [Eval][Epoch 115][Iter: 10/16]CELoss: 0.81000, loss: 0.81000, top1: 0.75959, batch_cost: 0.57315s, reader_cost: 0.00334, ips: 111.66444 images/sec
[2022/06/19 00:55:19] ppcls INFO: [Eval][Epoch 115][Avg]CELoss: 0.75052, loss: 0.75052, top1: 0.76912
[2022/06/19 00:55:19] ppcls INFO: [Eval][Epoch 115][best metric: 0.7990196347236633]
[2022/06/19 00:55:19] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:55:24] ppcls INFO: [Train][Epoch 116/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06112141, top1: 0.92188, CELoss: 0.21399, loss: 0.21399, batch_cost: 0.61923s, reader_cost: 0.04514, ips: 103.35401 samples/s, eta: 5:26:29
[2022/06/19 00:55:32] ppcls INFO: [Train][Epoch 116/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06109568, top1: 0.91761, CELoss: 0.22419, loss: 0.22419, batch_cost: 0.81564s, reader_cost: 0.15162, ips: 78.46553 samples/s, eta: 7:09:54
[2022/06/19 00:55:40] ppcls INFO: [Train][Epoch 116/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06106994, top1: 0.91220, CELoss: 0.23738, loss: 0.23738, batch_cost: 0.82350s, reader_cost: 0.16924, ips: 77.71685 samples/s, eta: 7:13:55
[2022/06/19 00:55:45] ppcls INFO: [Train][Epoch 116/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06104420, top1: 0.91179, CELoss: 0.24590, loss: 0.24590, batch_cost: 0.70315s, reader_cost: 0.11525, ips: 91.01840 samples/s, eta: 6:10:23
[2022/06/19 00:55:51] ppcls INFO: [Train][Epoch 116/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06101845, top1: 0.91463, CELoss: 0.24151, loss: 0.24151, batch_cost: 0.68056s, reader_cost: 0.08679, ips: 94.04087 samples/s, eta: 5:58:22
[2022/06/19 00:55:57] ppcls INFO: [Train][Epoch 116/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06099269, top1: 0.91575, CELoss: 0.23931, loss: 0.23931, batch_cost: 0.66069s, reader_cost: 0.07459, ips: 96.86793 samples/s, eta: 5:47:47
[2022/06/19 00:56:03] ppcls INFO: [Train][Epoch 116/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06096693, top1: 0.91342, CELoss: 0.24127, loss: 0.24127, batch_cost: 0.64076s, reader_cost: 0.06492, ips: 99.88148 samples/s, eta: 5:37:11
[2022/06/19 00:56:09] ppcls INFO: [Train][Epoch 116/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06094116, top1: 0.91527, CELoss: 0.24042, loss: 0.24042, batch_cost: 0.63304s, reader_cost: 0.06796, ips: 101.09928 samples/s, eta: 5:33:01
[2022/06/19 00:56:15] ppcls INFO: [Train][Epoch 116/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06091539, top1: 0.91628, CELoss: 0.23887, loss: 0.23887, batch_cost: 0.63760s, reader_cost: 0.06622, ips: 100.37664 samples/s, eta: 5:35:19
[2022/06/19 00:56:21] ppcls INFO: [Train][Epoch 116/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06088961, top1: 0.91501, CELoss: 0.24179, loss: 0.24179, batch_cost: 0.63439s, reader_cost: 0.06581, ips: 100.88475 samples/s, eta: 5:33:31
[2022/06/19 00:56:28] ppcls INFO: [Train][Epoch 116/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06086382, top1: 0.91662, CELoss: 0.23925, loss: 0.23925, batch_cost: 0.64130s, reader_cost: 0.06138, ips: 99.79682 samples/s, eta: 5:37:03
[2022/06/19 00:56:35] ppcls INFO: [Train][Epoch 116/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06083803, top1: 0.91568, CELoss: 0.24180, loss: 0.24180, batch_cost: 0.64388s, reader_cost: 0.05735, ips: 99.39773 samples/s, eta: 5:38:18
[2022/06/19 00:56:41] ppcls INFO: [Train][Epoch 116/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06081224, top1: 0.91464, CELoss: 0.24344, loss: 0.24344, batch_cost: 0.64022s, reader_cost: 0.05386, ips: 99.96632 samples/s, eta: 5:36:16
[2022/06/19 00:56:46] ppcls INFO: [Train][Epoch 116/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06078643, top1: 0.91329, CELoss: 0.24767, loss: 0.24767, batch_cost: 0.63004s, reader_cost: 0.05148, ips: 101.58081 samples/s, eta: 5:30:49
[2022/06/19 00:56:53] ppcls INFO: [Train][Epoch 116/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06076062, top1: 0.91323, CELoss: 0.24753, loss: 0.24753, batch_cost: 0.63423s, reader_cost: 0.04860, ips: 100.90981 samples/s, eta: 5:32:55
[2022/06/19 00:56:58] ppcls INFO: [Train][Epoch 116/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06073481, top1: 0.91215, CELoss: 0.25006, loss: 0.25006, batch_cost: 0.62714s, reader_cost: 0.04604, ips: 102.05083 samples/s, eta: 5:29:05
[2022/06/19 00:57:05] ppcls INFO: [Train][Epoch 116/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06070899, top1: 0.91101, CELoss: 0.25213, loss: 0.25213, batch_cost: 0.62695s, reader_cost: 0.04372, ips: 102.08078 samples/s, eta: 5:28:53
[2022/06/19 00:57:07] ppcls INFO: [Train][Epoch 116/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06068316, top1: 0.91115, CELoss: 0.25375, loss: 0.25375, batch_cost: 0.60178s, reader_cost: 0.04114, ips: 81.42568 samples/s, eta: 5:15:34
[2022/06/19 00:57:07] ppcls INFO: [Train][Epoch 116/300][Avg]top1: 0.91115, CELoss: 0.25375, loss: 0.25375
[2022/06/19 00:57:07] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:57:14] ppcls INFO: [Train][Epoch 117/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06068058, top1: 0.89062, CELoss: 0.26706, loss: 0.26706, batch_cost: 0.63556s, reader_cost: 0.07403, ips: 100.69937 samples/s, eta: 5:33:17
[2022/06/19 00:57:21] ppcls INFO: [Train][Epoch 117/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06065474, top1: 0.90767, CELoss: 0.24249, loss: 0.24249, batch_cost: 0.60128s, reader_cost: 0.00412, ips: 106.43929 samples/s, eta: 5:15:12
[2022/06/19 00:57:27] ppcls INFO: [Train][Epoch 117/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06062890, top1: 0.90848, CELoss: 0.23629, loss: 0.23629, batch_cost: 0.59446s, reader_cost: 0.00837, ips: 107.66116 samples/s, eta: 5:11:32
[2022/06/19 00:57:34] ppcls INFO: [Train][Epoch 117/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06060306, top1: 0.91331, CELoss: 0.23820, loss: 0.23820, batch_cost: 0.61175s, reader_cost: 0.01166, ips: 104.61757 samples/s, eta: 5:20:29
[2022/06/19 00:57:40] ppcls INFO: [Train][Epoch 117/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06057721, top1: 0.91387, CELoss: 0.23559, loss: 0.23559, batch_cost: 0.60628s, reader_cost: 0.01688, ips: 105.56203 samples/s, eta: 5:17:31
[2022/06/19 00:57:46] ppcls INFO: [Train][Epoch 117/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06055135, top1: 0.91850, CELoss: 0.22472, loss: 0.22472, batch_cost: 0.60480s, reader_cost: 0.01632, ips: 105.82088 samples/s, eta: 5:16:39
[2022/06/19 00:57:52] ppcls INFO: [Train][Epoch 117/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06052549, top1: 0.92008, CELoss: 0.22063, loss: 0.22063, batch_cost: 0.61953s, reader_cost: 0.01923, ips: 103.30336 samples/s, eta: 5:24:15
[2022/06/19 00:57:58] ppcls INFO: [Train][Epoch 117/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06049962, top1: 0.91857, CELoss: 0.22667, loss: 0.22667, batch_cost: 0.61080s, reader_cost: 0.01732, ips: 104.78138 samples/s, eta: 5:19:35
[2022/06/19 00:58:04] ppcls INFO: [Train][Epoch 117/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06047374, top1: 0.91667, CELoss: 0.22819, loss: 0.22819, batch_cost: 0.61565s, reader_cost: 0.01615, ips: 103.95546 samples/s, eta: 5:22:01
[2022/06/19 00:58:10] ppcls INFO: [Train][Epoch 117/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06044786, top1: 0.91432, CELoss: 0.23674, loss: 0.23674, batch_cost: 0.60932s, reader_cost: 0.01535, ips: 105.03502 samples/s, eta: 5:18:36
[2022/06/19 00:58:17] ppcls INFO: [Train][Epoch 117/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.06042198, top1: 0.91522, CELoss: 0.23596, loss: 0.23596, batch_cost: 0.61275s, reader_cost: 0.01429, ips: 104.44660 samples/s, eta: 5:20:18
[2022/06/19 00:58:22] ppcls INFO: [Train][Epoch 117/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.06039609, top1: 0.91484, CELoss: 0.23474, loss: 0.23474, batch_cost: 0.61132s, reader_cost: 0.01393, ips: 104.69192 samples/s, eta: 5:19:27
[2022/06/19 00:58:29] ppcls INFO: [Train][Epoch 117/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.06037019, top1: 0.91335, CELoss: 0.23782, loss: 0.23782, batch_cost: 0.61817s, reader_cost: 0.01320, ips: 103.53092 samples/s, eta: 5:22:56
[2022/06/19 00:58:35] ppcls INFO: [Train][Epoch 117/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.06034428, top1: 0.91484, CELoss: 0.23570, loss: 0.23570, batch_cost: 0.60964s, reader_cost: 0.01333, ips: 104.98002 samples/s, eta: 5:18:22
[2022/06/19 00:58:41] ppcls INFO: [Train][Epoch 117/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.06031838, top1: 0.91345, CELoss: 0.24093, loss: 0.24093, batch_cost: 0.61550s, reader_cost: 0.01341, ips: 103.98108 samples/s, eta: 5:21:19
[2022/06/19 00:58:47] ppcls INFO: [Train][Epoch 117/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.06029246, top1: 0.91132, CELoss: 0.24597, loss: 0.24597, batch_cost: 0.61040s, reader_cost: 0.01356, ips: 104.84885 samples/s, eta: 5:18:34
[2022/06/19 00:58:52] ppcls INFO: [Train][Epoch 117/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.06026654, top1: 0.91110, CELoss: 0.24537, loss: 0.24537, batch_cost: 0.60471s, reader_cost: 0.01342, ips: 105.83546 samples/s, eta: 5:15:29
[2022/06/19 00:58:54] ppcls INFO: [Train][Epoch 117/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.06024061, top1: 0.91152, CELoss: 0.24643, loss: 0.24643, batch_cost: 0.58092s, reader_cost: 0.01270, ips: 84.34954 samples/s, eta: 5:02:59
[2022/06/19 00:58:55] ppcls INFO: [Train][Epoch 117/300][Avg]top1: 0.91152, CELoss: 0.24643, loss: 0.24643
[2022/06/19 00:58:55] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 00:59:01] ppcls INFO: [Train][Epoch 118/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.06023802, top1: 0.89062, CELoss: 0.24619, loss: 0.24619, batch_cost: 0.61656s, reader_cost: 0.04629, ips: 103.80208 samples/s, eta: 5:21:33
[2022/06/19 00:59:08] ppcls INFO: [Train][Epoch 118/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.06021209, top1: 0.89631, CELoss: 0.29487, loss: 0.29487, batch_cost: 0.56402s, reader_cost: 0.01959, ips: 113.47123 samples/s, eta: 4:54:04
[2022/06/19 00:59:14] ppcls INFO: [Train][Epoch 118/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.06018615, top1: 0.90104, CELoss: 0.27046, loss: 0.27046, batch_cost: 0.59988s, reader_cost: 0.01994, ips: 106.68845 samples/s, eta: 5:12:39
[2022/06/19 00:59:20] ppcls INFO: [Train][Epoch 118/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.06016021, top1: 0.90020, CELoss: 0.26691, loss: 0.26691, batch_cost: 0.59943s, reader_cost: 0.02151, ips: 106.76791 samples/s, eta: 5:12:20
[2022/06/19 00:59:26] ppcls INFO: [Train][Epoch 118/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.06013426, top1: 0.90091, CELoss: 0.26241, loss: 0.26241, batch_cost: 0.61098s, reader_cost: 0.01989, ips: 104.74897 samples/s, eta: 5:18:15
[2022/06/19 00:59:32] ppcls INFO: [Train][Epoch 118/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.06010830, top1: 0.90502, CELoss: 0.25161, loss: 0.25161, batch_cost: 0.60642s, reader_cost: 0.02149, ips: 105.53817 samples/s, eta: 5:15:46
[2022/06/19 00:59:39] ppcls INFO: [Train][Epoch 118/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.06008234, top1: 0.90958, CELoss: 0.24308, loss: 0.24308, batch_cost: 0.61390s, reader_cost: 0.02244, ips: 104.25173 samples/s, eta: 5:19:33
[2022/06/19 00:59:45] ppcls INFO: [Train][Epoch 118/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.06005637, top1: 0.91175, CELoss: 0.24018, loss: 0.24018, batch_cost: 0.61343s, reader_cost: 0.02083, ips: 104.33149 samples/s, eta: 5:19:13
[2022/06/19 00:59:51] ppcls INFO: [Train][Epoch 118/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.06003040, top1: 0.91300, CELoss: 0.23945, loss: 0.23945, batch_cost: 0.60791s, reader_cost: 0.02186, ips: 105.27891 samples/s, eta: 5:16:14
[2022/06/19 00:59:56] ppcls INFO: [Train][Epoch 118/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.06000442, top1: 0.91312, CELoss: 0.24119, loss: 0.24119, batch_cost: 0.59916s, reader_cost: 0.01997, ips: 106.81607 samples/s, eta: 5:11:35
[2022/06/19 01:00:02] ppcls INFO: [Train][Epoch 118/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05997844, top1: 0.91368, CELoss: 0.23997, loss: 0.23997, batch_cost: 0.59716s, reader_cost: 0.02076, ips: 107.17335 samples/s, eta: 5:10:27
[2022/06/19 01:00:08] ppcls INFO: [Train][Epoch 118/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05995245, top1: 0.91301, CELoss: 0.24177, loss: 0.24177, batch_cost: 0.60390s, reader_cost: 0.02016, ips: 105.97791 samples/s, eta: 5:13:51
[2022/06/19 01:00:14] ppcls INFO: [Train][Epoch 118/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05992645, top1: 0.91335, CELoss: 0.24299, loss: 0.24299, batch_cost: 0.60097s, reader_cost: 0.01996, ips: 106.49455 samples/s, eta: 5:12:14
[2022/06/19 01:00:20] ppcls INFO: [Train][Epoch 118/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05990045, top1: 0.91198, CELoss: 0.24701, loss: 0.24701, batch_cost: 0.60005s, reader_cost: 0.01939, ips: 106.65823 samples/s, eta: 5:11:39
[2022/06/19 01:00:27] ppcls INFO: [Train][Epoch 118/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05987445, top1: 0.91168, CELoss: 0.24886, loss: 0.24886, batch_cost: 0.60527s, reader_cost: 0.01839, ips: 105.73754 samples/s, eta: 5:14:16
[2022/06/19 01:00:32] ppcls INFO: [Train][Epoch 118/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05984844, top1: 0.91132, CELoss: 0.25082, loss: 0.25082, batch_cost: 0.60204s, reader_cost: 0.01765, ips: 106.30582 samples/s, eta: 5:12:29
[2022/06/19 01:00:38] ppcls INFO: [Train][Epoch 118/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05982242, top1: 0.91178, CELoss: 0.24845, loss: 0.24845, batch_cost: 0.59741s, reader_cost: 0.01668, ips: 107.12905 samples/s, eta: 5:09:59
[2022/06/19 01:00:40] ppcls INFO: [Train][Epoch 118/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05979640, top1: 0.91253, CELoss: 0.24696, loss: 0.24696, batch_cost: 0.57425s, reader_cost: 0.01570, ips: 85.32896 samples/s, eta: 4:57:52
[2022/06/19 01:00:40] ppcls INFO: [Train][Epoch 118/300][Avg]top1: 0.91253, CELoss: 0.24696, loss: 0.24696
[2022/06/19 01:00:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:00:47] ppcls INFO: [Train][Epoch 119/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05979379, top1: 0.92188, CELoss: 0.21273, loss: 0.21273, batch_cost: 0.61008s, reader_cost: 0.04218, ips: 104.90348 samples/s, eta: 5:16:27
[2022/06/19 01:00:54] ppcls INFO: [Train][Epoch 119/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05976777, top1: 0.90767, CELoss: 0.25875, loss: 0.25875, batch_cost: 0.70334s, reader_cost: 0.00070, ips: 90.99409 samples/s, eta: 6:04:42
[2022/06/19 01:01:00] ppcls INFO: [Train][Epoch 119/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05974173, top1: 0.90848, CELoss: 0.24429, loss: 0.24429, batch_cost: 0.66246s, reader_cost: 0.00044, ips: 96.60914 samples/s, eta: 5:43:23
[2022/06/19 01:01:06] ppcls INFO: [Train][Epoch 119/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05971569, top1: 0.91331, CELoss: 0.23778, loss: 0.23778, batch_cost: 0.64565s, reader_cost: 0.00060, ips: 99.12518 samples/s, eta: 5:34:34
[2022/06/19 01:01:13] ppcls INFO: [Train][Epoch 119/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05968965, top1: 0.91692, CELoss: 0.23297, loss: 0.23297, batch_cost: 0.65810s, reader_cost: 0.00066, ips: 97.24907 samples/s, eta: 5:40:55
[2022/06/19 01:01:19] ppcls INFO: [Train][Epoch 119/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05966359, top1: 0.91636, CELoss: 0.23321, loss: 0.23321, batch_cost: 0.63511s, reader_cost: 0.00109, ips: 100.77037 samples/s, eta: 5:28:54
[2022/06/19 01:01:24] ppcls INFO: [Train][Epoch 119/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05963754, top1: 0.91496, CELoss: 0.23934, loss: 0.23934, batch_cost: 0.61619s, reader_cost: 0.00433, ips: 103.86325 samples/s, eta: 5:19:00
[2022/06/19 01:01:30] ppcls INFO: [Train][Epoch 119/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05961148, top1: 0.91593, CELoss: 0.23716, loss: 0.23716, batch_cost: 0.61207s, reader_cost: 0.00599, ips: 104.56302 samples/s, eta: 5:16:46
[2022/06/19 01:01:36] ppcls INFO: [Train][Epoch 119/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05958541, top1: 0.91512, CELoss: 0.23758, loss: 0.23758, batch_cost: 0.61179s, reader_cost: 0.00931, ips: 104.61053 samples/s, eta: 5:16:31
[2022/06/19 01:01:42] ppcls INFO: [Train][Epoch 119/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05955934, top1: 0.91518, CELoss: 0.23644, loss: 0.23644, batch_cost: 0.61394s, reader_cost: 0.01050, ips: 104.24447 samples/s, eta: 5:17:31
[2022/06/19 01:01:48] ppcls INFO: [Train][Epoch 119/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05953326, top1: 0.91491, CELoss: 0.23809, loss: 0.23809, batch_cost: 0.60731s, reader_cost: 0.01054, ips: 105.38313 samples/s, eta: 5:13:59
[2022/06/19 01:01:54] ppcls INFO: [Train][Epoch 119/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05950717, top1: 0.91385, CELoss: 0.24020, loss: 0.24020, batch_cost: 0.60947s, reader_cost: 0.01067, ips: 105.00960 samples/s, eta: 5:15:00
[2022/06/19 01:02:00] ppcls INFO: [Train][Epoch 119/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05948108, top1: 0.91477, CELoss: 0.24101, loss: 0.24101, batch_cost: 0.60609s, reader_cost: 0.01066, ips: 105.59564 samples/s, eta: 5:13:09
[2022/06/19 01:02:06] ppcls INFO: [Train][Epoch 119/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05945499, top1: 0.91293, CELoss: 0.24535, loss: 0.24535, batch_cost: 0.60616s, reader_cost: 0.01007, ips: 105.58240 samples/s, eta: 5:13:06
[2022/06/19 01:02:11] ppcls INFO: [Train][Epoch 119/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05942889, top1: 0.91246, CELoss: 0.24667, loss: 0.24667, batch_cost: 0.60062s, reader_cost: 0.01023, ips: 106.55613 samples/s, eta: 5:10:08
[2022/06/19 01:02:19] ppcls INFO: [Train][Epoch 119/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05940278, top1: 0.91329, CELoss: 0.24554, loss: 0.24554, batch_cost: 0.61355s, reader_cost: 0.00990, ips: 104.31149 samples/s, eta: 5:16:42
[2022/06/19 01:02:24] ppcls INFO: [Train][Epoch 119/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05937667, top1: 0.91285, CELoss: 0.24540, loss: 0.24540, batch_cost: 0.60460s, reader_cost: 0.00943, ips: 105.85591 samples/s, eta: 5:11:59
[2022/06/19 01:02:26] ppcls INFO: [Train][Epoch 119/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05935056, top1: 0.91243, CELoss: 0.24539, loss: 0.24539, batch_cost: 0.58093s, reader_cost: 0.00887, ips: 84.34752 samples/s, eta: 4:59:40
[2022/06/19 01:02:26] ppcls INFO: [Train][Epoch 119/300][Avg]top1: 0.91243, CELoss: 0.24539, loss: 0.24539
[2022/06/19 01:02:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:02:33] ppcls INFO: [Train][Epoch 120/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05934795, top1: 0.95312, CELoss: 0.16480, loss: 0.16480, batch_cost: 0.61636s, reader_cost: 0.03385, ips: 103.83521 samples/s, eta: 5:17:56
[2022/06/19 01:02:39] ppcls INFO: [Train][Epoch 120/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05932182, top1: 0.90625, CELoss: 0.29218, loss: 0.29218, batch_cost: 0.63415s, reader_cost: 0.00095, ips: 100.92306 samples/s, eta: 5:27:01
[2022/06/19 01:02:45] ppcls INFO: [Train][Epoch 120/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05929570, top1: 0.90848, CELoss: 0.26758, loss: 0.26758, batch_cost: 0.62321s, reader_cost: 0.00148, ips: 102.69431 samples/s, eta: 5:21:16
[2022/06/19 01:02:52] ppcls INFO: [Train][Epoch 120/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05926956, top1: 0.91734, CELoss: 0.25590, loss: 0.25590, batch_cost: 0.63036s, reader_cost: 0.00179, ips: 101.52910 samples/s, eta: 5:24:51
[2022/06/19 01:02:58] ppcls INFO: [Train][Epoch 120/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05924342, top1: 0.91654, CELoss: 0.25225, loss: 0.25225, batch_cost: 0.62150s, reader_cost: 0.00236, ips: 102.97631 samples/s, eta: 5:20:11
[2022/06/19 01:03:04] ppcls INFO: [Train][Epoch 120/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05921728, top1: 0.91667, CELoss: 0.24891, loss: 0.24891, batch_cost: 0.60828s, reader_cost: 0.00540, ips: 105.21507 samples/s, eta: 5:13:16
[2022/06/19 01:03:10] ppcls INFO: [Train][Epoch 120/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05919113, top1: 0.91470, CELoss: 0.25520, loss: 0.25520, batch_cost: 0.60693s, reader_cost: 0.00508, ips: 105.44836 samples/s, eta: 5:12:28
[2022/06/19 01:03:15] ppcls INFO: [Train][Epoch 120/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05916498, top1: 0.91417, CELoss: 0.25509, loss: 0.25509, batch_cost: 0.59812s, reader_cost: 0.00619, ips: 107.00138 samples/s, eta: 5:07:50
[2022/06/19 01:03:21] ppcls INFO: [Train][Epoch 120/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05913882, top1: 0.91532, CELoss: 0.24937, loss: 0.24937, batch_cost: 0.59564s, reader_cost: 0.00711, ips: 107.44771 samples/s, eta: 5:06:27
[2022/06/19 01:03:27] ppcls INFO: [Train][Epoch 120/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05911265, top1: 0.91518, CELoss: 0.24902, loss: 0.24902, batch_cost: 0.59635s, reader_cost: 0.01744, ips: 107.31912 samples/s, eta: 5:06:44
[2022/06/19 01:03:33] ppcls INFO: [Train][Epoch 120/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05908648, top1: 0.91429, CELoss: 0.25238, loss: 0.25238, batch_cost: 0.59456s, reader_cost: 0.01900, ips: 107.64263 samples/s, eta: 5:05:42
[2022/06/19 01:03:39] ppcls INFO: [Train][Epoch 120/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05906031, top1: 0.91413, CELoss: 0.25271, loss: 0.25271, batch_cost: 0.59768s, reader_cost: 0.01833, ips: 107.08071 samples/s, eta: 5:07:13
[2022/06/19 01:03:45] ppcls INFO: [Train][Epoch 120/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05903413, top1: 0.91400, CELoss: 0.25152, loss: 0.25152, batch_cost: 0.60119s, reader_cost: 0.01773, ips: 106.45530 samples/s, eta: 5:08:55
[2022/06/19 01:03:51] ppcls INFO: [Train][Epoch 120/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05900794, top1: 0.91341, CELoss: 0.25189, loss: 0.25189, batch_cost: 0.60118s, reader_cost: 0.01648, ips: 106.45671 samples/s, eta: 5:08:49
[2022/06/19 01:03:57] ppcls INFO: [Train][Epoch 120/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05898175, top1: 0.91157, CELoss: 0.25435, loss: 0.25435, batch_cost: 0.60188s, reader_cost: 0.01663, ips: 106.33400 samples/s, eta: 5:09:04
[2022/06/19 01:04:03] ppcls INFO: [Train][Epoch 120/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05895555, top1: 0.91091, CELoss: 0.25527, loss: 0.25527, batch_cost: 0.59624s, reader_cost: 0.01611, ips: 107.33877 samples/s, eta: 5:06:04
[2022/06/19 01:04:08] ppcls INFO: [Train][Epoch 120/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05892935, top1: 0.91168, CELoss: 0.25350, loss: 0.25350, batch_cost: 0.59010s, reader_cost: 0.01566, ips: 108.45573 samples/s, eta: 5:02:49
[2022/06/19 01:04:10] ppcls INFO: [Train][Epoch 120/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05890314, top1: 0.91125, CELoss: 0.25545, loss: 0.25545, batch_cost: 0.56772s, reader_cost: 0.01472, ips: 86.31042 samples/s, eta: 4:51:14
[2022/06/19 01:04:10] ppcls INFO: [Train][Epoch 120/300][Avg]top1: 0.91125, CELoss: 0.25545, loss: 0.25545
[2022/06/19 01:04:17] ppcls INFO: [Eval][Epoch 120][Iter: 0/16]CELoss: 0.79518, loss: 0.79518, top1: 0.77734, batch_cost: 6.98676s, reader_cost: 3.57428, ips: 9.16018 images/sec
[2022/06/19 01:04:25] ppcls INFO: [Eval][Epoch 120][Iter: 10/16]CELoss: 0.74023, loss: 0.74023, top1: 0.78498, batch_cost: 0.59391s, reader_cost: 0.00273, ips: 107.76109 images/sec
[2022/06/19 01:04:27] ppcls INFO: [Eval][Epoch 120][Avg]CELoss: 0.65160, loss: 0.65160, top1: 0.79449
[2022/06/19 01:04:27] ppcls INFO: [Eval][Epoch 120][best metric: 0.7990196347236633]
[2022/06/19 01:04:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_120
[2022/06/19 01:04:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:04:33] ppcls INFO: [Train][Epoch 121/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05890052, top1: 0.96875, CELoss: 0.14509, loss: 0.14509, batch_cost: 0.59970s, reader_cost: 0.04581, ips: 106.72047 samples/s, eta: 5:07:38
[2022/06/19 01:04:40] ppcls INFO: [Train][Epoch 121/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05887431, top1: 0.89915, CELoss: 0.28557, loss: 0.28557, batch_cost: 0.71494s, reader_cost: 0.11922, ips: 89.51750 samples/s, eta: 6:06:38
[2022/06/19 01:04:47] ppcls INFO: [Train][Epoch 121/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05884809, top1: 0.90997, CELoss: 0.26174, loss: 0.26174, batch_cost: 0.71780s, reader_cost: 0.08998, ips: 89.16172 samples/s, eta: 6:07:59
[2022/06/19 01:04:53] ppcls INFO: [Train][Epoch 121/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05882187, top1: 0.90978, CELoss: 0.25889, loss: 0.25889, batch_cost: 0.67696s, reader_cost: 0.08914, ips: 94.54070 samples/s, eta: 5:46:56
[2022/06/19 01:05:01] ppcls INFO: [Train][Epoch 121/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05879564, top1: 0.91235, CELoss: 0.24870, loss: 0.24870, batch_cost: 0.69145s, reader_cost: 0.10035, ips: 92.55895 samples/s, eta: 5:54:15
[2022/06/19 01:05:06] ppcls INFO: [Train][Epoch 121/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05876941, top1: 0.91330, CELoss: 0.24621, loss: 0.24621, batch_cost: 0.65623s, reader_cost: 0.08524, ips: 97.52748 samples/s, eta: 5:36:05
[2022/06/19 01:05:12] ppcls INFO: [Train][Epoch 121/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05874317, top1: 0.91496, CELoss: 0.23994, loss: 0.23994, batch_cost: 0.64246s, reader_cost: 0.07905, ips: 99.61779 samples/s, eta: 5:28:56
[2022/06/19 01:05:17] ppcls INFO: [Train][Epoch 121/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05871693, top1: 0.91571, CELoss: 0.23984, loss: 0.23984, batch_cost: 0.62423s, reader_cost: 0.06894, ips: 102.52711 samples/s, eta: 5:19:29
[2022/06/19 01:05:23] ppcls INFO: [Train][Epoch 121/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05869068, top1: 0.91705, CELoss: 0.23892, loss: 0.23892, batch_cost: 0.62107s, reader_cost: 0.06747, ips: 103.04843 samples/s, eta: 5:17:46
[2022/06/19 01:05:28] ppcls INFO: [Train][Epoch 121/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05866442, top1: 0.91604, CELoss: 0.23790, loss: 0.23790, batch_cost: 0.61140s, reader_cost: 0.06314, ips: 104.67776 samples/s, eta: 5:12:43
[2022/06/19 01:05:36] ppcls INFO: [Train][Epoch 121/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05863816, top1: 0.91584, CELoss: 0.23740, loss: 0.23740, batch_cost: 0.62608s, reader_cost: 0.08535, ips: 102.22381 samples/s, eta: 5:20:08
[2022/06/19 01:05:41] ppcls INFO: [Train][Epoch 121/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05861190, top1: 0.91484, CELoss: 0.23924, loss: 0.23924, batch_cost: 0.61791s, reader_cost: 0.08295, ips: 103.57491 samples/s, eta: 5:15:51
[2022/06/19 01:05:48] ppcls INFO: [Train][Epoch 121/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05858563, top1: 0.91296, CELoss: 0.24233, loss: 0.24233, batch_cost: 0.62309s, reader_cost: 0.08052, ips: 102.71339 samples/s, eta: 5:18:24
[2022/06/19 01:05:55] ppcls INFO: [Train][Epoch 121/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05855935, top1: 0.91114, CELoss: 0.24590, loss: 0.24590, batch_cost: 0.62532s, reader_cost: 0.07461, ips: 102.34757 samples/s, eta: 5:19:26
[2022/06/19 01:06:00] ppcls INFO: [Train][Epoch 121/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05853308, top1: 0.91179, CELoss: 0.24527, loss: 0.24527, batch_cost: 0.61667s, reader_cost: 0.07031, ips: 103.78308 samples/s, eta: 5:14:54
[2022/06/19 01:06:06] ppcls INFO: [Train][Epoch 121/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05850679, top1: 0.91349, CELoss: 0.24230, loss: 0.24230, batch_cost: 0.61778s, reader_cost: 0.06563, ips: 103.59624 samples/s, eta: 5:15:22
[2022/06/19 01:06:17] ppcls INFO: [Train][Epoch 121/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05848050, top1: 0.91343, CELoss: 0.24195, loss: 0.24195, batch_cost: 0.64887s, reader_cost: 0.09503, ips: 98.63252 samples/s, eta: 5:31:08
[2022/06/19 01:06:19] ppcls INFO: [Train][Epoch 121/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05845421, top1: 0.91280, CELoss: 0.24365, loss: 0.24365, batch_cost: 0.62320s, reader_cost: 0.08933, ips: 78.62693 samples/s, eta: 5:17:56
[2022/06/19 01:06:20] ppcls INFO: [Train][Epoch 121/300][Avg]top1: 0.91280, CELoss: 0.24365, loss: 0.24365
[2022/06/19 01:06:20] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:06:27] ppcls INFO: [Train][Epoch 122/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05845158, top1: 0.92188, CELoss: 0.21936, loss: 0.21936, batch_cost: 0.66281s, reader_cost: 0.12795, ips: 96.55881 samples/s, eta: 5:38:07
[2022/06/19 01:06:34] ppcls INFO: [Train][Epoch 122/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05842528, top1: 0.91619, CELoss: 0.23875, loss: 0.23875, batch_cost: 0.63642s, reader_cost: 0.00731, ips: 100.56208 samples/s, eta: 5:24:33
[2022/06/19 01:06:39] ppcls INFO: [Train][Epoch 122/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05839897, top1: 0.91295, CELoss: 0.25069, loss: 0.25069, batch_cost: 0.60164s, reader_cost: 0.01762, ips: 106.37596 samples/s, eta: 5:06:43
[2022/06/19 01:06:46] ppcls INFO: [Train][Epoch 122/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05837266, top1: 0.91331, CELoss: 0.23969, loss: 0.23969, batch_cost: 0.60861s, reader_cost: 0.02724, ips: 105.15745 samples/s, eta: 5:10:10
[2022/06/19 01:06:53] ppcls INFO: [Train][Epoch 122/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05834634, top1: 0.91197, CELoss: 0.24282, loss: 0.24282, batch_cost: 0.64689s, reader_cost: 0.02802, ips: 98.93451 samples/s, eta: 5:29:34
[2022/06/19 01:06:59] ppcls INFO: [Train][Epoch 122/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05832002, top1: 0.91207, CELoss: 0.24176, loss: 0.24176, batch_cost: 0.63230s, reader_cost: 0.02500, ips: 101.21775 samples/s, eta: 5:22:02
[2022/06/19 01:07:05] ppcls INFO: [Train][Epoch 122/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05829370, top1: 0.91137, CELoss: 0.24053, loss: 0.24053, batch_cost: 0.62475s, reader_cost: 0.02536, ips: 102.44047 samples/s, eta: 5:18:05
[2022/06/19 01:07:11] ppcls INFO: [Train][Epoch 122/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05826737, top1: 0.91153, CELoss: 0.24064, loss: 0.24064, batch_cost: 0.62102s, reader_cost: 0.02453, ips: 103.05668 samples/s, eta: 5:16:05
[2022/06/19 01:07:16] ppcls INFO: [Train][Epoch 122/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05824103, top1: 0.91184, CELoss: 0.23970, loss: 0.23970, batch_cost: 0.61290s, reader_cost: 0.02298, ips: 104.42203 samples/s, eta: 5:11:51
[2022/06/19 01:07:23] ppcls INFO: [Train][Epoch 122/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05821469, top1: 0.91106, CELoss: 0.24140, loss: 0.24140, batch_cost: 0.61834s, reader_cost: 0.02126, ips: 103.50364 samples/s, eta: 5:14:30
[2022/06/19 01:07:29] ppcls INFO: [Train][Epoch 122/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05818835, top1: 0.91182, CELoss: 0.24214, loss: 0.24214, batch_cost: 0.61858s, reader_cost: 0.02079, ips: 103.46310 samples/s, eta: 5:14:32
[2022/06/19 01:07:35] ppcls INFO: [Train][Epoch 122/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05816200, top1: 0.91273, CELoss: 0.23972, loss: 0.23972, batch_cost: 0.61690s, reader_cost: 0.01991, ips: 103.74479 samples/s, eta: 5:13:34
[2022/06/19 01:07:42] ppcls INFO: [Train][Epoch 122/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05813564, top1: 0.91400, CELoss: 0.23817, loss: 0.23817, batch_cost: 0.62225s, reader_cost: 0.01938, ips: 102.85210 samples/s, eta: 5:16:11
[2022/06/19 01:07:47] ppcls INFO: [Train][Epoch 122/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05810928, top1: 0.91448, CELoss: 0.23692, loss: 0.23692, batch_cost: 0.61348s, reader_cost: 0.01876, ips: 104.32253 samples/s, eta: 5:11:38
[2022/06/19 01:07:53] ppcls INFO: [Train][Epoch 122/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05808292, top1: 0.91412, CELoss: 0.23767, loss: 0.23767, batch_cost: 0.61081s, reader_cost: 0.01876, ips: 104.77862 samples/s, eta: 5:10:10
[2022/06/19 01:07:58] ppcls INFO: [Train][Epoch 122/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05805655, top1: 0.91318, CELoss: 0.24160, loss: 0.24160, batch_cost: 0.60527s, reader_cost: 0.01791, ips: 105.73798 samples/s, eta: 5:07:15
[2022/06/19 01:08:05] ppcls INFO: [Train][Epoch 122/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05803017, top1: 0.91266, CELoss: 0.24295, loss: 0.24295, batch_cost: 0.60935s, reader_cost: 0.01697, ips: 105.02977 samples/s, eta: 5:09:14
[2022/06/19 01:08:07] ppcls INFO: [Train][Epoch 122/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05800379, top1: 0.91225, CELoss: 0.24567, loss: 0.24567, batch_cost: 0.58586s, reader_cost: 0.01597, ips: 83.63775 samples/s, eta: 4:57:12
[2022/06/19 01:08:07] ppcls INFO: [Train][Epoch 122/300][Avg]top1: 0.91225, CELoss: 0.24567, loss: 0.24567
[2022/06/19 01:08:08] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:08:14] ppcls INFO: [Train][Epoch 123/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05800115, top1: 0.98438, CELoss: 0.08960, loss: 0.08960, batch_cost: 0.61979s, reader_cost: 0.04311, ips: 103.26044 samples/s, eta: 5:14:25
[2022/06/19 01:08:20] ppcls INFO: [Train][Epoch 123/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05797477, top1: 0.93040, CELoss: 0.20856, loss: 0.20856, batch_cost: 0.58178s, reader_cost: 0.00222, ips: 110.00696 samples/s, eta: 4:55:02
[2022/06/19 01:08:28] ppcls INFO: [Train][Epoch 123/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05794838, top1: 0.92336, CELoss: 0.21575, loss: 0.21575, batch_cost: 0.68720s, reader_cost: 0.00151, ips: 93.13173 samples/s, eta: 5:48:23
[2022/06/19 01:08:33] ppcls INFO: [Train][Epoch 123/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05792198, top1: 0.92440, CELoss: 0.21516, loss: 0.21516, batch_cost: 0.63705s, reader_cost: 0.00470, ips: 100.46326 samples/s, eta: 5:22:51
[2022/06/19 01:08:40] ppcls INFO: [Train][Epoch 123/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05789559, top1: 0.92073, CELoss: 0.22187, loss: 0.22187, batch_cost: 0.64677s, reader_cost: 0.00361, ips: 98.95297 samples/s, eta: 5:27:40
[2022/06/19 01:08:46] ppcls INFO: [Train][Epoch 123/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05786918, top1: 0.91820, CELoss: 0.22968, loss: 0.22968, batch_cost: 0.63655s, reader_cost: 0.00759, ips: 100.54138 samples/s, eta: 5:22:23
[2022/06/19 01:08:52] ppcls INFO: [Train][Epoch 123/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05784277, top1: 0.91496, CELoss: 0.23824, loss: 0.23824, batch_cost: 0.63522s, reader_cost: 0.00799, ips: 100.75322 samples/s, eta: 5:21:36
[2022/06/19 01:08:58] ppcls INFO: [Train][Epoch 123/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05781636, top1: 0.91593, CELoss: 0.23655, loss: 0.23655, batch_cost: 0.62550s, reader_cost: 0.00805, ips: 102.31734 samples/s, eta: 5:16:35
[2022/06/19 01:09:04] ppcls INFO: [Train][Epoch 123/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05778994, top1: 0.91744, CELoss: 0.23745, loss: 0.23745, batch_cost: 0.62982s, reader_cost: 0.01042, ips: 101.61670 samples/s, eta: 5:18:40
[2022/06/19 01:09:10] ppcls INFO: [Train][Epoch 123/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05776351, top1: 0.91672, CELoss: 0.23726, loss: 0.23726, batch_cost: 0.62192s, reader_cost: 0.00988, ips: 102.90638 samples/s, eta: 5:14:34
[2022/06/19 01:09:17] ppcls INFO: [Train][Epoch 123/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05773709, top1: 0.91801, CELoss: 0.23400, loss: 0.23400, batch_cost: 0.62793s, reader_cost: 0.01610, ips: 101.92155 samples/s, eta: 5:17:30
[2022/06/19 01:09:24] ppcls INFO: [Train][Epoch 123/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05771065, top1: 0.91582, CELoss: 0.23992, loss: 0.23992, batch_cost: 0.63360s, reader_cost: 0.01493, ips: 101.00974 samples/s, eta: 5:20:15
[2022/06/19 01:09:28] ppcls INFO: [Train][Epoch 123/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05768421, top1: 0.91555, CELoss: 0.23804, loss: 0.23804, batch_cost: 0.62045s, reader_cost: 0.01474, ips: 103.15045 samples/s, eta: 5:13:30
[2022/06/19 01:09:35] ppcls INFO: [Train][Epoch 123/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05765777, top1: 0.91567, CELoss: 0.23686, loss: 0.23686, batch_cost: 0.62449s, reader_cost: 0.01370, ips: 102.48387 samples/s, eta: 5:15:26
[2022/06/19 01:09:42] ppcls INFO: [Train][Epoch 123/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05763132, top1: 0.91578, CELoss: 0.23764, loss: 0.23764, batch_cost: 0.62550s, reader_cost: 0.01274, ips: 102.31784 samples/s, eta: 5:15:51
[2022/06/19 01:09:48] ppcls INFO: [Train][Epoch 123/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05760487, top1: 0.91484, CELoss: 0.24034, loss: 0.24034, batch_cost: 0.62502s, reader_cost: 0.01194, ips: 102.39691 samples/s, eta: 5:15:30
[2022/06/19 01:09:53] ppcls INFO: [Train][Epoch 123/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05757842, top1: 0.91576, CELoss: 0.23931, loss: 0.23931, batch_cost: 0.61983s, reader_cost: 0.01190, ips: 103.25396 samples/s, eta: 5:12:47
[2022/06/19 01:09:55] ppcls INFO: [Train][Epoch 123/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05755195, top1: 0.91582, CELoss: 0.23951, loss: 0.23951, batch_cost: 0.59571s, reader_cost: 0.01121, ips: 82.25515 samples/s, eta: 5:00:30
[2022/06/19 01:09:56] ppcls INFO: [Train][Epoch 123/300][Avg]top1: 0.91582, CELoss: 0.23951, loss: 0.23951
[2022/06/19 01:09:56] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:10:02] ppcls INFO: [Train][Epoch 124/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05754931, top1: 0.96875, CELoss: 0.10200, loss: 0.10200, batch_cost: 0.62586s, reader_cost: 0.03232, ips: 102.25984 samples/s, eta: 5:15:42
[2022/06/19 01:10:10] ppcls INFO: [Train][Epoch 124/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05752284, top1: 0.94460, CELoss: 0.19156, loss: 0.19156, batch_cost: 0.86400s, reader_cost: 0.02195, ips: 74.07400 samples/s, eta: 7:15:42
[2022/06/19 01:10:17] ppcls INFO: [Train][Epoch 124/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05749637, top1: 0.93601, CELoss: 0.19552, loss: 0.19552, batch_cost: 0.74257s, reader_cost: 0.01567, ips: 86.18695 samples/s, eta: 6:14:20
[2022/06/19 01:10:22] ppcls INFO: [Train][Epoch 124/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05746989, top1: 0.93044, CELoss: 0.20837, loss: 0.20837, batch_cost: 0.65849s, reader_cost: 0.01362, ips: 97.19162 samples/s, eta: 5:31:50
[2022/06/19 01:10:28] ppcls INFO: [Train][Epoch 124/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05744341, top1: 0.92454, CELoss: 0.21551, loss: 0.21551, batch_cost: 0.63915s, reader_cost: 0.01430, ips: 100.13221 samples/s, eta: 5:21:59
[2022/06/19 01:10:34] ppcls INFO: [Train][Epoch 124/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05741693, top1: 0.92310, CELoss: 0.22214, loss: 0.22214, batch_cost: 0.62118s, reader_cost: 0.01441, ips: 103.02910 samples/s, eta: 5:12:50
[2022/06/19 01:10:39] ppcls INFO: [Train][Epoch 124/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05739044, top1: 0.92264, CELoss: 0.22355, loss: 0.22355, batch_cost: 0.60878s, reader_cost: 0.01451, ips: 105.12876 samples/s, eta: 5:06:29
[2022/06/19 01:10:46] ppcls INFO: [Train][Epoch 124/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05736394, top1: 0.92386, CELoss: 0.22190, loss: 0.22190, batch_cost: 0.61220s, reader_cost: 0.01568, ips: 104.54147 samples/s, eta: 5:08:06
[2022/06/19 01:10:53] ppcls INFO: [Train][Epoch 124/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05733744, top1: 0.92458, CELoss: 0.22272, loss: 0.22272, batch_cost: 0.62462s, reader_cost: 0.01514, ips: 102.46219 samples/s, eta: 5:14:15
[2022/06/19 01:10:59] ppcls INFO: [Train][Epoch 124/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05731094, top1: 0.92222, CELoss: 0.22299, loss: 0.22299, batch_cost: 0.62091s, reader_cost: 0.01635, ips: 103.07490 samples/s, eta: 5:12:17
[2022/06/19 01:11:05] ppcls INFO: [Train][Epoch 124/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05728443, top1: 0.92141, CELoss: 0.22286, loss: 0.22286, batch_cost: 0.62276s, reader_cost: 0.01631, ips: 102.76908 samples/s, eta: 5:13:06
[2022/06/19 01:11:12] ppcls INFO: [Train][Epoch 124/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05725791, top1: 0.92145, CELoss: 0.22215, loss: 0.22215, batch_cost: 0.63184s, reader_cost: 0.01609, ips: 101.29179 samples/s, eta: 5:17:34
[2022/06/19 01:11:17] ppcls INFO: [Train][Epoch 124/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05723140, top1: 0.92123, CELoss: 0.22134, loss: 0.22134, batch_cost: 0.62048s, reader_cost: 0.01583, ips: 103.14589 samples/s, eta: 5:11:45
[2022/06/19 01:11:23] ppcls INFO: [Train][Epoch 124/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05720487, top1: 0.92080, CELoss: 0.22203, loss: 0.22203, batch_cost: 0.61485s, reader_cost: 0.01561, ips: 104.09042 samples/s, eta: 5:08:49
[2022/06/19 01:11:28] ppcls INFO: [Train][Epoch 124/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05717835, top1: 0.92055, CELoss: 0.22302, loss: 0.22302, batch_cost: 0.60932s, reader_cost: 0.01539, ips: 105.03469 samples/s, eta: 5:05:57
[2022/06/19 01:11:35] ppcls INFO: [Train][Epoch 124/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05715181, top1: 0.91950, CELoss: 0.22900, loss: 0.22900, batch_cost: 0.61830s, reader_cost: 0.01446, ips: 103.50920 samples/s, eta: 5:10:21
[2022/06/19 01:11:40] ppcls INFO: [Train][Epoch 124/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05712528, top1: 0.91887, CELoss: 0.23141, loss: 0.23141, batch_cost: 0.60943s, reader_cost: 0.01358, ips: 105.01678 samples/s, eta: 5:05:48
[2022/06/19 01:11:42] ppcls INFO: [Train][Epoch 124/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05709874, top1: 0.91829, CELoss: 0.23223, loss: 0.23223, batch_cost: 0.58548s, reader_cost: 0.01277, ips: 83.69184 samples/s, eta: 4:53:41
[2022/06/19 01:11:43] ppcls INFO: [Train][Epoch 124/300][Avg]top1: 0.91829, CELoss: 0.23223, loss: 0.23223
[2022/06/19 01:11:43] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:11:49] ppcls INFO: [Train][Epoch 125/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05709608, top1: 0.90625, CELoss: 0.22897, loss: 0.22897, batch_cost: 0.61798s, reader_cost: 0.03788, ips: 103.56355 samples/s, eta: 5:09:58
[2022/06/19 01:11:57] ppcls INFO: [Train][Epoch 125/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05706954, top1: 0.93750, CELoss: 0.21201, loss: 0.21201, batch_cost: 0.79945s, reader_cost: 0.00032, ips: 80.05545 samples/s, eta: 6:40:52
[2022/06/19 01:12:02] ppcls INFO: [Train][Epoch 125/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05704299, top1: 0.92485, CELoss: 0.23445, loss: 0.23445, batch_cost: 0.64440s, reader_cost: 0.01492, ips: 99.31744 samples/s, eta: 5:23:00
[2022/06/19 01:12:09] ppcls INFO: [Train][Epoch 125/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05701643, top1: 0.92540, CELoss: 0.22235, loss: 0.22235, batch_cost: 0.64591s, reader_cost: 0.01503, ips: 99.08537 samples/s, eta: 5:23:39
[2022/06/19 01:12:15] ppcls INFO: [Train][Epoch 125/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05698987, top1: 0.91921, CELoss: 0.23054, loss: 0.23054, batch_cost: 0.63660s, reader_cost: 0.01674, ips: 100.53485 samples/s, eta: 5:18:53
[2022/06/19 01:12:21] ppcls INFO: [Train][Epoch 125/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05696331, top1: 0.92371, CELoss: 0.22308, loss: 0.22308, batch_cost: 0.62245s, reader_cost: 0.01754, ips: 102.81965 samples/s, eta: 5:11:42
[2022/06/19 01:12:26] ppcls INFO: [Train][Epoch 125/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05693674, top1: 0.92290, CELoss: 0.23095, loss: 0.23095, batch_cost: 0.60942s, reader_cost: 0.01668, ips: 105.01760 samples/s, eta: 5:05:04
[2022/06/19 01:12:31] ppcls INFO: [Train][Epoch 125/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05691017, top1: 0.92188, CELoss: 0.23136, loss: 0.23136, batch_cost: 0.59411s, reader_cost: 0.01791, ips: 107.72469 samples/s, eta: 4:57:18
[2022/06/19 01:12:38] ppcls INFO: [Train][Epoch 125/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05688359, top1: 0.92265, CELoss: 0.22798, loss: 0.22798, batch_cost: 0.61338s, reader_cost: 0.01688, ips: 104.34008 samples/s, eta: 5:06:51
[2022/06/19 01:12:44] ppcls INFO: [Train][Epoch 125/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05685701, top1: 0.92205, CELoss: 0.23104, loss: 0.23104, batch_cost: 0.60708s, reader_cost: 0.01526, ips: 105.42187 samples/s, eta: 5:03:36
[2022/06/19 01:12:51] ppcls INFO: [Train][Epoch 125/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05683042, top1: 0.92172, CELoss: 0.23072, loss: 0.23072, batch_cost: 0.61554s, reader_cost: 0.01489, ips: 103.97317 samples/s, eta: 5:07:43
[2022/06/19 01:12:56] ppcls INFO: [Train][Epoch 125/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05680383, top1: 0.92117, CELoss: 0.23040, loss: 0.23040, batch_cost: 0.60683s, reader_cost: 0.01453, ips: 105.46594 samples/s, eta: 5:03:16
[2022/06/19 01:13:03] ppcls INFO: [Train][Epoch 125/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05677724, top1: 0.91955, CELoss: 0.23315, loss: 0.23315, batch_cost: 0.61231s, reader_cost: 0.01469, ips: 104.52292 samples/s, eta: 5:05:54
[2022/06/19 01:13:09] ppcls INFO: [Train][Epoch 125/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05675064, top1: 0.92032, CELoss: 0.23083, loss: 0.23083, batch_cost: 0.61263s, reader_cost: 0.01377, ips: 104.46725 samples/s, eta: 5:05:58
[2022/06/19 01:13:15] ppcls INFO: [Train][Epoch 125/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05672403, top1: 0.92021, CELoss: 0.23184, loss: 0.23184, batch_cost: 0.60799s, reader_cost: 0.01299, ips: 105.26560 samples/s, eta: 5:03:32
[2022/06/19 01:13:22] ppcls INFO: [Train][Epoch 125/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05669743, top1: 0.91970, CELoss: 0.23193, loss: 0.23193, batch_cost: 0.61660s, reader_cost: 0.02781, ips: 103.79510 samples/s, eta: 5:07:44
[2022/06/19 01:13:30] ppcls INFO: [Train][Epoch 125/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05667081, top1: 0.91828, CELoss: 0.23360, loss: 0.23360, batch_cost: 0.62665s, reader_cost: 0.02623, ips: 102.13072 samples/s, eta: 5:12:39
[2022/06/19 01:13:32] ppcls INFO: [Train][Epoch 125/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05664420, top1: 0.91884, CELoss: 0.23240, loss: 0.23240, batch_cost: 0.60157s, reader_cost: 0.02473, ips: 81.45314 samples/s, eta: 5:00:02
[2022/06/19 01:13:32] ppcls INFO: [Train][Epoch 125/300][Avg]top1: 0.91884, CELoss: 0.23240, loss: 0.23240
[2022/06/19 01:13:39] ppcls INFO: [Eval][Epoch 125][Iter: 0/16]CELoss: 0.95546, loss: 0.95546, top1: 0.77344, batch_cost: 6.60888s, reader_cost: 3.51048, ips: 9.68395 images/sec
[2022/06/19 01:13:47] ppcls INFO: [Eval][Epoch 125][Iter: 10/16]CELoss: 0.75138, loss: 0.75138, top1: 0.78817, batch_cost: 0.61328s, reader_cost: 0.00403, ips: 104.35725 images/sec
[2022/06/19 01:13:49] ppcls INFO: [Eval][Epoch 125][Avg]CELoss: 0.71277, loss: 0.71277, top1: 0.79608
[2022/06/19 01:13:49] ppcls INFO: [Eval][Epoch 125][best metric: 0.7990196347236633]
[2022/06/19 01:13:49] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:13:56] ppcls INFO: [Train][Epoch 126/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05664153, top1: 0.89062, CELoss: 0.30439, loss: 0.30439, batch_cost: 0.63737s, reader_cost: 0.05369, ips: 100.41324 samples/s, eta: 5:17:53
[2022/06/19 01:14:02] ppcls INFO: [Train][Epoch 126/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05661491, top1: 0.91051, CELoss: 0.24774, loss: 0.24774, batch_cost: 0.71787s, reader_cost: 0.01731, ips: 89.15244 samples/s, eta: 5:57:55
[2022/06/19 01:14:10] ppcls INFO: [Train][Epoch 126/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05658829, top1: 0.91369, CELoss: 0.23218, loss: 0.23218, batch_cost: 0.71352s, reader_cost: 0.01347, ips: 89.69644 samples/s, eta: 5:55:37
[2022/06/19 01:14:15] ppcls INFO: [Train][Epoch 126/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05656165, top1: 0.91532, CELoss: 0.23283, loss: 0.23283, batch_cost: 0.65336s, reader_cost: 0.01270, ips: 97.95561 samples/s, eta: 5:25:32
[2022/06/19 01:14:22] ppcls INFO: [Train][Epoch 126/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05653502, top1: 0.91463, CELoss: 0.23743, loss: 0.23743, batch_cost: 0.66106s, reader_cost: 0.01285, ips: 96.81434 samples/s, eta: 5:29:15
[2022/06/19 01:14:28] ppcls INFO: [Train][Epoch 126/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05650838, top1: 0.91850, CELoss: 0.22829, loss: 0.22829, batch_cost: 0.63916s, reader_cost: 0.01472, ips: 100.13201 samples/s, eta: 5:18:14
[2022/06/19 01:14:33] ppcls INFO: [Train][Epoch 126/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05648174, top1: 0.91547, CELoss: 0.23429, loss: 0.23429, batch_cost: 0.62638s, reader_cost: 0.01432, ips: 102.17502 samples/s, eta: 5:11:46
[2022/06/19 01:14:39] ppcls INFO: [Train][Epoch 126/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05645509, top1: 0.91505, CELoss: 0.23815, loss: 0.23815, batch_cost: 0.61345s, reader_cost: 0.01566, ips: 104.32809 samples/s, eta: 5:05:14
[2022/06/19 01:14:45] ppcls INFO: [Train][Epoch 126/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05642844, top1: 0.91628, CELoss: 0.23512, loss: 0.23512, batch_cost: 0.62322s, reader_cost: 0.01576, ips: 102.69312 samples/s, eta: 5:09:59
[2022/06/19 01:14:53] ppcls INFO: [Train][Epoch 126/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05640178, top1: 0.91501, CELoss: 0.23709, loss: 0.23709, batch_cost: 0.63337s, reader_cost: 0.01542, ips: 101.04655 samples/s, eta: 5:14:56
[2022/06/19 01:14:58] ppcls INFO: [Train][Epoch 126/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05637512, top1: 0.91275, CELoss: 0.24212, loss: 0.24212, batch_cost: 0.62373s, reader_cost: 0.01583, ips: 102.60917 samples/s, eta: 5:10:02
[2022/06/19 01:15:04] ppcls INFO: [Train][Epoch 126/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05634845, top1: 0.91132, CELoss: 0.24435, loss: 0.24435, batch_cost: 0.62054s, reader_cost: 0.01498, ips: 103.13630 samples/s, eta: 5:08:21
[2022/06/19 01:15:10] ppcls INFO: [Train][Epoch 126/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05632179, top1: 0.91258, CELoss: 0.24168, loss: 0.24168, batch_cost: 0.61948s, reader_cost: 0.01452, ips: 103.31223 samples/s, eta: 5:07:43
[2022/06/19 01:15:16] ppcls INFO: [Train][Epoch 126/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05629511, top1: 0.91245, CELoss: 0.24166, loss: 0.24166, batch_cost: 0.62126s, reader_cost: 0.01521, ips: 103.01614 samples/s, eta: 5:08:30
[2022/06/19 01:15:22] ppcls INFO: [Train][Epoch 126/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05626843, top1: 0.91234, CELoss: 0.24107, loss: 0.24107, batch_cost: 0.61905s, reader_cost: 0.01457, ips: 103.38493 samples/s, eta: 5:07:18
[2022/06/19 01:15:28] ppcls INFO: [Train][Epoch 126/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05624175, top1: 0.91215, CELoss: 0.24192, loss: 0.24192, batch_cost: 0.61293s, reader_cost: 0.01448, ips: 104.41669 samples/s, eta: 5:04:09
[2022/06/19 01:15:33] ppcls INFO: [Train][Epoch 126/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05621507, top1: 0.91207, CELoss: 0.24179, loss: 0.24179, batch_cost: 0.60848s, reader_cost: 0.01478, ips: 105.18004 samples/s, eta: 5:01:51
[2022/06/19 01:15:35] ppcls INFO: [Train][Epoch 126/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05618838, top1: 0.91280, CELoss: 0.24149, loss: 0.24149, batch_cost: 0.58455s, reader_cost: 0.01390, ips: 83.82446 samples/s, eta: 4:49:53
[2022/06/19 01:15:36] ppcls INFO: [Train][Epoch 126/300][Avg]top1: 0.91280, CELoss: 0.24149, loss: 0.24149
[2022/06/19 01:15:36] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:15:43] ppcls INFO: [Train][Epoch 127/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05618571, top1: 0.93750, CELoss: 0.16655, loss: 0.16655, batch_cost: 0.62272s, reader_cost: 0.04109, ips: 102.77498 samples/s, eta: 5:08:48
[2022/06/19 01:15:50] ppcls INFO: [Train][Epoch 127/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05615901, top1: 0.91335, CELoss: 0.24487, loss: 0.24487, batch_cost: 0.80000s, reader_cost: 0.00234, ips: 79.99976 samples/s, eta: 6:36:35
[2022/06/19 01:15:56] ppcls INFO: [Train][Epoch 127/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05613231, top1: 0.91667, CELoss: 0.22915, loss: 0.22915, batch_cost: 0.65082s, reader_cost: 0.01566, ips: 98.33721 samples/s, eta: 5:22:31
[2022/06/19 01:16:02] ppcls INFO: [Train][Epoch 127/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05610561, top1: 0.92036, CELoss: 0.22527, loss: 0.22527, batch_cost: 0.64557s, reader_cost: 0.01791, ips: 99.13725 samples/s, eta: 5:19:48
[2022/06/19 01:16:08] ppcls INFO: [Train][Epoch 127/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05607890, top1: 0.91730, CELoss: 0.23435, loss: 0.23435, batch_cost: 0.62724s, reader_cost: 0.01512, ips: 102.03412 samples/s, eta: 5:10:37
[2022/06/19 01:16:14] ppcls INFO: [Train][Epoch 127/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05605219, top1: 0.91728, CELoss: 0.23617, loss: 0.23617, batch_cost: 0.61563s, reader_cost: 0.01650, ips: 103.95925 samples/s, eta: 5:04:46
[2022/06/19 01:16:20] ppcls INFO: [Train][Epoch 127/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05602547, top1: 0.91778, CELoss: 0.23230, loss: 0.23230, batch_cost: 0.61592s, reader_cost: 0.01694, ips: 103.90988 samples/s, eta: 5:04:49
[2022/06/19 01:16:26] ppcls INFO: [Train][Epoch 127/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05599875, top1: 0.91593, CELoss: 0.23265, loss: 0.23265, batch_cost: 0.61348s, reader_cost: 0.01672, ips: 104.32212 samples/s, eta: 5:03:30
[2022/06/19 01:16:31] ppcls INFO: [Train][Epoch 127/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05597203, top1: 0.91647, CELoss: 0.23274, loss: 0.23274, batch_cost: 0.60366s, reader_cost: 0.01556, ips: 106.01938 samples/s, eta: 4:58:33
[2022/06/19 01:16:37] ppcls INFO: [Train][Epoch 127/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05594530, top1: 0.91604, CELoss: 0.23531, loss: 0.23531, batch_cost: 0.60556s, reader_cost: 0.01583, ips: 105.68753 samples/s, eta: 4:59:23
[2022/06/19 01:16:43] ppcls INFO: [Train][Epoch 127/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05591857, top1: 0.91692, CELoss: 0.23627, loss: 0.23627, batch_cost: 0.60412s, reader_cost: 0.01458, ips: 105.93850 samples/s, eta: 4:58:34
[2022/06/19 01:16:49] ppcls INFO: [Train][Epoch 127/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05589183, top1: 0.91596, CELoss: 0.23665, loss: 0.23665, batch_cost: 0.60173s, reader_cost: 0.01380, ips: 106.35974 samples/s, eta: 4:57:17
[2022/06/19 01:16:55] ppcls INFO: [Train][Epoch 127/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05586509, top1: 0.91684, CELoss: 0.23595, loss: 0.23595, batch_cost: 0.59988s, reader_cost: 0.01415, ips: 106.68846 samples/s, eta: 4:56:16
[2022/06/19 01:17:01] ppcls INFO: [Train][Epoch 127/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05583835, top1: 0.91687, CELoss: 0.23611, loss: 0.23611, batch_cost: 0.59996s, reader_cost: 0.01476, ips: 106.67395 samples/s, eta: 4:56:13
[2022/06/19 01:17:07] ppcls INFO: [Train][Epoch 127/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05581160, top1: 0.91656, CELoss: 0.23501, loss: 0.23501, batch_cost: 0.60459s, reader_cost: 0.02353, ips: 105.85763 samples/s, eta: 4:58:24
[2022/06/19 01:17:14] ppcls INFO: [Train][Epoch 127/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05578485, top1: 0.91753, CELoss: 0.23262, loss: 0.23262, batch_cost: 0.60684s, reader_cost: 0.03664, ips: 105.46357 samples/s, eta: 4:59:25
[2022/06/19 01:17:22] ppcls INFO: [Train][Epoch 127/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05575809, top1: 0.91722, CELoss: 0.23329, loss: 0.23329, batch_cost: 0.62229s, reader_cost: 0.06320, ips: 102.84636 samples/s, eta: 5:06:55
[2022/06/19 01:17:24] ppcls INFO: [Train][Epoch 127/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05573133, top1: 0.91792, CELoss: 0.23201, loss: 0.23201, batch_cost: 0.59761s, reader_cost: 0.05941, ips: 81.99351 samples/s, eta: 4:54:39
[2022/06/19 01:17:25] ppcls INFO: [Train][Epoch 127/300][Avg]top1: 0.91792, CELoss: 0.23201, loss: 0.23201
[2022/06/19 01:17:25] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:17:31] ppcls INFO: [Train][Epoch 128/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05572865, top1: 0.90625, CELoss: 0.32946, loss: 0.32946, batch_cost: 0.62942s, reader_cost: 0.08376, ips: 101.68099 samples/s, eta: 5:10:20
[2022/06/19 01:17:38] ppcls INFO: [Train][Epoch 128/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05570189, top1: 0.91761, CELoss: 0.23063, loss: 0.23063, batch_cost: 0.56232s, reader_cost: 0.00032, ips: 113.81331 samples/s, eta: 4:37:09
[2022/06/19 01:17:44] ppcls INFO: [Train][Epoch 128/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05567512, top1: 0.92560, CELoss: 0.20906, loss: 0.20906, batch_cost: 0.61781s, reader_cost: 0.00460, ips: 103.59176 samples/s, eta: 5:04:24
[2022/06/19 01:17:50] ppcls INFO: [Train][Epoch 128/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05564835, top1: 0.92137, CELoss: 0.21097, loss: 0.21097, batch_cost: 0.60703s, reader_cost: 0.00883, ips: 105.43205 samples/s, eta: 4:58:59
[2022/06/19 01:17:56] ppcls INFO: [Train][Epoch 128/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05562157, top1: 0.92111, CELoss: 0.21206, loss: 0.21206, batch_cost: 0.61040s, reader_cost: 0.01097, ips: 104.84964 samples/s, eta: 5:00:32
[2022/06/19 01:18:03] ppcls INFO: [Train][Epoch 128/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05559479, top1: 0.92004, CELoss: 0.21669, loss: 0.21669, batch_cost: 0.60844s, reader_cost: 0.00865, ips: 105.18672 samples/s, eta: 4:59:29
[2022/06/19 01:18:09] ppcls INFO: [Train][Epoch 128/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05556800, top1: 0.92034, CELoss: 0.21717, loss: 0.21717, batch_cost: 0.60992s, reader_cost: 0.00738, ips: 104.93239 samples/s, eta: 5:00:06
[2022/06/19 01:18:17] ppcls INFO: [Train][Epoch 128/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05554121, top1: 0.92055, CELoss: 0.21927, loss: 0.21927, batch_cost: 0.64987s, reader_cost: 0.00655, ips: 98.48091 samples/s, eta: 5:19:39
[2022/06/19 01:18:21] ppcls INFO: [Train][Epoch 128/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05551442, top1: 0.92130, CELoss: 0.21624, loss: 0.21624, batch_cost: 0.61799s, reader_cost: 0.00590, ips: 103.56111 samples/s, eta: 5:03:52
[2022/06/19 01:18:27] ppcls INFO: [Train][Epoch 128/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05548762, top1: 0.92170, CELoss: 0.21903, loss: 0.21903, batch_cost: 0.61239s, reader_cost: 0.00545, ips: 104.50876 samples/s, eta: 5:01:01
[2022/06/19 01:18:33] ppcls INFO: [Train][Epoch 128/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05546082, top1: 0.91986, CELoss: 0.22418, loss: 0.22418, batch_cost: 0.60921s, reader_cost: 0.00618, ips: 105.05359 samples/s, eta: 4:59:21
[2022/06/19 01:18:40] ppcls INFO: [Train][Epoch 128/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05543402, top1: 0.91920, CELoss: 0.22550, loss: 0.22550, batch_cost: 0.61487s, reader_cost: 0.00662, ips: 104.08689 samples/s, eta: 5:02:02
[2022/06/19 01:18:45] ppcls INFO: [Train][Epoch 128/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05540721, top1: 0.92020, CELoss: 0.22323, loss: 0.22323, batch_cost: 0.60647s, reader_cost: 0.00720, ips: 105.52861 samples/s, eta: 4:57:48
[2022/06/19 01:18:51] ppcls INFO: [Train][Epoch 128/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05538040, top1: 0.92032, CELoss: 0.22393, loss: 0.22393, batch_cost: 0.60763s, reader_cost: 0.00726, ips: 105.32746 samples/s, eta: 4:58:16
[2022/06/19 01:18:58] ppcls INFO: [Train][Epoch 128/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05535358, top1: 0.91977, CELoss: 0.22700, loss: 0.22700, batch_cost: 0.61226s, reader_cost: 0.00699, ips: 104.53146 samples/s, eta: 5:00:26
[2022/06/19 01:19:03] ppcls INFO: [Train][Epoch 128/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05532676, top1: 0.91939, CELoss: 0.22770, loss: 0.22770, batch_cost: 0.60551s, reader_cost: 0.00653, ips: 105.69556 samples/s, eta: 4:57:02
[2022/06/19 01:19:09] ppcls INFO: [Train][Epoch 128/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05529993, top1: 0.91916, CELoss: 0.22816, loss: 0.22816, batch_cost: 0.60268s, reader_cost: 0.00621, ips: 106.19238 samples/s, eta: 4:55:32
[2022/06/19 01:19:13] ppcls INFO: [Train][Epoch 128/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05527311, top1: 0.91811, CELoss: 0.23211, loss: 0.23211, batch_cost: 0.59257s, reader_cost: 0.00592, ips: 82.69105 samples/s, eta: 4:50:29
[2022/06/19 01:19:13] ppcls INFO: [Train][Epoch 128/300][Avg]top1: 0.91811, CELoss: 0.23211, loss: 0.23211
[2022/06/19 01:19:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:19:20] ppcls INFO: [Train][Epoch 129/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05527042, top1: 0.96875, CELoss: 0.20645, loss: 0.20645, batch_cost: 0.62679s, reader_cost: 0.03891, ips: 102.10792 samples/s, eta: 5:07:15
[2022/06/19 01:19:27] ppcls INFO: [Train][Epoch 129/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05524359, top1: 0.93182, CELoss: 0.22138, loss: 0.22138, batch_cost: 0.68421s, reader_cost: 0.06548, ips: 93.53804 samples/s, eta: 5:35:17
[2022/06/19 01:19:33] ppcls INFO: [Train][Epoch 129/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05521675, top1: 0.92039, CELoss: 0.22846, loss: 0.22846, batch_cost: 0.62678s, reader_cost: 0.04463, ips: 102.10861 samples/s, eta: 5:07:02
[2022/06/19 01:19:39] ppcls INFO: [Train][Epoch 129/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05518991, top1: 0.92036, CELoss: 0.22314, loss: 0.22314, batch_cost: 0.63662s, reader_cost: 0.03439, ips: 100.53116 samples/s, eta: 5:11:45
[2022/06/19 01:19:46] ppcls INFO: [Train][Epoch 129/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05516307, top1: 0.91921, CELoss: 0.22554, loss: 0.22554, batch_cost: 0.64872s, reader_cost: 0.05609, ips: 98.65555 samples/s, eta: 5:17:34
[2022/06/19 01:19:52] ppcls INFO: [Train][Epoch 129/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05513622, top1: 0.91942, CELoss: 0.22472, loss: 0.22472, batch_cost: 0.62888s, reader_cost: 0.04645, ips: 101.76799 samples/s, eta: 5:07:45
[2022/06/19 01:19:57] ppcls INFO: [Train][Epoch 129/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05510937, top1: 0.91880, CELoss: 0.22931, loss: 0.22931, batch_cost: 0.61850s, reader_cost: 0.04273, ips: 103.47627 samples/s, eta: 5:02:34
[2022/06/19 01:20:03] ppcls INFO: [Train][Epoch 129/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05508252, top1: 0.92077, CELoss: 0.22646, loss: 0.22646, batch_cost: 0.61430s, reader_cost: 0.03709, ips: 104.18298 samples/s, eta: 5:00:24
[2022/06/19 01:20:10] ppcls INFO: [Train][Epoch 129/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05505566, top1: 0.92188, CELoss: 0.22604, loss: 0.22604, batch_cost: 0.62418s, reader_cost: 0.03776, ips: 102.53463 samples/s, eta: 5:05:08
[2022/06/19 01:20:16] ppcls INFO: [Train][Epoch 129/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05502879, top1: 0.92205, CELoss: 0.22744, loss: 0.22744, batch_cost: 0.62115s, reader_cost: 0.04362, ips: 103.03439 samples/s, eta: 5:03:33
[2022/06/19 01:20:22] ppcls INFO: [Train][Epoch 129/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05500193, top1: 0.92172, CELoss: 0.22851, loss: 0.22851, batch_cost: 0.61398s, reader_cost: 0.04085, ips: 104.23843 samples/s, eta: 4:59:56
[2022/06/19 01:20:28] ppcls INFO: [Train][Epoch 129/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05497506, top1: 0.92272, CELoss: 0.22728, loss: 0.22728, batch_cost: 0.61922s, reader_cost: 0.03733, ips: 103.35616 samples/s, eta: 5:02:24
[2022/06/19 01:20:35] ppcls INFO: [Train][Epoch 129/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05494818, top1: 0.92149, CELoss: 0.22885, loss: 0.22885, batch_cost: 0.62249s, reader_cost: 0.03519, ips: 102.81310 samples/s, eta: 5:03:53
[2022/06/19 01:20:40] ppcls INFO: [Train][Epoch 129/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05492131, top1: 0.92104, CELoss: 0.22978, loss: 0.22978, batch_cost: 0.61289s, reader_cost: 0.03362, ips: 104.42413 samples/s, eta: 4:59:06
[2022/06/19 01:20:46] ppcls INFO: [Train][Epoch 129/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05489442, top1: 0.92132, CELoss: 0.22756, loss: 0.22756, batch_cost: 0.61047s, reader_cost: 0.03152, ips: 104.83672 samples/s, eta: 4:57:49
[2022/06/19 01:20:52] ppcls INFO: [Train][Epoch 129/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05486754, top1: 0.92188, CELoss: 0.22741, loss: 0.22741, batch_cost: 0.61054s, reader_cost: 0.02965, ips: 104.82514 samples/s, eta: 4:57:45
[2022/06/19 01:20:57] ppcls INFO: [Train][Epoch 129/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05484065, top1: 0.92090, CELoss: 0.22789, loss: 0.22789, batch_cost: 0.60608s, reader_cost: 0.02863, ips: 105.59739 samples/s, eta: 4:55:28
[2022/06/19 01:20:59] ppcls INFO: [Train][Epoch 129/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05481376, top1: 0.91930, CELoss: 0.23195, loss: 0.23195, batch_cost: 0.58224s, reader_cost: 0.02697, ips: 84.15763 samples/s, eta: 4:43:45
[2022/06/19 01:21:00] ppcls INFO: [Train][Epoch 129/300][Avg]top1: 0.91930, CELoss: 0.23195, loss: 0.23195
[2022/06/19 01:21:00] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:21:06] ppcls INFO: [Train][Epoch 130/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05481107, top1: 0.90625, CELoss: 0.23342, loss: 0.23342, batch_cost: 0.61572s, reader_cost: 0.05659, ips: 103.94393 samples/s, eta: 5:00:04
[2022/06/19 01:21:13] ppcls INFO: [Train][Epoch 130/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05478417, top1: 0.92756, CELoss: 0.21555, loss: 0.21555, batch_cost: 0.63347s, reader_cost: 0.02842, ips: 101.03103 samples/s, eta: 5:08:36
[2022/06/19 01:21:19] ppcls INFO: [Train][Epoch 130/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05475727, top1: 0.92857, CELoss: 0.20364, loss: 0.20364, batch_cost: 0.62560s, reader_cost: 0.02823, ips: 102.30151 samples/s, eta: 5:04:40
[2022/06/19 01:21:26] ppcls INFO: [Train][Epoch 130/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05473037, top1: 0.92692, CELoss: 0.20792, loss: 0.20792, batch_cost: 0.64674s, reader_cost: 0.03040, ips: 98.95750 samples/s, eta: 5:14:51
[2022/06/19 01:21:31] ppcls INFO: [Train][Epoch 130/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05470346, top1: 0.92797, CELoss: 0.20209, loss: 0.20209, batch_cost: 0.62249s, reader_cost: 0.02997, ips: 102.81334 samples/s, eta: 5:02:57
[2022/06/19 01:21:38] ppcls INFO: [Train][Epoch 130/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05467655, top1: 0.92708, CELoss: 0.20235, loss: 0.20235, batch_cost: 0.63217s, reader_cost: 0.02806, ips: 101.23788 samples/s, eta: 5:07:33
[2022/06/19 01:21:44] ppcls INFO: [Train][Epoch 130/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05464963, top1: 0.92751, CELoss: 0.20351, loss: 0.20351, batch_cost: 0.62099s, reader_cost: 0.02555, ips: 103.06120 samples/s, eta: 5:02:01
[2022/06/19 01:21:50] ppcls INFO: [Train][Epoch 130/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05462271, top1: 0.92760, CELoss: 0.20932, loss: 0.20932, batch_cost: 0.62547s, reader_cost: 0.02286, ips: 102.32381 samples/s, eta: 5:04:05
[2022/06/19 01:21:56] ppcls INFO: [Train][Epoch 130/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05459579, top1: 0.92554, CELoss: 0.21492, loss: 0.21492, batch_cost: 0.62717s, reader_cost: 0.02066, ips: 102.04564 samples/s, eta: 5:04:48
[2022/06/19 01:22:02] ppcls INFO: [Train][Epoch 130/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05456887, top1: 0.92462, CELoss: 0.21768, loss: 0.21768, batch_cost: 0.62285s, reader_cost: 0.02085, ips: 102.75361 samples/s, eta: 5:02:36
[2022/06/19 01:22:08] ppcls INFO: [Train][Epoch 130/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05454194, top1: 0.92497, CELoss: 0.21871, loss: 0.21871, batch_cost: 0.61750s, reader_cost: 0.01982, ips: 103.64428 samples/s, eta: 4:59:54
[2022/06/19 01:22:15] ppcls INFO: [Train][Epoch 130/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05451500, top1: 0.92399, CELoss: 0.21980, loss: 0.21980, batch_cost: 0.62050s, reader_cost: 0.01922, ips: 103.14188 samples/s, eta: 5:01:15
[2022/06/19 01:22:21] ppcls INFO: [Train][Epoch 130/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05448807, top1: 0.92394, CELoss: 0.21939, loss: 0.21939, batch_cost: 0.62403s, reader_cost: 0.01875, ips: 102.55987 samples/s, eta: 5:02:52
[2022/06/19 01:22:27] ppcls INFO: [Train][Epoch 130/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05446113, top1: 0.92354, CELoss: 0.22170, loss: 0.22170, batch_cost: 0.61795s, reader_cost: 0.01916, ips: 103.56845 samples/s, eta: 4:59:49
[2022/06/19 01:22:33] ppcls INFO: [Train][Epoch 130/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05443418, top1: 0.92298, CELoss: 0.22454, loss: 0.22454, batch_cost: 0.62117s, reader_cost: 0.01808, ips: 103.03200 samples/s, eta: 5:01:16
[2022/06/19 01:22:40] ppcls INFO: [Train][Epoch 130/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05440724, top1: 0.92291, CELoss: 0.22538, loss: 0.22538, batch_cost: 0.62154s, reader_cost: 0.01976, ips: 102.96946 samples/s, eta: 5:01:21
[2022/06/19 01:22:44] ppcls INFO: [Train][Epoch 130/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05438028, top1: 0.92217, CELoss: 0.22895, loss: 0.22895, batch_cost: 0.60984s, reader_cost: 0.01853, ips: 104.94620 samples/s, eta: 4:55:34
[2022/06/19 01:22:46] ppcls INFO: [Train][Epoch 130/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05435333, top1: 0.92213, CELoss: 0.22809, loss: 0.22809, batch_cost: 0.58555s, reader_cost: 0.01744, ips: 83.68227 samples/s, eta: 4:43:42
[2022/06/19 01:22:47] ppcls INFO: [Train][Epoch 130/300][Avg]top1: 0.92213, CELoss: 0.22809, loss: 0.22809
[2022/06/19 01:22:54] ppcls INFO: [Eval][Epoch 130][Iter: 0/16]CELoss: 1.03706, loss: 1.03706, top1: 0.77148, batch_cost: 7.07515s, reader_cost: 3.18533, ips: 9.04574 images/sec
[2022/06/19 01:23:02] ppcls INFO: [Eval][Epoch 130][Iter: 10/16]CELoss: 0.87782, loss: 0.87782, top1: 0.78675, batch_cost: 0.59103s, reader_cost: 0.00122, ips: 108.28603 images/sec
[2022/06/19 01:23:03] ppcls INFO: [Eval][Epoch 130][Avg]CELoss: 0.80405, loss: 0.80405, top1: 0.79154
[2022/06/19 01:23:03] ppcls INFO: [Eval][Epoch 130][best metric: 0.7990196347236633]
[2022/06/19 01:23:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_130
[2022/06/19 01:23:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:23:09] ppcls INFO: [Train][Epoch 131/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05435064, top1: 0.95312, CELoss: 0.11795, loss: 0.11795, batch_cost: 0.61548s, reader_cost: 0.04535, ips: 103.98311 samples/s, eta: 4:58:12
[2022/06/19 01:23:16] ppcls INFO: [Train][Epoch 131/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05432368, top1: 0.91903, CELoss: 0.21380, loss: 0.21380, batch_cost: 0.65064s, reader_cost: 0.00845, ips: 98.36532 samples/s, eta: 5:15:07
[2022/06/19 01:23:23] ppcls INFO: [Train][Epoch 131/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05429672, top1: 0.90476, CELoss: 0.25241, loss: 0.25241, batch_cost: 0.64168s, reader_cost: 0.02199, ips: 99.73832 samples/s, eta: 5:10:40
[2022/06/19 01:23:29] ppcls INFO: [Train][Epoch 131/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05426975, top1: 0.90877, CELoss: 0.24747, loss: 0.24747, batch_cost: 0.63015s, reader_cost: 0.02079, ips: 101.56246 samples/s, eta: 5:04:59
[2022/06/19 01:23:35] ppcls INFO: [Train][Epoch 131/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05424278, top1: 0.91273, CELoss: 0.23830, loss: 0.23830, batch_cost: 0.64135s, reader_cost: 0.01867, ips: 99.78918 samples/s, eta: 5:10:18
[2022/06/19 01:23:41] ppcls INFO: [Train][Epoch 131/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05421581, top1: 0.91452, CELoss: 0.23652, loss: 0.23652, batch_cost: 0.61713s, reader_cost: 0.02152, ips: 103.70641 samples/s, eta: 4:58:29
[2022/06/19 01:23:47] ppcls INFO: [Train][Epoch 131/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05418883, top1: 0.91189, CELoss: 0.23822, loss: 0.23822, batch_cost: 0.61584s, reader_cost: 0.02014, ips: 103.92335 samples/s, eta: 4:57:45
[2022/06/19 01:23:53] ppcls INFO: [Train][Epoch 131/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05416186, top1: 0.91351, CELoss: 0.24092, loss: 0.24092, batch_cost: 0.61019s, reader_cost: 0.01901, ips: 104.88500 samples/s, eta: 4:54:55
[2022/06/19 01:23:59] ppcls INFO: [Train][Epoch 131/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05413487, top1: 0.91590, CELoss: 0.23630, loss: 0.23630, batch_cost: 0.60781s, reader_cost: 0.01827, ips: 105.29625 samples/s, eta: 4:53:40
[2022/06/19 01:24:05] ppcls INFO: [Train][Epoch 131/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05410789, top1: 0.91775, CELoss: 0.23210, loss: 0.23210, batch_cost: 0.60789s, reader_cost: 0.01676, ips: 105.28201 samples/s, eta: 4:53:36
[2022/06/19 01:24:12] ppcls INFO: [Train][Epoch 131/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05408090, top1: 0.91770, CELoss: 0.23163, loss: 0.23163, batch_cost: 0.61652s, reader_cost: 0.01535, ips: 103.80824 samples/s, eta: 4:57:40
[2022/06/19 01:24:17] ppcls INFO: [Train][Epoch 131/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05405391, top1: 0.91723, CELoss: 0.23125, loss: 0.23125, batch_cost: 0.61392s, reader_cost: 0.01488, ips: 104.24837 samples/s, eta: 4:56:19
[2022/06/19 01:24:24] ppcls INFO: [Train][Epoch 131/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05402691, top1: 0.91710, CELoss: 0.23089, loss: 0.23089, batch_cost: 0.62216s, reader_cost: 0.01371, ips: 102.86761 samples/s, eta: 5:00:11
[2022/06/19 01:24:30] ppcls INFO: [Train][Epoch 131/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05399991, top1: 0.91746, CELoss: 0.23030, loss: 0.23030, batch_cost: 0.61484s, reader_cost: 0.01306, ips: 104.09184 samples/s, eta: 4:56:33
[2022/06/19 01:24:36] ppcls INFO: [Train][Epoch 131/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05397291, top1: 0.91600, CELoss: 0.23466, loss: 0.23466, batch_cost: 0.61376s, reader_cost: 0.01351, ips: 104.27496 samples/s, eta: 4:55:56
[2022/06/19 01:24:42] ppcls INFO: [Train][Epoch 131/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05394590, top1: 0.91587, CELoss: 0.23447, loss: 0.23447, batch_cost: 0.61626s, reader_cost: 0.01392, ips: 103.85227 samples/s, eta: 4:57:02
[2022/06/19 01:24:47] ppcls INFO: [Train][Epoch 131/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05391889, top1: 0.91576, CELoss: 0.23525, loss: 0.23525, batch_cost: 0.60897s, reader_cost: 0.01359, ips: 105.09511 samples/s, eta: 4:53:25
[2022/06/19 01:24:50] ppcls INFO: [Train][Epoch 131/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05389188, top1: 0.91591, CELoss: 0.23542, loss: 0.23542, batch_cost: 0.58545s, reader_cost: 0.01278, ips: 83.69686 samples/s, eta: 4:41:59
[2022/06/19 01:24:50] ppcls INFO: [Train][Epoch 131/300][Avg]top1: 0.91591, CELoss: 0.23542, loss: 0.23542
[2022/06/19 01:24:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:24:55] ppcls INFO: [Train][Epoch 132/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05388918, top1: 0.89062, CELoss: 0.26817, loss: 0.26817, batch_cost: 0.61307s, reader_cost: 0.03964, ips: 104.39303 samples/s, eta: 4:55:17
[2022/06/19 01:25:03] ppcls INFO: [Train][Epoch 132/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05386216, top1: 0.92472, CELoss: 0.23846, loss: 0.23846, batch_cost: 0.74732s, reader_cost: 0.01538, ips: 85.63990 samples/s, eta: 5:59:49
[2022/06/19 01:25:10] ppcls INFO: [Train][Epoch 132/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05383514, top1: 0.93006, CELoss: 0.22153, loss: 0.22153, batch_cost: 0.68604s, reader_cost: 0.01702, ips: 93.28891 samples/s, eta: 5:30:12
[2022/06/19 01:25:16] ppcls INFO: [Train][Epoch 132/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05380812, top1: 0.92490, CELoss: 0.22448, loss: 0.22448, batch_cost: 0.65371s, reader_cost: 0.01560, ips: 97.90285 samples/s, eta: 5:14:31
[2022/06/19 01:25:22] ppcls INFO: [Train][Epoch 132/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05378109, top1: 0.92873, CELoss: 0.21117, loss: 0.21117, batch_cost: 0.64438s, reader_cost: 0.02869, ips: 99.32003 samples/s, eta: 5:09:56
[2022/06/19 01:25:28] ppcls INFO: [Train][Epoch 132/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05375406, top1: 0.92862, CELoss: 0.21421, loss: 0.21421, batch_cost: 0.63703s, reader_cost: 0.02949, ips: 100.46558 samples/s, eta: 5:06:17
[2022/06/19 01:25:34] ppcls INFO: [Train][Epoch 132/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05372703, top1: 0.92879, CELoss: 0.20872, loss: 0.20872, batch_cost: 0.63012s, reader_cost: 0.02915, ips: 101.56823 samples/s, eta: 5:02:51
[2022/06/19 01:25:40] ppcls INFO: [Train][Epoch 132/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05369999, top1: 0.92672, CELoss: 0.20993, loss: 0.20993, batch_cost: 0.61946s, reader_cost: 0.02809, ips: 103.31547 samples/s, eta: 4:57:38
[2022/06/19 01:25:45] ppcls INFO: [Train][Epoch 132/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05367295, top1: 0.92535, CELoss: 0.21490, loss: 0.21490, batch_cost: 0.61031s, reader_cost: 0.02661, ips: 104.86419 samples/s, eta: 4:53:08
[2022/06/19 01:25:51] ppcls INFO: [Train][Epoch 132/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05364591, top1: 0.92531, CELoss: 0.21467, loss: 0.21467, batch_cost: 0.61018s, reader_cost: 0.02427, ips: 104.88668 samples/s, eta: 4:52:58
[2022/06/19 01:25:58] ppcls INFO: [Train][Epoch 132/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05361886, top1: 0.92512, CELoss: 0.21544, loss: 0.21544, batch_cost: 0.61328s, reader_cost: 0.02303, ips: 104.35649 samples/s, eta: 4:54:21
[2022/06/19 01:26:03] ppcls INFO: [Train][Epoch 132/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05359182, top1: 0.92455, CELoss: 0.21667, loss: 0.21667, batch_cost: 0.60733s, reader_cost: 0.02275, ips: 105.37876 samples/s, eta: 4:51:24
[2022/06/19 01:26:10] ppcls INFO: [Train][Epoch 132/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05356476, top1: 0.92265, CELoss: 0.21973, loss: 0.21973, batch_cost: 0.61702s, reader_cost: 0.02137, ips: 103.72513 samples/s, eta: 4:55:57
[2022/06/19 01:26:17] ppcls INFO: [Train][Epoch 132/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05353771, top1: 0.92247, CELoss: 0.22095, loss: 0.22095, batch_cost: 0.62137s, reader_cost: 0.02068, ips: 102.99813 samples/s, eta: 4:57:56
[2022/06/19 01:26:23] ppcls INFO: [Train][Epoch 132/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05351065, top1: 0.92121, CELoss: 0.22347, loss: 0.22347, batch_cost: 0.61462s, reader_cost: 0.02018, ips: 104.12854 samples/s, eta: 4:54:35
[2022/06/19 01:26:29] ppcls INFO: [Train][Epoch 132/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05348359, top1: 0.92208, CELoss: 0.22267, loss: 0.22267, batch_cost: 0.61662s, reader_cost: 0.01915, ips: 103.79163 samples/s, eta: 4:55:27
[2022/06/19 01:26:34] ppcls INFO: [Train][Epoch 132/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05345652, top1: 0.92149, CELoss: 0.22285, loss: 0.22285, batch_cost: 0.60619s, reader_cost: 0.01815, ips: 105.57785 samples/s, eta: 4:50:21
[2022/06/19 01:26:36] ppcls INFO: [Train][Epoch 132/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05342945, top1: 0.92113, CELoss: 0.22275, loss: 0.22275, batch_cost: 0.58346s, reader_cost: 0.01709, ips: 83.98172 samples/s, eta: 4:39:22
[2022/06/19 01:26:36] ppcls INFO: [Train][Epoch 132/300][Avg]top1: 0.92113, CELoss: 0.22275, loss: 0.22275
[2022/06/19 01:26:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:26:42] ppcls INFO: [Train][Epoch 133/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05342675, top1: 0.89062, CELoss: 0.28004, loss: 0.28004, batch_cost: 0.61526s, reader_cost: 0.04216, ips: 104.02101 samples/s, eta: 4:54:35
[2022/06/19 01:26:50] ppcls INFO: [Train][Epoch 133/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05339967, top1: 0.92188, CELoss: 0.21817, loss: 0.21817, batch_cost: 0.79740s, reader_cost: 0.12229, ips: 80.26132 samples/s, eta: 6:21:39
[2022/06/19 01:26:56] ppcls INFO: [Train][Epoch 133/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05337260, top1: 0.91890, CELoss: 0.21677, loss: 0.21677, batch_cost: 0.68658s, reader_cost: 0.04839, ips: 93.21517 samples/s, eta: 5:28:30
[2022/06/19 01:27:02] ppcls INFO: [Train][Epoch 133/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05334552, top1: 0.91784, CELoss: 0.22259, loss: 0.22259, batch_cost: 0.65671s, reader_cost: 0.03257, ips: 97.45614 samples/s, eta: 5:14:06
[2022/06/19 01:27:08] ppcls INFO: [Train][Epoch 133/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05331844, top1: 0.91921, CELoss: 0.22290, loss: 0.22290, batch_cost: 0.63551s, reader_cost: 0.02736, ips: 100.70593 samples/s, eta: 5:03:51
[2022/06/19 01:27:14] ppcls INFO: [Train][Epoch 133/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05329135, top1: 0.91759, CELoss: 0.22625, loss: 0.22625, batch_cost: 0.63904s, reader_cost: 0.02452, ips: 100.14960 samples/s, eta: 5:05:26
[2022/06/19 01:27:21] ppcls INFO: [Train][Epoch 133/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05326427, top1: 0.91445, CELoss: 0.23173, loss: 0.23173, batch_cost: 0.65144s, reader_cost: 0.02194, ips: 98.24341 samples/s, eta: 5:11:15
[2022/06/19 01:27:28] ppcls INFO: [Train][Epoch 133/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05323718, top1: 0.91571, CELoss: 0.23103, loss: 0.23103, batch_cost: 0.65100s, reader_cost: 0.02097, ips: 98.31062 samples/s, eta: 5:10:56
[2022/06/19 01:27:34] ppcls INFO: [Train][Epoch 133/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05321008, top1: 0.91647, CELoss: 0.22880, loss: 0.22880, batch_cost: 0.63939s, reader_cost: 0.01933, ips: 100.09477 samples/s, eta: 5:05:17
[2022/06/19 01:27:40] ppcls INFO: [Train][Epoch 133/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05318299, top1: 0.91621, CELoss: 0.23205, loss: 0.23205, batch_cost: 0.64046s, reader_cost: 0.01969, ips: 99.92762 samples/s, eta: 5:05:41
[2022/06/19 01:27:46] ppcls INFO: [Train][Epoch 133/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05315589, top1: 0.91662, CELoss: 0.23022, loss: 0.23022, batch_cost: 0.63813s, reader_cost: 0.02183, ips: 100.29314 samples/s, eta: 5:04:28
[2022/06/19 01:27:53] ppcls INFO: [Train][Epoch 133/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05312878, top1: 0.91568, CELoss: 0.22776, loss: 0.22776, batch_cost: 0.63745s, reader_cost: 0.02071, ips: 100.40071 samples/s, eta: 5:04:02
[2022/06/19 01:27:59] ppcls INFO: [Train][Epoch 133/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05310168, top1: 0.91684, CELoss: 0.22727, loss: 0.22727, batch_cost: 0.63759s, reader_cost: 0.01958, ips: 100.37800 samples/s, eta: 5:04:00
[2022/06/19 01:28:05] ppcls INFO: [Train][Epoch 133/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05307457, top1: 0.91531, CELoss: 0.23109, loss: 0.23109, batch_cost: 0.63142s, reader_cost: 0.01979, ips: 101.35914 samples/s, eta: 5:00:57
[2022/06/19 01:28:11] ppcls INFO: [Train][Epoch 133/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05304746, top1: 0.91589, CELoss: 0.23004, loss: 0.23004, batch_cost: 0.63209s, reader_cost: 0.01956, ips: 101.25181 samples/s, eta: 5:01:10
[2022/06/19 01:28:17] ppcls INFO: [Train][Epoch 133/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05302034, top1: 0.91598, CELoss: 0.22981, loss: 0.22981, batch_cost: 0.62914s, reader_cost: 0.01885, ips: 101.72638 samples/s, eta: 4:59:39
[2022/06/19 01:28:22] ppcls INFO: [Train][Epoch 133/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05299322, top1: 0.91625, CELoss: 0.22880, loss: 0.22880, batch_cost: 0.62321s, reader_cost: 0.01833, ips: 102.69382 samples/s, eta: 4:56:43
[2022/06/19 01:28:24] ppcls INFO: [Train][Epoch 133/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05296610, top1: 0.91637, CELoss: 0.22801, loss: 0.22801, batch_cost: 0.59849s, reader_cost: 0.01724, ips: 81.87319 samples/s, eta: 4:44:51
[2022/06/19 01:28:25] ppcls INFO: [Train][Epoch 133/300][Avg]top1: 0.91637, CELoss: 0.22801, loss: 0.22801
[2022/06/19 01:28:25] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:28:31] ppcls INFO: [Train][Epoch 134/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05296339, top1: 0.96875, CELoss: 0.13063, loss: 0.13063, batch_cost: 0.62773s, reader_cost: 0.04647, ips: 101.95409 samples/s, eta: 4:58:46
[2022/06/19 01:28:38] ppcls INFO: [Train][Epoch 134/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05293626, top1: 0.93608, CELoss: 0.20856, loss: 0.20856, batch_cost: 0.63570s, reader_cost: 0.01407, ips: 100.67713 samples/s, eta: 5:02:27
[2022/06/19 01:28:44] ppcls INFO: [Train][Epoch 134/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05290914, top1: 0.92783, CELoss: 0.21184, loss: 0.21184, batch_cost: 0.61160s, reader_cost: 0.01713, ips: 104.64417 samples/s, eta: 4:50:53
[2022/06/19 01:28:50] ppcls INFO: [Train][Epoch 134/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05288201, top1: 0.92843, CELoss: 0.20087, loss: 0.20087, batch_cost: 0.59247s, reader_cost: 0.01491, ips: 108.02212 samples/s, eta: 4:41:41
[2022/06/19 01:28:56] ppcls INFO: [Train][Epoch 134/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05285487, top1: 0.92835, CELoss: 0.20624, loss: 0.20624, batch_cost: 0.58930s, reader_cost: 0.01686, ips: 108.60300 samples/s, eta: 4:40:05
[2022/06/19 01:29:03] ppcls INFO: [Train][Epoch 134/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05282774, top1: 0.92678, CELoss: 0.20517, loss: 0.20517, batch_cost: 0.62783s, reader_cost: 0.02210, ips: 101.93840 samples/s, eta: 4:58:17
[2022/06/19 01:29:08] ppcls INFO: [Train][Epoch 134/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05280060, top1: 0.92828, CELoss: 0.20492, loss: 0.20492, batch_cost: 0.60379s, reader_cost: 0.01974, ips: 105.99661 samples/s, eta: 4:46:46
[2022/06/19 01:29:14] ppcls INFO: [Train][Epoch 134/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05277346, top1: 0.92606, CELoss: 0.21054, loss: 0.21054, batch_cost: 0.60873s, reader_cost: 0.01996, ips: 105.13669 samples/s, eta: 4:49:00
[2022/06/19 01:29:20] ppcls INFO: [Train][Epoch 134/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05274631, top1: 0.92573, CELoss: 0.21085, loss: 0.21085, batch_cost: 0.60269s, reader_cost: 0.01951, ips: 106.19036 samples/s, eta: 4:46:02
[2022/06/19 01:29:26] ppcls INFO: [Train][Epoch 134/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05271916, top1: 0.92617, CELoss: 0.21001, loss: 0.21001, batch_cost: 0.60332s, reader_cost: 0.01969, ips: 106.07984 samples/s, eta: 4:46:14
[2022/06/19 01:29:33] ppcls INFO: [Train][Epoch 134/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05269201, top1: 0.92497, CELoss: 0.21192, loss: 0.21192, batch_cost: 0.61357s, reader_cost: 0.01985, ips: 104.30767 samples/s, eta: 4:51:00
[2022/06/19 01:29:39] ppcls INFO: [Train][Epoch 134/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05266486, top1: 0.92455, CELoss: 0.21295, loss: 0.21295, batch_cost: 0.61474s, reader_cost: 0.01864, ips: 104.10827 samples/s, eta: 4:51:27
[2022/06/19 01:29:44] ppcls INFO: [Train][Epoch 134/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05263770, top1: 0.92330, CELoss: 0.21617, loss: 0.21617, batch_cost: 0.60427s, reader_cost: 0.01772, ips: 105.91220 samples/s, eta: 4:46:23
[2022/06/19 01:29:50] ppcls INFO: [Train][Epoch 134/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05261054, top1: 0.92378, CELoss: 0.21471, loss: 0.21471, batch_cost: 0.60394s, reader_cost: 0.01786, ips: 105.97103 samples/s, eta: 4:46:08
[2022/06/19 01:29:56] ppcls INFO: [Train][Epoch 134/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05258338, top1: 0.92354, CELoss: 0.21499, loss: 0.21499, batch_cost: 0.59751s, reader_cost: 0.01691, ips: 107.11113 samples/s, eta: 4:42:59
[2022/06/19 01:30:03] ppcls INFO: [Train][Epoch 134/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05255622, top1: 0.92229, CELoss: 0.21906, loss: 0.21906, batch_cost: 0.61016s, reader_cost: 0.01610, ips: 104.89108 samples/s, eta: 4:48:52
[2022/06/19 01:30:08] ppcls INFO: [Train][Epoch 134/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05252905, top1: 0.92110, CELoss: 0.22158, loss: 0.22158, batch_cost: 0.59943s, reader_cost: 0.01529, ips: 106.76749 samples/s, eta: 4:43:42
[2022/06/19 01:30:10] ppcls INFO: [Train][Epoch 134/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05250188, top1: 0.92067, CELoss: 0.22356, loss: 0.22356, batch_cost: 0.57604s, reader_cost: 0.01439, ips: 85.06337 samples/s, eta: 4:32:32
[2022/06/19 01:30:10] ppcls INFO: [Train][Epoch 134/300][Avg]top1: 0.92067, CELoss: 0.22356, loss: 0.22356
[2022/06/19 01:30:11] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:30:16] ppcls INFO: [Train][Epoch 135/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05249916, top1: 0.93750, CELoss: 0.17953, loss: 0.17953, batch_cost: 0.60699s, reader_cost: 0.04159, ips: 105.43778 samples/s, eta: 4:47:10
[2022/06/19 01:30:24] ppcls INFO: [Train][Epoch 135/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05247199, top1: 0.91051, CELoss: 0.25783, loss: 0.25783, batch_cost: 0.76639s, reader_cost: 0.01627, ips: 83.50785 samples/s, eta: 6:02:27
[2022/06/19 01:30:30] ppcls INFO: [Train][Epoch 135/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05244481, top1: 0.91369, CELoss: 0.23111, loss: 0.23111, batch_cost: 0.71190s, reader_cost: 0.00945, ips: 89.90065 samples/s, eta: 5:36:33
[2022/06/19 01:30:37] ppcls INFO: [Train][Epoch 135/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05241763, top1: 0.91784, CELoss: 0.23001, loss: 0.23001, batch_cost: 0.67748s, reader_cost: 0.01491, ips: 94.46720 samples/s, eta: 5:20:10
[2022/06/19 01:30:43] ppcls INFO: [Train][Epoch 135/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05239045, top1: 0.91921, CELoss: 0.23062, loss: 0.23062, batch_cost: 0.67205s, reader_cost: 0.01667, ips: 95.23101 samples/s, eta: 5:17:29
[2022/06/19 01:30:49] ppcls INFO: [Train][Epoch 135/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05236326, top1: 0.91942, CELoss: 0.23614, loss: 0.23614, batch_cost: 0.65472s, reader_cost: 0.01707, ips: 97.75220 samples/s, eta: 5:09:12
[2022/06/19 01:30:55] ppcls INFO: [Train][Epoch 135/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05233607, top1: 0.92008, CELoss: 0.23374, loss: 0.23374, batch_cost: 0.64150s, reader_cost: 0.01578, ips: 99.76657 samples/s, eta: 5:02:51
[2022/06/19 01:31:00] ppcls INFO: [Train][Epoch 135/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05230888, top1: 0.92188, CELoss: 0.22963, loss: 0.22963, batch_cost: 0.62888s, reader_cost: 0.01607, ips: 101.76811 samples/s, eta: 4:56:47
[2022/06/19 01:31:07] ppcls INFO: [Train][Epoch 135/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05228169, top1: 0.92515, CELoss: 0.22282, loss: 0.22282, batch_cost: 0.63029s, reader_cost: 0.01477, ips: 101.54081 samples/s, eta: 4:57:20
[2022/06/19 01:31:14] ppcls INFO: [Train][Epoch 135/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05225449, top1: 0.92565, CELoss: 0.21770, loss: 0.21770, batch_cost: 0.64433s, reader_cost: 0.01589, ips: 99.32782 samples/s, eta: 5:03:51
[2022/06/19 01:31:20] ppcls INFO: [Train][Epoch 135/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05222730, top1: 0.92543, CELoss: 0.21699, loss: 0.21699, batch_cost: 0.63034s, reader_cost: 0.01565, ips: 101.53219 samples/s, eta: 4:57:09
[2022/06/19 01:31:26] ppcls INFO: [Train][Epoch 135/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05220009, top1: 0.92497, CELoss: 0.22162, loss: 0.22162, batch_cost: 0.63202s, reader_cost: 0.01647, ips: 101.26258 samples/s, eta: 4:57:51
[2022/06/19 01:31:33] ppcls INFO: [Train][Epoch 135/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05217289, top1: 0.92433, CELoss: 0.22535, loss: 0.22535, batch_cost: 0.63706s, reader_cost: 0.01720, ips: 100.46076 samples/s, eta: 5:00:07
[2022/06/19 01:31:38] ppcls INFO: [Train][Epoch 135/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05214568, top1: 0.92259, CELoss: 0.22744, loss: 0.22744, batch_cost: 0.63028s, reader_cost: 0.01743, ips: 101.54236 samples/s, eta: 4:56:49
[2022/06/19 01:31:44] ppcls INFO: [Train][Epoch 135/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05211847, top1: 0.92320, CELoss: 0.22454, loss: 0.22454, batch_cost: 0.62232s, reader_cost: 0.01769, ips: 102.84152 samples/s, eta: 4:52:57
[2022/06/19 01:31:50] ppcls INFO: [Train][Epoch 135/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05209126, top1: 0.92312, CELoss: 0.22530, loss: 0.22530, batch_cost: 0.62008s, reader_cost: 0.01670, ips: 103.21184 samples/s, eta: 4:51:48
[2022/06/19 01:31:56] ppcls INFO: [Train][Epoch 135/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05206405, top1: 0.92362, CELoss: 0.22704, loss: 0.22704, batch_cost: 0.61827s, reader_cost: 0.01634, ips: 103.51504 samples/s, eta: 4:50:51
[2022/06/19 01:31:58] ppcls INFO: [Train][Epoch 135/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05203683, top1: 0.92287, CELoss: 0.22995, loss: 0.22995, batch_cost: 0.59405s, reader_cost: 0.01538, ips: 82.48524 samples/s, eta: 4:39:21
[2022/06/19 01:31:58] ppcls INFO: [Train][Epoch 135/300][Avg]top1: 0.92287, CELoss: 0.22995, loss: 0.22995
[2022/06/19 01:32:05] ppcls INFO: [Eval][Epoch 135][Iter: 0/16]CELoss: 0.84668, loss: 0.84668, top1: 0.76758, batch_cost: 6.86135s, reader_cost: 3.69019, ips: 9.32762 images/sec
[2022/06/19 01:32:13] ppcls INFO: [Eval][Epoch 135][Iter: 10/16]CELoss: 0.63844, loss: 0.63844, top1: 0.79510, batch_cost: 0.60466s, reader_cost: 0.01030, ips: 105.84486 images/sec
[2022/06/19 01:32:15] ppcls INFO: [Eval][Epoch 135][Avg]CELoss: 0.63414, loss: 0.63414, top1: 0.80294
[2022/06/19 01:32:15] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 01:32:15] ppcls INFO: [Eval][Epoch 135][best metric: 0.8029412031173706]
[2022/06/19 01:32:15] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:32:23] ppcls INFO: [Train][Epoch 136/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05203411, top1: 0.93750, CELoss: 0.19109, loss: 0.19109, batch_cost: 0.63984s, reader_cost: 0.06109, ips: 100.02438 samples/s, eta: 5:00:53
[2022/06/19 01:32:29] ppcls INFO: [Train][Epoch 136/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05200689, top1: 0.91903, CELoss: 0.22723, loss: 0.22723, batch_cost: 0.60593s, reader_cost: 0.01727, ips: 105.62301 samples/s, eta: 4:44:50
[2022/06/19 01:32:35] ppcls INFO: [Train][Epoch 136/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05197966, top1: 0.92262, CELoss: 0.22313, loss: 0.22313, batch_cost: 0.59685s, reader_cost: 0.01565, ips: 107.22974 samples/s, eta: 4:40:28
[2022/06/19 01:32:41] ppcls INFO: [Train][Epoch 136/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05195244, top1: 0.92440, CELoss: 0.21292, loss: 0.21292, batch_cost: 0.60199s, reader_cost: 0.01975, ips: 106.31395 samples/s, eta: 4:42:47
[2022/06/19 01:32:47] ppcls INFO: [Train][Epoch 136/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05192521, top1: 0.92264, CELoss: 0.22018, loss: 0.22018, batch_cost: 0.59896s, reader_cost: 0.02153, ips: 106.85256 samples/s, eta: 4:41:15
[2022/06/19 01:32:53] ppcls INFO: [Train][Epoch 136/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05189798, top1: 0.92004, CELoss: 0.22531, loss: 0.22531, batch_cost: 0.60548s, reader_cost: 0.02253, ips: 105.70138 samples/s, eta: 4:44:13
[2022/06/19 01:32:59] ppcls INFO: [Train][Epoch 136/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05187075, top1: 0.91957, CELoss: 0.22460, loss: 0.22460, batch_cost: 0.60071s, reader_cost: 0.01984, ips: 106.54118 samples/s, eta: 4:41:52
[2022/06/19 01:33:05] ppcls INFO: [Train][Epoch 136/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05184351, top1: 0.92143, CELoss: 0.22376, loss: 0.22376, batch_cost: 0.60231s, reader_cost: 0.02069, ips: 106.25796 samples/s, eta: 4:42:31
[2022/06/19 01:33:11] ppcls INFO: [Train][Epoch 136/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05181627, top1: 0.91995, CELoss: 0.22627, loss: 0.22627, batch_cost: 0.60710s, reader_cost: 0.01954, ips: 105.41973 samples/s, eta: 4:44:40
[2022/06/19 01:33:17] ppcls INFO: [Train][Epoch 136/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05178903, top1: 0.91896, CELoss: 0.22929, loss: 0.22929, batch_cost: 0.60261s, reader_cost: 0.01946, ips: 106.20423 samples/s, eta: 4:42:28
[2022/06/19 01:33:23] ppcls INFO: [Train][Epoch 136/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05176179, top1: 0.91925, CELoss: 0.22695, loss: 0.22695, batch_cost: 0.60232s, reader_cost: 0.01807, ips: 106.25528 samples/s, eta: 4:42:14
[2022/06/19 01:33:29] ppcls INFO: [Train][Epoch 136/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05173454, top1: 0.92047, CELoss: 0.22503, loss: 0.22503, batch_cost: 0.60500s, reader_cost: 0.01840, ips: 105.78449 samples/s, eta: 4:43:23
[2022/06/19 01:33:35] ppcls INFO: [Train][Epoch 136/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05170729, top1: 0.92097, CELoss: 0.22558, loss: 0.22558, batch_cost: 0.60548s, reader_cost: 0.01793, ips: 105.70101 samples/s, eta: 4:43:31
[2022/06/19 01:33:42] ppcls INFO: [Train][Epoch 136/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05168004, top1: 0.91877, CELoss: 0.23085, loss: 0.23085, batch_cost: 0.60760s, reader_cost: 0.01738, ips: 105.33229 samples/s, eta: 4:44:24
[2022/06/19 01:33:50] ppcls INFO: [Train][Epoch 136/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05165279, top1: 0.91933, CELoss: 0.22925, loss: 0.22925, batch_cost: 0.62181s, reader_cost: 0.01629, ips: 102.92595 samples/s, eta: 4:50:57
[2022/06/19 01:34:02] ppcls INFO: [Train][Epoch 136/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05162553, top1: 0.91836, CELoss: 0.22923, loss: 0.22923, batch_cost: 0.66258s, reader_cost: 0.01532, ips: 96.59228 samples/s, eta: 5:09:55
[2022/06/19 01:34:13] ppcls INFO: [Train][Epoch 136/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05159827, top1: 0.91799, CELoss: 0.22924, loss: 0.22924, batch_cost: 0.69264s, reader_cost: 0.01445, ips: 92.40000 samples/s, eta: 5:23:52
[2022/06/19 01:34:15] ppcls INFO: [Train][Epoch 136/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05157101, top1: 0.91884, CELoss: 0.22856, loss: 0.22856, batch_cost: 0.66348s, reader_cost: 0.01364, ips: 73.85296 samples/s, eta: 5:10:07
[2022/06/19 01:34:16] ppcls INFO: [Train][Epoch 136/300][Avg]top1: 0.91884, CELoss: 0.22856, loss: 0.22856
[2022/06/19 01:34:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:34:23] ppcls INFO: [Train][Epoch 137/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05156828, top1: 0.90625, CELoss: 0.27030, loss: 0.27030, batch_cost: 0.70054s, reader_cost: 0.04080, ips: 91.35837 samples/s, eta: 5:27:25
[2022/06/19 01:34:30] ppcls INFO: [Train][Epoch 137/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05154102, top1: 0.92045, CELoss: 0.23513, loss: 0.23513, batch_cost: 0.59284s, reader_cost: 0.00035, ips: 107.95410 samples/s, eta: 4:36:59
[2022/06/19 01:34:35] ppcls INFO: [Train][Epoch 137/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05151375, top1: 0.92560, CELoss: 0.22662, loss: 0.22662, batch_cost: 0.57296s, reader_cost: 0.00061, ips: 111.70114 samples/s, eta: 4:27:36
[2022/06/19 01:34:42] ppcls INFO: [Train][Epoch 137/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05148648, top1: 0.92339, CELoss: 0.23079, loss: 0.23079, batch_cost: 0.60286s, reader_cost: 0.00896, ips: 106.16119 samples/s, eta: 4:41:28
[2022/06/19 01:34:49] ppcls INFO: [Train][Epoch 137/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05145921, top1: 0.92607, CELoss: 0.22580, loss: 0.22580, batch_cost: 0.62890s, reader_cost: 0.00679, ips: 101.76418 samples/s, eta: 4:53:31
[2022/06/19 01:34:54] ppcls INFO: [Train][Epoch 137/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05143194, top1: 0.92586, CELoss: 0.22308, loss: 0.22308, batch_cost: 0.61230s, reader_cost: 0.00655, ips: 104.52405 samples/s, eta: 4:45:40
[2022/06/19 01:35:00] ppcls INFO: [Train][Epoch 137/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05140466, top1: 0.92623, CELoss: 0.22195, loss: 0.22195, batch_cost: 0.60090s, reader_cost: 0.01035, ips: 106.50771 samples/s, eta: 4:40:15
[2022/06/19 01:35:05] ppcls INFO: [Train][Epoch 137/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05137739, top1: 0.92606, CELoss: 0.22054, loss: 0.22054, batch_cost: 0.58845s, reader_cost: 0.00991, ips: 108.75952 samples/s, eta: 4:34:21
[2022/06/19 01:35:11] ppcls INFO: [Train][Epoch 137/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05135010, top1: 0.92515, CELoss: 0.22090, loss: 0.22090, batch_cost: 0.59289s, reader_cost: 0.01038, ips: 107.94643 samples/s, eta: 4:36:19
[2022/06/19 01:35:17] ppcls INFO: [Train][Epoch 137/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05132282, top1: 0.92359, CELoss: 0.22262, loss: 0.22262, batch_cost: 0.58693s, reader_cost: 0.01079, ips: 109.04256 samples/s, eta: 4:33:26
[2022/06/19 01:35:23] ppcls INFO: [Train][Epoch 137/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05129554, top1: 0.92327, CELoss: 0.22220, loss: 0.22220, batch_cost: 0.59546s, reader_cost: 0.01077, ips: 107.47908 samples/s, eta: 4:37:19
[2022/06/19 01:35:31] ppcls INFO: [Train][Epoch 137/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05126825, top1: 0.92356, CELoss: 0.22199, loss: 0.22199, batch_cost: 0.61263s, reader_cost: 0.01136, ips: 104.46811 samples/s, eta: 4:45:13
[2022/06/19 01:35:37] ppcls INFO: [Train][Epoch 137/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05124096, top1: 0.92420, CELoss: 0.21819, loss: 0.21819, batch_cost: 0.60720s, reader_cost: 0.01186, ips: 105.40185 samples/s, eta: 4:42:35
[2022/06/19 01:35:42] ppcls INFO: [Train][Epoch 137/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05121366, top1: 0.92402, CELoss: 0.21933, loss: 0.21933, batch_cost: 0.60354s, reader_cost: 0.01186, ips: 106.04162 samples/s, eta: 4:40:47
[2022/06/19 01:35:48] ppcls INFO: [Train][Epoch 137/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05118637, top1: 0.92575, CELoss: 0.21526, loss: 0.21526, batch_cost: 0.59888s, reader_cost: 0.01307, ips: 106.86664 samples/s, eta: 4:38:31
[2022/06/19 01:35:54] ppcls INFO: [Train][Epoch 137/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05115907, top1: 0.92519, CELoss: 0.21619, loss: 0.21619, batch_cost: 0.60315s, reader_cost: 0.01242, ips: 106.10934 samples/s, eta: 4:40:24
[2022/06/19 01:36:00] ppcls INFO: [Train][Epoch 137/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05113177, top1: 0.92469, CELoss: 0.21665, loss: 0.21665, batch_cost: 0.59950s, reader_cost: 0.01280, ips: 106.75511 samples/s, eta: 4:38:36
[2022/06/19 01:36:02] ppcls INFO: [Train][Epoch 137/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05110447, top1: 0.92442, CELoss: 0.21730, loss: 0.21730, batch_cost: 0.57588s, reader_cost: 0.01205, ips: 85.08708 samples/s, eta: 4:27:32
[2022/06/19 01:36:02] ppcls INFO: [Train][Epoch 137/300][Avg]top1: 0.92442, CELoss: 0.21730, loss: 0.21730
[2022/06/19 01:36:02] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:36:08] ppcls INFO: [Train][Epoch 138/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05110174, top1: 0.90625, CELoss: 0.15668, loss: 0.15668, batch_cost: 0.60716s, reader_cost: 0.04239, ips: 105.40925 samples/s, eta: 4:42:03
[2022/06/19 01:36:15] ppcls INFO: [Train][Epoch 138/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05107444, top1: 0.93040, CELoss: 0.17836, loss: 0.17836, batch_cost: 0.68068s, reader_cost: 0.03496, ips: 94.02371 samples/s, eta: 5:16:05
[2022/06/19 01:36:21] ppcls INFO: [Train][Epoch 138/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05104713, top1: 0.93378, CELoss: 0.18406, loss: 0.18406, batch_cost: 0.65594s, reader_cost: 0.02144, ips: 97.56994 samples/s, eta: 5:04:29
[2022/06/19 01:36:28] ppcls INFO: [Train][Epoch 138/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05101982, top1: 0.92893, CELoss: 0.19825, loss: 0.19825, batch_cost: 0.66849s, reader_cost: 0.01463, ips: 95.73755 samples/s, eta: 5:10:12
[2022/06/19 01:36:35] ppcls INFO: [Train][Epoch 138/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05099251, top1: 0.92797, CELoss: 0.20465, loss: 0.20465, batch_cost: 0.66595s, reader_cost: 0.01433, ips: 96.10384 samples/s, eta: 5:08:55
[2022/06/19 01:36:41] ppcls INFO: [Train][Epoch 138/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05096520, top1: 0.92494, CELoss: 0.20815, loss: 0.20815, batch_cost: 0.65811s, reader_cost: 0.01275, ips: 97.24772 samples/s, eta: 5:05:10
[2022/06/19 01:36:47] ppcls INFO: [Train][Epoch 138/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05093788, top1: 0.92367, CELoss: 0.21319, loss: 0.21319, batch_cost: 0.65355s, reader_cost: 0.01554, ips: 97.92735 samples/s, eta: 5:02:57
[2022/06/19 01:36:53] ppcls INFO: [Train][Epoch 138/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05091056, top1: 0.92650, CELoss: 0.20762, loss: 0.20762, batch_cost: 0.64531s, reader_cost: 0.01591, ips: 99.17784 samples/s, eta: 4:59:01
[2022/06/19 01:36:59] ppcls INFO: [Train][Epoch 138/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05088324, top1: 0.92535, CELoss: 0.21163, loss: 0.21163, batch_cost: 0.63800s, reader_cost: 0.01683, ips: 100.31270 samples/s, eta: 4:55:32
[2022/06/19 01:37:06] ppcls INFO: [Train][Epoch 138/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05085592, top1: 0.92479, CELoss: 0.21089, loss: 0.21089, batch_cost: 0.64400s, reader_cost: 0.01568, ips: 99.37902 samples/s, eta: 4:58:12
[2022/06/19 01:37:13] ppcls INFO: [Train][Epoch 138/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05082859, top1: 0.92450, CELoss: 0.21279, loss: 0.21279, batch_cost: 0.64757s, reader_cost: 0.01464, ips: 98.83103 samples/s, eta: 4:59:44
[2022/06/19 01:37:18] ppcls INFO: [Train][Epoch 138/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05080127, top1: 0.92258, CELoss: 0.21692, loss: 0.21692, batch_cost: 0.63194s, reader_cost: 0.01518, ips: 101.27473 samples/s, eta: 4:52:24
[2022/06/19 01:37:23] ppcls INFO: [Train][Epoch 138/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05077394, top1: 0.92446, CELoss: 0.21225, loss: 0.21225, batch_cost: 0.62834s, reader_cost: 0.01447, ips: 101.85512 samples/s, eta: 4:50:38
[2022/06/19 01:37:30] ppcls INFO: [Train][Epoch 138/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05074661, top1: 0.92521, CELoss: 0.20986, loss: 0.20986, batch_cost: 0.62757s, reader_cost: 0.01488, ips: 101.98077 samples/s, eta: 4:50:10
[2022/06/19 01:37:36] ppcls INFO: [Train][Epoch 138/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05071927, top1: 0.92620, CELoss: 0.20816, loss: 0.20816, batch_cost: 0.62847s, reader_cost: 0.01883, ips: 101.83430 samples/s, eta: 4:50:29
[2022/06/19 01:37:42] ppcls INFO: [Train][Epoch 138/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05069194, top1: 0.92529, CELoss: 0.20938, loss: 0.20938, batch_cost: 0.62601s, reader_cost: 0.02294, ips: 102.23465 samples/s, eta: 4:49:14
[2022/06/19 01:37:47] ppcls INFO: [Train][Epoch 138/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05066460, top1: 0.92595, CELoss: 0.20789, loss: 0.20789, batch_cost: 0.61932s, reader_cost: 0.02799, ips: 103.33853 samples/s, eta: 4:46:03
[2022/06/19 01:37:49] ppcls INFO: [Train][Epoch 138/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05063726, top1: 0.92561, CELoss: 0.21074, loss: 0.21074, batch_cost: 0.59466s, reader_cost: 0.02632, ips: 82.40049 samples/s, eta: 4:34:33
[2022/06/19 01:37:50] ppcls INFO: [Train][Epoch 138/300][Avg]top1: 0.92561, CELoss: 0.21074, loss: 0.21074
[2022/06/19 01:37:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:37:56] ppcls INFO: [Train][Epoch 139/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05063453, top1: 0.93750, CELoss: 0.21550, loss: 0.21550, batch_cost: 0.62422s, reader_cost: 0.05564, ips: 102.52803 samples/s, eta: 4:48:12
[2022/06/19 01:38:02] ppcls INFO: [Train][Epoch 139/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05060719, top1: 0.92472, CELoss: 0.24938, loss: 0.24938, batch_cost: 0.59915s, reader_cost: 0.00367, ips: 106.81788 samples/s, eta: 4:36:31
[2022/06/19 01:38:10] ppcls INFO: [Train][Epoch 139/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05057984, top1: 0.92708, CELoss: 0.22141, loss: 0.22141, batch_cost: 0.74480s, reader_cost: 0.00700, ips: 85.92914 samples/s, eta: 5:43:37
[2022/06/19 01:38:15] ppcls INFO: [Train][Epoch 139/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05055250, top1: 0.92540, CELoss: 0.22532, loss: 0.22532, batch_cost: 0.65802s, reader_cost: 0.00468, ips: 97.26184 samples/s, eta: 5:03:28
[2022/06/19 01:38:21] ppcls INFO: [Train][Epoch 139/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05052515, top1: 0.92492, CELoss: 0.22907, loss: 0.22907, batch_cost: 0.63565s, reader_cost: 0.00377, ips: 100.68397 samples/s, eta: 4:53:03
[2022/06/19 01:38:27] ppcls INFO: [Train][Epoch 139/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05049780, top1: 0.92371, CELoss: 0.23384, loss: 0.23384, batch_cost: 0.62589s, reader_cost: 0.00879, ips: 102.25455 samples/s, eta: 4:48:27
[2022/06/19 01:38:33] ppcls INFO: [Train][Epoch 139/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05047044, top1: 0.92367, CELoss: 0.22594, loss: 0.22594, batch_cost: 0.61980s, reader_cost: 0.01069, ips: 103.25970 samples/s, eta: 4:45:32
[2022/06/19 01:38:41] ppcls INFO: [Train][Epoch 139/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.05044309, top1: 0.92210, CELoss: 0.22766, loss: 0.22766, batch_cost: 0.64545s, reader_cost: 0.01223, ips: 99.15506 samples/s, eta: 4:57:15
[2022/06/19 01:38:46] ppcls INFO: [Train][Epoch 139/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.05041573, top1: 0.92188, CELoss: 0.22708, loss: 0.22708, batch_cost: 0.63157s, reader_cost: 0.01421, ips: 101.33486 samples/s, eta: 4:50:45
[2022/06/19 01:38:52] ppcls INFO: [Train][Epoch 139/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.05038837, top1: 0.92256, CELoss: 0.22611, loss: 0.22611, batch_cost: 0.62438s, reader_cost: 0.01574, ips: 102.50196 samples/s, eta: 4:47:20
[2022/06/19 01:38:58] ppcls INFO: [Train][Epoch 139/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.05036101, top1: 0.92265, CELoss: 0.22649, loss: 0.22649, batch_cost: 0.61851s, reader_cost: 0.01528, ips: 103.47454 samples/s, eta: 4:44:32
[2022/06/19 01:39:03] ppcls INFO: [Train][Epoch 139/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.05033365, top1: 0.92286, CELoss: 0.22853, loss: 0.22853, batch_cost: 0.61048s, reader_cost: 0.01423, ips: 104.83544 samples/s, eta: 4:40:44
[2022/06/19 01:39:10] ppcls INFO: [Train][Epoch 139/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.05030629, top1: 0.92342, CELoss: 0.22589, loss: 0.22589, batch_cost: 0.61367s, reader_cost: 0.02233, ips: 104.28973 samples/s, eta: 4:42:06
[2022/06/19 01:39:15] ppcls INFO: [Train][Epoch 139/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.05027892, top1: 0.92199, CELoss: 0.22791, loss: 0.22791, batch_cost: 0.61108s, reader_cost: 0.02746, ips: 104.73319 samples/s, eta: 4:40:48
[2022/06/19 01:39:21] ppcls INFO: [Train][Epoch 139/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.05025155, top1: 0.92176, CELoss: 0.22734, loss: 0.22734, batch_cost: 0.60731s, reader_cost: 0.02998, ips: 105.38280 samples/s, eta: 4:38:58
[2022/06/19 01:39:29] ppcls INFO: [Train][Epoch 139/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.05022418, top1: 0.92136, CELoss: 0.22930, loss: 0.22930, batch_cost: 0.62244s, reader_cost: 0.03034, ips: 102.82048 samples/s, eta: 4:45:49
[2022/06/19 01:39:34] ppcls INFO: [Train][Epoch 139/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.05019681, top1: 0.92158, CELoss: 0.22640, loss: 0.22640, batch_cost: 0.61000s, reader_cost: 0.02859, ips: 104.91879 samples/s, eta: 4:40:00
[2022/06/19 01:39:36] ppcls INFO: [Train][Epoch 139/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.05016943, top1: 0.92177, CELoss: 0.22769, loss: 0.22769, batch_cost: 0.58574s, reader_cost: 0.02693, ips: 83.65415 samples/s, eta: 4:28:46
[2022/06/19 01:39:36] ppcls INFO: [Train][Epoch 139/300][Avg]top1: 0.92177, CELoss: 0.22769, loss: 0.22769
[2022/06/19 01:39:36] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:39:44] ppcls INFO: [Train][Epoch 140/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.05016670, top1: 0.93750, CELoss: 0.22485, loss: 0.22485, batch_cost: 0.62799s, reader_cost: 0.06175, ips: 101.91278 samples/s, eta: 4:48:09
[2022/06/19 01:39:50] ppcls INFO: [Train][Epoch 140/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.05013932, top1: 0.91761, CELoss: 0.24318, loss: 0.24318, batch_cost: 0.70066s, reader_cost: 0.00033, ips: 91.34277 samples/s, eta: 5:21:22
[2022/06/19 01:39:57] ppcls INFO: [Train][Epoch 140/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.05011194, top1: 0.90625, CELoss: 0.25699, loss: 0.25699, batch_cost: 0.66135s, reader_cost: 0.00032, ips: 96.77182 samples/s, eta: 5:03:14
[2022/06/19 01:40:02] ppcls INFO: [Train][Epoch 140/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.05008456, top1: 0.91683, CELoss: 0.23463, loss: 0.23463, batch_cost: 0.62214s, reader_cost: 0.00095, ips: 102.86991 samples/s, eta: 4:45:09
[2022/06/19 01:40:08] ppcls INFO: [Train][Epoch 140/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.05005718, top1: 0.91616, CELoss: 0.22927, loss: 0.22927, batch_cost: 0.61046s, reader_cost: 0.01901, ips: 104.83868 samples/s, eta: 4:39:42
[2022/06/19 01:40:14] ppcls INFO: [Train][Epoch 140/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.05002979, top1: 0.91513, CELoss: 0.23213, loss: 0.23213, batch_cost: 0.60451s, reader_cost: 0.03270, ips: 105.87039 samples/s, eta: 4:36:52
[2022/06/19 01:40:20] ppcls INFO: [Train][Epoch 140/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.05000241, top1: 0.91880, CELoss: 0.22687, loss: 0.22687, batch_cost: 0.61429s, reader_cost: 0.06447, ips: 104.18474 samples/s, eta: 4:41:15
[2022/06/19 01:40:26] ppcls INFO: [Train][Epoch 140/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04997502, top1: 0.91945, CELoss: 0.22407, loss: 0.22407, batch_cost: 0.59996s, reader_cost: 0.05531, ips: 106.67335 samples/s, eta: 4:34:35
[2022/06/19 01:40:32] ppcls INFO: [Train][Epoch 140/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04994763, top1: 0.91937, CELoss: 0.22273, loss: 0.22273, batch_cost: 0.60645s, reader_cost: 0.05943, ips: 105.53182 samples/s, eta: 4:37:27
[2022/06/19 01:40:38] ppcls INFO: [Train][Epoch 140/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04992024, top1: 0.92102, CELoss: 0.21964, loss: 0.21964, batch_cost: 0.61027s, reader_cost: 0.05290, ips: 104.87184 samples/s, eta: 4:39:06
[2022/06/19 01:40:45] ppcls INFO: [Train][Epoch 140/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04989285, top1: 0.92141, CELoss: 0.21762, loss: 0.21762, batch_cost: 0.61030s, reader_cost: 0.05410, ips: 104.86583 samples/s, eta: 4:39:01
[2022/06/19 01:40:51] ppcls INFO: [Train][Epoch 140/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04986545, top1: 0.92145, CELoss: 0.21815, loss: 0.21815, batch_cost: 0.60919s, reader_cost: 0.05029, ips: 105.05757 samples/s, eta: 4:38:24
[2022/06/19 01:40:57] ppcls INFO: [Train][Epoch 140/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04983805, top1: 0.92200, CELoss: 0.21720, loss: 0.21720, batch_cost: 0.61541s, reader_cost: 0.05012, ips: 103.99627 samples/s, eta: 4:41:08
[2022/06/19 01:41:03] ppcls INFO: [Train][Epoch 140/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04981065, top1: 0.92199, CELoss: 0.21659, loss: 0.21659, batch_cost: 0.60851s, reader_cost: 0.04757, ips: 105.17439 samples/s, eta: 4:37:53
[2022/06/19 01:41:09] ppcls INFO: [Train][Epoch 140/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04978325, top1: 0.92332, CELoss: 0.21473, loss: 0.21473, batch_cost: 0.61146s, reader_cost: 0.04459, ips: 104.66731 samples/s, eta: 4:39:08
[2022/06/19 01:41:15] ppcls INFO: [Train][Epoch 140/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04975585, top1: 0.92322, CELoss: 0.21542, loss: 0.21542, batch_cost: 0.61273s, reader_cost: 0.05345, ips: 104.44994 samples/s, eta: 4:39:37
[2022/06/19 01:41:21] ppcls INFO: [Train][Epoch 140/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04972845, top1: 0.92352, CELoss: 0.21686, loss: 0.21686, batch_cost: 0.60573s, reader_cost: 0.05406, ips: 105.65753 samples/s, eta: 4:36:19
[2022/06/19 01:41:23] ppcls INFO: [Train][Epoch 140/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04970104, top1: 0.92287, CELoss: 0.21962, loss: 0.21962, batch_cost: 0.58173s, reader_cost: 0.05081, ips: 84.23193 samples/s, eta: 4:25:16
[2022/06/19 01:41:23] ppcls INFO: [Train][Epoch 140/300][Avg]top1: 0.92287, CELoss: 0.21962, loss: 0.21962
[2022/06/19 01:41:30] ppcls INFO: [Eval][Epoch 140][Iter: 0/16]CELoss: 0.84235, loss: 0.84235, top1: 0.78906, batch_cost: 7.27966s, reader_cost: 3.58432, ips: 8.79162 images/sec
[2022/06/19 01:41:38] ppcls INFO: [Eval][Epoch 140][Iter: 10/16]CELoss: 0.77922, loss: 0.77922, top1: 0.79208, batch_cost: 0.56940s, reader_cost: 0.00994, ips: 112.39841 images/sec
[2022/06/19 01:41:40] ppcls INFO: [Eval][Epoch 140][Avg]CELoss: 0.66695, loss: 0.66695, top1: 0.80282
[2022/06/19 01:41:40] ppcls INFO: [Eval][Epoch 140][best metric: 0.8029412031173706]
[2022/06/19 01:41:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_140
[2022/06/19 01:41:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:41:46] ppcls INFO: [Train][Epoch 141/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04969830, top1: 0.95312, CELoss: 0.18965, loss: 0.18965, batch_cost: 0.61491s, reader_cost: 0.07585, ips: 104.07975 samples/s, eta: 4:40:24
[2022/06/19 01:41:52] ppcls INFO: [Train][Epoch 141/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04967089, top1: 0.91761, CELoss: 0.20383, loss: 0.20383, batch_cost: 0.56732s, reader_cost: 0.00842, ips: 112.81131 samples/s, eta: 4:18:36
[2022/06/19 01:41:59] ppcls INFO: [Train][Epoch 141/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04964348, top1: 0.92113, CELoss: 0.20492, loss: 0.20492, batch_cost: 0.64434s, reader_cost: 0.02484, ips: 99.32661 samples/s, eta: 4:53:36
[2022/06/19 01:42:06] ppcls INFO: [Train][Epoch 141/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04961607, top1: 0.91431, CELoss: 0.22271, loss: 0.22271, batch_cost: 0.63442s, reader_cost: 0.02083, ips: 100.87911 samples/s, eta: 4:48:58
[2022/06/19 01:42:11] ppcls INFO: [Train][Epoch 141/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04958866, top1: 0.91578, CELoss: 0.22202, loss: 0.22202, batch_cost: 0.62236s, reader_cost: 0.02036, ips: 102.83485 samples/s, eta: 4:43:22
[2022/06/19 01:42:18] ppcls INFO: [Train][Epoch 141/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04956124, top1: 0.91789, CELoss: 0.22069, loss: 0.22069, batch_cost: 0.63261s, reader_cost: 0.01890, ips: 101.16816 samples/s, eta: 4:47:56
[2022/06/19 01:42:24] ppcls INFO: [Train][Epoch 141/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04953382, top1: 0.91829, CELoss: 0.22077, loss: 0.22077, batch_cost: 0.62161s, reader_cost: 0.01661, ips: 102.95809 samples/s, eta: 4:42:50
[2022/06/19 01:42:30] ppcls INFO: [Train][Epoch 141/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04950641, top1: 0.91615, CELoss: 0.22837, loss: 0.22837, batch_cost: 0.61236s, reader_cost: 0.02687, ips: 104.51391 samples/s, eta: 4:38:31
[2022/06/19 01:42:36] ppcls INFO: [Train][Epoch 141/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04947899, top1: 0.91686, CELoss: 0.22736, loss: 0.22736, batch_cost: 0.62231s, reader_cost: 0.03209, ips: 102.84239 samples/s, eta: 4:42:56
[2022/06/19 01:42:43] ppcls INFO: [Train][Epoch 141/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04945156, top1: 0.91896, CELoss: 0.22332, loss: 0.22332, batch_cost: 0.62445s, reader_cost: 0.02918, ips: 102.49000 samples/s, eta: 4:43:48
[2022/06/19 01:42:49] ppcls INFO: [Train][Epoch 141/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04942414, top1: 0.91925, CELoss: 0.22242, loss: 0.22242, batch_cost: 0.62309s, reader_cost: 0.02740, ips: 102.71452 samples/s, eta: 4:43:05
[2022/06/19 01:42:56] ppcls INFO: [Train][Epoch 141/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04939672, top1: 0.91976, CELoss: 0.22258, loss: 0.22258, batch_cost: 0.62846s, reader_cost: 0.02661, ips: 101.83562 samples/s, eta: 4:45:25
[2022/06/19 01:43:00] ppcls INFO: [Train][Epoch 141/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04936929, top1: 0.92045, CELoss: 0.21926, loss: 0.21926, batch_cost: 0.61424s, reader_cost: 0.02557, ips: 104.19447 samples/s, eta: 4:38:51
[2022/06/19 01:43:08] ppcls INFO: [Train][Epoch 141/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04934186, top1: 0.92104, CELoss: 0.21831, loss: 0.21831, batch_cost: 0.62258s, reader_cost: 0.02429, ips: 102.79754 samples/s, eta: 4:42:32
[2022/06/19 01:43:13] ppcls INFO: [Train][Epoch 141/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04931443, top1: 0.92121, CELoss: 0.21853, loss: 0.21853, batch_cost: 0.61852s, reader_cost: 0.02353, ips: 103.47358 samples/s, eta: 4:40:35
[2022/06/19 01:43:19] ppcls INFO: [Train][Epoch 141/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04928700, top1: 0.92146, CELoss: 0.21895, loss: 0.21895, batch_cost: 0.61311s, reader_cost: 0.02361, ips: 104.38579 samples/s, eta: 4:38:02
[2022/06/19 01:43:24] ppcls INFO: [Train][Epoch 141/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04925957, top1: 0.92246, CELoss: 0.21709, loss: 0.21709, batch_cost: 0.60536s, reader_cost: 0.02357, ips: 105.72199 samples/s, eta: 4:34:25
[2022/06/19 01:43:26] ppcls INFO: [Train][Epoch 141/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04923213, top1: 0.92305, CELoss: 0.21517, loss: 0.21517, batch_cost: 0.58380s, reader_cost: 0.02220, ips: 83.93349 samples/s, eta: 4:24:33
[2022/06/19 01:43:27] ppcls INFO: [Train][Epoch 141/300][Avg]top1: 0.92305, CELoss: 0.21517, loss: 0.21517
[2022/06/19 01:43:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:43:33] ppcls INFO: [Train][Epoch 142/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04922939, top1: 0.96875, CELoss: 0.13396, loss: 0.13396, batch_cost: 0.61819s, reader_cost: 0.05161, ips: 103.52754 samples/s, eta: 4:40:08
[2022/06/19 01:43:39] ppcls INFO: [Train][Epoch 142/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04920195, top1: 0.93182, CELoss: 0.20072, loss: 0.20072, batch_cost: 0.59915s, reader_cost: 0.00208, ips: 106.81852 samples/s, eta: 4:31:24
[2022/06/19 01:43:46] ppcls INFO: [Train][Epoch 142/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04917451, top1: 0.92262, CELoss: 0.21384, loss: 0.21384, batch_cost: 0.64192s, reader_cost: 0.02299, ips: 99.70164 samples/s, eta: 4:50:40
[2022/06/19 01:43:52] ppcls INFO: [Train][Epoch 142/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04914707, top1: 0.91835, CELoss: 0.22247, loss: 0.22247, batch_cost: 0.63743s, reader_cost: 0.02447, ips: 100.40246 samples/s, eta: 4:48:32
[2022/06/19 01:44:00] ppcls INFO: [Train][Epoch 142/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04911963, top1: 0.92073, CELoss: 0.22114, loss: 0.22114, batch_cost: 0.66237s, reader_cost: 0.02215, ips: 96.62202 samples/s, eta: 4:59:42
[2022/06/19 01:44:05] ppcls INFO: [Train][Epoch 142/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04909219, top1: 0.91912, CELoss: 0.21909, loss: 0.21909, batch_cost: 0.62957s, reader_cost: 0.01936, ips: 101.65684 samples/s, eta: 4:44:45
[2022/06/19 01:44:10] ppcls INFO: [Train][Epoch 142/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04906474, top1: 0.91957, CELoss: 0.22223, loss: 0.22223, batch_cost: 0.61690s, reader_cost: 0.01925, ips: 103.74412 samples/s, eta: 4:38:55
[2022/06/19 01:44:16] ppcls INFO: [Train][Epoch 142/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04903730, top1: 0.92011, CELoss: 0.21971, loss: 0.21971, batch_cost: 0.61165s, reader_cost: 0.01947, ips: 104.63501 samples/s, eta: 4:36:27
[2022/06/19 01:44:23] ppcls INFO: [Train][Epoch 142/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04900985, top1: 0.91956, CELoss: 0.22276, loss: 0.22276, batch_cost: 0.61794s, reader_cost: 0.01852, ips: 103.56983 samples/s, eta: 4:39:11
[2022/06/19 01:44:29] ppcls INFO: [Train][Epoch 142/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04898240, top1: 0.91878, CELoss: 0.22601, loss: 0.22601, batch_cost: 0.61333s, reader_cost: 0.01809, ips: 104.34808 samples/s, eta: 4:37:00
[2022/06/19 01:44:34] ppcls INFO: [Train][Epoch 142/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04895495, top1: 0.91894, CELoss: 0.22735, loss: 0.22735, batch_cost: 0.60570s, reader_cost: 0.01742, ips: 105.66321 samples/s, eta: 4:33:27
[2022/06/19 01:44:40] ppcls INFO: [Train][Epoch 142/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04892750, top1: 0.92033, CELoss: 0.22565, loss: 0.22565, batch_cost: 0.60692s, reader_cost: 0.01769, ips: 105.45125 samples/s, eta: 4:33:54
[2022/06/19 01:44:46] ppcls INFO: [Train][Epoch 142/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04890005, top1: 0.92136, CELoss: 0.22356, loss: 0.22356, batch_cost: 0.60654s, reader_cost: 0.01683, ips: 105.51704 samples/s, eta: 4:33:38
[2022/06/19 01:44:52] ppcls INFO: [Train][Epoch 142/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04887259, top1: 0.92128, CELoss: 0.22231, loss: 0.22231, batch_cost: 0.60532s, reader_cost: 0.01743, ips: 105.72848 samples/s, eta: 4:32:59
[2022/06/19 01:44:58] ppcls INFO: [Train][Epoch 142/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04884513, top1: 0.92188, CELoss: 0.22137, loss: 0.22137, batch_cost: 0.60366s, reader_cost: 0.01721, ips: 106.02047 samples/s, eta: 4:32:08
[2022/06/19 01:45:04] ppcls INFO: [Train][Epoch 142/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04881768, top1: 0.92115, CELoss: 0.22293, loss: 0.22293, batch_cost: 0.60031s, reader_cost: 0.01630, ips: 106.61121 samples/s, eta: 4:30:31
[2022/06/19 01:45:12] ppcls INFO: [Train][Epoch 142/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04879022, top1: 0.92042, CELoss: 0.22377, loss: 0.22377, batch_cost: 0.61653s, reader_cost: 0.01538, ips: 103.80619 samples/s, eta: 4:37:44
[2022/06/19 01:45:14] ppcls INFO: [Train][Epoch 142/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04876276, top1: 0.92076, CELoss: 0.22321, loss: 0.22321, batch_cost: 0.59228s, reader_cost: 0.01449, ips: 82.73069 samples/s, eta: 4:26:42
[2022/06/19 01:45:15] ppcls INFO: [Train][Epoch 142/300][Avg]top1: 0.92076, CELoss: 0.22321, loss: 0.22321
[2022/06/19 01:45:15] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:45:22] ppcls INFO: [Train][Epoch 143/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04876001, top1: 0.92188, CELoss: 0.21662, loss: 0.21662, batch_cost: 0.63023s, reader_cost: 0.04686, ips: 101.55099 samples/s, eta: 4:43:47
[2022/06/19 01:45:29] ppcls INFO: [Train][Epoch 143/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04873255, top1: 0.91761, CELoss: 0.21538, loss: 0.21538, batch_cost: 0.68368s, reader_cost: 0.00486, ips: 93.61163 samples/s, eta: 5:07:44
[2022/06/19 01:45:34] ppcls INFO: [Train][Epoch 143/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04870509, top1: 0.92039, CELoss: 0.23433, loss: 0.23433, batch_cost: 0.62519s, reader_cost: 0.01515, ips: 102.36920 samples/s, eta: 4:41:18
[2022/06/19 01:45:41] ppcls INFO: [Train][Epoch 143/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04867762, top1: 0.92389, CELoss: 0.21962, loss: 0.21962, batch_cost: 0.61938s, reader_cost: 0.01563, ips: 103.32904 samples/s, eta: 4:38:35
[2022/06/19 01:45:48] ppcls INFO: [Train][Epoch 143/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04865015, top1: 0.92835, CELoss: 0.21380, loss: 0.21380, batch_cost: 0.64173s, reader_cost: 0.01808, ips: 99.72996 samples/s, eta: 4:48:32
[2022/06/19 01:45:54] ppcls INFO: [Train][Epoch 143/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04862269, top1: 0.93015, CELoss: 0.20967, loss: 0.20967, batch_cost: 0.63229s, reader_cost: 0.02079, ips: 101.21944 samples/s, eta: 4:44:11
[2022/06/19 01:46:00] ppcls INFO: [Train][Epoch 143/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04859522, top1: 0.92956, CELoss: 0.20760, loss: 0.20760, batch_cost: 0.62679s, reader_cost: 0.02036, ips: 102.10714 samples/s, eta: 4:41:37
[2022/06/19 01:46:06] ppcls INFO: [Train][Epoch 143/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04856775, top1: 0.92694, CELoss: 0.21282, loss: 0.21282, batch_cost: 0.63026s, reader_cost: 0.01958, ips: 101.54473 samples/s, eta: 4:43:04
[2022/06/19 01:46:13] ppcls INFO: [Train][Epoch 143/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04854027, top1: 0.92824, CELoss: 0.20893, loss: 0.20893, batch_cost: 0.63416s, reader_cost: 0.01905, ips: 100.92099 samples/s, eta: 4:44:42
[2022/06/19 01:46:19] ppcls INFO: [Train][Epoch 143/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04851280, top1: 0.92720, CELoss: 0.20897, loss: 0.20897, batch_cost: 0.63581s, reader_cost: 0.01889, ips: 100.65963 samples/s, eta: 4:45:20
[2022/06/19 01:46:24] ppcls INFO: [Train][Epoch 143/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04848533, top1: 0.92837, CELoss: 0.20592, loss: 0.20592, batch_cost: 0.62470s, reader_cost: 0.01863, ips: 102.44970 samples/s, eta: 4:40:15
[2022/06/19 01:46:30] ppcls INFO: [Train][Epoch 143/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04845785, top1: 0.92793, CELoss: 0.21013, loss: 0.21013, batch_cost: 0.61693s, reader_cost: 0.01798, ips: 103.73956 samples/s, eta: 4:36:40
[2022/06/19 01:46:36] ppcls INFO: [Train][Epoch 143/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04843037, top1: 0.92756, CELoss: 0.21072, loss: 0.21072, batch_cost: 0.61803s, reader_cost: 0.01879, ips: 103.55510 samples/s, eta: 4:37:03
[2022/06/19 01:46:42] ppcls INFO: [Train][Epoch 143/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04840290, top1: 0.92653, CELoss: 0.21404, loss: 0.21404, batch_cost: 0.61484s, reader_cost: 0.01993, ips: 104.09277 samples/s, eta: 4:35:31
[2022/06/19 01:46:48] ppcls INFO: [Train][Epoch 143/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04837542, top1: 0.92476, CELoss: 0.21738, loss: 0.21738, batch_cost: 0.61463s, reader_cost: 0.02041, ips: 104.12845 samples/s, eta: 4:35:19
[2022/06/19 01:46:55] ppcls INFO: [Train][Epoch 143/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04834794, top1: 0.92529, CELoss: 0.21604, loss: 0.21604, batch_cost: 0.62040s, reader_cost: 0.02099, ips: 103.15958 samples/s, eta: 4:37:48
[2022/06/19 01:47:00] ppcls INFO: [Train][Epoch 143/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04832045, top1: 0.92566, CELoss: 0.21344, loss: 0.21344, batch_cost: 0.61088s, reader_cost: 0.01978, ips: 104.76661 samples/s, eta: 4:33:27
[2022/06/19 01:47:02] ppcls INFO: [Train][Epoch 143/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04829297, top1: 0.92607, CELoss: 0.21311, loss: 0.21311, batch_cost: 0.58727s, reader_cost: 0.01860, ips: 83.43753 samples/s, eta: 4:22:46
[2022/06/19 01:47:03] ppcls INFO: [Train][Epoch 143/300][Avg]top1: 0.92607, CELoss: 0.21311, loss: 0.21311
[2022/06/19 01:47:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:47:09] ppcls INFO: [Train][Epoch 144/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04829022, top1: 0.92188, CELoss: 0.14895, loss: 0.14895, batch_cost: 0.62181s, reader_cost: 0.04318, ips: 102.92517 samples/s, eta: 4:38:13
[2022/06/19 01:47:16] ppcls INFO: [Train][Epoch 144/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04826274, top1: 0.93324, CELoss: 0.18244, loss: 0.18244, batch_cost: 0.78127s, reader_cost: 0.01241, ips: 81.91800 samples/s, eta: 5:49:26
[2022/06/19 01:47:22] ppcls INFO: [Train][Epoch 144/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04823525, top1: 0.93006, CELoss: 0.21032, loss: 0.21032, batch_cost: 0.68630s, reader_cost: 0.04934, ips: 93.25413 samples/s, eta: 5:06:51
[2022/06/19 01:47:28] ppcls INFO: [Train][Epoch 144/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04820776, top1: 0.92944, CELoss: 0.20793, loss: 0.20793, batch_cost: 0.63821s, reader_cost: 0.04116, ips: 100.28096 samples/s, eta: 4:45:14
[2022/06/19 01:47:34] ppcls INFO: [Train][Epoch 144/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04818028, top1: 0.92988, CELoss: 0.20093, loss: 0.20093, batch_cost: 0.63840s, reader_cost: 0.03618, ips: 100.25021 samples/s, eta: 4:45:13
[2022/06/19 01:47:41] ppcls INFO: [Train][Epoch 144/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04815279, top1: 0.93260, CELoss: 0.19722, loss: 0.19722, batch_cost: 0.64301s, reader_cost: 0.05357, ips: 99.53116 samples/s, eta: 4:47:10
[2022/06/19 01:47:47] ppcls INFO: [Train][Epoch 144/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04812530, top1: 0.93033, CELoss: 0.19814, loss: 0.19814, batch_cost: 0.63347s, reader_cost: 0.04984, ips: 101.03094 samples/s, eta: 4:42:48
[2022/06/19 01:47:53] ppcls INFO: [Train][Epoch 144/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04809780, top1: 0.93068, CELoss: 0.19617, loss: 0.19617, batch_cost: 0.63296s, reader_cost: 0.05564, ips: 101.11206 samples/s, eta: 4:42:28
[2022/06/19 01:48:00] ppcls INFO: [Train][Epoch 144/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04807031, top1: 0.92901, CELoss: 0.20078, loss: 0.20078, batch_cost: 0.63652s, reader_cost: 0.08097, ips: 100.54671 samples/s, eta: 4:43:57
[2022/06/19 01:48:06] ppcls INFO: [Train][Epoch 144/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04804282, top1: 0.92754, CELoss: 0.20392, loss: 0.20392, batch_cost: 0.63478s, reader_cost: 0.08146, ips: 100.82204 samples/s, eta: 4:43:04
[2022/06/19 01:48:12] ppcls INFO: [Train][Epoch 144/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04801532, top1: 0.92636, CELoss: 0.20831, loss: 0.20831, batch_cost: 0.63023s, reader_cost: 0.07904, ips: 101.55049 samples/s, eta: 4:40:56
[2022/06/19 01:48:18] ppcls INFO: [Train][Epoch 144/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04798783, top1: 0.92708, CELoss: 0.20840, loss: 0.20840, batch_cost: 0.62338s, reader_cost: 0.07824, ips: 102.66543 samples/s, eta: 4:37:47
[2022/06/19 01:48:24] ppcls INFO: [Train][Epoch 144/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04796033, top1: 0.92717, CELoss: 0.20787, loss: 0.20787, batch_cost: 0.62224s, reader_cost: 0.08052, ips: 102.85339 samples/s, eta: 4:37:10
[2022/06/19 01:48:31] ppcls INFO: [Train][Epoch 144/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04793283, top1: 0.92712, CELoss: 0.20809, loss: 0.20809, batch_cost: 0.62843s, reader_cost: 0.09019, ips: 101.84072 samples/s, eta: 4:39:49
[2022/06/19 01:48:36] ppcls INFO: [Train][Epoch 144/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04790533, top1: 0.92686, CELoss: 0.20882, loss: 0.20882, batch_cost: 0.62424s, reader_cost: 0.08372, ips: 102.52509 samples/s, eta: 4:37:51
[2022/06/19 01:48:45] ppcls INFO: [Train][Epoch 144/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04787783, top1: 0.92498, CELoss: 0.21321, loss: 0.21321, batch_cost: 0.63655s, reader_cost: 0.07878, ips: 100.54263 samples/s, eta: 4:43:13
[2022/06/19 01:48:48] ppcls INFO: [Train][Epoch 144/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04785033, top1: 0.92556, CELoss: 0.21177, loss: 0.21177, batch_cost: 0.62098s, reader_cost: 0.07411, ips: 103.06211 samples/s, eta: 4:36:12
[2022/06/19 01:48:51] ppcls INFO: [Train][Epoch 144/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04782282, top1: 0.92607, CELoss: 0.21020, loss: 0.21020, batch_cost: 0.59606s, reader_cost: 0.06965, ips: 82.20660 samples/s, eta: 4:25:01
[2022/06/19 01:48:51] ppcls INFO: [Train][Epoch 144/300][Avg]top1: 0.92607, CELoss: 0.21020, loss: 0.21020
[2022/06/19 01:48:51] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:48:58] ppcls INFO: [Train][Epoch 145/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04782007, top1: 0.93750, CELoss: 0.17242, loss: 0.17242, batch_cost: 0.63334s, reader_cost: 0.10658, ips: 101.05148 samples/s, eta: 4:41:34
[2022/06/19 01:49:05] ppcls INFO: [Train][Epoch 145/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04779257, top1: 0.92756, CELoss: 0.20790, loss: 0.20790, batch_cost: 0.69516s, reader_cost: 0.00817, ips: 92.06547 samples/s, eta: 5:08:57
[2022/06/19 01:49:11] ppcls INFO: [Train][Epoch 145/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04776506, top1: 0.92634, CELoss: 0.22860, loss: 0.22860, batch_cost: 0.64784s, reader_cost: 0.01528, ips: 98.78950 samples/s, eta: 4:47:48
[2022/06/19 01:49:17] ppcls INFO: [Train][Epoch 145/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04773756, top1: 0.92742, CELoss: 0.22205, loss: 0.22205, batch_cost: 0.62562s, reader_cost: 0.01487, ips: 102.29772 samples/s, eta: 4:37:50
[2022/06/19 01:49:23] ppcls INFO: [Train][Epoch 145/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04771005, top1: 0.92530, CELoss: 0.22193, loss: 0.22193, batch_cost: 0.63237s, reader_cost: 0.01269, ips: 101.20592 samples/s, eta: 4:40:43
[2022/06/19 01:49:29] ppcls INFO: [Train][Epoch 145/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04768254, top1: 0.92525, CELoss: 0.22036, loss: 0.22036, batch_cost: 0.60800s, reader_cost: 0.01318, ips: 105.26233 samples/s, eta: 4:29:48
[2022/06/19 01:49:35] ppcls INFO: [Train][Epoch 145/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04765503, top1: 0.92649, CELoss: 0.21716, loss: 0.21716, batch_cost: 0.61535s, reader_cost: 0.01400, ips: 104.00526 samples/s, eta: 4:32:58
[2022/06/19 01:49:40] ppcls INFO: [Train][Epoch 145/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04762752, top1: 0.92716, CELoss: 0.21465, loss: 0.21465, batch_cost: 0.60278s, reader_cost: 0.01595, ips: 106.17392 samples/s, eta: 4:27:17
[2022/06/19 01:49:46] ppcls INFO: [Train][Epoch 145/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04760001, top1: 0.92747, CELoss: 0.21415, loss: 0.21415, batch_cost: 0.60238s, reader_cost: 0.01603, ips: 106.24588 samples/s, eta: 4:27:00
[2022/06/19 01:49:52] ppcls INFO: [Train][Epoch 145/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04757250, top1: 0.92754, CELoss: 0.21316, loss: 0.21316, batch_cost: 0.59974s, reader_cost: 0.01588, ips: 106.71234 samples/s, eta: 4:25:44
[2022/06/19 01:49:58] ppcls INFO: [Train][Epoch 145/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04754499, top1: 0.92822, CELoss: 0.21096, loss: 0.21096, batch_cost: 0.59999s, reader_cost: 0.01557, ips: 106.66862 samples/s, eta: 4:25:45
[2022/06/19 01:50:04] ppcls INFO: [Train][Epoch 145/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04751747, top1: 0.92722, CELoss: 0.21262, loss: 0.21262, batch_cost: 0.59770s, reader_cost: 0.01744, ips: 107.07663 samples/s, eta: 4:24:38
[2022/06/19 01:50:10] ppcls INFO: [Train][Epoch 145/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04748996, top1: 0.92652, CELoss: 0.21224, loss: 0.21224, batch_cost: 0.59991s, reader_cost: 0.02129, ips: 106.68233 samples/s, eta: 4:25:31
[2022/06/19 01:50:17] ppcls INFO: [Train][Epoch 145/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04746244, top1: 0.92629, CELoss: 0.21171, loss: 0.21171, batch_cost: 0.60600s, reader_cost: 0.02114, ips: 105.61067 samples/s, eta: 4:28:06
[2022/06/19 01:50:23] ppcls INFO: [Train][Epoch 145/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04743492, top1: 0.92609, CELoss: 0.21215, loss: 0.21215, batch_cost: 0.60789s, reader_cost: 0.02004, ips: 105.28219 samples/s, eta: 4:28:50
[2022/06/19 01:50:30] ppcls INFO: [Train][Epoch 145/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04740740, top1: 0.92581, CELoss: 0.21241, loss: 0.21241, batch_cost: 0.61068s, reader_cost: 0.03055, ips: 104.80190 samples/s, eta: 4:29:58
[2022/06/19 01:50:34] ppcls INFO: [Train][Epoch 145/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04737989, top1: 0.92644, CELoss: 0.21226, loss: 0.21226, batch_cost: 0.59724s, reader_cost: 0.02896, ips: 107.15993 samples/s, eta: 4:23:56
[2022/06/19 01:50:36] ppcls INFO: [Train][Epoch 145/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04735237, top1: 0.92689, CELoss: 0.21100, loss: 0.21100, batch_cost: 0.57390s, reader_cost: 0.02727, ips: 85.38076 samples/s, eta: 4:13:31
[2022/06/19 01:50:37] ppcls INFO: [Train][Epoch 145/300][Avg]top1: 0.92689, CELoss: 0.21100, loss: 0.21100
[2022/06/19 01:50:44] ppcls INFO: [Eval][Epoch 145][Iter: 0/16]CELoss: 0.84026, loss: 0.84026, top1: 0.78711, batch_cost: 7.07497s, reader_cost: 3.88177, ips: 9.04598 images/sec
[2022/06/19 01:50:52] ppcls INFO: [Eval][Epoch 145][Iter: 10/16]CELoss: 0.72491, loss: 0.72491, top1: 0.80806, batch_cost: 0.56554s, reader_cost: 0.00268, ips: 113.16529 images/sec
[2022/06/19 01:50:53] ppcls INFO: [Eval][Epoch 145][Avg]CELoss: 0.65319, loss: 0.65319, top1: 0.81324
[2022/06/19 01:50:53] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 01:50:53] ppcls INFO: [Eval][Epoch 145][best metric: 0.813235342502594]
[2022/06/19 01:50:53] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:51:00] ppcls INFO: [Train][Epoch 146/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04734961, top1: 0.92188, CELoss: 0.21754, loss: 0.21754, batch_cost: 0.61088s, reader_cost: 0.05501, ips: 104.76716 samples/s, eta: 4:29:51
[2022/06/19 01:51:06] ppcls INFO: [Train][Epoch 146/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04732209, top1: 0.93466, CELoss: 0.19650, loss: 0.19650, batch_cost: 0.60063s, reader_cost: 0.00621, ips: 106.55478 samples/s, eta: 4:25:13
[2022/06/19 01:51:13] ppcls INFO: [Train][Epoch 146/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04729457, top1: 0.92634, CELoss: 0.21733, loss: 0.21733, batch_cost: 0.63226s, reader_cost: 0.00735, ips: 101.22456 samples/s, eta: 4:39:05
[2022/06/19 01:51:18] ppcls INFO: [Train][Epoch 146/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04726705, top1: 0.92893, CELoss: 0.21017, loss: 0.21017, batch_cost: 0.60466s, reader_cost: 0.01132, ips: 105.84373 samples/s, eta: 4:26:48
[2022/06/19 01:51:24] ppcls INFO: [Train][Epoch 146/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04723953, top1: 0.92416, CELoss: 0.21280, loss: 0.21280, batch_cost: 0.58954s, reader_cost: 0.00980, ips: 108.55882 samples/s, eta: 4:20:02
[2022/06/19 01:51:30] ppcls INFO: [Train][Epoch 146/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04721200, top1: 0.92678, CELoss: 0.20606, loss: 0.20606, batch_cost: 0.60679s, reader_cost: 0.01099, ips: 105.47267 samples/s, eta: 4:27:32
[2022/06/19 01:51:36] ppcls INFO: [Train][Epoch 146/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04718448, top1: 0.92751, CELoss: 0.20179, loss: 0.20179, batch_cost: 0.59120s, reader_cost: 0.01032, ips: 108.25483 samples/s, eta: 4:20:34
[2022/06/19 01:51:42] ppcls INFO: [Train][Epoch 146/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04715695, top1: 0.92914, CELoss: 0.20255, loss: 0.20255, batch_cost: 0.59560s, reader_cost: 0.01523, ips: 107.45495 samples/s, eta: 4:22:24
[2022/06/19 01:51:47] ppcls INFO: [Train][Epoch 146/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04712942, top1: 0.92978, CELoss: 0.20427, loss: 0.20427, batch_cost: 0.58700s, reader_cost: 0.01426, ips: 109.02900 samples/s, eta: 4:18:31
[2022/06/19 01:51:55] ppcls INFO: [Train][Epoch 146/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04710190, top1: 0.92943, CELoss: 0.20565, loss: 0.20565, batch_cost: 0.61061s, reader_cost: 0.01432, ips: 104.81322 samples/s, eta: 4:28:49
[2022/06/19 01:52:00] ppcls INFO: [Train][Epoch 146/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04707437, top1: 0.92868, CELoss: 0.20700, loss: 0.20700, batch_cost: 0.59887s, reader_cost: 0.01414, ips: 106.86778 samples/s, eta: 4:23:33
[2022/06/19 01:52:06] ppcls INFO: [Train][Epoch 146/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04704684, top1: 0.92891, CELoss: 0.20665, loss: 0.20665, batch_cost: 0.59804s, reader_cost: 0.01294, ips: 107.01600 samples/s, eta: 4:23:05
[2022/06/19 01:52:11] ppcls INFO: [Train][Epoch 146/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04701931, top1: 0.92833, CELoss: 0.20634, loss: 0.20634, batch_cost: 0.59406s, reader_cost: 0.01219, ips: 107.73274 samples/s, eta: 4:21:14
[2022/06/19 01:52:19] ppcls INFO: [Train][Epoch 146/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04699178, top1: 0.92808, CELoss: 0.20622, loss: 0.20622, batch_cost: 0.60310s, reader_cost: 0.01205, ips: 106.11769 samples/s, eta: 4:25:06
[2022/06/19 01:52:24] ppcls INFO: [Train][Epoch 146/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04696425, top1: 0.92830, CELoss: 0.20491, loss: 0.20491, batch_cost: 0.59719s, reader_cost: 0.01264, ips: 107.16784 samples/s, eta: 4:22:25
[2022/06/19 01:52:28] ppcls INFO: [Train][Epoch 146/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04693672, top1: 0.92736, CELoss: 0.20683, loss: 0.20683, batch_cost: 0.58682s, reader_cost: 0.01206, ips: 109.06199 samples/s, eta: 4:17:45
[2022/06/19 01:52:35] ppcls INFO: [Train][Epoch 146/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04690918, top1: 0.92605, CELoss: 0.20872, loss: 0.20872, batch_cost: 0.59400s, reader_cost: 0.01152, ips: 107.74333 samples/s, eta: 4:20:49
[2022/06/19 01:52:37] ppcls INFO: [Train][Epoch 146/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04688165, top1: 0.92653, CELoss: 0.20892, loss: 0.20892, batch_cost: 0.57075s, reader_cost: 0.01085, ips: 85.85266 samples/s, eta: 4:10:30
[2022/06/19 01:52:38] ppcls INFO: [Train][Epoch 146/300][Avg]top1: 0.92653, CELoss: 0.20892, loss: 0.20892
[2022/06/19 01:52:38] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:52:45] ppcls INFO: [Train][Epoch 147/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04687890, top1: 0.89062, CELoss: 0.29823, loss: 0.29823, batch_cost: 0.60795s, reader_cost: 0.04473, ips: 105.27187 samples/s, eta: 4:26:49
[2022/06/19 01:52:51] ppcls INFO: [Train][Epoch 147/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04685136, top1: 0.93608, CELoss: 0.18339, loss: 0.18339, batch_cost: 0.67020s, reader_cost: 0.08576, ips: 95.49404 samples/s, eta: 4:54:02
[2022/06/19 01:52:58] ppcls INFO: [Train][Epoch 147/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04682383, top1: 0.92188, CELoss: 0.20646, loss: 0.20646, batch_cost: 0.66296s, reader_cost: 0.03254, ips: 96.53607 samples/s, eta: 4:50:45
[2022/06/19 01:53:04] ppcls INFO: [Train][Epoch 147/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04679629, top1: 0.92893, CELoss: 0.19307, loss: 0.19307, batch_cost: 0.63828s, reader_cost: 0.02115, ips: 100.27010 samples/s, eta: 4:39:49
[2022/06/19 01:53:10] ppcls INFO: [Train][Epoch 147/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04676876, top1: 0.93216, CELoss: 0.18636, loss: 0.18636, batch_cost: 0.62525s, reader_cost: 0.01959, ips: 102.35880 samples/s, eta: 4:34:00
[2022/06/19 01:53:16] ppcls INFO: [Train][Epoch 147/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04674122, top1: 0.92984, CELoss: 0.19571, loss: 0.19571, batch_cost: 0.62835s, reader_cost: 0.02117, ips: 101.85435 samples/s, eta: 4:35:15
[2022/06/19 01:53:22] ppcls INFO: [Train][Epoch 147/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04671368, top1: 0.92853, CELoss: 0.19798, loss: 0.19798, batch_cost: 0.62334s, reader_cost: 0.01905, ips: 102.67341 samples/s, eta: 4:32:57
[2022/06/19 01:53:28] ppcls INFO: [Train][Epoch 147/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04668614, top1: 0.93046, CELoss: 0.19497, loss: 0.19497, batch_cost: 0.61481s, reader_cost: 0.01862, ips: 104.09784 samples/s, eta: 4:29:07
[2022/06/19 01:53:35] ppcls INFO: [Train][Epoch 147/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04665861, top1: 0.92959, CELoss: 0.19811, loss: 0.19811, batch_cost: 0.62340s, reader_cost: 0.01821, ips: 102.66323 samples/s, eta: 4:32:46
[2022/06/19 01:53:41] ppcls INFO: [Train][Epoch 147/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04663107, top1: 0.92960, CELoss: 0.19731, loss: 0.19731, batch_cost: 0.62302s, reader_cost: 0.01696, ips: 102.72590 samples/s, eta: 4:32:30
[2022/06/19 01:53:47] ppcls INFO: [Train][Epoch 147/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04660353, top1: 0.92976, CELoss: 0.19555, loss: 0.19555, batch_cost: 0.61779s, reader_cost: 0.01677, ips: 103.59554 samples/s, eta: 4:30:07
[2022/06/19 01:53:53] ppcls INFO: [Train][Epoch 147/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04657599, top1: 0.92976, CELoss: 0.19845, loss: 0.19845, batch_cost: 0.62238s, reader_cost: 0.01784, ips: 102.83128 samples/s, eta: 4:32:01
[2022/06/19 01:53:59] ppcls INFO: [Train][Epoch 147/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04654844, top1: 0.92988, CELoss: 0.19821, loss: 0.19821, batch_cost: 0.61785s, reader_cost: 0.01774, ips: 103.58482 samples/s, eta: 4:29:56
[2022/06/19 01:54:04] ppcls INFO: [Train][Epoch 147/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04652090, top1: 0.92903, CELoss: 0.19946, loss: 0.19946, batch_cost: 0.60863s, reader_cost: 0.01708, ips: 105.15484 samples/s, eta: 4:25:48
[2022/06/19 01:54:10] ppcls INFO: [Train][Epoch 147/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04649336, top1: 0.92875, CELoss: 0.19990, loss: 0.19990, batch_cost: 0.61026s, reader_cost: 0.01786, ips: 104.87290 samples/s, eta: 4:26:25
[2022/06/19 01:54:17] ppcls INFO: [Train][Epoch 147/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04646582, top1: 0.92808, CELoss: 0.20086, loss: 0.20086, batch_cost: 0.61686s, reader_cost: 0.01821, ips: 103.75059 samples/s, eta: 4:29:11
[2022/06/19 01:54:22] ppcls INFO: [Train][Epoch 147/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04643827, top1: 0.92760, CELoss: 0.20333, loss: 0.20333, batch_cost: 0.60665s, reader_cost: 0.01739, ips: 105.49766 samples/s, eta: 4:24:38
[2022/06/19 01:54:24] ppcls INFO: [Train][Epoch 147/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04641073, top1: 0.92744, CELoss: 0.20399, loss: 0.20399, batch_cost: 0.58268s, reader_cost: 0.01641, ips: 84.09414 samples/s, eta: 4:14:05
[2022/06/19 01:54:25] ppcls INFO: [Train][Epoch 147/300][Avg]top1: 0.92744, CELoss: 0.20399, loss: 0.20399
[2022/06/19 01:54:25] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:54:30] ppcls INFO: [Train][Epoch 148/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04640798, top1: 0.93750, CELoss: 0.12305, loss: 0.12305, batch_cost: 0.61288s, reader_cost: 0.04625, ips: 104.42452 samples/s, eta: 4:27:14
[2022/06/19 01:54:38] ppcls INFO: [Train][Epoch 148/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04638043, top1: 0.93466, CELoss: 0.19460, loss: 0.19460, batch_cost: 0.59990s, reader_cost: 0.00743, ips: 106.68420 samples/s, eta: 4:21:29
[2022/06/19 01:54:44] ppcls INFO: [Train][Epoch 148/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04635289, top1: 0.93304, CELoss: 0.19566, loss: 0.19566, batch_cost: 0.60631s, reader_cost: 0.02133, ips: 105.55579 samples/s, eta: 4:24:10
[2022/06/19 01:54:50] ppcls INFO: [Train][Epoch 148/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04632534, top1: 0.92792, CELoss: 0.20160, loss: 0.20160, batch_cost: 0.61568s, reader_cost: 0.01741, ips: 103.95015 samples/s, eta: 4:28:09
[2022/06/19 01:54:58] ppcls INFO: [Train][Epoch 148/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04629779, top1: 0.92683, CELoss: 0.20376, loss: 0.20376, batch_cost: 0.64711s, reader_cost: 0.01546, ips: 98.90100 samples/s, eta: 4:41:44
[2022/06/19 01:55:03] ppcls INFO: [Train][Epoch 148/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04627025, top1: 0.92678, CELoss: 0.20711, loss: 0.20711, batch_cost: 0.62875s, reader_cost: 0.01448, ips: 101.78871 samples/s, eta: 4:33:38
[2022/06/19 01:55:09] ppcls INFO: [Train][Epoch 148/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04624270, top1: 0.92674, CELoss: 0.20730, loss: 0.20730, batch_cost: 0.62187s, reader_cost: 0.01353, ips: 102.91577 samples/s, eta: 4:30:32
[2022/06/19 01:55:16] ppcls INFO: [Train][Epoch 148/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04621515, top1: 0.92716, CELoss: 0.20518, loss: 0.20518, batch_cost: 0.62919s, reader_cost: 0.01495, ips: 101.71831 samples/s, eta: 4:33:37
[2022/06/19 01:55:22] ppcls INFO: [Train][Epoch 148/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04618760, top1: 0.92593, CELoss: 0.20361, loss: 0.20361, batch_cost: 0.62551s, reader_cost: 0.01477, ips: 102.31621 samples/s, eta: 4:31:55
[2022/06/19 01:55:27] ppcls INFO: [Train][Epoch 148/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04616006, top1: 0.92823, CELoss: 0.19959, loss: 0.19959, batch_cost: 0.61563s, reader_cost: 0.01649, ips: 103.95897 samples/s, eta: 4:27:31
[2022/06/19 01:55:34] ppcls INFO: [Train][Epoch 148/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04613251, top1: 0.92621, CELoss: 0.20332, loss: 0.20332, batch_cost: 0.61491s, reader_cost: 0.01744, ips: 104.08005 samples/s, eta: 4:27:06
[2022/06/19 01:55:41] ppcls INFO: [Train][Epoch 148/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04610496, top1: 0.92708, CELoss: 0.20040, loss: 0.20040, batch_cost: 0.62216s, reader_cost: 0.01695, ips: 102.86755 samples/s, eta: 4:30:09
[2022/06/19 01:55:46] ppcls INFO: [Train][Epoch 148/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04607741, top1: 0.92678, CELoss: 0.20041, loss: 0.20041, batch_cost: 0.61248s, reader_cost: 0.01660, ips: 104.49250 samples/s, eta: 4:25:50
[2022/06/19 01:55:52] ppcls INFO: [Train][Epoch 148/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04604986, top1: 0.92748, CELoss: 0.19862, loss: 0.19862, batch_cost: 0.61205s, reader_cost: 0.01567, ips: 104.56703 samples/s, eta: 4:25:33
[2022/06/19 01:55:59] ppcls INFO: [Train][Epoch 148/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04602231, top1: 0.92775, CELoss: 0.19785, loss: 0.19785, batch_cost: 0.61852s, reader_cost: 0.02198, ips: 103.47332 samples/s, eta: 4:28:15
[2022/06/19 01:56:04] ppcls INFO: [Train][Epoch 148/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04599476, top1: 0.92870, CELoss: 0.19552, loss: 0.19552, batch_cost: 0.61459s, reader_cost: 0.02434, ips: 104.13526 samples/s, eta: 4:26:27
[2022/06/19 01:56:10] ppcls INFO: [Train][Epoch 148/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04596721, top1: 0.92993, CELoss: 0.19366, loss: 0.19366, batch_cost: 0.61017s, reader_cost: 0.02771, ips: 104.88834 samples/s, eta: 4:24:26
[2022/06/19 01:56:12] ppcls INFO: [Train][Epoch 148/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04593965, top1: 0.92872, CELoss: 0.19672, loss: 0.19672, batch_cost: 0.58585s, reader_cost: 0.02607, ips: 83.63884 samples/s, eta: 4:13:48
[2022/06/19 01:56:12] ppcls INFO: [Train][Epoch 148/300][Avg]top1: 0.92872, CELoss: 0.19672, loss: 0.19672
[2022/06/19 01:56:13] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:56:19] ppcls INFO: [Train][Epoch 149/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04593690, top1: 0.90625, CELoss: 0.30579, loss: 0.30579, batch_cost: 0.62102s, reader_cost: 0.05749, ips: 103.05678 samples/s, eta: 4:29:01
[2022/06/19 01:56:25] ppcls INFO: [Train][Epoch 149/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04590935, top1: 0.94176, CELoss: 0.17677, loss: 0.17677, batch_cost: 0.60234s, reader_cost: 0.00685, ips: 106.25215 samples/s, eta: 4:20:50
[2022/06/19 01:56:31] ppcls INFO: [Train][Epoch 149/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04588179, top1: 0.94420, CELoss: 0.16711, loss: 0.16711, batch_cost: 0.59523s, reader_cost: 0.02025, ips: 107.52107 samples/s, eta: 4:17:39
[2022/06/19 01:56:38] ppcls INFO: [Train][Epoch 149/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04585424, top1: 0.94002, CELoss: 0.17491, loss: 0.17491, batch_cost: 0.64241s, reader_cost: 0.02207, ips: 99.62515 samples/s, eta: 4:37:58
[2022/06/19 01:56:45] ppcls INFO: [Train][Epoch 149/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04582669, top1: 0.93788, CELoss: 0.17769, loss: 0.17769, batch_cost: 0.64198s, reader_cost: 0.02011, ips: 99.69222 samples/s, eta: 4:37:40
[2022/06/19 01:56:51] ppcls INFO: [Train][Epoch 149/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04579914, top1: 0.93811, CELoss: 0.17941, loss: 0.17941, batch_cost: 0.62815s, reader_cost: 0.01711, ips: 101.88677 samples/s, eta: 4:31:35
[2022/06/19 01:56:57] ppcls INFO: [Train][Epoch 149/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04577158, top1: 0.93622, CELoss: 0.18735, loss: 0.18735, batch_cost: 0.62358s, reader_cost: 0.01832, ips: 102.63280 samples/s, eta: 4:29:30
[2022/06/19 01:57:02] ppcls INFO: [Train][Epoch 149/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04574403, top1: 0.93640, CELoss: 0.18907, loss: 0.18907, batch_cost: 0.61528s, reader_cost: 0.02093, ips: 104.01722 samples/s, eta: 4:25:49
[2022/06/19 01:57:10] ppcls INFO: [Train][Epoch 149/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04571647, top1: 0.93345, CELoss: 0.19536, loss: 0.19536, batch_cost: 0.62799s, reader_cost: 0.01958, ips: 101.91174 samples/s, eta: 4:31:12
[2022/06/19 01:57:15] ppcls INFO: [Train][Epoch 149/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04568892, top1: 0.93252, CELoss: 0.19700, loss: 0.19700, batch_cost: 0.62223s, reader_cost: 0.01880, ips: 102.85661 samples/s, eta: 4:28:36
[2022/06/19 01:57:21] ppcls INFO: [Train][Epoch 149/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04566136, top1: 0.93178, CELoss: 0.19866, loss: 0.19866, batch_cost: 0.61989s, reader_cost: 0.01911, ips: 103.24368 samples/s, eta: 4:27:30
[2022/06/19 01:57:28] ppcls INFO: [Train][Epoch 149/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04563381, top1: 0.93131, CELoss: 0.19796, loss: 0.19796, batch_cost: 0.62354s, reader_cost: 0.01811, ips: 102.64014 samples/s, eta: 4:28:58
[2022/06/19 01:57:34] ppcls INFO: [Train][Epoch 149/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04560625, top1: 0.93027, CELoss: 0.19937, loss: 0.19937, batch_cost: 0.62434s, reader_cost: 0.01750, ips: 102.50873 samples/s, eta: 4:29:12
[2022/06/19 01:57:41] ppcls INFO: [Train][Epoch 149/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04557870, top1: 0.92867, CELoss: 0.20204, loss: 0.20204, batch_cost: 0.62402s, reader_cost: 0.01673, ips: 102.56136 samples/s, eta: 4:28:58
[2022/06/19 01:57:47] ppcls INFO: [Train][Epoch 149/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04555114, top1: 0.92919, CELoss: 0.20162, loss: 0.20162, batch_cost: 0.62429s, reader_cost: 0.01698, ips: 102.51653 samples/s, eta: 4:28:59
[2022/06/19 01:57:53] ppcls INFO: [Train][Epoch 149/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04552359, top1: 0.93046, CELoss: 0.19994, loss: 0.19994, batch_cost: 0.62449s, reader_cost: 0.01663, ips: 102.48403 samples/s, eta: 4:28:58
[2022/06/19 01:57:58] ppcls INFO: [Train][Epoch 149/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04549603, top1: 0.93012, CELoss: 0.20060, loss: 0.20060, batch_cost: 0.61630s, reader_cost: 0.01640, ips: 103.84525 samples/s, eta: 4:25:20
[2022/06/19 01:58:00] ppcls INFO: [Train][Epoch 149/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04546847, top1: 0.92991, CELoss: 0.20103, loss: 0.20103, batch_cost: 0.59188s, reader_cost: 0.01544, ips: 82.78755 samples/s, eta: 4:14:43
[2022/06/19 01:58:01] ppcls INFO: [Train][Epoch 149/300][Avg]top1: 0.92991, CELoss: 0.20103, loss: 0.20103
[2022/06/19 01:58:01] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 01:58:07] ppcls INFO: [Train][Epoch 150/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04546572, top1: 0.92188, CELoss: 0.24062, loss: 0.24062, batch_cost: 0.62260s, reader_cost: 0.04247, ips: 102.79469 samples/s, eta: 4:27:56
[2022/06/19 01:58:14] ppcls INFO: [Train][Epoch 150/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04543816, top1: 0.90341, CELoss: 0.26196, loss: 0.26196, batch_cost: 0.62130s, reader_cost: 0.01826, ips: 103.00951 samples/s, eta: 4:27:16
[2022/06/19 01:58:21] ppcls INFO: [Train][Epoch 150/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04541061, top1: 0.91220, CELoss: 0.23979, loss: 0.23979, batch_cost: 0.63146s, reader_cost: 0.02213, ips: 101.35228 samples/s, eta: 4:31:32
[2022/06/19 01:58:27] ppcls INFO: [Train][Epoch 150/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04538305, top1: 0.91885, CELoss: 0.22496, loss: 0.22496, batch_cost: 0.62044s, reader_cost: 0.02210, ips: 103.15312 samples/s, eta: 4:26:41
[2022/06/19 01:58:32] ppcls INFO: [Train][Epoch 150/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04535549, top1: 0.92149, CELoss: 0.22050, loss: 0.22050, batch_cost: 0.60145s, reader_cost: 0.01937, ips: 106.40879 samples/s, eta: 4:18:26
[2022/06/19 01:58:38] ppcls INFO: [Train][Epoch 150/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04532794, top1: 0.92310, CELoss: 0.21486, loss: 0.21486, batch_cost: 0.60331s, reader_cost: 0.01711, ips: 106.08127 samples/s, eta: 4:19:07
[2022/06/19 01:58:45] ppcls INFO: [Train][Epoch 150/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04530038, top1: 0.92546, CELoss: 0.21343, loss: 0.21343, batch_cost: 0.61691s, reader_cost: 0.01729, ips: 103.74259 samples/s, eta: 4:24:52
[2022/06/19 01:58:51] ppcls INFO: [Train][Epoch 150/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04527282, top1: 0.92694, CELoss: 0.21032, loss: 0.21032, batch_cost: 0.60665s, reader_cost: 0.01843, ips: 105.49709 samples/s, eta: 4:20:21
[2022/06/19 01:58:58] ppcls INFO: [Train][Epoch 150/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04524526, top1: 0.92843, CELoss: 0.20663, loss: 0.20663, batch_cost: 0.62431s, reader_cost: 0.02172, ips: 102.51300 samples/s, eta: 4:27:50
[2022/06/19 01:59:05] ppcls INFO: [Train][Epoch 150/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04521771, top1: 0.93012, CELoss: 0.20395, loss: 0.20395, batch_cost: 0.63701s, reader_cost: 0.02561, ips: 100.46999 samples/s, eta: 4:33:10
[2022/06/19 01:59:10] ppcls INFO: [Train][Epoch 150/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04519015, top1: 0.93054, CELoss: 0.20252, loss: 0.20252, batch_cost: 0.61710s, reader_cost: 0.02356, ips: 103.71016 samples/s, eta: 4:24:32
[2022/06/19 01:59:17] ppcls INFO: [Train][Epoch 150/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04516259, top1: 0.92990, CELoss: 0.20160, loss: 0.20160, batch_cost: 0.62880s, reader_cost: 0.02338, ips: 101.78159 samples/s, eta: 4:29:27
[2022/06/19 01:59:22] ppcls INFO: [Train][Epoch 150/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04513503, top1: 0.93104, CELoss: 0.20055, loss: 0.20055, batch_cost: 0.61404s, reader_cost: 0.02201, ips: 104.22815 samples/s, eta: 4:23:01
[2022/06/19 01:59:29] ppcls INFO: [Train][Epoch 150/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04510748, top1: 0.93189, CELoss: 0.20032, loss: 0.20032, batch_cost: 0.61925s, reader_cost: 0.02127, ips: 103.35037 samples/s, eta: 4:25:09
[2022/06/19 01:59:35] ppcls INFO: [Train][Epoch 150/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04507992, top1: 0.93207, CELoss: 0.20004, loss: 0.20004, batch_cost: 0.62292s, reader_cost: 0.02043, ips: 102.74186 samples/s, eta: 4:26:37
[2022/06/19 01:59:40] ppcls INFO: [Train][Epoch 150/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04505236, top1: 0.93171, CELoss: 0.20191, loss: 0.20191, batch_cost: 0.61530s, reader_cost: 0.01988, ips: 104.01425 samples/s, eta: 4:23:15
[2022/06/19 01:59:45] ppcls INFO: [Train][Epoch 150/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04502480, top1: 0.93148, CELoss: 0.20172, loss: 0.20172, batch_cost: 0.60713s, reader_cost: 0.01928, ips: 105.41450 samples/s, eta: 4:19:39
[2022/06/19 01:59:47] ppcls INFO: [Train][Epoch 150/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04499724, top1: 0.93128, CELoss: 0.20208, loss: 0.20208, batch_cost: 0.58307s, reader_cost: 0.01816, ips: 84.03863 samples/s, eta: 4:09:16
[2022/06/19 01:59:48] ppcls INFO: [Train][Epoch 150/300][Avg]top1: 0.93128, CELoss: 0.20208, loss: 0.20208
[2022/06/19 01:59:55] ppcls INFO: [Eval][Epoch 150][Iter: 0/16]CELoss: 1.05356, loss: 1.05356, top1: 0.78125, batch_cost: 6.98304s, reader_cost: 3.54526, ips: 9.16506 images/sec
[2022/06/19 02:00:03] ppcls INFO: [Eval][Epoch 150][Iter: 10/16]CELoss: 0.96299, loss: 0.96299, top1: 0.79031, batch_cost: 0.56488s, reader_cost: 0.00158, ips: 113.29758 images/sec
[2022/06/19 02:00:05] ppcls INFO: [Eval][Epoch 150][Avg]CELoss: 0.75441, loss: 0.75441, top1: 0.79547
[2022/06/19 02:00:05] ppcls INFO: [Eval][Epoch 150][best metric: 0.813235342502594]
[2022/06/19 02:00:05] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_150
[2022/06/19 02:00:05] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:00:13] ppcls INFO: [Train][Epoch 151/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04499449, top1: 0.89062, CELoss: 0.26605, loss: 0.26605, batch_cost: 0.62626s, reader_cost: 0.05199, ips: 102.19405 samples/s, eta: 4:27:43
[2022/06/19 02:00:20] ppcls INFO: [Train][Epoch 151/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04496693, top1: 0.94176, CELoss: 0.18356, loss: 0.18356, batch_cost: 0.87125s, reader_cost: 0.00299, ips: 73.45797 samples/s, eta: 6:12:18
[2022/06/19 02:00:25] ppcls INFO: [Train][Epoch 151/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04493937, top1: 0.92411, CELoss: 0.21910, loss: 0.21910, batch_cost: 0.66915s, reader_cost: 0.00132, ips: 95.64327 samples/s, eta: 4:45:50
[2022/06/19 02:00:31] ppcls INFO: [Train][Epoch 151/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04491182, top1: 0.92944, CELoss: 0.20965, loss: 0.20965, batch_cost: 0.64165s, reader_cost: 0.00466, ips: 99.74267 samples/s, eta: 4:33:59
[2022/06/19 02:00:38] ppcls INFO: [Train][Epoch 151/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04488426, top1: 0.93102, CELoss: 0.20157, loss: 0.20157, batch_cost: 0.66349s, reader_cost: 0.00782, ips: 96.46004 samples/s, eta: 4:43:11
[2022/06/19 02:00:44] ppcls INFO: [Train][Epoch 151/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04485670, top1: 0.93413, CELoss: 0.19269, loss: 0.19269, batch_cost: 0.65176s, reader_cost: 0.00754, ips: 98.19640 samples/s, eta: 4:38:04
[2022/06/19 02:00:50] ppcls INFO: [Train][Epoch 151/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04482914, top1: 0.93443, CELoss: 0.19056, loss: 0.19056, batch_cost: 0.63919s, reader_cost: 0.00847, ips: 100.12690 samples/s, eta: 4:32:36
[2022/06/19 02:00:56] ppcls INFO: [Train][Epoch 151/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04480158, top1: 0.93574, CELoss: 0.19131, loss: 0.19131, batch_cost: 0.62691s, reader_cost: 0.00832, ips: 102.08752 samples/s, eta: 4:27:16
[2022/06/19 02:01:02] ppcls INFO: [Train][Epoch 151/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04477403, top1: 0.93480, CELoss: 0.19240, loss: 0.19240, batch_cost: 0.62878s, reader_cost: 0.00820, ips: 101.78465 samples/s, eta: 4:27:57
[2022/06/19 02:01:10] ppcls INFO: [Train][Epoch 151/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04474647, top1: 0.93355, CELoss: 0.19358, loss: 0.19358, batch_cost: 0.64285s, reader_cost: 0.00791, ips: 99.55616 samples/s, eta: 4:33:51
[2022/06/19 02:01:16] ppcls INFO: [Train][Epoch 151/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04471891, top1: 0.93472, CELoss: 0.19121, loss: 0.19121, batch_cost: 0.64052s, reader_cost: 0.00764, ips: 99.91809 samples/s, eta: 4:32:45
[2022/06/19 02:01:22] ppcls INFO: [Train][Epoch 151/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04469135, top1: 0.93300, CELoss: 0.19387, loss: 0.19387, batch_cost: 0.63562s, reader_cost: 0.00747, ips: 100.68941 samples/s, eta: 4:30:33
[2022/06/19 02:01:27] ppcls INFO: [Train][Epoch 151/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04466380, top1: 0.93350, CELoss: 0.19149, loss: 0.19149, batch_cost: 0.62990s, reader_cost: 0.00793, ips: 101.60332 samples/s, eta: 4:28:01
[2022/06/19 02:01:35] ppcls INFO: [Train][Epoch 151/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04463624, top1: 0.93404, CELoss: 0.18917, loss: 0.18917, batch_cost: 0.63713s, reader_cost: 0.00879, ips: 100.45103 samples/s, eta: 4:30:59
[2022/06/19 02:01:40] ppcls INFO: [Train][Epoch 151/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04460868, top1: 0.93418, CELoss: 0.19116, loss: 0.19116, batch_cost: 0.63015s, reader_cost: 0.00927, ips: 101.56254 samples/s, eta: 4:27:55
[2022/06/19 02:01:46] ppcls INFO: [Train][Epoch 151/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04458113, top1: 0.93264, CELoss: 0.19493, loss: 0.19493, batch_cost: 0.62793s, reader_cost: 0.00895, ips: 101.92190 samples/s, eta: 4:26:52
[2022/06/19 02:01:51] ppcls INFO: [Train][Epoch 151/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04455357, top1: 0.93245, CELoss: 0.19586, loss: 0.19586, batch_cost: 0.61944s, reader_cost: 0.00929, ips: 103.31856 samples/s, eta: 4:23:09
[2022/06/19 02:01:53] ppcls INFO: [Train][Epoch 151/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04452601, top1: 0.93174, CELoss: 0.19824, loss: 0.19824, batch_cost: 0.59587s, reader_cost: 0.00877, ips: 82.23311 samples/s, eta: 4:13:02
[2022/06/19 02:01:54] ppcls INFO: [Train][Epoch 151/300][Avg]top1: 0.93174, CELoss: 0.19824, loss: 0.19824
[2022/06/19 02:01:54] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:02:01] ppcls INFO: [Train][Epoch 152/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04452326, top1: 0.90625, CELoss: 0.23797, loss: 0.23797, batch_cost: 0.63428s, reader_cost: 0.04373, ips: 100.90119 samples/s, eta: 4:29:20
[2022/06/19 02:02:07] ppcls INFO: [Train][Epoch 152/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04449570, top1: 0.92330, CELoss: 0.21058, loss: 0.21058, batch_cost: 0.64747s, reader_cost: 0.00452, ips: 98.84599 samples/s, eta: 4:34:50
[2022/06/19 02:02:14] ppcls INFO: [Train][Epoch 152/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04446815, top1: 0.93452, CELoss: 0.18706, loss: 0.18706, batch_cost: 0.65603s, reader_cost: 0.05549, ips: 97.55618 samples/s, eta: 4:38:21
[2022/06/19 02:02:20] ppcls INFO: [Train][Epoch 152/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04444059, top1: 0.92641, CELoss: 0.20903, loss: 0.20903, batch_cost: 0.64208s, reader_cost: 0.10253, ips: 99.67610 samples/s, eta: 4:32:20
[2022/06/19 02:02:26] ppcls INFO: [Train][Epoch 152/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04441304, top1: 0.92912, CELoss: 0.19720, loss: 0.19720, batch_cost: 0.63329s, reader_cost: 0.11119, ips: 101.05969 samples/s, eta: 4:28:30
[2022/06/19 02:02:32] ppcls INFO: [Train][Epoch 152/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04438548, top1: 0.93137, CELoss: 0.19488, loss: 0.19488, batch_cost: 0.62996s, reader_cost: 0.09974, ips: 101.59411 samples/s, eta: 4:26:59
[2022/06/19 02:02:38] ppcls INFO: [Train][Epoch 152/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04435792, top1: 0.93289, CELoss: 0.19424, loss: 0.19424, batch_cost: 0.61608s, reader_cost: 0.08522, ips: 103.88279 samples/s, eta: 4:21:00
[2022/06/19 02:02:43] ppcls INFO: [Train][Epoch 152/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04433037, top1: 0.93310, CELoss: 0.19426, loss: 0.19426, batch_cost: 0.60565s, reader_cost: 0.07413, ips: 105.67168 samples/s, eta: 4:16:28
[2022/06/19 02:02:50] ppcls INFO: [Train][Epoch 152/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04430281, top1: 0.93383, CELoss: 0.19276, loss: 0.19276, batch_cost: 0.61298s, reader_cost: 0.07642, ips: 104.40755 samples/s, eta: 4:19:29
[2022/06/19 02:02:57] ppcls INFO: [Train][Epoch 152/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04427526, top1: 0.93218, CELoss: 0.19884, loss: 0.19884, batch_cost: 0.62402s, reader_cost: 0.09220, ips: 102.56064 samples/s, eta: 4:24:03
[2022/06/19 02:03:03] ppcls INFO: [Train][Epoch 152/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04424771, top1: 0.93100, CELoss: 0.20280, loss: 0.20280, batch_cost: 0.61448s, reader_cost: 0.08691, ips: 104.15266 samples/s, eta: 4:19:54
[2022/06/19 02:03:10] ppcls INFO: [Train][Epoch 152/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04422015, top1: 0.93173, CELoss: 0.19972, loss: 0.19972, batch_cost: 0.62451s, reader_cost: 0.10060, ips: 102.48045 samples/s, eta: 4:24:03
[2022/06/19 02:03:15] ppcls INFO: [Train][Epoch 152/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04419260, top1: 0.93208, CELoss: 0.19899, loss: 0.19899, batch_cost: 0.62050s, reader_cost: 0.09348, ips: 103.14299 samples/s, eta: 4:22:15
[2022/06/19 02:03:22] ppcls INFO: [Train][Epoch 152/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04416505, top1: 0.93273, CELoss: 0.19701, loss: 0.19701, batch_cost: 0.62113s, reader_cost: 0.09727, ips: 103.03864 samples/s, eta: 4:22:24
[2022/06/19 02:03:28] ppcls INFO: [Train][Epoch 152/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04413749, top1: 0.93207, CELoss: 0.20016, loss: 0.20016, batch_cost: 0.62395s, reader_cost: 0.10791, ips: 102.57256 samples/s, eta: 4:23:30
[2022/06/19 02:03:33] ppcls INFO: [Train][Epoch 152/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04410994, top1: 0.93160, CELoss: 0.20101, loss: 0.20101, batch_cost: 0.61475s, reader_cost: 0.10139, ips: 104.10687 samples/s, eta: 4:19:31
[2022/06/19 02:03:38] ppcls INFO: [Train][Epoch 152/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04408239, top1: 0.93080, CELoss: 0.20230, loss: 0.20230, batch_cost: 0.60676s, reader_cost: 0.09516, ips: 105.47795 samples/s, eta: 4:16:02
[2022/06/19 02:03:40] ppcls INFO: [Train][Epoch 152/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04405484, top1: 0.93046, CELoss: 0.20319, loss: 0.20319, batch_cost: 0.58301s, reader_cost: 0.08944, ips: 84.04642 samples/s, eta: 4:05:55
[2022/06/19 02:03:41] ppcls INFO: [Train][Epoch 152/300][Avg]top1: 0.93046, CELoss: 0.20319, loss: 0.20319
[2022/06/19 02:03:41] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:03:47] ppcls INFO: [Train][Epoch 153/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04405208, top1: 0.92188, CELoss: 0.20577, loss: 0.20577, batch_cost: 0.61804s, reader_cost: 0.11789, ips: 103.55391 samples/s, eta: 4:20:41
[2022/06/19 02:03:56] ppcls INFO: [Train][Epoch 153/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04402453, top1: 0.93040, CELoss: 0.20623, loss: 0.20623, batch_cost: 0.90253s, reader_cost: 0.00428, ips: 70.91191 samples/s, eta: 6:20:32
[2022/06/19 02:04:01] ppcls INFO: [Train][Epoch 153/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04399698, top1: 0.92634, CELoss: 0.20131, loss: 0.20131, batch_cost: 0.68047s, reader_cost: 0.02507, ips: 94.05331 samples/s, eta: 4:46:47
[2022/06/19 02:04:07] ppcls INFO: [Train][Epoch 153/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04396943, top1: 0.93044, CELoss: 0.19811, loss: 0.19811, batch_cost: 0.64907s, reader_cost: 0.02258, ips: 98.60201 samples/s, eta: 4:33:27
[2022/06/19 02:04:14] ppcls INFO: [Train][Epoch 153/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04394188, top1: 0.92950, CELoss: 0.19972, loss: 0.19972, batch_cost: 0.65214s, reader_cost: 0.01954, ips: 98.13871 samples/s, eta: 4:34:38
[2022/06/19 02:04:20] ppcls INFO: [Train][Epoch 153/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04391433, top1: 0.93045, CELoss: 0.20318, loss: 0.20318, batch_cost: 0.64111s, reader_cost: 0.02121, ips: 99.82640 samples/s, eta: 4:29:53
[2022/06/19 02:04:26] ppcls INFO: [Train][Epoch 153/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04388678, top1: 0.92802, CELoss: 0.20932, loss: 0.20932, batch_cost: 0.63562s, reader_cost: 0.02099, ips: 100.68903 samples/s, eta: 4:27:28
[2022/06/19 02:04:31] ppcls INFO: [Train][Epoch 153/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04385923, top1: 0.92320, CELoss: 0.21692, loss: 0.21692, batch_cost: 0.62238s, reader_cost: 0.02167, ips: 102.83075 samples/s, eta: 4:21:47
[2022/06/19 02:04:38] ppcls INFO: [Train][Epoch 153/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04383168, top1: 0.92342, CELoss: 0.21893, loss: 0.21893, batch_cost: 0.62591s, reader_cost: 0.02047, ips: 102.25123 samples/s, eta: 4:23:10
[2022/06/19 02:04:43] ppcls INFO: [Train][Epoch 153/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04380413, top1: 0.92548, CELoss: 0.21383, loss: 0.21383, batch_cost: 0.61623s, reader_cost: 0.01962, ips: 103.85700 samples/s, eta: 4:19:00
[2022/06/19 02:04:49] ppcls INFO: [Train][Epoch 153/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04377658, top1: 0.92574, CELoss: 0.21224, loss: 0.21224, batch_cost: 0.60812s, reader_cost: 0.01880, ips: 105.24250 samples/s, eta: 4:15:29
[2022/06/19 02:04:55] ppcls INFO: [Train][Epoch 153/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04374904, top1: 0.92638, CELoss: 0.20864, loss: 0.20864, batch_cost: 0.61390s, reader_cost: 0.01826, ips: 104.25176 samples/s, eta: 4:17:49
[2022/06/19 02:05:00] ppcls INFO: [Train][Epoch 153/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04372149, top1: 0.92639, CELoss: 0.20733, loss: 0.20733, batch_cost: 0.60569s, reader_cost: 0.01738, ips: 105.66486 samples/s, eta: 4:14:16
[2022/06/19 02:05:08] ppcls INFO: [Train][Epoch 153/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04369394, top1: 0.92653, CELoss: 0.20627, loss: 0.20627, batch_cost: 0.61633s, reader_cost: 0.01658, ips: 103.84043 samples/s, eta: 4:18:37
[2022/06/19 02:05:14] ppcls INFO: [Train][Epoch 153/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04366640, top1: 0.92598, CELoss: 0.20709, loss: 0.20709, batch_cost: 0.61805s, reader_cost: 0.01596, ips: 103.55099 samples/s, eta: 4:19:15
[2022/06/19 02:05:20] ppcls INFO: [Train][Epoch 153/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04363885, top1: 0.92550, CELoss: 0.20815, loss: 0.20815, batch_cost: 0.61345s, reader_cost: 0.01572, ips: 104.32725 samples/s, eta: 4:17:13
[2022/06/19 02:05:25] ppcls INFO: [Train][Epoch 153/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04361131, top1: 0.92605, CELoss: 0.20648, loss: 0.20648, batch_cost: 0.60456s, reader_cost: 0.01537, ips: 105.86168 samples/s, eta: 4:13:23
[2022/06/19 02:05:27] ppcls INFO: [Train][Epoch 153/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04358376, top1: 0.92589, CELoss: 0.20569, loss: 0.20569, batch_cost: 0.58140s, reader_cost: 0.01445, ips: 84.27944 samples/s, eta: 4:03:35
[2022/06/19 02:05:27] ppcls INFO: [Train][Epoch 153/300][Avg]top1: 0.92589, CELoss: 0.20569, loss: 0.20569
[2022/06/19 02:05:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:05:34] ppcls INFO: [Train][Epoch 154/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04358101, top1: 0.92188, CELoss: 0.23191, loss: 0.23191, batch_cost: 0.61470s, reader_cost: 0.04468, ips: 104.11637 samples/s, eta: 4:17:31
[2022/06/19 02:05:40] ppcls INFO: [Train][Epoch 154/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04355346, top1: 0.91761, CELoss: 0.22932, loss: 0.22932, batch_cost: 0.61407s, reader_cost: 0.01546, ips: 104.22224 samples/s, eta: 4:17:09
[2022/06/19 02:05:46] ppcls INFO: [Train][Epoch 154/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04352592, top1: 0.92783, CELoss: 0.19554, loss: 0.19554, batch_cost: 0.61693s, reader_cost: 0.02676, ips: 103.73870 samples/s, eta: 4:18:15
[2022/06/19 02:05:53] ppcls INFO: [Train][Epoch 154/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04349838, top1: 0.92994, CELoss: 0.19026, loss: 0.19026, batch_cost: 0.63375s, reader_cost: 0.01976, ips: 100.98602 samples/s, eta: 4:25:11
[2022/06/19 02:05:59] ppcls INFO: [Train][Epoch 154/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04347084, top1: 0.92759, CELoss: 0.19747, loss: 0.19747, batch_cost: 0.62700s, reader_cost: 0.01658, ips: 102.07259 samples/s, eta: 4:22:15
[2022/06/19 02:06:06] ppcls INFO: [Train][Epoch 154/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04344329, top1: 0.92831, CELoss: 0.20445, loss: 0.20445, batch_cost: 0.64111s, reader_cost: 0.07604, ips: 99.82614 samples/s, eta: 4:28:03
[2022/06/19 02:06:12] ppcls INFO: [Train][Epoch 154/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04341575, top1: 0.92700, CELoss: 0.20773, loss: 0.20773, batch_cost: 0.63181s, reader_cost: 0.06992, ips: 101.29703 samples/s, eta: 4:24:03
[2022/06/19 02:06:18] ppcls INFO: [Train][Epoch 154/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04338821, top1: 0.92738, CELoss: 0.21007, loss: 0.21007, batch_cost: 0.62963s, reader_cost: 0.07166, ips: 101.64639 samples/s, eta: 4:23:03
[2022/06/19 02:06:24] ppcls INFO: [Train][Epoch 154/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04336067, top1: 0.92805, CELoss: 0.20677, loss: 0.20677, batch_cost: 0.62881s, reader_cost: 0.06310, ips: 101.78028 samples/s, eta: 4:22:35
[2022/06/19 02:06:30] ppcls INFO: [Train][Epoch 154/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04333313, top1: 0.92840, CELoss: 0.20906, loss: 0.20906, batch_cost: 0.62281s, reader_cost: 0.05902, ips: 102.76021 samples/s, eta: 4:19:59
[2022/06/19 02:06:37] ppcls INFO: [Train][Epoch 154/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04330559, top1: 0.92992, CELoss: 0.20950, loss: 0.20950, batch_cost: 0.62573s, reader_cost: 0.05571, ips: 102.28096 samples/s, eta: 4:21:06
[2022/06/19 02:06:42] ppcls INFO: [Train][Epoch 154/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04327806, top1: 0.92990, CELoss: 0.21044, loss: 0.21044, batch_cost: 0.62126s, reader_cost: 0.05124, ips: 103.01683 samples/s, eta: 4:19:08
[2022/06/19 02:06:49] ppcls INFO: [Train][Epoch 154/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04325052, top1: 0.92846, CELoss: 0.20998, loss: 0.20998, batch_cost: 0.62145s, reader_cost: 0.04727, ips: 102.98552 samples/s, eta: 4:19:06
[2022/06/19 02:06:54] ppcls INFO: [Train][Epoch 154/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04322298, top1: 0.92832, CELoss: 0.21172, loss: 0.21172, batch_cost: 0.61703s, reader_cost: 0.04486, ips: 103.72210 samples/s, eta: 4:17:10
[2022/06/19 02:07:01] ppcls INFO: [Train][Epoch 154/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04319545, top1: 0.92797, CELoss: 0.21218, loss: 0.21218, batch_cost: 0.62093s, reader_cost: 0.04198, ips: 103.07044 samples/s, eta: 4:18:41
[2022/06/19 02:07:07] ppcls INFO: [Train][Epoch 154/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04316791, top1: 0.92870, CELoss: 0.20990, loss: 0.20990, batch_cost: 0.62013s, reader_cost: 0.04614, ips: 103.20449 samples/s, eta: 4:18:15
[2022/06/19 02:07:12] ppcls INFO: [Train][Epoch 154/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04314038, top1: 0.93012, CELoss: 0.20686, loss: 0.20686, batch_cost: 0.61304s, reader_cost: 0.04390, ips: 104.39837 samples/s, eta: 4:15:11
[2022/06/19 02:07:14] ppcls INFO: [Train][Epoch 154/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04311284, top1: 0.93009, CELoss: 0.20555, loss: 0.20555, batch_cost: 0.58940s, reader_cost: 0.04176, ips: 83.13565 samples/s, eta: 4:05:15
[2022/06/19 02:07:15] ppcls INFO: [Train][Epoch 154/300][Avg]top1: 0.93009, CELoss: 0.20555, loss: 0.20555
[2022/06/19 02:07:15] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:07:21] ppcls INFO: [Train][Epoch 155/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04311009, top1: 0.93750, CELoss: 0.15738, loss: 0.15738, batch_cost: 0.62016s, reader_cost: 0.06802, ips: 103.19991 samples/s, eta: 4:18:02
[2022/06/19 02:07:29] ppcls INFO: [Train][Epoch 155/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04308256, top1: 0.94460, CELoss: 0.15858, loss: 0.15858, batch_cost: 0.66681s, reader_cost: 0.02970, ips: 95.97965 samples/s, eta: 4:37:20
[2022/06/19 02:07:35] ppcls INFO: [Train][Epoch 155/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04305502, top1: 0.94122, CELoss: 0.17049, loss: 0.17049, batch_cost: 0.64364s, reader_cost: 0.02500, ips: 99.43373 samples/s, eta: 4:27:36
[2022/06/19 02:07:41] ppcls INFO: [Train][Epoch 155/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04302749, top1: 0.93700, CELoss: 0.18003, loss: 0.18003, batch_cost: 0.63310s, reader_cost: 0.01776, ips: 101.08912 samples/s, eta: 4:23:07
[2022/06/19 02:07:47] ppcls INFO: [Train][Epoch 155/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04299996, top1: 0.93826, CELoss: 0.17250, loss: 0.17250, batch_cost: 0.61313s, reader_cost: 0.01786, ips: 104.38294 samples/s, eta: 4:14:42
[2022/06/19 02:07:53] ppcls INFO: [Train][Epoch 155/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04297243, top1: 0.93873, CELoss: 0.17467, loss: 0.17467, batch_cost: 0.60409s, reader_cost: 0.01849, ips: 105.94370 samples/s, eta: 4:10:51
[2022/06/19 02:07:59] ppcls INFO: [Train][Epoch 155/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04294490, top1: 0.93852, CELoss: 0.17679, loss: 0.17679, batch_cost: 0.59812s, reader_cost: 0.01753, ips: 107.00110 samples/s, eta: 4:08:16
[2022/06/19 02:08:06] ppcls INFO: [Train][Epoch 155/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04291737, top1: 0.93728, CELoss: 0.18051, loss: 0.18051, batch_cost: 0.61485s, reader_cost: 0.01790, ips: 104.09088 samples/s, eta: 4:15:07
[2022/06/19 02:08:11] ppcls INFO: [Train][Epoch 155/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04288984, top1: 0.93673, CELoss: 0.17971, loss: 0.17971, batch_cost: 0.61140s, reader_cost: 0.01788, ips: 104.67763 samples/s, eta: 4:13:35
[2022/06/19 02:08:17] ppcls INFO: [Train][Epoch 155/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04286232, top1: 0.93664, CELoss: 0.18178, loss: 0.18178, batch_cost: 0.60799s, reader_cost: 0.01785, ips: 105.26432 samples/s, eta: 4:12:04
[2022/06/19 02:08:24] ppcls INFO: [Train][Epoch 155/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04283479, top1: 0.93688, CELoss: 0.18458, loss: 0.18458, batch_cost: 0.61118s, reader_cost: 0.01731, ips: 104.71462 samples/s, eta: 4:13:17
[2022/06/19 02:08:31] ppcls INFO: [Train][Epoch 155/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04280727, top1: 0.93553, CELoss: 0.18714, loss: 0.18714, batch_cost: 0.62447s, reader_cost: 0.01634, ips: 102.48682 samples/s, eta: 4:18:41
[2022/06/19 02:08:36] ppcls INFO: [Train][Epoch 155/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04277974, top1: 0.93492, CELoss: 0.18850, loss: 0.18850, batch_cost: 0.61080s, reader_cost: 0.01559, ips: 104.78098 samples/s, eta: 4:12:55
[2022/06/19 02:08:41] ppcls INFO: [Train][Epoch 155/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04275222, top1: 0.93297, CELoss: 0.19217, loss: 0.19217, batch_cost: 0.60537s, reader_cost: 0.01549, ips: 105.72043 samples/s, eta: 4:10:34
[2022/06/19 02:08:47] ppcls INFO: [Train][Epoch 155/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04272469, top1: 0.93329, CELoss: 0.19117, loss: 0.19117, batch_cost: 0.60200s, reader_cost: 0.01499, ips: 106.31148 samples/s, eta: 4:09:05
[2022/06/19 02:08:54] ppcls INFO: [Train][Epoch 155/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04269717, top1: 0.93315, CELoss: 0.19190, loss: 0.19190, batch_cost: 0.60862s, reader_cost: 0.01432, ips: 105.15638 samples/s, eta: 4:11:43
[2022/06/19 02:08:59] ppcls INFO: [Train][Epoch 155/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04266965, top1: 0.93274, CELoss: 0.19168, loss: 0.19168, batch_cost: 0.60227s, reader_cost: 0.01361, ips: 106.26480 samples/s, eta: 4:08:59
[2022/06/19 02:09:01] ppcls INFO: [Train][Epoch 155/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04264213, top1: 0.93311, CELoss: 0.19126, loss: 0.19126, batch_cost: 0.57851s, reader_cost: 0.01287, ips: 84.69995 samples/s, eta: 3:59:04
[2022/06/19 02:09:02] ppcls INFO: [Train][Epoch 155/300][Avg]top1: 0.93311, CELoss: 0.19126, loss: 0.19126
[2022/06/19 02:09:09] ppcls INFO: [Eval][Epoch 155][Iter: 0/16]CELoss: 1.03765, loss: 1.03765, top1: 0.78711, batch_cost: 7.12655s, reader_cost: 3.83552, ips: 8.98051 images/sec
[2022/06/19 02:09:17] ppcls INFO: [Eval][Epoch 155][Iter: 10/16]CELoss: 0.90199, loss: 0.90199, top1: 0.79901, batch_cost: 0.56021s, reader_cost: 0.01381, ips: 114.24245 images/sec
[2022/06/19 02:09:18] ppcls INFO: [Eval][Epoch 155][Avg]CELoss: 0.78797, loss: 0.78797, top1: 0.80784
[2022/06/19 02:09:18] ppcls INFO: [Eval][Epoch 155][best metric: 0.813235342502594]
[2022/06/19 02:09:19] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:09:25] ppcls INFO: [Train][Epoch 156/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04263938, top1: 0.95312, CELoss: 0.13749, loss: 0.13749, batch_cost: 0.61273s, reader_cost: 0.04430, ips: 104.45061 samples/s, eta: 4:13:12
[2022/06/19 02:09:33] ppcls INFO: [Train][Epoch 156/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04261186, top1: 0.94460, CELoss: 0.17507, loss: 0.17507, batch_cost: 0.94563s, reader_cost: 0.00425, ips: 67.67979 samples/s, eta: 6:30:37
[2022/06/19 02:09:39] ppcls INFO: [Train][Epoch 156/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04258434, top1: 0.94271, CELoss: 0.17916, loss: 0.17916, batch_cost: 0.73089s, reader_cost: 0.01035, ips: 87.56436 samples/s, eta: 5:01:47
[2022/06/19 02:09:45] ppcls INFO: [Train][Epoch 156/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04255682, top1: 0.93448, CELoss: 0.19249, loss: 0.19249, batch_cost: 0.67582s, reader_cost: 0.01217, ips: 94.70005 samples/s, eta: 4:38:56
[2022/06/19 02:09:50] ppcls INFO: [Train][Epoch 156/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04252931, top1: 0.93407, CELoss: 0.19568, loss: 0.19568, batch_cost: 0.63601s, reader_cost: 0.01325, ips: 100.62712 samples/s, eta: 4:22:24
[2022/06/19 02:09:57] ppcls INFO: [Train][Epoch 156/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04250179, top1: 0.93505, CELoss: 0.19405, loss: 0.19405, batch_cost: 0.63664s, reader_cost: 0.01201, ips: 100.52716 samples/s, eta: 4:22:33
[2022/06/19 02:10:04] ppcls INFO: [Train][Epoch 156/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04247428, top1: 0.93007, CELoss: 0.20429, loss: 0.20429, batch_cost: 0.65176s, reader_cost: 0.01092, ips: 98.19555 samples/s, eta: 4:28:41
[2022/06/19 02:10:09] ppcls INFO: [Train][Epoch 156/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04244676, top1: 0.92980, CELoss: 0.20709, loss: 0.20709, batch_cost: 0.63619s, reader_cost: 0.01069, ips: 100.59955 samples/s, eta: 4:22:09
[2022/06/19 02:10:16] ppcls INFO: [Train][Epoch 156/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04241925, top1: 0.92785, CELoss: 0.20953, loss: 0.20953, batch_cost: 0.64569s, reader_cost: 0.01084, ips: 99.11886 samples/s, eta: 4:25:58
[2022/06/19 02:10:22] ppcls INFO: [Train][Epoch 156/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04239174, top1: 0.92960, CELoss: 0.20495, loss: 0.20495, batch_cost: 0.63357s, reader_cost: 0.01038, ips: 101.01525 samples/s, eta: 4:20:52
[2022/06/19 02:10:28] ppcls INFO: [Train][Epoch 156/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04236423, top1: 0.92868, CELoss: 0.20664, loss: 0.20664, batch_cost: 0.63623s, reader_cost: 0.01122, ips: 100.59241 samples/s, eta: 4:21:51
[2022/06/19 02:10:35] ppcls INFO: [Train][Epoch 156/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04233672, top1: 0.92976, CELoss: 0.20371, loss: 0.20371, batch_cost: 0.64040s, reader_cost: 0.01079, ips: 99.93702 samples/s, eta: 4:23:28
[2022/06/19 02:10:41] ppcls INFO: [Train][Epoch 156/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04230921, top1: 0.92988, CELoss: 0.20403, loss: 0.20403, batch_cost: 0.63269s, reader_cost: 0.01180, ips: 101.15559 samples/s, eta: 4:20:11
[2022/06/19 02:10:47] ppcls INFO: [Train][Epoch 156/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04228170, top1: 0.92987, CELoss: 0.20382, loss: 0.20382, batch_cost: 0.63389s, reader_cost: 0.01356, ips: 100.96313 samples/s, eta: 4:20:35
[2022/06/19 02:10:53] ppcls INFO: [Train][Epoch 156/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04225419, top1: 0.93129, CELoss: 0.20126, loss: 0.20126, batch_cost: 0.62940s, reader_cost: 0.01367, ips: 101.68357 samples/s, eta: 4:18:37
[2022/06/19 02:11:00] ppcls INFO: [Train][Epoch 156/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04222669, top1: 0.93057, CELoss: 0.20128, loss: 0.20128, batch_cost: 0.63172s, reader_cost: 0.01407, ips: 101.31013 samples/s, eta: 4:19:28
[2022/06/19 02:11:04] ppcls INFO: [Train][Epoch 156/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04219918, top1: 0.93022, CELoss: 0.20189, loss: 0.20189, batch_cost: 0.62162s, reader_cost: 0.01405, ips: 102.95702 samples/s, eta: 4:15:13
[2022/06/19 02:11:07] ppcls INFO: [Train][Epoch 156/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04217168, top1: 0.92936, CELoss: 0.20196, loss: 0.20196, batch_cost: 0.59781s, reader_cost: 0.01436, ips: 81.96606 samples/s, eta: 4:05:21
[2022/06/19 02:11:07] ppcls INFO: [Train][Epoch 156/300][Avg]top1: 0.92936, CELoss: 0.20196, loss: 0.20196
[2022/06/19 02:11:07] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:11:14] ppcls INFO: [Train][Epoch 157/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04216893, top1: 0.96875, CELoss: 0.09787, loss: 0.09787, batch_cost: 0.63611s, reader_cost: 0.05137, ips: 100.61202 samples/s, eta: 4:21:03
[2022/06/19 02:11:21] ppcls INFO: [Train][Epoch 157/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04214142, top1: 0.94318, CELoss: 0.19353, loss: 0.19353, batch_cost: 0.65315s, reader_cost: 0.00044, ips: 97.98642 samples/s, eta: 4:27:56
[2022/06/19 02:11:27] ppcls INFO: [Train][Epoch 157/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04211392, top1: 0.94196, CELoss: 0.18939, loss: 0.18939, batch_cost: 0.62606s, reader_cost: 0.01200, ips: 102.22631 samples/s, eta: 4:16:43
[2022/06/19 02:11:33] ppcls INFO: [Train][Epoch 157/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04208642, top1: 0.94103, CELoss: 0.18233, loss: 0.18233, batch_cost: 0.61983s, reader_cost: 0.01306, ips: 103.25397 samples/s, eta: 4:14:04
[2022/06/19 02:11:40] ppcls INFO: [Train][Epoch 157/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04205892, top1: 0.94093, CELoss: 0.18262, loss: 0.18262, batch_cost: 0.63370s, reader_cost: 0.01105, ips: 100.99346 samples/s, eta: 4:19:38
[2022/06/19 02:11:45] ppcls INFO: [Train][Epoch 157/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04203142, top1: 0.93811, CELoss: 0.19124, loss: 0.19124, batch_cost: 0.61972s, reader_cost: 0.01131, ips: 103.27222 samples/s, eta: 4:13:49
[2022/06/19 02:11:51] ppcls INFO: [Train][Epoch 157/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04200393, top1: 0.93724, CELoss: 0.19190, loss: 0.19190, batch_cost: 0.60920s, reader_cost: 0.01253, ips: 105.05589 samples/s, eta: 4:09:24
[2022/06/19 02:11:57] ppcls INFO: [Train][Epoch 157/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04197643, top1: 0.93552, CELoss: 0.19479, loss: 0.19479, batch_cost: 0.60295s, reader_cost: 0.01250, ips: 106.14429 samples/s, eta: 4:06:44
[2022/06/19 02:12:03] ppcls INFO: [Train][Epoch 157/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04194894, top1: 0.93634, CELoss: 0.19345, loss: 0.19345, batch_cost: 0.60663s, reader_cost: 0.01476, ips: 105.50075 samples/s, eta: 4:08:09
[2022/06/19 02:12:09] ppcls INFO: [Train][Epoch 157/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04192144, top1: 0.93149, CELoss: 0.20307, loss: 0.20307, batch_cost: 0.60235s, reader_cost: 0.01564, ips: 106.25080 samples/s, eta: 4:06:18
[2022/06/19 02:12:15] ppcls INFO: [Train][Epoch 157/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04189395, top1: 0.92992, CELoss: 0.20764, loss: 0.20764, batch_cost: 0.60843s, reader_cost: 0.01744, ips: 105.18794 samples/s, eta: 4:08:41
[2022/06/19 02:12:22] ppcls INFO: [Train][Epoch 157/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04186646, top1: 0.92962, CELoss: 0.20636, loss: 0.20636, batch_cost: 0.61593s, reader_cost: 0.01637, ips: 103.90867 samples/s, eta: 4:11:38
[2022/06/19 02:12:28] ppcls INFO: [Train][Epoch 157/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04183897, top1: 0.92833, CELoss: 0.21017, loss: 0.21017, batch_cost: 0.60873s, reader_cost: 0.01628, ips: 105.13612 samples/s, eta: 4:08:36
[2022/06/19 02:12:33] ppcls INFO: [Train][Epoch 157/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04181148, top1: 0.92808, CELoss: 0.21047, loss: 0.21047, batch_cost: 0.60233s, reader_cost: 0.01745, ips: 106.25442 samples/s, eta: 4:05:53
[2022/06/19 02:12:39] ppcls INFO: [Train][Epoch 157/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04178399, top1: 0.92841, CELoss: 0.20924, loss: 0.20924, batch_cost: 0.60211s, reader_cost: 0.01721, ips: 106.29212 samples/s, eta: 4:05:42
[2022/06/19 02:12:47] ppcls INFO: [Train][Epoch 157/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04175650, top1: 0.92995, CELoss: 0.20770, loss: 0.20770, batch_cost: 0.61425s, reader_cost: 0.01661, ips: 104.19152 samples/s, eta: 4:10:33
[2022/06/19 02:12:51] ppcls INFO: [Train][Epoch 157/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04172902, top1: 0.93080, CELoss: 0.20519, loss: 0.20519, batch_cost: 0.60416s, reader_cost: 0.01581, ips: 105.93289 samples/s, eta: 4:06:20
[2022/06/19 02:12:53] ppcls INFO: [Train][Epoch 157/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04170153, top1: 0.93037, CELoss: 0.20430, loss: 0.20430, batch_cost: 0.58050s, reader_cost: 0.01488, ips: 84.41041 samples/s, eta: 3:56:35
[2022/06/19 02:12:54] ppcls INFO: [Train][Epoch 157/300][Avg]top1: 0.93037, CELoss: 0.20430, loss: 0.20430
[2022/06/19 02:12:54] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:13:01] ppcls INFO: [Train][Epoch 158/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04169878, top1: 0.95312, CELoss: 0.14006, loss: 0.14006, batch_cost: 0.61546s, reader_cost: 0.04176, ips: 103.98703 samples/s, eta: 4:10:49
[2022/06/19 02:13:08] ppcls INFO: [Train][Epoch 158/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04167130, top1: 0.93608, CELoss: 0.18328, loss: 0.18328, batch_cost: 0.86401s, reader_cost: 0.00338, ips: 74.07296 samples/s, eta: 5:51:59
[2022/06/19 02:13:14] ppcls INFO: [Train][Epoch 158/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04164382, top1: 0.93452, CELoss: 0.18092, loss: 0.18092, batch_cost: 0.66926s, reader_cost: 0.01105, ips: 95.62757 samples/s, eta: 4:32:32
[2022/06/19 02:13:21] ppcls INFO: [Train][Epoch 158/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04161634, top1: 0.92591, CELoss: 0.20358, loss: 0.20358, batch_cost: 0.66903s, reader_cost: 0.01208, ips: 95.66147 samples/s, eta: 4:32:19
[2022/06/19 02:13:27] ppcls INFO: [Train][Epoch 158/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04158886, top1: 0.92873, CELoss: 0.19467, loss: 0.19467, batch_cost: 0.64722s, reader_cost: 0.01226, ips: 98.88478 samples/s, eta: 4:23:20
[2022/06/19 02:13:35] ppcls INFO: [Train][Epoch 158/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04156138, top1: 0.92708, CELoss: 0.20249, loss: 0.20249, batch_cost: 0.68780s, reader_cost: 0.01112, ips: 93.05019 samples/s, eta: 4:39:44
[2022/06/19 02:13:39] ppcls INFO: [Train][Epoch 158/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04153391, top1: 0.92674, CELoss: 0.20348, loss: 0.20348, batch_cost: 0.64761s, reader_cost: 0.01073, ips: 98.82419 samples/s, eta: 4:23:17
[2022/06/19 02:13:45] ppcls INFO: [Train][Epoch 158/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04150643, top1: 0.92606, CELoss: 0.20448, loss: 0.20448, batch_cost: 0.63773s, reader_cost: 0.01110, ips: 100.35646 samples/s, eta: 4:19:09
[2022/06/19 02:13:51] ppcls INFO: [Train][Epoch 158/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04147896, top1: 0.92380, CELoss: 0.20607, loss: 0.20607, batch_cost: 0.63147s, reader_cost: 0.01196, ips: 101.35122 samples/s, eta: 4:16:30
[2022/06/19 02:13:57] ppcls INFO: [Train][Epoch 158/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04145148, top1: 0.92411, CELoss: 0.20953, loss: 0.20953, batch_cost: 0.61966s, reader_cost: 0.01261, ips: 103.28255 samples/s, eta: 4:11:36
[2022/06/19 02:14:03] ppcls INFO: [Train][Epoch 158/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04142401, top1: 0.92450, CELoss: 0.20633, loss: 0.20633, batch_cost: 0.61849s, reader_cost: 0.01257, ips: 103.47836 samples/s, eta: 4:11:02
[2022/06/19 02:14:10] ppcls INFO: [Train][Epoch 158/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04139654, top1: 0.92497, CELoss: 0.20736, loss: 0.20736, batch_cost: 0.62716s, reader_cost: 0.01212, ips: 102.04689 samples/s, eta: 4:14:27
[2022/06/19 02:14:15] ppcls INFO: [Train][Epoch 158/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04136907, top1: 0.92523, CELoss: 0.20670, loss: 0.20670, batch_cost: 0.62050s, reader_cost: 0.01151, ips: 103.14279 samples/s, eta: 4:11:38
[2022/06/19 02:14:22] ppcls INFO: [Train][Epoch 158/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04134161, top1: 0.92605, CELoss: 0.20679, loss: 0.20679, batch_cost: 0.62206s, reader_cost: 0.01170, ips: 102.88460 samples/s, eta: 4:12:10
[2022/06/19 02:14:28] ppcls INFO: [Train][Epoch 158/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04131414, top1: 0.92631, CELoss: 0.20616, loss: 0.20616, batch_cost: 0.61970s, reader_cost: 0.01146, ips: 103.27609 samples/s, eta: 4:11:06
[2022/06/19 02:14:33] ppcls INFO: [Train][Epoch 158/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04128668, top1: 0.92643, CELoss: 0.20777, loss: 0.20777, batch_cost: 0.61688s, reader_cost: 0.01199, ips: 103.74750 samples/s, eta: 4:09:52
[2022/06/19 02:14:39] ppcls INFO: [Train][Epoch 158/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04125921, top1: 0.92498, CELoss: 0.20999, loss: 0.20999, batch_cost: 0.61122s, reader_cost: 0.01153, ips: 104.70947 samples/s, eta: 4:07:28
[2022/06/19 02:14:41] ppcls INFO: [Train][Epoch 158/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04123175, top1: 0.92607, CELoss: 0.20784, loss: 0.20784, batch_cost: 0.58819s, reader_cost: 0.01091, ips: 83.30617 samples/s, eta: 3:58:03
[2022/06/19 02:14:41] ppcls INFO: [Train][Epoch 158/300][Avg]top1: 0.92607, CELoss: 0.20784, loss: 0.20784
[2022/06/19 02:14:42] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:14:48] ppcls INFO: [Train][Epoch 159/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04122901, top1: 0.96875, CELoss: 0.11091, loss: 0.11091, batch_cost: 0.61996s, reader_cost: 0.03648, ips: 103.23245 samples/s, eta: 4:10:53
[2022/06/19 02:14:55] ppcls INFO: [Train][Epoch 159/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04120154, top1: 0.93324, CELoss: 0.17624, loss: 0.17624, batch_cost: 0.83145s, reader_cost: 0.00159, ips: 76.97422 samples/s, eta: 5:36:20
[2022/06/19 02:15:00] ppcls INFO: [Train][Epoch 159/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04117409, top1: 0.92857, CELoss: 0.19801, loss: 0.19801, batch_cost: 0.65587s, reader_cost: 0.00581, ips: 97.58040 samples/s, eta: 4:25:12
[2022/06/19 02:15:06] ppcls INFO: [Train][Epoch 159/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04114663, top1: 0.92742, CELoss: 0.20010, loss: 0.20010, batch_cost: 0.63393s, reader_cost: 0.00501, ips: 100.95813 samples/s, eta: 4:16:13
[2022/06/19 02:15:12] ppcls INFO: [Train][Epoch 159/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04111917, top1: 0.92683, CELoss: 0.20237, loss: 0.20237, batch_cost: 0.62483s, reader_cost: 0.00405, ips: 102.42770 samples/s, eta: 4:12:27
[2022/06/19 02:15:19] ppcls INFO: [Train][Epoch 159/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04109172, top1: 0.93076, CELoss: 0.19367, loss: 0.19367, batch_cost: 0.63878s, reader_cost: 0.00759, ips: 100.19021 samples/s, eta: 4:17:59
[2022/06/19 02:15:26] ppcls INFO: [Train][Epoch 159/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04106427, top1: 0.92700, CELoss: 0.20048, loss: 0.20048, batch_cost: 0.64228s, reader_cost: 0.00825, ips: 99.64522 samples/s, eta: 4:19:17
[2022/06/19 02:15:31] ppcls INFO: [Train][Epoch 159/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04103681, top1: 0.92980, CELoss: 0.19506, loss: 0.19506, batch_cost: 0.62840s, reader_cost: 0.00786, ips: 101.84572 samples/s, eta: 4:13:34
[2022/06/19 02:15:37] ppcls INFO: [Train][Epoch 159/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04100936, top1: 0.92940, CELoss: 0.19534, loss: 0.19534, batch_cost: 0.62082s, reader_cost: 0.00837, ips: 103.08923 samples/s, eta: 4:10:25
[2022/06/19 02:15:43] ppcls INFO: [Train][Epoch 159/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04098192, top1: 0.92840, CELoss: 0.19607, loss: 0.19607, batch_cost: 0.62288s, reader_cost: 0.00890, ips: 102.74826 samples/s, eta: 4:11:08
[2022/06/19 02:15:49] ppcls INFO: [Train][Epoch 159/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04095447, top1: 0.92976, CELoss: 0.19180, loss: 0.19180, batch_cost: 0.61440s, reader_cost: 0.01042, ips: 104.16589 samples/s, eta: 4:07:37
[2022/06/19 02:15:54] ppcls INFO: [Train][Epoch 159/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04092702, top1: 0.92948, CELoss: 0.19084, loss: 0.19084, batch_cost: 0.60738s, reader_cost: 0.01222, ips: 105.37093 samples/s, eta: 4:04:41
[2022/06/19 02:16:01] ppcls INFO: [Train][Epoch 159/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04089958, top1: 0.92975, CELoss: 0.19156, loss: 0.19156, batch_cost: 0.61179s, reader_cost: 0.02335, ips: 104.61039 samples/s, eta: 4:06:22
[2022/06/19 02:16:06] ppcls INFO: [Train][Epoch 159/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04087214, top1: 0.93058, CELoss: 0.19068, loss: 0.19068, batch_cost: 0.60692s, reader_cost: 0.02356, ips: 105.45103 samples/s, eta: 4:04:18
[2022/06/19 02:16:13] ppcls INFO: [Train][Epoch 159/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04084470, top1: 0.93118, CELoss: 0.18960, loss: 0.18960, batch_cost: 0.61390s, reader_cost: 0.02532, ips: 104.25218 samples/s, eta: 4:07:00
[2022/06/19 02:16:20] ppcls INFO: [Train][Epoch 159/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04081726, top1: 0.93160, CELoss: 0.19069, loss: 0.19069, batch_cost: 0.61835s, reader_cost: 0.02463, ips: 103.50199 samples/s, eta: 4:08:41
[2022/06/19 02:16:25] ppcls INFO: [Train][Epoch 159/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04078982, top1: 0.93148, CELoss: 0.19082, loss: 0.19082, batch_cost: 0.60693s, reader_cost: 0.02333, ips: 105.44923 samples/s, eta: 4:04:00
[2022/06/19 02:16:27] ppcls INFO: [Train][Epoch 159/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04076238, top1: 0.93220, CELoss: 0.18966, loss: 0.18966, batch_cost: 0.58313s, reader_cost: 0.02195, ips: 84.02884 samples/s, eta: 3:54:20
[2022/06/19 02:16:27] ppcls INFO: [Train][Epoch 159/300][Avg]top1: 0.93220, CELoss: 0.18966, loss: 0.18966
[2022/06/19 02:16:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:16:34] ppcls INFO: [Train][Epoch 160/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04075964, top1: 0.93750, CELoss: 0.13126, loss: 0.13126, batch_cost: 0.61665s, reader_cost: 0.05464, ips: 103.78612 samples/s, eta: 4:07:48
[2022/06/19 02:16:41] ppcls INFO: [Train][Epoch 160/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04073220, top1: 0.93608, CELoss: 0.15367, loss: 0.15367, batch_cost: 0.73562s, reader_cost: 0.03129, ips: 87.00166 samples/s, eta: 4:55:29
[2022/06/19 02:16:48] ppcls INFO: [Train][Epoch 160/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04070477, top1: 0.94643, CELoss: 0.14740, loss: 0.14740, batch_cost: 0.69066s, reader_cost: 0.01526, ips: 92.66516 samples/s, eta: 4:37:18
[2022/06/19 02:16:53] ppcls INFO: [Train][Epoch 160/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04067734, top1: 0.94304, CELoss: 0.16113, loss: 0.16113, batch_cost: 0.65117s, reader_cost: 0.01648, ips: 98.28490 samples/s, eta: 4:21:20
[2022/06/19 02:17:00] ppcls INFO: [Train][Epoch 160/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04064991, top1: 0.94017, CELoss: 0.17310, loss: 0.17310, batch_cost: 0.64252s, reader_cost: 0.04110, ips: 99.60727 samples/s, eta: 4:17:46
[2022/06/19 02:17:06] ppcls INFO: [Train][Epoch 160/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04062248, top1: 0.93811, CELoss: 0.17863, loss: 0.17863, batch_cost: 0.64613s, reader_cost: 0.06255, ips: 99.05176 samples/s, eta: 4:19:06
[2022/06/19 02:17:12] ppcls INFO: [Train][Epoch 160/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04059506, top1: 0.93801, CELoss: 0.17836, loss: 0.17836, batch_cost: 0.63106s, reader_cost: 0.05618, ips: 101.41715 samples/s, eta: 4:12:57
[2022/06/19 02:17:17] ppcls INFO: [Train][Epoch 160/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04056763, top1: 0.93750, CELoss: 0.18428, loss: 0.18428, batch_cost: 0.62138s, reader_cost: 0.05029, ips: 102.99659 samples/s, eta: 4:08:58
[2022/06/19 02:17:24] ppcls INFO: [Train][Epoch 160/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04054021, top1: 0.93711, CELoss: 0.18375, loss: 0.18375, batch_cost: 0.62679s, reader_cost: 0.06166, ips: 102.10701 samples/s, eta: 4:11:02
[2022/06/19 02:17:30] ppcls INFO: [Train][Epoch 160/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04051279, top1: 0.93527, CELoss: 0.18628, loss: 0.18628, batch_cost: 0.62017s, reader_cost: 0.05647, ips: 103.19809 samples/s, eta: 4:08:17
[2022/06/19 02:17:37] ppcls INFO: [Train][Epoch 160/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04048537, top1: 0.93533, CELoss: 0.18681, loss: 0.18681, batch_cost: 0.62925s, reader_cost: 0.05185, ips: 101.70908 samples/s, eta: 4:11:48
[2022/06/19 02:17:42] ppcls INFO: [Train][Epoch 160/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.04045795, top1: 0.93511, CELoss: 0.18656, loss: 0.18656, batch_cost: 0.62114s, reader_cost: 0.04829, ips: 103.03614 samples/s, eta: 4:08:28
[2022/06/19 02:17:49] ppcls INFO: [Train][Epoch 160/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.04043053, top1: 0.93440, CELoss: 0.18628, loss: 0.18628, batch_cost: 0.62776s, reader_cost: 0.04544, ips: 101.94998 samples/s, eta: 4:11:00
[2022/06/19 02:17:55] ppcls INFO: [Train][Epoch 160/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.04040312, top1: 0.93511, CELoss: 0.18571, loss: 0.18571, batch_cost: 0.62544s, reader_cost: 0.04285, ips: 102.32849 samples/s, eta: 4:09:58
[2022/06/19 02:18:00] ppcls INFO: [Train][Epoch 160/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.04037571, top1: 0.93517, CELoss: 0.18543, loss: 0.18543, batch_cost: 0.61636s, reader_cost: 0.04010, ips: 103.83478 samples/s, eta: 4:06:14
[2022/06/19 02:18:07] ppcls INFO: [Train][Epoch 160/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.04034830, top1: 0.93533, CELoss: 0.18500, loss: 0.18500, batch_cost: 0.62209s, reader_cost: 0.03749, ips: 102.87924 samples/s, eta: 4:08:25
[2022/06/19 02:18:12] ppcls INFO: [Train][Epoch 160/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.04032089, top1: 0.93527, CELoss: 0.18500, loss: 0.18500, batch_cost: 0.61193s, reader_cost: 0.03518, ips: 104.58779 samples/s, eta: 4:04:16
[2022/06/19 02:18:14] ppcls INFO: [Train][Epoch 160/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.04029348, top1: 0.93467, CELoss: 0.18654, loss: 0.18654, batch_cost: 0.58778s, reader_cost: 0.03310, ips: 83.36417 samples/s, eta: 3:54:32
[2022/06/19 02:18:15] ppcls INFO: [Train][Epoch 160/300][Avg]top1: 0.93467, CELoss: 0.18654, loss: 0.18654
[2022/06/19 02:18:22] ppcls INFO: [Eval][Epoch 160][Iter: 0/16]CELoss: 1.03961, loss: 1.03961, top1: 0.77930, batch_cost: 7.08715s, reader_cost: 3.37875, ips: 9.03043 images/sec
[2022/06/19 02:18:30] ppcls INFO: [Eval][Epoch 160][Iter: 10/16]CELoss: 0.81742, loss: 0.81742, top1: 0.79847, batch_cost: 0.56018s, reader_cost: 0.00112, ips: 114.24806 images/sec
[2022/06/19 02:18:31] ppcls INFO: [Eval][Epoch 160][Avg]CELoss: 0.73176, loss: 0.73176, top1: 0.80907
[2022/06/19 02:18:31] ppcls INFO: [Eval][Epoch 160][best metric: 0.813235342502594]
[2022/06/19 02:18:31] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_160
[2022/06/19 02:18:31] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:18:38] ppcls INFO: [Train][Epoch 161/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.04029074, top1: 0.95312, CELoss: 0.16323, loss: 0.16323, batch_cost: 0.62531s, reader_cost: 0.06907, ips: 102.34953 samples/s, eta: 4:09:29
[2022/06/19 02:18:45] ppcls INFO: [Train][Epoch 161/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.04026333, top1: 0.92330, CELoss: 0.20587, loss: 0.20587, batch_cost: 0.68170s, reader_cost: 0.05467, ips: 93.88362 samples/s, eta: 4:31:52
[2022/06/19 02:18:51] ppcls INFO: [Train][Epoch 161/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.04023593, top1: 0.93676, CELoss: 0.18607, loss: 0.18607, batch_cost: 0.61841s, reader_cost: 0.03253, ips: 103.49115 samples/s, eta: 4:06:32
[2022/06/19 02:18:57] ppcls INFO: [Train][Epoch 161/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.04020853, top1: 0.93800, CELoss: 0.17627, loss: 0.17627, batch_cost: 0.61987s, reader_cost: 0.03063, ips: 103.24715 samples/s, eta: 4:07:01
[2022/06/19 02:19:02] ppcls INFO: [Train][Epoch 161/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.04018113, top1: 0.93445, CELoss: 0.18251, loss: 0.18251, batch_cost: 0.60279s, reader_cost: 0.02539, ips: 106.17313 samples/s, eta: 4:00:06
[2022/06/19 02:19:08] ppcls INFO: [Train][Epoch 161/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.04015373, top1: 0.93474, CELoss: 0.18232, loss: 0.18232, batch_cost: 0.58712s, reader_cost: 0.02317, ips: 109.00656 samples/s, eta: 3:53:46
[2022/06/19 02:19:15] ppcls INFO: [Train][Epoch 161/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.04012633, top1: 0.93699, CELoss: 0.17878, loss: 0.17878, batch_cost: 0.60338s, reader_cost: 0.02315, ips: 106.06900 samples/s, eta: 4:00:08
[2022/06/19 02:19:21] ppcls INFO: [Train][Epoch 161/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.04009894, top1: 0.93794, CELoss: 0.17914, loss: 0.17914, batch_cost: 0.60300s, reader_cost: 0.02153, ips: 106.13577 samples/s, eta: 3:59:53
[2022/06/19 02:19:26] ppcls INFO: [Train][Epoch 161/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.04007154, top1: 0.93846, CELoss: 0.17796, loss: 0.17796, batch_cost: 0.59193s, reader_cost: 0.02054, ips: 108.12164 samples/s, eta: 3:55:23
[2022/06/19 02:19:32] ppcls INFO: [Train][Epoch 161/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.04004415, top1: 0.93956, CELoss: 0.17447, loss: 0.17447, batch_cost: 0.59413s, reader_cost: 0.02441, ips: 107.72052 samples/s, eta: 3:56:10
[2022/06/19 02:19:39] ppcls INFO: [Train][Epoch 161/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.04001676, top1: 0.93967, CELoss: 0.17560, loss: 0.17560, batch_cost: 0.60288s, reader_cost: 0.02282, ips: 106.15669 samples/s, eta: 3:59:32
[2022/06/19 02:19:44] ppcls INFO: [Train][Epoch 161/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03998938, top1: 0.94032, CELoss: 0.17588, loss: 0.17588, batch_cost: 0.60003s, reader_cost: 0.02175, ips: 106.66054 samples/s, eta: 3:58:18
[2022/06/19 02:19:49] ppcls INFO: [Train][Epoch 161/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03996199, top1: 0.94073, CELoss: 0.17437, loss: 0.17437, batch_cost: 0.58887s, reader_cost: 0.02084, ips: 108.68355 samples/s, eta: 3:53:46
[2022/06/19 02:19:56] ppcls INFO: [Train][Epoch 161/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03993461, top1: 0.93917, CELoss: 0.17778, loss: 0.17778, batch_cost: 0.59395s, reader_cost: 0.02026, ips: 107.75339 samples/s, eta: 3:55:41
[2022/06/19 02:20:02] ppcls INFO: [Train][Epoch 161/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03990722, top1: 0.93961, CELoss: 0.17930, loss: 0.17930, batch_cost: 0.59352s, reader_cost: 0.02012, ips: 107.83162 samples/s, eta: 3:55:25
[2022/06/19 02:20:08] ppcls INFO: [Train][Epoch 161/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03987984, top1: 0.93998, CELoss: 0.17978, loss: 0.17978, batch_cost: 0.59607s, reader_cost: 0.01993, ips: 107.37003 samples/s, eta: 3:56:20
[2022/06/19 02:20:13] ppcls INFO: [Train][Epoch 161/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03985247, top1: 0.93954, CELoss: 0.18074, loss: 0.18074, batch_cost: 0.59262s, reader_cost: 0.01898, ips: 107.99491 samples/s, eta: 3:54:52
[2022/06/19 02:20:15] ppcls INFO: [Train][Epoch 161/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03982509, top1: 0.93961, CELoss: 0.17907, loss: 0.17907, batch_cost: 0.56957s, reader_cost: 0.01786, ips: 86.02932 samples/s, eta: 3:45:38
[2022/06/19 02:20:16] ppcls INFO: [Train][Epoch 161/300][Avg]top1: 0.93961, CELoss: 0.17907, loss: 0.17907
[2022/06/19 02:20:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:20:23] ppcls INFO: [Train][Epoch 162/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03982235, top1: 0.93750, CELoss: 0.19836, loss: 0.19836, batch_cost: 0.60637s, reader_cost: 0.05258, ips: 105.54645 samples/s, eta: 4:00:12
[2022/06/19 02:20:30] ppcls INFO: [Train][Epoch 162/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03979498, top1: 0.93892, CELoss: 0.17553, loss: 0.17553, batch_cost: 0.58498s, reader_cost: 0.00717, ips: 109.40491 samples/s, eta: 3:51:38
[2022/06/19 02:20:36] ppcls INFO: [Train][Epoch 162/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03976761, top1: 0.93601, CELoss: 0.18176, loss: 0.18176, batch_cost: 0.59984s, reader_cost: 0.00543, ips: 106.69454 samples/s, eta: 3:57:25
[2022/06/19 02:20:42] ppcls INFO: [Train][Epoch 162/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03974024, top1: 0.93851, CELoss: 0.17759, loss: 0.17759, batch_cost: 0.59630s, reader_cost: 0.00619, ips: 107.32895 samples/s, eta: 3:55:55
[2022/06/19 02:20:48] ppcls INFO: [Train][Epoch 162/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03971287, top1: 0.93864, CELoss: 0.17769, loss: 0.17769, batch_cost: 0.61097s, reader_cost: 0.00573, ips: 104.75109 samples/s, eta: 4:01:37
[2022/06/19 02:20:55] ppcls INFO: [Train][Epoch 162/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03968550, top1: 0.93873, CELoss: 0.18367, loss: 0.18367, batch_cost: 0.61771s, reader_cost: 0.00563, ips: 103.60786 samples/s, eta: 4:04:11
[2022/06/19 02:21:00] ppcls INFO: [Train][Epoch 162/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03965814, top1: 0.93904, CELoss: 0.18584, loss: 0.18584, batch_cost: 0.60711s, reader_cost: 0.00935, ips: 105.41693 samples/s, eta: 3:59:54
[2022/06/19 02:21:06] ppcls INFO: [Train][Epoch 162/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03963078, top1: 0.94080, CELoss: 0.18185, loss: 0.18185, batch_cost: 0.59699s, reader_cost: 0.01009, ips: 107.20514 samples/s, eta: 3:55:47
[2022/06/19 02:21:11] ppcls INFO: [Train][Epoch 162/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03960342, top1: 0.93943, CELoss: 0.18373, loss: 0.18373, batch_cost: 0.58716s, reader_cost: 0.01231, ips: 108.99955 samples/s, eta: 3:51:49
[2022/06/19 02:21:18] ppcls INFO: [Train][Epoch 162/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03957606, top1: 0.93853, CELoss: 0.18317, loss: 0.18317, batch_cost: 0.59789s, reader_cost: 0.01555, ips: 107.04315 samples/s, eta: 3:55:57
[2022/06/19 02:21:23] ppcls INFO: [Train][Epoch 162/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03954870, top1: 0.93626, CELoss: 0.18672, loss: 0.18672, batch_cost: 0.59274s, reader_cost: 0.01609, ips: 107.97268 samples/s, eta: 3:53:49
[2022/06/19 02:21:29] ppcls INFO: [Train][Epoch 162/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03952135, top1: 0.93539, CELoss: 0.18761, loss: 0.18761, batch_cost: 0.59625s, reader_cost: 0.01590, ips: 107.33694 samples/s, eta: 3:55:06
[2022/06/19 02:21:35] ppcls INFO: [Train][Epoch 162/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03949400, top1: 0.93543, CELoss: 0.18728, loss: 0.18728, batch_cost: 0.59143s, reader_cost: 0.01667, ips: 108.21197 samples/s, eta: 3:53:06
[2022/06/19 02:21:41] ppcls INFO: [Train][Epoch 162/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03946665, top1: 0.93631, CELoss: 0.18517, loss: 0.18517, batch_cost: 0.59599s, reader_cost: 0.01701, ips: 107.38442 samples/s, eta: 3:54:48
[2022/06/19 02:21:47] ppcls INFO: [Train][Epoch 162/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03943930, top1: 0.93517, CELoss: 0.18848, loss: 0.18848, batch_cost: 0.59722s, reader_cost: 0.01776, ips: 107.16343 samples/s, eta: 3:55:11
[2022/06/19 02:21:53] ppcls INFO: [Train][Epoch 162/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03941196, top1: 0.93605, CELoss: 0.18694, loss: 0.18694, batch_cost: 0.59142s, reader_cost: 0.01717, ips: 108.21452 samples/s, eta: 3:52:48
[2022/06/19 02:21:57] ppcls INFO: [Train][Epoch 162/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03938461, top1: 0.93488, CELoss: 0.18932, loss: 0.18932, batch_cost: 0.58370s, reader_cost: 0.01659, ips: 109.64516 samples/s, eta: 3:49:40
[2022/06/19 02:22:00] ppcls INFO: [Train][Epoch 162/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03935727, top1: 0.93494, CELoss: 0.19040, loss: 0.19040, batch_cost: 0.56223s, reader_cost: 0.01560, ips: 87.15287 samples/s, eta: 3:41:08
[2022/06/19 02:22:00] ppcls INFO: [Train][Epoch 162/300][Avg]top1: 0.93494, CELoss: 0.19040, loss: 0.19040
[2022/06/19 02:22:00] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:22:07] ppcls INFO: [Train][Epoch 163/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03935454, top1: 0.92188, CELoss: 0.25499, loss: 0.25499, batch_cost: 0.59923s, reader_cost: 0.04234, ips: 106.80396 samples/s, eta: 3:55:40
[2022/06/19 02:22:15] ppcls INFO: [Train][Epoch 163/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03932720, top1: 0.95028, CELoss: 0.15611, loss: 0.15611, batch_cost: 0.91584s, reader_cost: 0.02001, ips: 69.88123 samples/s, eta: 6:00:02
[2022/06/19 02:22:20] ppcls INFO: [Train][Epoch 163/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03929986, top1: 0.94345, CELoss: 0.16729, loss: 0.16729, batch_cost: 0.63114s, reader_cost: 0.02249, ips: 101.40407 samples/s, eta: 4:08:00
[2022/06/19 02:22:26] ppcls INFO: [Train][Epoch 163/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03927253, top1: 0.93851, CELoss: 0.17792, loss: 0.17792, batch_cost: 0.61906s, reader_cost: 0.01564, ips: 103.38307 samples/s, eta: 4:03:09
[2022/06/19 02:22:32] ppcls INFO: [Train][Epoch 163/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03924519, top1: 0.93864, CELoss: 0.17723, loss: 0.17723, batch_cost: 0.62543s, reader_cost: 0.01684, ips: 102.33001 samples/s, eta: 4:05:33
[2022/06/19 02:22:38] ppcls INFO: [Train][Epoch 163/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03921786, top1: 0.93597, CELoss: 0.18600, loss: 0.18600, batch_cost: 0.62591s, reader_cost: 0.01479, ips: 102.25171 samples/s, eta: 4:05:38
[2022/06/19 02:22:45] ppcls INFO: [Train][Epoch 163/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03919053, top1: 0.93494, CELoss: 0.18468, loss: 0.18468, batch_cost: 0.62375s, reader_cost: 0.01587, ips: 102.60593 samples/s, eta: 4:04:41
[2022/06/19 02:22:51] ppcls INFO: [Train][Epoch 163/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03916321, top1: 0.93662, CELoss: 0.18183, loss: 0.18183, batch_cost: 0.62456s, reader_cost: 0.01710, ips: 102.47180 samples/s, eta: 4:04:54
[2022/06/19 02:22:57] ppcls INFO: [Train][Epoch 163/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03913588, top1: 0.93769, CELoss: 0.17961, loss: 0.17961, batch_cost: 0.62765s, reader_cost: 0.01639, ips: 101.96711 samples/s, eta: 4:06:01
[2022/06/19 02:23:03] ppcls INFO: [Train][Epoch 163/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03910856, top1: 0.93630, CELoss: 0.18250, loss: 0.18250, batch_cost: 0.61653s, reader_cost: 0.01568, ips: 103.80664 samples/s, eta: 4:01:33
[2022/06/19 02:23:09] ppcls INFO: [Train][Epoch 163/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03908124, top1: 0.93595, CELoss: 0.18406, loss: 0.18406, batch_cost: 0.61580s, reader_cost: 0.01515, ips: 103.92990 samples/s, eta: 4:01:10
[2022/06/19 02:23:15] ppcls INFO: [Train][Epoch 163/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03905393, top1: 0.93637, CELoss: 0.18536, loss: 0.18536, batch_cost: 0.61502s, reader_cost: 0.01454, ips: 104.06119 samples/s, eta: 4:00:45
[2022/06/19 02:23:21] ppcls INFO: [Train][Epoch 163/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03902661, top1: 0.93750, CELoss: 0.18556, loss: 0.18556, batch_cost: 0.61880s, reader_cost: 0.01541, ips: 103.42576 samples/s, eta: 4:02:08
[2022/06/19 02:23:28] ppcls INFO: [Train][Epoch 163/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03899930, top1: 0.93798, CELoss: 0.18386, loss: 0.18386, batch_cost: 0.61896s, reader_cost: 0.01513, ips: 103.39984 samples/s, eta: 4:02:05
[2022/06/19 02:23:34] ppcls INFO: [Train][Epoch 163/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03897199, top1: 0.93894, CELoss: 0.18120, loss: 0.18120, batch_cost: 0.62269s, reader_cost: 0.01513, ips: 102.77928 samples/s, eta: 4:03:27
[2022/06/19 02:23:41] ppcls INFO: [Train][Epoch 163/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03894468, top1: 0.93802, CELoss: 0.18277, loss: 0.18277, batch_cost: 0.62600s, reader_cost: 0.01480, ips: 102.23649 samples/s, eta: 4:04:38
[2022/06/19 02:23:46] ppcls INFO: [Train][Epoch 163/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03891737, top1: 0.93672, CELoss: 0.18547, loss: 0.18547, batch_cost: 0.61722s, reader_cost: 0.01414, ips: 103.69134 samples/s, eta: 4:01:06
[2022/06/19 02:23:48] ppcls INFO: [Train][Epoch 163/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03889007, top1: 0.93659, CELoss: 0.18619, loss: 0.18619, batch_cost: 0.59266s, reader_cost: 0.01334, ips: 82.67865 samples/s, eta: 3:51:24
[2022/06/19 02:23:49] ppcls INFO: [Train][Epoch 163/300][Avg]top1: 0.93659, CELoss: 0.18619, loss: 0.18619
[2022/06/19 02:23:49] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:23:56] ppcls INFO: [Train][Epoch 164/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03888734, top1: 0.95312, CELoss: 0.10065, loss: 0.10065, batch_cost: 0.62997s, reader_cost: 0.03676, ips: 101.59269 samples/s, eta: 4:05:58
[2022/06/19 02:24:03] ppcls INFO: [Train][Epoch 164/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03886004, top1: 0.93466, CELoss: 0.19183, loss: 0.19183, batch_cost: 0.71490s, reader_cost: 0.02046, ips: 89.52306 samples/s, eta: 4:39:00
[2022/06/19 02:24:08] ppcls INFO: [Train][Epoch 164/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03883274, top1: 0.93899, CELoss: 0.17711, loss: 0.17711, batch_cost: 0.62911s, reader_cost: 0.01376, ips: 101.73098 samples/s, eta: 4:05:25
[2022/06/19 02:24:14] ppcls INFO: [Train][Epoch 164/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03880544, top1: 0.94204, CELoss: 0.18080, loss: 0.18080, batch_cost: 0.60734s, reader_cost: 0.01260, ips: 105.37818 samples/s, eta: 3:56:49
[2022/06/19 02:24:21] ppcls INFO: [Train][Epoch 164/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03877815, top1: 0.94169, CELoss: 0.18247, loss: 0.18247, batch_cost: 0.63325s, reader_cost: 0.01870, ips: 101.06614 samples/s, eta: 4:06:49
[2022/06/19 02:24:27] ppcls INFO: [Train][Epoch 164/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03875086, top1: 0.93964, CELoss: 0.18340, loss: 0.18340, batch_cost: 0.61771s, reader_cost: 0.01814, ips: 103.60819 samples/s, eta: 4:00:40
[2022/06/19 02:24:33] ppcls INFO: [Train][Epoch 164/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03872357, top1: 0.93366, CELoss: 0.19216, loss: 0.19216, batch_cost: 0.62482s, reader_cost: 0.01860, ips: 102.42929 samples/s, eta: 4:03:20
[2022/06/19 02:24:40] ppcls INFO: [Train][Epoch 164/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03869628, top1: 0.93288, CELoss: 0.19334, loss: 0.19334, batch_cost: 0.62754s, reader_cost: 0.01786, ips: 101.98631 samples/s, eta: 4:04:17
[2022/06/19 02:24:47] ppcls INFO: [Train][Epoch 164/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03866899, top1: 0.93210, CELoss: 0.19302, loss: 0.19302, batch_cost: 0.63323s, reader_cost: 0.01803, ips: 101.06927 samples/s, eta: 4:06:23
[2022/06/19 02:24:51] ppcls INFO: [Train][Epoch 164/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03864171, top1: 0.93321, CELoss: 0.18961, loss: 0.18961, batch_cost: 0.61690s, reader_cost: 0.01817, ips: 103.74461 samples/s, eta: 3:59:56
[2022/06/19 02:24:57] ppcls INFO: [Train][Epoch 164/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03861443, top1: 0.93147, CELoss: 0.19185, loss: 0.19185, batch_cost: 0.61417s, reader_cost: 0.01842, ips: 104.20632 samples/s, eta: 3:58:46
[2022/06/19 02:25:03] ppcls INFO: [Train][Epoch 164/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03858715, top1: 0.93046, CELoss: 0.19594, loss: 0.19594, batch_cost: 0.61185s, reader_cost: 0.01822, ips: 104.60153 samples/s, eta: 3:57:46
[2022/06/19 02:25:10] ppcls INFO: [Train][Epoch 164/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03855988, top1: 0.93143, CELoss: 0.19457, loss: 0.19457, batch_cost: 0.61921s, reader_cost: 0.01839, ips: 103.35708 samples/s, eta: 4:00:31
[2022/06/19 02:25:16] ppcls INFO: [Train][Epoch 164/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03853261, top1: 0.93142, CELoss: 0.19340, loss: 0.19340, batch_cost: 0.61926s, reader_cost: 0.01806, ips: 103.34981 samples/s, eta: 4:00:26
[2022/06/19 02:25:22] ppcls INFO: [Train][Epoch 164/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03850533, top1: 0.93218, CELoss: 0.19150, loss: 0.19150, batch_cost: 0.61124s, reader_cost: 0.01761, ips: 104.70528 samples/s, eta: 3:57:13
[2022/06/19 02:25:29] ppcls INFO: [Train][Epoch 164/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03847807, top1: 0.93150, CELoss: 0.19110, loss: 0.19110, batch_cost: 0.61880s, reader_cost: 0.01648, ips: 103.42636 samples/s, eta: 4:00:03
[2022/06/19 02:25:34] ppcls INFO: [Train][Epoch 164/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03845080, top1: 0.93255, CELoss: 0.18867, loss: 0.18867, batch_cost: 0.60990s, reader_cost: 0.01569, ips: 104.93601 samples/s, eta: 3:56:30
[2022/06/19 02:25:36] ppcls INFO: [Train][Epoch 164/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03842354, top1: 0.93321, CELoss: 0.18700, loss: 0.18700, batch_cost: 0.58583s, reader_cost: 0.01476, ips: 83.64173 samples/s, eta: 3:47:04
[2022/06/19 02:25:36] ppcls INFO: [Train][Epoch 164/300][Avg]top1: 0.93321, CELoss: 0.18700, loss: 0.18700
[2022/06/19 02:25:36] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:25:43] ppcls INFO: [Train][Epoch 165/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03842081, top1: 0.93750, CELoss: 0.18341, loss: 0.18341, batch_cost: 0.62215s, reader_cost: 0.03767, ips: 102.86902 samples/s, eta: 4:01:08
[2022/06/19 02:25:50] ppcls INFO: [Train][Epoch 165/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03839355, top1: 0.94744, CELoss: 0.18408, loss: 0.18408, batch_cost: 0.76836s, reader_cost: 0.04167, ips: 83.29446 samples/s, eta: 4:57:41
[2022/06/19 02:25:57] ppcls INFO: [Train][Epoch 165/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03836629, top1: 0.93304, CELoss: 0.21067, loss: 0.21067, batch_cost: 0.68736s, reader_cost: 0.02739, ips: 93.11033 samples/s, eta: 4:26:11
[2022/06/19 02:26:03] ppcls INFO: [Train][Epoch 165/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03833904, top1: 0.93397, CELoss: 0.19806, loss: 0.19806, batch_cost: 0.66540s, reader_cost: 0.02406, ips: 96.18218 samples/s, eta: 4:17:34
[2022/06/19 02:26:09] ppcls INFO: [Train][Epoch 165/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03831178, top1: 0.93445, CELoss: 0.19767, loss: 0.19767, batch_cost: 0.65241s, reader_cost: 0.02486, ips: 98.09853 samples/s, eta: 4:12:26
[2022/06/19 02:26:15] ppcls INFO: [Train][Epoch 165/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03828453, top1: 0.93719, CELoss: 0.19025, loss: 0.19025, batch_cost: 0.62823s, reader_cost: 0.02388, ips: 101.87395 samples/s, eta: 4:02:58
[2022/06/19 02:26:20] ppcls INFO: [Train][Epoch 165/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03825729, top1: 0.93750, CELoss: 0.18669, loss: 0.18669, batch_cost: 0.61749s, reader_cost: 0.02079, ips: 103.64579 samples/s, eta: 3:58:43
[2022/06/19 02:26:26] ppcls INFO: [Train][Epoch 165/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03823004, top1: 0.93816, CELoss: 0.18461, loss: 0.18461, batch_cost: 0.61306s, reader_cost: 0.01879, ips: 104.39403 samples/s, eta: 3:56:54
[2022/06/19 02:26:32] ppcls INFO: [Train][Epoch 165/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03820280, top1: 0.93769, CELoss: 0.18552, loss: 0.18552, batch_cost: 0.60775s, reader_cost: 0.01828, ips: 105.30599 samples/s, eta: 3:54:45
[2022/06/19 02:26:39] ppcls INFO: [Train][Epoch 165/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03817556, top1: 0.93750, CELoss: 0.18527, loss: 0.18527, batch_cost: 0.61719s, reader_cost: 0.03891, ips: 103.69649 samples/s, eta: 3:58:17
[2022/06/19 02:26:45] ppcls INFO: [Train][Epoch 165/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03814832, top1: 0.93719, CELoss: 0.18647, loss: 0.18647, batch_cost: 0.61741s, reader_cost: 0.04160, ips: 103.65809 samples/s, eta: 3:58:16
[2022/06/19 02:26:51] ppcls INFO: [Train][Epoch 165/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03812108, top1: 0.93820, CELoss: 0.18269, loss: 0.18269, batch_cost: 0.61570s, reader_cost: 0.04934, ips: 103.94617 samples/s, eta: 3:57:31
[2022/06/19 02:26:57] ppcls INFO: [Train][Epoch 165/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03809385, top1: 0.93827, CELoss: 0.18287, loss: 0.18287, batch_cost: 0.61288s, reader_cost: 0.04888, ips: 104.42491 samples/s, eta: 3:56:19
[2022/06/19 02:27:02] ppcls INFO: [Train][Epoch 165/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03806662, top1: 0.93762, CELoss: 0.18338, loss: 0.18338, batch_cost: 0.60921s, reader_cost: 0.04647, ips: 105.05441 samples/s, eta: 3:54:48
[2022/06/19 02:27:08] ppcls INFO: [Train][Epoch 165/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03803939, top1: 0.93706, CELoss: 0.18414, loss: 0.18414, batch_cost: 0.60558s, reader_cost: 0.04326, ips: 105.68323 samples/s, eta: 3:53:18
[2022/06/19 02:27:14] ppcls INFO: [Train][Epoch 165/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03801217, top1: 0.93740, CELoss: 0.18352, loss: 0.18352, batch_cost: 0.60244s, reader_cost: 0.04043, ips: 106.23414 samples/s, eta: 3:52:00
[2022/06/19 02:27:19] ppcls INFO: [Train][Epoch 165/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03798495, top1: 0.93624, CELoss: 0.18505, loss: 0.18505, batch_cost: 0.59886s, reader_cost: 0.03794, ips: 106.86914 samples/s, eta: 3:50:31
[2022/06/19 02:27:21] ppcls INFO: [Train][Epoch 165/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03795773, top1: 0.93622, CELoss: 0.18503, loss: 0.18503, batch_cost: 0.57603s, reader_cost: 0.03571, ips: 85.06444 samples/s, eta: 3:41:38
[2022/06/19 02:27:22] ppcls INFO: [Train][Epoch 165/300][Avg]top1: 0.93622, CELoss: 0.18503, loss: 0.18503
[2022/06/19 02:27:29] ppcls INFO: [Eval][Epoch 165][Iter: 0/16]CELoss: 0.97890, loss: 0.97890, top1: 0.78906, batch_cost: 7.25294s, reader_cost: 3.50757, ips: 8.82401 images/sec
[2022/06/19 02:27:37] ppcls INFO: [Eval][Epoch 165][Iter: 10/16]CELoss: 0.82682, loss: 0.82682, top1: 0.80717, batch_cost: 0.58544s, reader_cost: 0.00027, ips: 109.31952 images/sec
[2022/06/19 02:27:39] ppcls INFO: [Eval][Epoch 165][Avg]CELoss: 0.72011, loss: 0.72011, top1: 0.81409
[2022/06/19 02:27:39] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 02:27:39] ppcls INFO: [Eval][Epoch 165][best metric: 0.8140931725502014]
[2022/06/19 02:27:39] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:27:46] ppcls INFO: [Train][Epoch 166/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03795501, top1: 0.93750, CELoss: 0.13364, loss: 0.13364, batch_cost: 0.61616s, reader_cost: 0.07499, ips: 103.86932 samples/s, eta: 3:57:04
[2022/06/19 02:27:52] ppcls INFO: [Train][Epoch 166/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03792779, top1: 0.95455, CELoss: 0.15230, loss: 0.15230, batch_cost: 0.60395s, reader_cost: 0.00043, ips: 105.96951 samples/s, eta: 3:52:16
[2022/06/19 02:27:58] ppcls INFO: [Train][Epoch 166/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03790057, top1: 0.95164, CELoss: 0.16114, loss: 0.16114, batch_cost: 0.61933s, reader_cost: 0.00036, ips: 103.33826 samples/s, eta: 3:58:04
[2022/06/19 02:28:05] ppcls INFO: [Train][Epoch 166/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03787336, top1: 0.93952, CELoss: 0.18326, loss: 0.18326, batch_cost: 0.61652s, reader_cost: 0.01013, ips: 103.80913 samples/s, eta: 3:56:53
[2022/06/19 02:28:11] ppcls INFO: [Train][Epoch 166/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03784615, top1: 0.93521, CELoss: 0.18607, loss: 0.18607, batch_cost: 0.61715s, reader_cost: 0.01021, ips: 103.70226 samples/s, eta: 3:57:02
[2022/06/19 02:28:16] ppcls INFO: [Train][Epoch 166/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03781895, top1: 0.93627, CELoss: 0.18665, loss: 0.18665, batch_cost: 0.60512s, reader_cost: 0.01072, ips: 105.76391 samples/s, eta: 3:52:18
[2022/06/19 02:28:22] ppcls INFO: [Train][Epoch 166/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03779175, top1: 0.93596, CELoss: 0.18911, loss: 0.18911, batch_cost: 0.60225s, reader_cost: 0.01346, ips: 106.26831 samples/s, eta: 3:51:06
[2022/06/19 02:28:30] ppcls INFO: [Train][Epoch 166/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03776454, top1: 0.93706, CELoss: 0.18445, loss: 0.18445, batch_cost: 0.62287s, reader_cost: 0.01480, ips: 102.75022 samples/s, eta: 3:58:55
[2022/06/19 02:28:35] ppcls INFO: [Train][Epoch 166/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03773735, top1: 0.93519, CELoss: 0.18832, loss: 0.18832, batch_cost: 0.61187s, reader_cost: 0.01347, ips: 104.59713 samples/s, eta: 3:54:36
[2022/06/19 02:28:42] ppcls INFO: [Train][Epoch 166/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03771015, top1: 0.93578, CELoss: 0.18734, loss: 0.18734, batch_cost: 0.61742s, reader_cost: 0.01315, ips: 103.65640 samples/s, eta: 3:56:37
[2022/06/19 02:28:49] ppcls INFO: [Train][Epoch 166/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03768296, top1: 0.93719, CELoss: 0.18332, loss: 0.18332, batch_cost: 0.62704s, reader_cost: 0.01189, ips: 102.06660 samples/s, eta: 4:00:12
[2022/06/19 02:28:55] ppcls INFO: [Train][Epoch 166/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03765577, top1: 0.93680, CELoss: 0.18300, loss: 0.18300, batch_cost: 0.62339s, reader_cost: 0.01080, ips: 102.66455 samples/s, eta: 3:58:42
[2022/06/19 02:29:00] ppcls INFO: [Train][Epoch 166/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03762858, top1: 0.93634, CELoss: 0.18440, loss: 0.18440, batch_cost: 0.61899s, reader_cost: 0.01013, ips: 103.39482 samples/s, eta: 3:56:55
[2022/06/19 02:29:06] ppcls INFO: [Train][Epoch 166/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03760140, top1: 0.93738, CELoss: 0.18196, loss: 0.18196, batch_cost: 0.61351s, reader_cost: 0.00974, ips: 104.31776 samples/s, eta: 3:54:43
[2022/06/19 02:29:12] ppcls INFO: [Train][Epoch 166/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03757422, top1: 0.93717, CELoss: 0.18382, loss: 0.18382, batch_cost: 0.61602s, reader_cost: 0.00932, ips: 103.89329 samples/s, eta: 3:55:34
[2022/06/19 02:29:20] ppcls INFO: [Train][Epoch 166/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03754704, top1: 0.93678, CELoss: 0.18551, loss: 0.18551, batch_cost: 0.62597s, reader_cost: 0.00941, ips: 102.24212 samples/s, eta: 3:59:16
[2022/06/19 02:29:25] ppcls INFO: [Train][Epoch 166/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03751986, top1: 0.93692, CELoss: 0.18504, loss: 0.18504, batch_cost: 0.61939s, reader_cost: 0.00897, ips: 103.32823 samples/s, eta: 3:56:39
[2022/06/19 02:29:27] ppcls INFO: [Train][Epoch 166/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03749269, top1: 0.93522, CELoss: 0.18866, loss: 0.18866, batch_cost: 0.59487s, reader_cost: 0.00844, ips: 82.37163 samples/s, eta: 3:47:11
[2022/06/19 02:29:28] ppcls INFO: [Train][Epoch 166/300][Avg]top1: 0.93522, CELoss: 0.18866, loss: 0.18866
[2022/06/19 02:29:28] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:29:34] ppcls INFO: [Train][Epoch 167/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03748997, top1: 0.96875, CELoss: 0.10727, loss: 0.10727, batch_cost: 0.62885s, reader_cost: 0.02996, ips: 101.77366 samples/s, eta: 4:00:09
[2022/06/19 02:29:41] ppcls INFO: [Train][Epoch 167/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03746280, top1: 0.94176, CELoss: 0.16052, loss: 0.16052, batch_cost: 0.78705s, reader_cost: 0.00032, ips: 81.31626 samples/s, eta: 5:00:26
[2022/06/19 02:29:47] ppcls INFO: [Train][Epoch 167/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03743564, top1: 0.94420, CELoss: 0.15643, loss: 0.15643, batch_cost: 0.65064s, reader_cost: 0.00034, ips: 98.36508 samples/s, eta: 4:08:15
[2022/06/19 02:29:53] ppcls INFO: [Train][Epoch 167/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03740847, top1: 0.94052, CELoss: 0.15848, loss: 0.15848, batch_cost: 0.63912s, reader_cost: 0.00084, ips: 100.13819 samples/s, eta: 4:03:45
[2022/06/19 02:29:59] ppcls INFO: [Train][Epoch 167/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03738131, top1: 0.94131, CELoss: 0.15810, loss: 0.15810, batch_cost: 0.63392s, reader_cost: 0.00081, ips: 100.95903 samples/s, eta: 4:01:40
[2022/06/19 02:30:05] ppcls INFO: [Train][Epoch 167/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03735415, top1: 0.94026, CELoss: 0.16073, loss: 0.16073, batch_cost: 0.62431s, reader_cost: 0.00349, ips: 102.51354 samples/s, eta: 3:57:54
[2022/06/19 02:30:11] ppcls INFO: [Train][Epoch 167/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03732700, top1: 0.93878, CELoss: 0.16645, loss: 0.16645, batch_cost: 0.61993s, reader_cost: 0.00612, ips: 103.23764 samples/s, eta: 3:56:07
[2022/06/19 02:30:16] ppcls INFO: [Train][Epoch 167/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03729984, top1: 0.93882, CELoss: 0.16633, loss: 0.16633, batch_cost: 0.60472s, reader_cost: 0.00806, ips: 105.83397 samples/s, eta: 3:50:14
[2022/06/19 02:30:22] ppcls INFO: [Train][Epoch 167/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03727269, top1: 0.93769, CELoss: 0.16762, loss: 0.16762, batch_cost: 0.60026s, reader_cost: 0.01077, ips: 106.61990 samples/s, eta: 3:48:26
[2022/06/19 02:30:28] ppcls INFO: [Train][Epoch 167/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03724555, top1: 0.93802, CELoss: 0.17161, loss: 0.17161, batch_cost: 0.59422s, reader_cost: 0.01205, ips: 107.70454 samples/s, eta: 3:46:02
[2022/06/19 02:30:34] ppcls INFO: [Train][Epoch 167/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03721840, top1: 0.93874, CELoss: 0.17376, loss: 0.17376, batch_cost: 0.59807s, reader_cost: 0.01316, ips: 107.01157 samples/s, eta: 3:47:24
[2022/06/19 02:30:40] ppcls INFO: [Train][Epoch 167/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03719126, top1: 0.93694, CELoss: 0.17723, loss: 0.17723, batch_cost: 0.59710s, reader_cost: 0.01345, ips: 107.18445 samples/s, eta: 3:46:56
[2022/06/19 02:30:46] ppcls INFO: [Train][Epoch 167/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03716412, top1: 0.93505, CELoss: 0.18157, loss: 0.18157, batch_cost: 0.60023s, reader_cost: 0.01250, ips: 106.62592 samples/s, eta: 3:48:01
[2022/06/19 02:30:51] ppcls INFO: [Train][Epoch 167/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03713699, top1: 0.93500, CELoss: 0.18244, loss: 0.18244, batch_cost: 0.59215s, reader_cost: 0.01244, ips: 108.07985 samples/s, eta: 3:44:51
[2022/06/19 02:30:58] ppcls INFO: [Train][Epoch 167/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03710985, top1: 0.93562, CELoss: 0.18103, loss: 0.18103, batch_cost: 0.59999s, reader_cost: 0.01217, ips: 106.66842 samples/s, eta: 3:47:44
[2022/06/19 02:31:04] ppcls INFO: [Train][Epoch 167/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03708272, top1: 0.93564, CELoss: 0.18134, loss: 0.18134, batch_cost: 0.59912s, reader_cost: 0.01188, ips: 106.82312 samples/s, eta: 3:47:18
[2022/06/19 02:31:10] ppcls INFO: [Train][Epoch 167/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03705560, top1: 0.93653, CELoss: 0.17969, loss: 0.17969, batch_cost: 0.59686s, reader_cost: 0.01193, ips: 107.22755 samples/s, eta: 3:46:20
[2022/06/19 02:31:12] ppcls INFO: [Train][Epoch 167/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03702847, top1: 0.93668, CELoss: 0.17955, loss: 0.17955, batch_cost: 0.57412s, reader_cost: 0.01122, ips: 85.34855 samples/s, eta: 3:37:37
[2022/06/19 02:31:12] ppcls INFO: [Train][Epoch 167/300][Avg]top1: 0.93668, CELoss: 0.17955, loss: 0.17955
[2022/06/19 02:31:13] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:31:21] ppcls INFO: [Train][Epoch 168/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03702576, top1: 0.93750, CELoss: 0.13359, loss: 0.13359, batch_cost: 0.61857s, reader_cost: 0.03739, ips: 103.46486 samples/s, eta: 3:54:28
[2022/06/19 02:31:26] ppcls INFO: [Train][Epoch 168/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03699864, top1: 0.95170, CELoss: 0.14174, loss: 0.14174, batch_cost: 0.62105s, reader_cost: 0.00033, ips: 103.05051 samples/s, eta: 3:55:18
[2022/06/19 02:31:32] ppcls INFO: [Train][Epoch 168/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03697153, top1: 0.94643, CELoss: 0.15609, loss: 0.15609, batch_cost: 0.61272s, reader_cost: 0.00101, ips: 104.45163 samples/s, eta: 3:52:02
[2022/06/19 02:31:38] ppcls INFO: [Train][Epoch 168/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03694441, top1: 0.94456, CELoss: 0.15877, loss: 0.15877, batch_cost: 0.60403s, reader_cost: 0.00662, ips: 105.95473 samples/s, eta: 3:48:39
[2022/06/19 02:31:45] ppcls INFO: [Train][Epoch 168/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03691730, top1: 0.94093, CELoss: 0.16980, loss: 0.16980, batch_cost: 0.60900s, reader_cost: 0.00521, ips: 105.09001 samples/s, eta: 3:50:26
[2022/06/19 02:31:51] ppcls INFO: [Train][Epoch 168/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03689019, top1: 0.93964, CELoss: 0.17083, loss: 0.17083, batch_cost: 0.60862s, reader_cost: 0.00456, ips: 105.15629 samples/s, eta: 3:50:11
[2022/06/19 02:31:56] ppcls INFO: [Train][Epoch 168/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03686309, top1: 0.93955, CELoss: 0.17352, loss: 0.17352, batch_cost: 0.60170s, reader_cost: 0.00390, ips: 106.36591 samples/s, eta: 3:47:28
[2022/06/19 02:32:03] ppcls INFO: [Train][Epoch 168/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03683598, top1: 0.94124, CELoss: 0.16804, loss: 0.16804, batch_cost: 0.60763s, reader_cost: 0.00543, ips: 105.32743 samples/s, eta: 3:49:36
[2022/06/19 02:32:09] ppcls INFO: [Train][Epoch 168/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03680889, top1: 0.94001, CELoss: 0.17162, loss: 0.17162, batch_cost: 0.61077s, reader_cost: 0.00713, ips: 104.78537 samples/s, eta: 3:50:41
[2022/06/19 02:32:16] ppcls INFO: [Train][Epoch 168/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03678179, top1: 0.94008, CELoss: 0.17455, loss: 0.17455, batch_cost: 0.61897s, reader_cost: 0.00947, ips: 103.39794 samples/s, eta: 3:53:41
[2022/06/19 02:32:21] ppcls INFO: [Train][Epoch 168/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03675470, top1: 0.93874, CELoss: 0.17730, loss: 0.17730, batch_cost: 0.61032s, reader_cost: 0.01017, ips: 104.86275 samples/s, eta: 3:50:19
[2022/06/19 02:32:28] ppcls INFO: [Train][Epoch 168/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03672761, top1: 0.93820, CELoss: 0.18040, loss: 0.18040, batch_cost: 0.61212s, reader_cost: 0.00986, ips: 104.55509 samples/s, eta: 3:50:54
[2022/06/19 02:32:33] ppcls INFO: [Train][Epoch 168/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03670052, top1: 0.93698, CELoss: 0.18181, loss: 0.18181, batch_cost: 0.60435s, reader_cost: 0.01076, ips: 105.89869 samples/s, eta: 3:47:52
[2022/06/19 02:32:39] ppcls INFO: [Train][Epoch 168/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03667344, top1: 0.93726, CELoss: 0.17983, loss: 0.17983, batch_cost: 0.60301s, reader_cost: 0.01107, ips: 106.13417 samples/s, eta: 3:47:15
[2022/06/19 02:32:45] ppcls INFO: [Train][Epoch 168/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03664636, top1: 0.93617, CELoss: 0.18042, loss: 0.18042, batch_cost: 0.60877s, reader_cost: 0.01812, ips: 105.12931 samples/s, eta: 3:49:20
[2022/06/19 02:32:51] ppcls INFO: [Train][Epoch 168/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03661928, top1: 0.93553, CELoss: 0.18194, loss: 0.18194, batch_cost: 0.60747s, reader_cost: 0.02214, ips: 105.35545 samples/s, eta: 3:48:44
[2022/06/19 02:32:57] ppcls INFO: [Train][Epoch 168/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03659221, top1: 0.93595, CELoss: 0.18110, loss: 0.18110, batch_cost: 0.60187s, reader_cost: 0.02527, ips: 106.33452 samples/s, eta: 3:46:32
[2022/06/19 02:32:59] ppcls INFO: [Train][Epoch 168/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03656513, top1: 0.93613, CELoss: 0.18129, loss: 0.18129, batch_cost: 0.57884s, reader_cost: 0.02377, ips: 84.65177 samples/s, eta: 3:37:46
[2022/06/19 02:32:59] ppcls INFO: [Train][Epoch 168/300][Avg]top1: 0.93613, CELoss: 0.18129, loss: 0.18129
[2022/06/19 02:32:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:33:05] ppcls INFO: [Train][Epoch 169/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03656243, top1: 0.93750, CELoss: 0.12227, loss: 0.12227, batch_cost: 0.60895s, reader_cost: 0.04746, ips: 105.09971 samples/s, eta: 3:49:05
[2022/06/19 02:33:12] ppcls INFO: [Train][Epoch 169/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03653536, top1: 0.95312, CELoss: 0.13566, loss: 0.13566, batch_cost: 0.64926s, reader_cost: 0.01721, ips: 98.57316 samples/s, eta: 4:04:08
[2022/06/19 02:33:19] ppcls INFO: [Train][Epoch 169/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03650830, top1: 0.94940, CELoss: 0.14558, loss: 0.14558, batch_cost: 0.66777s, reader_cost: 0.01487, ips: 95.84087 samples/s, eta: 4:10:59
[2022/06/19 02:33:25] ppcls INFO: [Train][Epoch 169/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03648123, top1: 0.94254, CELoss: 0.16424, loss: 0.16424, batch_cost: 0.65805s, reader_cost: 0.01399, ips: 97.25702 samples/s, eta: 4:07:13
[2022/06/19 02:33:31] ppcls INFO: [Train][Epoch 169/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03645418, top1: 0.94474, CELoss: 0.16183, loss: 0.16183, batch_cost: 0.63904s, reader_cost: 0.01565, ips: 100.15003 samples/s, eta: 3:59:58
[2022/06/19 02:33:38] ppcls INFO: [Train][Epoch 169/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03642712, top1: 0.94148, CELoss: 0.17024, loss: 0.17024, batch_cost: 0.65413s, reader_cost: 0.01488, ips: 97.83922 samples/s, eta: 4:05:32
[2022/06/19 02:33:44] ppcls INFO: [Train][Epoch 169/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03640007, top1: 0.94109, CELoss: 0.17250, loss: 0.17250, batch_cost: 0.63940s, reader_cost: 0.01340, ips: 100.09387 samples/s, eta: 3:59:54
[2022/06/19 02:33:50] ppcls INFO: [Train][Epoch 169/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03637302, top1: 0.94256, CELoss: 0.17056, loss: 0.17056, batch_cost: 0.63343s, reader_cost: 0.01538, ips: 101.03742 samples/s, eta: 3:57:33
[2022/06/19 02:33:56] ppcls INFO: [Train][Epoch 169/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03634598, top1: 0.94174, CELoss: 0.17442, loss: 0.17442, batch_cost: 0.62491s, reader_cost: 0.01587, ips: 102.41412 samples/s, eta: 3:54:15
[2022/06/19 02:34:02] ppcls INFO: [Train][Epoch 169/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03631893, top1: 0.94231, CELoss: 0.17188, loss: 0.17188, batch_cost: 0.62677s, reader_cost: 0.02553, ips: 102.11121 samples/s, eta: 3:54:50
[2022/06/19 02:34:08] ppcls INFO: [Train][Epoch 169/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03629190, top1: 0.94090, CELoss: 0.17573, loss: 0.17573, batch_cost: 0.62609s, reader_cost: 0.02362, ips: 102.22180 samples/s, eta: 3:54:29
[2022/06/19 02:34:15] ppcls INFO: [Train][Epoch 169/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03626486, top1: 0.93947, CELoss: 0.17843, loss: 0.17843, batch_cost: 0.62814s, reader_cost: 0.02307, ips: 101.88788 samples/s, eta: 3:55:09
[2022/06/19 02:34:20] ppcls INFO: [Train][Epoch 169/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03623783, top1: 0.93892, CELoss: 0.17864, loss: 0.17864, batch_cost: 0.62386s, reader_cost: 0.02268, ips: 102.58780 samples/s, eta: 3:53:26
[2022/06/19 02:34:26] ppcls INFO: [Train][Epoch 169/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03621080, top1: 0.93905, CELoss: 0.17725, loss: 0.17725, batch_cost: 0.62050s, reader_cost: 0.02102, ips: 103.14315 samples/s, eta: 3:52:05
[2022/06/19 02:34:32] ppcls INFO: [Train][Epoch 169/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03618377, top1: 0.93872, CELoss: 0.17803, loss: 0.17803, batch_cost: 0.61607s, reader_cost: 0.02117, ips: 103.88392 samples/s, eta: 3:50:19
[2022/06/19 02:34:38] ppcls INFO: [Train][Epoch 169/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03615675, top1: 0.93833, CELoss: 0.18024, loss: 0.18024, batch_cost: 0.61497s, reader_cost: 0.01983, ips: 104.07000 samples/s, eta: 3:49:48
[2022/06/19 02:34:44] ppcls INFO: [Train][Epoch 169/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03612973, top1: 0.93595, CELoss: 0.18440, loss: 0.18440, batch_cost: 0.61645s, reader_cost: 0.01917, ips: 103.81976 samples/s, eta: 3:50:15
[2022/06/19 02:34:46] ppcls INFO: [Train][Epoch 169/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03610272, top1: 0.93668, CELoss: 0.18225, loss: 0.18225, batch_cost: 0.59198s, reader_cost: 0.01802, ips: 82.77240 samples/s, eta: 3:41:01
[2022/06/19 02:34:47] ppcls INFO: [Train][Epoch 169/300][Avg]top1: 0.93668, CELoss: 0.18225, loss: 0.18225
[2022/06/19 02:34:47] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:34:55] ppcls INFO: [Train][Epoch 170/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03610002, top1: 0.93750, CELoss: 0.20870, loss: 0.20870, batch_cost: 0.63394s, reader_cost: 0.04351, ips: 100.95668 samples/s, eta: 3:56:40
[2022/06/19 02:35:01] ppcls INFO: [Train][Epoch 170/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03607301, top1: 0.93608, CELoss: 0.19882, loss: 0.19882, batch_cost: 0.71497s, reader_cost: 0.01525, ips: 89.51364 samples/s, eta: 4:26:49
[2022/06/19 02:35:07] ppcls INFO: [Train][Epoch 170/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03604600, top1: 0.93676, CELoss: 0.19803, loss: 0.19803, batch_cost: 0.66212s, reader_cost: 0.01749, ips: 96.65989 samples/s, eta: 4:06:58
[2022/06/19 02:35:14] ppcls INFO: [Train][Epoch 170/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03601899, top1: 0.93700, CELoss: 0.19243, loss: 0.19243, batch_cost: 0.65391s, reader_cost: 0.01833, ips: 97.87290 samples/s, eta: 4:03:48
[2022/06/19 02:35:20] ppcls INFO: [Train][Epoch 170/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03599199, top1: 0.93941, CELoss: 0.18815, loss: 0.18815, batch_cost: 0.63639s, reader_cost: 0.01964, ips: 100.56709 samples/s, eta: 3:57:10
[2022/06/19 02:35:25] ppcls INFO: [Train][Epoch 170/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03596499, top1: 0.94148, CELoss: 0.18776, loss: 0.18776, batch_cost: 0.61906s, reader_cost: 0.02057, ips: 103.38335 samples/s, eta: 3:50:36
[2022/06/19 02:35:32] ppcls INFO: [Train][Epoch 170/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03593800, top1: 0.94262, CELoss: 0.18017, loss: 0.18017, batch_cost: 0.63160s, reader_cost: 0.02000, ips: 101.33020 samples/s, eta: 3:55:10
[2022/06/19 02:35:38] ppcls INFO: [Train][Epoch 170/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03591101, top1: 0.94322, CELoss: 0.17872, loss: 0.17872, batch_cost: 0.62536s, reader_cost: 0.01860, ips: 102.34047 samples/s, eta: 3:52:44
[2022/06/19 02:35:44] ppcls INFO: [Train][Epoch 170/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03588402, top1: 0.94097, CELoss: 0.18112, loss: 0.18112, batch_cost: 0.62212s, reader_cost: 0.01938, ips: 102.87419 samples/s, eta: 3:51:26
[2022/06/19 02:35:50] ppcls INFO: [Train][Epoch 170/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03585703, top1: 0.94093, CELoss: 0.17842, loss: 0.17842, batch_cost: 0.61356s, reader_cost: 0.01988, ips: 104.30928 samples/s, eta: 3:48:09
[2022/06/19 02:35:55] ppcls INFO: [Train][Epoch 170/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03583005, top1: 0.94168, CELoss: 0.17972, loss: 0.17972, batch_cost: 0.60892s, reader_cost: 0.02001, ips: 105.10331 samples/s, eta: 3:46:19
[2022/06/19 02:36:02] ppcls INFO: [Train][Epoch 170/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03580307, top1: 0.94017, CELoss: 0.18301, loss: 0.18301, batch_cost: 0.61184s, reader_cost: 0.02013, ips: 104.60234 samples/s, eta: 3:47:18
[2022/06/19 02:36:08] ppcls INFO: [Train][Epoch 170/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03577610, top1: 0.94124, CELoss: 0.18143, loss: 0.18143, batch_cost: 0.61165s, reader_cost: 0.02013, ips: 104.63432 samples/s, eta: 3:47:08
[2022/06/19 02:36:14] ppcls INFO: [Train][Epoch 170/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03574913, top1: 0.94132, CELoss: 0.18154, loss: 0.18154, batch_cost: 0.61473s, reader_cost: 0.01965, ips: 104.11129 samples/s, eta: 3:48:10
[2022/06/19 02:36:20] ppcls INFO: [Train][Epoch 170/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03572216, top1: 0.94160, CELoss: 0.18029, loss: 0.18029, batch_cost: 0.61505s, reader_cost: 0.01893, ips: 104.05600 samples/s, eta: 3:48:11
[2022/06/19 02:36:28] ppcls INFO: [Train][Epoch 170/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03569520, top1: 0.94112, CELoss: 0.18229, loss: 0.18229, batch_cost: 0.62357s, reader_cost: 0.01835, ips: 102.63418 samples/s, eta: 3:51:15
[2022/06/19 02:36:31] ppcls INFO: [Train][Epoch 170/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03566824, top1: 0.94128, CELoss: 0.18142, loss: 0.18142, batch_cost: 0.60462s, reader_cost: 0.01734, ips: 105.85209 samples/s, eta: 3:44:07
[2022/06/19 02:36:33] ppcls INFO: [Train][Epoch 170/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03564128, top1: 0.94162, CELoss: 0.18064, loss: 0.18064, batch_cost: 0.58084s, reader_cost: 0.01630, ips: 84.36036 samples/s, eta: 3:35:12
[2022/06/19 02:36:34] ppcls INFO: [Train][Epoch 170/300][Avg]top1: 0.94162, CELoss: 0.18064, loss: 0.18064
[2022/06/19 02:36:41] ppcls INFO: [Eval][Epoch 170][Iter: 0/16]CELoss: 0.89630, loss: 0.89630, top1: 0.78516, batch_cost: 6.75761s, reader_cost: 3.66948, ips: 9.47081 images/sec
[2022/06/19 02:36:49] ppcls INFO: [Eval][Epoch 170][Iter: 10/16]CELoss: 0.82200, loss: 0.82200, top1: 0.80487, batch_cost: 0.60629s, reader_cost: 0.00685, ips: 105.56030 images/sec
[2022/06/19 02:36:50] ppcls INFO: [Eval][Epoch 170][Avg]CELoss: 0.68541, loss: 0.68541, top1: 0.81152
[2022/06/19 02:36:50] ppcls INFO: [Eval][Epoch 170][best metric: 0.8140931725502014]
[2022/06/19 02:36:51] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_170
[2022/06/19 02:36:51] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:36:57] ppcls INFO: [Train][Epoch 171/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03563858, top1: 0.95312, CELoss: 0.13344, loss: 0.13344, batch_cost: 0.61375s, reader_cost: 0.04663, ips: 104.27684 samples/s, eta: 3:47:23
[2022/06/19 02:37:04] ppcls INFO: [Train][Epoch 171/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03561163, top1: 0.92614, CELoss: 0.21013, loss: 0.21013, batch_cost: 0.69734s, reader_cost: 0.06924, ips: 91.77682 samples/s, eta: 4:18:14
[2022/06/19 02:37:10] ppcls INFO: [Train][Epoch 171/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03558468, top1: 0.93155, CELoss: 0.19241, loss: 0.19241, batch_cost: 0.64990s, reader_cost: 0.03791, ips: 98.47655 samples/s, eta: 4:00:34
[2022/06/19 02:37:16] ppcls INFO: [Train][Epoch 171/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03555773, top1: 0.93296, CELoss: 0.18650, loss: 0.18650, batch_cost: 0.64178s, reader_cost: 0.03063, ips: 99.72286 samples/s, eta: 3:57:27
[2022/06/19 02:37:22] ppcls INFO: [Train][Epoch 171/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03553079, top1: 0.92835, CELoss: 0.18740, loss: 0.18740, batch_cost: 0.63301s, reader_cost: 0.02652, ips: 101.10443 samples/s, eta: 3:54:06
[2022/06/19 02:37:28] ppcls INFO: [Train][Epoch 171/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03550385, top1: 0.92892, CELoss: 0.18682, loss: 0.18682, batch_cost: 0.62596s, reader_cost: 0.02277, ips: 102.24231 samples/s, eta: 3:51:23
[2022/06/19 02:37:34] ppcls INFO: [Train][Epoch 171/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03547692, top1: 0.93212, CELoss: 0.18199, loss: 0.18199, batch_cost: 0.61789s, reader_cost: 0.02328, ips: 103.57906 samples/s, eta: 3:48:18
[2022/06/19 02:37:39] ppcls INFO: [Train][Epoch 171/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03544999, top1: 0.93200, CELoss: 0.18314, loss: 0.18314, batch_cost: 0.60439s, reader_cost: 0.02362, ips: 105.89241 samples/s, eta: 3:43:13
[2022/06/19 02:37:45] ppcls INFO: [Train][Epoch 171/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03542306, top1: 0.93461, CELoss: 0.17846, loss: 0.17846, batch_cost: 0.60215s, reader_cost: 0.02207, ips: 106.28562 samples/s, eta: 3:42:17
[2022/06/19 02:37:52] ppcls INFO: [Train][Epoch 171/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03539613, top1: 0.93475, CELoss: 0.17937, loss: 0.17937, batch_cost: 0.61031s, reader_cost: 0.02158, ips: 104.86447 samples/s, eta: 3:45:12
[2022/06/19 02:37:58] ppcls INFO: [Train][Epoch 171/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03536921, top1: 0.93425, CELoss: 0.18109, loss: 0.18109, batch_cost: 0.60709s, reader_cost: 0.02359, ips: 105.42036 samples/s, eta: 3:43:54
[2022/06/19 02:38:04] ppcls INFO: [Train][Epoch 171/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03534229, top1: 0.93497, CELoss: 0.17924, loss: 0.17924, batch_cost: 0.61006s, reader_cost: 0.02622, ips: 104.90753 samples/s, eta: 3:44:54
[2022/06/19 02:38:11] ppcls INFO: [Train][Epoch 171/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03531538, top1: 0.93427, CELoss: 0.17982, loss: 0.17982, batch_cost: 0.61947s, reader_cost: 0.02514, ips: 103.31390 samples/s, eta: 3:48:16
[2022/06/19 02:38:18] ppcls INFO: [Train][Epoch 171/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03528847, top1: 0.93476, CELoss: 0.18283, loss: 0.18283, batch_cost: 0.62664s, reader_cost: 0.02352, ips: 102.13173 samples/s, eta: 3:50:48
[2022/06/19 02:38:23] ppcls INFO: [Train][Epoch 171/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03526156, top1: 0.93584, CELoss: 0.18151, loss: 0.18151, batch_cost: 0.61523s, reader_cost: 0.02324, ips: 104.02594 samples/s, eta: 3:46:30
[2022/06/19 02:38:28] ppcls INFO: [Train][Epoch 171/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03523466, top1: 0.93533, CELoss: 0.18130, loss: 0.18130, batch_cost: 0.60944s, reader_cost: 0.02274, ips: 105.01468 samples/s, eta: 3:44:16
[2022/06/19 02:38:34] ppcls INFO: [Train][Epoch 171/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03520776, top1: 0.93556, CELoss: 0.18151, loss: 0.18151, batch_cost: 0.60873s, reader_cost: 0.02176, ips: 105.13629 samples/s, eta: 3:43:54
[2022/06/19 02:38:37] ppcls INFO: [Train][Epoch 171/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03518086, top1: 0.93522, CELoss: 0.18321, loss: 0.18321, batch_cost: 0.58483s, reader_cost: 0.02049, ips: 83.78561 samples/s, eta: 3:35:01
[2022/06/19 02:38:37] ppcls INFO: [Train][Epoch 171/300][Avg]top1: 0.93522, CELoss: 0.18321, loss: 0.18321
[2022/06/19 02:38:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:38:44] ppcls INFO: [Train][Epoch 172/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03517818, top1: 0.95312, CELoss: 0.09385, loss: 0.09385, batch_cost: 0.61941s, reader_cost: 0.04891, ips: 103.32348 samples/s, eta: 3:47:43
[2022/06/19 02:38:50] ppcls INFO: [Train][Epoch 172/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03515128, top1: 0.94034, CELoss: 0.15419, loss: 0.15419, batch_cost: 0.64873s, reader_cost: 0.00285, ips: 98.65402 samples/s, eta: 3:58:23
[2022/06/19 02:38:56] ppcls INFO: [Train][Epoch 172/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03512440, top1: 0.94494, CELoss: 0.16385, loss: 0.16385, batch_cost: 0.63536s, reader_cost: 0.00741, ips: 100.73097 samples/s, eta: 3:53:22
[2022/06/19 02:39:03] ppcls INFO: [Train][Epoch 172/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03509751, top1: 0.93952, CELoss: 0.17215, loss: 0.17215, batch_cost: 0.63723s, reader_cost: 0.00619, ips: 100.43522 samples/s, eta: 3:53:57
[2022/06/19 02:39:09] ppcls INFO: [Train][Epoch 172/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03507063, top1: 0.94055, CELoss: 0.16791, loss: 0.16791, batch_cost: 0.62471s, reader_cost: 0.00551, ips: 102.44834 samples/s, eta: 3:49:15
[2022/06/19 02:39:15] ppcls INFO: [Train][Epoch 172/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03504375, top1: 0.94301, CELoss: 0.16349, loss: 0.16349, batch_cost: 0.63678s, reader_cost: 0.00553, ips: 100.50564 samples/s, eta: 3:53:34
[2022/06/19 02:39:23] ppcls INFO: [Train][Epoch 172/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03501688, top1: 0.94134, CELoss: 0.16595, loss: 0.16595, batch_cost: 0.65332s, reader_cost: 0.00537, ips: 97.96176 samples/s, eta: 3:59:32
[2022/06/19 02:39:28] ppcls INFO: [Train][Epoch 172/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03499001, top1: 0.94080, CELoss: 0.16645, loss: 0.16645, batch_cost: 0.63464s, reader_cost: 0.00524, ips: 100.84535 samples/s, eta: 3:52:34
[2022/06/19 02:39:34] ppcls INFO: [Train][Epoch 172/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03496315, top1: 0.94020, CELoss: 0.16790, loss: 0.16790, batch_cost: 0.62712s, reader_cost: 0.00604, ips: 102.05424 samples/s, eta: 3:49:43
[2022/06/19 02:39:40] ppcls INFO: [Train][Epoch 172/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03493629, top1: 0.93733, CELoss: 0.17302, loss: 0.17302, batch_cost: 0.62300s, reader_cost: 0.00638, ips: 102.72801 samples/s, eta: 3:48:06
[2022/06/19 02:39:46] ppcls INFO: [Train][Epoch 172/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03490943, top1: 0.93781, CELoss: 0.17316, loss: 0.17316, batch_cost: 0.62050s, reader_cost: 0.00593, ips: 103.14189 samples/s, eta: 3:47:05
[2022/06/19 02:39:52] ppcls INFO: [Train][Epoch 172/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03488257, top1: 0.93722, CELoss: 0.17529, loss: 0.17529, batch_cost: 0.62342s, reader_cost: 0.00570, ips: 102.65936 samples/s, eta: 3:48:03
[2022/06/19 02:39:59] ppcls INFO: [Train][Epoch 172/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03485572, top1: 0.93815, CELoss: 0.17376, loss: 0.17376, batch_cost: 0.63244s, reader_cost: 0.00538, ips: 101.19549 samples/s, eta: 3:51:15
[2022/06/19 02:40:06] ppcls INFO: [Train][Epoch 172/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03482888, top1: 0.93929, CELoss: 0.17151, loss: 0.17151, batch_cost: 0.63465s, reader_cost: 0.00619, ips: 100.84330 samples/s, eta: 3:51:57
[2022/06/19 02:40:12] ppcls INFO: [Train][Epoch 172/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03480203, top1: 0.93905, CELoss: 0.17183, loss: 0.17183, batch_cost: 0.63134s, reader_cost: 0.00662, ips: 101.37096 samples/s, eta: 3:50:38
[2022/06/19 02:40:17] ppcls INFO: [Train][Epoch 172/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03477519, top1: 0.93874, CELoss: 0.17463, loss: 0.17463, batch_cost: 0.62449s, reader_cost: 0.00676, ips: 102.48381 samples/s, eta: 3:48:01
[2022/06/19 02:40:22] ppcls INFO: [Train][Epoch 172/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03474836, top1: 0.93876, CELoss: 0.17414, loss: 0.17414, batch_cost: 0.61826s, reader_cost: 0.00661, ips: 103.51659 samples/s, eta: 3:45:39
[2022/06/19 02:40:25] ppcls INFO: [Train][Epoch 172/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03472153, top1: 0.93860, CELoss: 0.17302, loss: 0.17302, batch_cost: 0.59407s, reader_cost: 0.00623, ips: 82.48177 samples/s, eta: 3:36:43
[2022/06/19 02:40:25] ppcls INFO: [Train][Epoch 172/300][Avg]top1: 0.93860, CELoss: 0.17302, loss: 0.17302
[2022/06/19 02:40:25] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:40:33] ppcls INFO: [Train][Epoch 173/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03471885, top1: 0.93750, CELoss: 0.24737, loss: 0.24737, batch_cost: 0.63522s, reader_cost: 0.04682, ips: 100.75216 samples/s, eta: 3:51:43
[2022/06/19 02:40:39] ppcls INFO: [Train][Epoch 173/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03469202, top1: 0.94460, CELoss: 0.13832, loss: 0.13832, batch_cost: 0.70212s, reader_cost: 0.23098, ips: 91.15222 samples/s, eta: 4:16:01
[2022/06/19 02:40:45] ppcls INFO: [Train][Epoch 173/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03466519, top1: 0.94568, CELoss: 0.15860, loss: 0.15860, batch_cost: 0.60154s, reader_cost: 0.09253, ips: 106.39355 samples/s, eta: 3:39:14
[2022/06/19 02:40:51] ppcls INFO: [Train][Epoch 173/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03463838, top1: 0.94355, CELoss: 0.16121, loss: 0.16121, batch_cost: 0.61182s, reader_cost: 0.05809, ips: 104.60559 samples/s, eta: 3:42:53
[2022/06/19 02:40:57] ppcls INFO: [Train][Epoch 173/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03461156, top1: 0.93979, CELoss: 0.17028, loss: 0.17028, batch_cost: 0.60847s, reader_cost: 0.04351, ips: 105.18245 samples/s, eta: 3:41:33
[2022/06/19 02:41:03] ppcls INFO: [Train][Epoch 173/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03458475, top1: 0.93873, CELoss: 0.17490, loss: 0.17490, batch_cost: 0.60024s, reader_cost: 0.03688, ips: 106.62353 samples/s, eta: 3:38:28
[2022/06/19 02:41:09] ppcls INFO: [Train][Epoch 173/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03455794, top1: 0.93904, CELoss: 0.17220, loss: 0.17220, batch_cost: 0.59841s, reader_cost: 0.03142, ips: 106.94974 samples/s, eta: 3:37:42
[2022/06/19 02:41:15] ppcls INFO: [Train][Epoch 173/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03453114, top1: 0.94058, CELoss: 0.16802, loss: 0.16802, batch_cost: 0.60764s, reader_cost: 0.02778, ips: 105.32564 samples/s, eta: 3:40:57
[2022/06/19 02:41:21] ppcls INFO: [Train][Epoch 173/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03450434, top1: 0.94078, CELoss: 0.16851, loss: 0.16851, batch_cost: 0.60385s, reader_cost: 0.02474, ips: 105.98676 samples/s, eta: 3:39:28
[2022/06/19 02:41:27] ppcls INFO: [Train][Epoch 173/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03447754, top1: 0.93939, CELoss: 0.17109, loss: 0.17109, batch_cost: 0.60688s, reader_cost: 0.02262, ips: 105.45732 samples/s, eta: 3:40:28
[2022/06/19 02:41:33] ppcls INFO: [Train][Epoch 173/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03445075, top1: 0.94028, CELoss: 0.17076, loss: 0.17076, batch_cost: 0.60218s, reader_cost: 0.02227, ips: 106.27980 samples/s, eta: 3:38:40
[2022/06/19 02:41:39] ppcls INFO: [Train][Epoch 173/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03442396, top1: 0.93877, CELoss: 0.17577, loss: 0.17577, batch_cost: 0.60305s, reader_cost: 0.02076, ips: 106.12692 samples/s, eta: 3:38:53
[2022/06/19 02:41:45] ppcls INFO: [Train][Epoch 173/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03439718, top1: 0.93815, CELoss: 0.17739, loss: 0.17739, batch_cost: 0.60425s, reader_cost: 0.01991, ips: 105.91661 samples/s, eta: 3:39:13
[2022/06/19 02:41:51] ppcls INFO: [Train][Epoch 173/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03437040, top1: 0.93929, CELoss: 0.17589, loss: 0.17589, batch_cost: 0.60399s, reader_cost: 0.01963, ips: 105.96290 samples/s, eta: 3:39:01
[2022/06/19 02:41:59] ppcls INFO: [Train][Epoch 173/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03434362, top1: 0.94049, CELoss: 0.17284, loss: 0.17284, batch_cost: 0.61392s, reader_cost: 0.01945, ips: 104.24802 samples/s, eta: 3:42:31
[2022/06/19 02:42:06] ppcls INFO: [Train][Epoch 173/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03431685, top1: 0.93998, CELoss: 0.17389, loss: 0.17389, batch_cost: 0.61971s, reader_cost: 0.01889, ips: 103.27481 samples/s, eta: 3:44:31
[2022/06/19 02:42:10] ppcls INFO: [Train][Epoch 173/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03429008, top1: 0.93944, CELoss: 0.17415, loss: 0.17415, batch_cost: 0.60867s, reader_cost: 0.01817, ips: 105.14784 samples/s, eta: 3:40:25
[2022/06/19 02:42:12] ppcls INFO: [Train][Epoch 173/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03426332, top1: 0.93805, CELoss: 0.17625, loss: 0.17625, batch_cost: 0.58454s, reader_cost: 0.01708, ips: 83.82638 samples/s, eta: 3:31:35
[2022/06/19 02:42:13] ppcls INFO: [Train][Epoch 173/300][Avg]top1: 0.93805, CELoss: 0.17625, loss: 0.17625
[2022/06/19 02:42:13] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:42:20] ppcls INFO: [Train][Epoch 174/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03426064, top1: 0.90625, CELoss: 0.25418, loss: 0.25418, batch_cost: 0.62252s, reader_cost: 0.04526, ips: 102.80738 samples/s, eta: 3:45:19
[2022/06/19 02:42:26] ppcls INFO: [Train][Epoch 174/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03423388, top1: 0.94744, CELoss: 0.15860, loss: 0.15860, batch_cost: 0.72049s, reader_cost: 0.00057, ips: 88.82826 samples/s, eta: 4:20:39
[2022/06/19 02:42:33] ppcls INFO: [Train][Epoch 174/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03420713, top1: 0.94792, CELoss: 0.15065, loss: 0.15065, batch_cost: 0.65043s, reader_cost: 0.00080, ips: 98.39707 samples/s, eta: 3:55:12
[2022/06/19 02:42:38] ppcls INFO: [Train][Epoch 174/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03418038, top1: 0.94456, CELoss: 0.15990, loss: 0.15990, batch_cost: 0.62695s, reader_cost: 0.00341, ips: 102.08131 samples/s, eta: 3:46:36
[2022/06/19 02:42:45] ppcls INFO: [Train][Epoch 174/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03415363, top1: 0.95008, CELoss: 0.14690, loss: 0.14690, batch_cost: 0.62484s, reader_cost: 0.00625, ips: 102.42563 samples/s, eta: 3:45:44
[2022/06/19 02:42:51] ppcls INFO: [Train][Epoch 174/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03412688, top1: 0.94761, CELoss: 0.14975, loss: 0.14975, batch_cost: 0.63435s, reader_cost: 0.00937, ips: 100.89112 samples/s, eta: 3:49:04
[2022/06/19 02:42:57] ppcls INFO: [Train][Epoch 174/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03410015, top1: 0.94647, CELoss: 0.15339, loss: 0.15339, batch_cost: 0.63202s, reader_cost: 0.00971, ips: 101.26298 samples/s, eta: 3:48:07
[2022/06/19 02:43:03] ppcls INFO: [Train][Epoch 174/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03407341, top1: 0.94630, CELoss: 0.15174, loss: 0.15174, batch_cost: 0.62109s, reader_cost: 0.01134, ips: 103.04477 samples/s, eta: 3:44:04
[2022/06/19 02:43:09] ppcls INFO: [Train][Epoch 174/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03404668, top1: 0.94483, CELoss: 0.15814, loss: 0.15814, batch_cost: 0.61430s, reader_cost: 0.01196, ips: 104.18403 samples/s, eta: 3:41:31
[2022/06/19 02:43:15] ppcls INFO: [Train][Epoch 174/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03401995, top1: 0.94351, CELoss: 0.16375, loss: 0.16375, batch_cost: 0.61145s, reader_cost: 0.01317, ips: 104.66986 samples/s, eta: 3:40:23
[2022/06/19 02:43:21] ppcls INFO: [Train][Epoch 174/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03399323, top1: 0.94400, CELoss: 0.16284, loss: 0.16284, batch_cost: 0.61843s, reader_cost: 0.01434, ips: 103.48863 samples/s, eta: 3:42:48
[2022/06/19 02:43:27] ppcls INFO: [Train][Epoch 174/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03396651, top1: 0.94271, CELoss: 0.16497, loss: 0.16497, batch_cost: 0.61134s, reader_cost: 0.01395, ips: 104.68840 samples/s, eta: 3:40:09
[2022/06/19 02:43:34] ppcls INFO: [Train][Epoch 174/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03393980, top1: 0.94163, CELoss: 0.16681, loss: 0.16681, batch_cost: 0.61708s, reader_cost: 0.01383, ips: 103.71452 samples/s, eta: 3:42:07
[2022/06/19 02:43:39] ppcls INFO: [Train][Epoch 174/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03391309, top1: 0.94311, CELoss: 0.16320, loss: 0.16320, batch_cost: 0.61163s, reader_cost: 0.01365, ips: 104.63761 samples/s, eta: 3:40:03
[2022/06/19 02:43:46] ppcls INFO: [Train][Epoch 174/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03388638, top1: 0.94171, CELoss: 0.16630, loss: 0.16630, batch_cost: 0.61450s, reader_cost: 0.01412, ips: 104.15021 samples/s, eta: 3:40:59
[2022/06/19 02:43:51] ppcls INFO: [Train][Epoch 174/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03385968, top1: 0.94040, CELoss: 0.16944, loss: 0.16944, batch_cost: 0.61146s, reader_cost: 0.01320, ips: 104.66711 samples/s, eta: 3:39:47
[2022/06/19 02:43:57] ppcls INFO: [Train][Epoch 174/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03383298, top1: 0.94070, CELoss: 0.16855, loss: 0.16855, batch_cost: 0.60754s, reader_cost: 0.01280, ips: 105.34272 samples/s, eta: 3:38:16
[2022/06/19 02:43:59] ppcls INFO: [Train][Epoch 174/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03380629, top1: 0.94062, CELoss: 0.16817, loss: 0.16817, batch_cost: 0.58348s, reader_cost: 0.01206, ips: 83.97887 samples/s, eta: 3:29:32
[2022/06/19 02:44:00] ppcls INFO: [Train][Epoch 174/300][Avg]top1: 0.94062, CELoss: 0.16817, loss: 0.16817
[2022/06/19 02:44:00] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:44:06] ppcls INFO: [Train][Epoch 175/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03380362, top1: 0.98438, CELoss: 0.10226, loss: 0.10226, batch_cost: 0.61491s, reader_cost: 0.03910, ips: 104.07988 samples/s, eta: 3:40:48
[2022/06/19 02:44:14] ppcls INFO: [Train][Epoch 175/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03377693, top1: 0.94460, CELoss: 0.16672, loss: 0.16672, batch_cost: 0.68763s, reader_cost: 0.01794, ips: 93.07303 samples/s, eta: 4:06:48
[2022/06/19 02:44:20] ppcls INFO: [Train][Epoch 175/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03375024, top1: 0.93824, CELoss: 0.17992, loss: 0.17992, batch_cost: 0.63118s, reader_cost: 0.02251, ips: 101.39693 samples/s, eta: 3:46:26
[2022/06/19 02:44:26] ppcls INFO: [Train][Epoch 175/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03372356, top1: 0.93901, CELoss: 0.16726, loss: 0.16726, batch_cost: 0.64347s, reader_cost: 0.02218, ips: 99.46092 samples/s, eta: 3:50:44
[2022/06/19 02:44:32] ppcls INFO: [Train][Epoch 175/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03369689, top1: 0.94017, CELoss: 0.16597, loss: 0.16597, batch_cost: 0.63092s, reader_cost: 0.02344, ips: 101.43965 samples/s, eta: 3:46:08
[2022/06/19 02:44:38] ppcls INFO: [Train][Epoch 175/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03367021, top1: 0.93995, CELoss: 0.16584, loss: 0.16584, batch_cost: 0.61561s, reader_cost: 0.02431, ips: 103.96265 samples/s, eta: 3:40:33
[2022/06/19 02:44:44] ppcls INFO: [Train][Epoch 175/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03364355, top1: 0.94032, CELoss: 0.16642, loss: 0.16642, batch_cost: 0.61276s, reader_cost: 0.02109, ips: 104.44568 samples/s, eta: 3:39:25
[2022/06/19 02:44:49] ppcls INFO: [Train][Epoch 175/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03361688, top1: 0.93992, CELoss: 0.16654, loss: 0.16654, batch_cost: 0.60020s, reader_cost: 0.02083, ips: 106.63074 samples/s, eta: 3:34:49
[2022/06/19 02:44:55] ppcls INFO: [Train][Epoch 175/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03359022, top1: 0.94097, CELoss: 0.16439, loss: 0.16439, batch_cost: 0.60277s, reader_cost: 0.02052, ips: 106.17593 samples/s, eta: 3:35:39
[2022/06/19 02:45:04] ppcls INFO: [Train][Epoch 175/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03356357, top1: 0.94265, CELoss: 0.16107, loss: 0.16107, batch_cost: 0.62818s, reader_cost: 0.01895, ips: 101.88088 samples/s, eta: 3:44:38
[2022/06/19 02:45:08] ppcls INFO: [Train][Epoch 175/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03353692, top1: 0.94168, CELoss: 0.16148, loss: 0.16148, batch_cost: 0.61246s, reader_cost: 0.01763, ips: 104.49579 samples/s, eta: 3:38:54
[2022/06/19 02:45:14] ppcls INFO: [Train][Epoch 175/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03351027, top1: 0.94116, CELoss: 0.16377, loss: 0.16377, batch_cost: 0.60672s, reader_cost: 0.01748, ips: 105.48584 samples/s, eta: 3:36:45
[2022/06/19 02:45:20] ppcls INFO: [Train][Epoch 175/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03348363, top1: 0.94189, CELoss: 0.16244, loss: 0.16244, batch_cost: 0.60515s, reader_cost: 0.01871, ips: 105.75947 samples/s, eta: 3:36:05
[2022/06/19 02:45:26] ppcls INFO: [Train][Epoch 175/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03345699, top1: 0.94144, CELoss: 0.16494, loss: 0.16494, batch_cost: 0.60973s, reader_cost: 0.01828, ips: 104.96367 samples/s, eta: 3:37:38
[2022/06/19 02:45:32] ppcls INFO: [Train][Epoch 175/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03343036, top1: 0.94127, CELoss: 0.16519, loss: 0.16519, batch_cost: 0.60953s, reader_cost: 0.01835, ips: 104.99945 samples/s, eta: 3:37:27
[2022/06/19 02:45:38] ppcls INFO: [Train][Epoch 175/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03340373, top1: 0.94060, CELoss: 0.16709, loss: 0.16709, batch_cost: 0.60896s, reader_cost: 0.01765, ips: 105.09786 samples/s, eta: 3:37:09
[2022/06/19 02:45:43] ppcls INFO: [Train][Epoch 175/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03337710, top1: 0.94031, CELoss: 0.16808, loss: 0.16808, batch_cost: 0.60197s, reader_cost: 0.01730, ips: 106.31826 samples/s, eta: 3:34:33
[2022/06/19 02:45:45] ppcls INFO: [Train][Epoch 175/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03335048, top1: 0.94062, CELoss: 0.16714, loss: 0.16714, batch_cost: 0.57826s, reader_cost: 0.01626, ips: 84.73723 samples/s, eta: 3:26:00
[2022/06/19 02:45:46] ppcls INFO: [Train][Epoch 175/300][Avg]top1: 0.94062, CELoss: 0.16714, loss: 0.16714
[2022/06/19 02:45:53] ppcls INFO: [Eval][Epoch 175][Iter: 0/16]CELoss: 1.04857, loss: 1.04857, top1: 0.79688, batch_cost: 7.18107s, reader_cost: 3.45862, ips: 8.91233 images/sec
[2022/06/19 02:46:01] ppcls INFO: [Eval][Epoch 175][Iter: 10/16]CELoss: 0.76799, loss: 0.76799, top1: 0.81232, batch_cost: 0.55368s, reader_cost: 0.00464, ips: 115.58966 images/sec
[2022/06/19 02:46:03] ppcls INFO: [Eval][Epoch 175][Avg]CELoss: 0.74886, loss: 0.74886, top1: 0.81716
[2022/06/19 02:46:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 02:46:03] ppcls INFO: [Eval][Epoch 175][best metric: 0.8171569108963013]
[2022/06/19 02:46:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:46:10] ppcls INFO: [Train][Epoch 176/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03334782, top1: 0.90625, CELoss: 0.23754, loss: 0.23754, batch_cost: 0.61436s, reader_cost: 0.05259, ips: 104.17372 samples/s, eta: 3:38:51
[2022/06/19 02:46:16] ppcls INFO: [Train][Epoch 176/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03332120, top1: 0.95028, CELoss: 0.15006, loss: 0.15006, batch_cost: 0.68493s, reader_cost: 0.00244, ips: 93.43997 samples/s, eta: 4:03:53
[2022/06/19 02:46:22] ppcls INFO: [Train][Epoch 176/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03329459, top1: 0.94122, CELoss: 0.15930, loss: 0.15930, batch_cost: 0.63656s, reader_cost: 0.00725, ips: 100.54013 samples/s, eta: 3:46:33
[2022/06/19 02:46:29] ppcls INFO: [Train][Epoch 176/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03326799, top1: 0.94103, CELoss: 0.16031, loss: 0.16031, batch_cost: 0.63003s, reader_cost: 0.03356, ips: 101.58180 samples/s, eta: 3:44:08
[2022/06/19 02:46:35] ppcls INFO: [Train][Epoch 176/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03324138, top1: 0.93521, CELoss: 0.17561, loss: 0.17561, batch_cost: 0.63882s, reader_cost: 0.03010, ips: 100.18488 samples/s, eta: 3:47:09
[2022/06/19 02:46:42] ppcls INFO: [Train][Epoch 176/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03321478, top1: 0.93903, CELoss: 0.16871, loss: 0.16871, batch_cost: 0.64732s, reader_cost: 0.02904, ips: 98.86925 samples/s, eta: 3:50:04
[2022/06/19 02:46:47] ppcls INFO: [Train][Epoch 176/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03318819, top1: 0.93878, CELoss: 0.16884, loss: 0.16884, batch_cost: 0.61801s, reader_cost: 0.02726, ips: 103.55873 samples/s, eta: 3:39:32
[2022/06/19 02:46:53] ppcls INFO: [Train][Epoch 176/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03316160, top1: 0.93882, CELoss: 0.17031, loss: 0.17031, batch_cost: 0.62102s, reader_cost: 0.02663, ips: 103.05574 samples/s, eta: 3:40:30
[2022/06/19 02:46:59] ppcls INFO: [Train][Epoch 176/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03313502, top1: 0.93885, CELoss: 0.17245, loss: 0.17245, batch_cost: 0.61436s, reader_cost: 0.02515, ips: 104.17302 samples/s, eta: 3:38:02
[2022/06/19 02:47:05] ppcls INFO: [Train][Epoch 176/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03310844, top1: 0.93922, CELoss: 0.17250, loss: 0.17250, batch_cost: 0.61384s, reader_cost: 0.02291, ips: 104.26210 samples/s, eta: 3:37:45
[2022/06/19 02:47:12] ppcls INFO: [Train][Epoch 176/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03308186, top1: 0.93827, CELoss: 0.17801, loss: 0.17801, batch_cost: 0.62368s, reader_cost: 0.02184, ips: 102.61610 samples/s, eta: 3:41:08
[2022/06/19 02:47:18] ppcls INFO: [Train][Epoch 176/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03305529, top1: 0.93792, CELoss: 0.17770, loss: 0.17770, batch_cost: 0.61865s, reader_cost: 0.02100, ips: 103.45178 samples/s, eta: 3:39:15
[2022/06/19 02:47:24] ppcls INFO: [Train][Epoch 176/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03302872, top1: 0.93905, CELoss: 0.17407, loss: 0.17407, batch_cost: 0.61453s, reader_cost: 0.02027, ips: 104.14479 samples/s, eta: 3:37:41
[2022/06/19 02:47:31] ppcls INFO: [Train][Epoch 176/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03300216, top1: 0.93977, CELoss: 0.17149, loss: 0.17149, batch_cost: 0.62117s, reader_cost: 0.01965, ips: 103.03196 samples/s, eta: 3:39:56
[2022/06/19 02:47:36] ppcls INFO: [Train][Epoch 176/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03297560, top1: 0.94082, CELoss: 0.16821, loss: 0.16821, batch_cost: 0.61884s, reader_cost: 0.01926, ips: 103.41956 samples/s, eta: 3:39:01
[2022/06/19 02:47:42] ppcls INFO: [Train][Epoch 176/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03294905, top1: 0.94060, CELoss: 0.16886, loss: 0.16886, batch_cost: 0.61689s, reader_cost: 0.01949, ips: 103.74585 samples/s, eta: 3:38:13
[2022/06/19 02:47:48] ppcls INFO: [Train][Epoch 176/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03292250, top1: 0.94177, CELoss: 0.16609, loss: 0.16609, batch_cost: 0.61203s, reader_cost: 0.01846, ips: 104.57024 samples/s, eta: 3:36:24
[2022/06/19 02:47:50] ppcls INFO: [Train][Epoch 176/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03289595, top1: 0.94162, CELoss: 0.16662, loss: 0.16662, batch_cost: 0.58772s, reader_cost: 0.01740, ips: 83.37265 samples/s, eta: 3:27:42
[2022/06/19 02:47:51] ppcls INFO: [Train][Epoch 176/300][Avg]top1: 0.94162, CELoss: 0.16662, loss: 0.16662
[2022/06/19 02:47:51] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:47:57] ppcls INFO: [Train][Epoch 177/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03289330, top1: 1.00000, CELoss: 0.03331, loss: 0.03331, batch_cost: 0.61981s, reader_cost: 0.04810, ips: 103.25678 samples/s, eta: 3:39:02
[2022/06/19 02:48:04] ppcls INFO: [Train][Epoch 177/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03286676, top1: 0.96449, CELoss: 0.13674, loss: 0.13674, batch_cost: 0.66955s, reader_cost: 0.02061, ips: 95.58702 samples/s, eta: 3:56:30
[2022/06/19 02:48:11] ppcls INFO: [Train][Epoch 177/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03284023, top1: 0.95982, CELoss: 0.13527, loss: 0.13527, batch_cost: 0.68704s, reader_cost: 0.02849, ips: 93.15275 samples/s, eta: 4:02:34
[2022/06/19 02:48:17] ppcls INFO: [Train][Epoch 177/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03281369, top1: 0.94909, CELoss: 0.16080, loss: 0.16080, batch_cost: 0.66117s, reader_cost: 0.02187, ips: 96.79869 samples/s, eta: 3:53:19
[2022/06/19 02:48:23] ppcls INFO: [Train][Epoch 177/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03278717, top1: 0.95236, CELoss: 0.15058, loss: 0.15058, batch_cost: 0.64997s, reader_cost: 0.02028, ips: 98.46579 samples/s, eta: 3:49:16
[2022/06/19 02:48:29] ppcls INFO: [Train][Epoch 177/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03276065, top1: 0.94853, CELoss: 0.15268, loss: 0.15268, batch_cost: 0.64563s, reader_cost: 0.02232, ips: 99.12813 samples/s, eta: 3:47:37
[2022/06/19 02:48:35] ppcls INFO: [Train][Epoch 177/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03273413, top1: 0.94928, CELoss: 0.14894, loss: 0.14894, batch_cost: 0.63394s, reader_cost: 0.01969, ips: 100.95570 samples/s, eta: 3:43:24
[2022/06/19 02:48:41] ppcls INFO: [Train][Epoch 177/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03270762, top1: 0.94542, CELoss: 0.15669, loss: 0.15669, batch_cost: 0.62592s, reader_cost: 0.01891, ips: 102.25000 samples/s, eta: 3:40:28
[2022/06/19 02:48:46] ppcls INFO: [Train][Epoch 177/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03268111, top1: 0.94425, CELoss: 0.15764, loss: 0.15764, batch_cost: 0.61433s, reader_cost: 0.01852, ips: 104.17903 samples/s, eta: 3:36:17
[2022/06/19 02:48:53] ppcls INFO: [Train][Epoch 177/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03265461, top1: 0.94471, CELoss: 0.15796, loss: 0.15796, batch_cost: 0.62207s, reader_cost: 0.01801, ips: 102.88260 samples/s, eta: 3:38:54
[2022/06/19 02:48:59] ppcls INFO: [Train][Epoch 177/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03262811, top1: 0.94353, CELoss: 0.16125, loss: 0.16125, batch_cost: 0.61958s, reader_cost: 0.02494, ips: 103.29586 samples/s, eta: 3:37:55
[2022/06/19 02:49:04] ppcls INFO: [Train][Epoch 177/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03260162, top1: 0.94355, CELoss: 0.16169, loss: 0.16169, batch_cost: 0.60915s, reader_cost: 0.02378, ips: 105.06447 samples/s, eta: 3:34:09
[2022/06/19 02:49:12] ppcls INFO: [Train][Epoch 177/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03257513, top1: 0.94357, CELoss: 0.16048, loss: 0.16048, batch_cost: 0.61897s, reader_cost: 0.03854, ips: 103.39679 samples/s, eta: 3:37:30
[2022/06/19 02:49:18] ppcls INFO: [Train][Epoch 177/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03254864, top1: 0.94179, CELoss: 0.16499, loss: 0.16499, batch_cost: 0.62515s, reader_cost: 0.03668, ips: 102.37618 samples/s, eta: 3:39:34
[2022/06/19 02:49:24] ppcls INFO: [Train][Epoch 177/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03252216, top1: 0.94171, CELoss: 0.16570, loss: 0.16570, batch_cost: 0.62331s, reader_cost: 0.03469, ips: 102.67686 samples/s, eta: 3:38:49
[2022/06/19 02:49:29] ppcls INFO: [Train][Epoch 177/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03249569, top1: 0.94133, CELoss: 0.16668, loss: 0.16668, batch_cost: 0.61359s, reader_cost: 0.03309, ips: 104.30349 samples/s, eta: 3:35:18
[2022/06/19 02:49:35] ppcls INFO: [Train][Epoch 177/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03246922, top1: 0.94080, CELoss: 0.16820, loss: 0.16820, batch_cost: 0.60892s, reader_cost: 0.03142, ips: 105.10447 samples/s, eta: 3:33:34
[2022/06/19 02:49:37] ppcls INFO: [Train][Epoch 177/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03244275, top1: 0.94043, CELoss: 0.16897, loss: 0.16897, batch_cost: 0.58497s, reader_cost: 0.02955, ips: 83.76428 samples/s, eta: 3:25:04
[2022/06/19 02:49:37] ppcls INFO: [Train][Epoch 177/300][Avg]top1: 0.94043, CELoss: 0.16897, loss: 0.16897
[2022/06/19 02:49:38] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:49:44] ppcls INFO: [Train][Epoch 178/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03244011, top1: 0.98438, CELoss: 0.09696, loss: 0.09696, batch_cost: 0.61929s, reader_cost: 0.05888, ips: 103.34383 samples/s, eta: 3:37:05
[2022/06/19 02:49:50] ppcls INFO: [Train][Epoch 178/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03241365, top1: 0.95739, CELoss: 0.13169, loss: 0.13169, batch_cost: 0.63655s, reader_cost: 0.00775, ips: 100.54225 samples/s, eta: 3:43:02
[2022/06/19 02:49:57] ppcls INFO: [Train][Epoch 178/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03238719, top1: 0.95164, CELoss: 0.15223, loss: 0.15223, batch_cost: 0.65942s, reader_cost: 0.01075, ips: 97.05518 samples/s, eta: 3:50:56
[2022/06/19 02:50:04] ppcls INFO: [Train][Epoch 178/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03236074, top1: 0.94859, CELoss: 0.15143, loss: 0.15143, batch_cost: 0.66272s, reader_cost: 0.00870, ips: 96.57228 samples/s, eta: 3:51:59
[2022/06/19 02:50:09] ppcls INFO: [Train][Epoch 178/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03233429, top1: 0.94627, CELoss: 0.15945, loss: 0.15945, batch_cost: 0.63470s, reader_cost: 0.00999, ips: 100.83479 samples/s, eta: 3:42:04
[2022/06/19 02:50:16] ppcls INFO: [Train][Epoch 178/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03230785, top1: 0.94608, CELoss: 0.15985, loss: 0.15985, batch_cost: 0.63813s, reader_cost: 0.01060, ips: 100.29229 samples/s, eta: 3:43:09
[2022/06/19 02:50:23] ppcls INFO: [Train][Epoch 178/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03228142, top1: 0.94467, CELoss: 0.16568, loss: 0.16568, batch_cost: 0.64493s, reader_cost: 0.01392, ips: 99.23553 samples/s, eta: 3:45:26
[2022/06/19 02:50:28] ppcls INFO: [Train][Epoch 178/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03225499, top1: 0.94498, CELoss: 0.16400, loss: 0.16400, batch_cost: 0.63096s, reader_cost: 0.01348, ips: 101.43353 samples/s, eta: 3:40:26
[2022/06/19 02:50:34] ppcls INFO: [Train][Epoch 178/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03222856, top1: 0.94348, CELoss: 0.16806, loss: 0.16806, batch_cost: 0.62332s, reader_cost: 0.01443, ips: 102.67533 samples/s, eta: 3:37:40
[2022/06/19 02:50:40] ppcls INFO: [Train][Epoch 178/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03220214, top1: 0.94299, CELoss: 0.17100, loss: 0.17100, batch_cost: 0.62509s, reader_cost: 0.01487, ips: 102.38528 samples/s, eta: 3:38:11
[2022/06/19 02:50:46] ppcls INFO: [Train][Epoch 178/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03217572, top1: 0.94307, CELoss: 0.17003, loss: 0.17003, batch_cost: 0.62253s, reader_cost: 0.01414, ips: 102.80633 samples/s, eta: 3:37:11
[2022/06/19 02:50:51] ppcls INFO: [Train][Epoch 178/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03214931, top1: 0.94383, CELoss: 0.16759, loss: 0.16759, batch_cost: 0.61265s, reader_cost: 0.01342, ips: 104.46422 samples/s, eta: 3:33:38
[2022/06/19 02:50:57] ppcls INFO: [Train][Epoch 178/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03212290, top1: 0.94331, CELoss: 0.16740, loss: 0.16740, batch_cost: 0.60633s, reader_cost: 0.01415, ips: 105.55276 samples/s, eta: 3:31:20
[2022/06/19 02:51:04] ppcls INFO: [Train][Epoch 178/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03209649, top1: 0.94442, CELoss: 0.16667, loss: 0.16667, batch_cost: 0.61547s, reader_cost: 0.01452, ips: 103.98477 samples/s, eta: 3:34:25
[2022/06/19 02:51:10] ppcls INFO: [Train][Epoch 178/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03207010, top1: 0.94448, CELoss: 0.16684, loss: 0.16684, batch_cost: 0.61578s, reader_cost: 0.01446, ips: 103.93299 samples/s, eta: 3:34:25
[2022/06/19 02:51:16] ppcls INFO: [Train][Epoch 178/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03204370, top1: 0.94454, CELoss: 0.16778, loss: 0.16778, batch_cost: 0.61189s, reader_cost: 0.01390, ips: 104.59371 samples/s, eta: 3:32:58
[2022/06/19 02:51:21] ppcls INFO: [Train][Epoch 178/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03201731, top1: 0.94420, CELoss: 0.16926, loss: 0.16926, batch_cost: 0.60820s, reader_cost: 0.01325, ips: 105.22920 samples/s, eta: 3:31:34
[2022/06/19 02:51:24] ppcls INFO: [Train][Epoch 178/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03199093, top1: 0.94464, CELoss: 0.16941, loss: 0.16941, batch_cost: 0.58443s, reader_cost: 0.01247, ips: 83.84237 samples/s, eta: 3:23:12
[2022/06/19 02:51:24] ppcls INFO: [Train][Epoch 178/300][Avg]top1: 0.94464, CELoss: 0.16941, loss: 0.16941
[2022/06/19 02:51:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:51:30] ppcls INFO: [Train][Epoch 179/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03198829, top1: 0.96875, CELoss: 0.09539, loss: 0.09539, batch_cost: 0.61614s, reader_cost: 0.04291, ips: 103.87228 samples/s, eta: 3:34:13
[2022/06/19 02:51:38] ppcls INFO: [Train][Epoch 179/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03196191, top1: 0.95455, CELoss: 0.14992, loss: 0.14992, batch_cost: 0.68246s, reader_cost: 0.03193, ips: 93.77852 samples/s, eta: 3:57:10
[2022/06/19 02:51:44] ppcls INFO: [Train][Epoch 179/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03193554, top1: 0.94866, CELoss: 0.16612, loss: 0.16612, batch_cost: 0.63108s, reader_cost: 0.06426, ips: 101.41388 samples/s, eta: 3:39:12
[2022/06/19 02:51:50] ppcls INFO: [Train][Epoch 179/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03190917, top1: 0.94103, CELoss: 0.17345, loss: 0.17345, batch_cost: 0.61634s, reader_cost: 0.05766, ips: 103.83924 samples/s, eta: 3:33:59
[2022/06/19 02:51:58] ppcls INFO: [Train][Epoch 179/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03188281, top1: 0.94474, CELoss: 0.16423, loss: 0.16423, batch_cost: 0.65805s, reader_cost: 0.10126, ips: 97.25730 samples/s, eta: 3:48:21
[2022/06/19 02:52:02] ppcls INFO: [Train][Epoch 179/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03185645, top1: 0.94148, CELoss: 0.17086, loss: 0.17086, batch_cost: 0.61553s, reader_cost: 0.08375, ips: 103.97568 samples/s, eta: 3:33:30
[2022/06/19 02:52:08] ppcls INFO: [Train][Epoch 179/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03183010, top1: 0.94083, CELoss: 0.17146, loss: 0.17146, batch_cost: 0.61078s, reader_cost: 0.07233, ips: 104.78433 samples/s, eta: 3:31:45
[2022/06/19 02:52:15] ppcls INFO: [Train][Epoch 179/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03180375, top1: 0.93706, CELoss: 0.17616, loss: 0.17616, batch_cost: 0.61798s, reader_cost: 0.06365, ips: 103.56296 samples/s, eta: 3:34:09
[2022/06/19 02:52:21] ppcls INFO: [Train][Epoch 179/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03177740, top1: 0.93750, CELoss: 0.17317, loss: 0.17317, batch_cost: 0.61821s, reader_cost: 0.05645, ips: 103.52388 samples/s, eta: 3:34:07
[2022/06/19 02:52:27] ppcls INFO: [Train][Epoch 179/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03175107, top1: 0.93836, CELoss: 0.17208, loss: 0.17208, batch_cost: 0.61508s, reader_cost: 0.05396, ips: 104.05182 samples/s, eta: 3:32:56
[2022/06/19 02:52:33] ppcls INFO: [Train][Epoch 179/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03172473, top1: 0.93982, CELoss: 0.16961, loss: 0.16961, batch_cost: 0.61562s, reader_cost: 0.05081, ips: 103.95972 samples/s, eta: 3:33:01
[2022/06/19 02:52:39] ppcls INFO: [Train][Epoch 179/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03169840, top1: 0.93933, CELoss: 0.17054, loss: 0.17054, batch_cost: 0.61790s, reader_cost: 0.04779, ips: 103.57589 samples/s, eta: 3:33:42
[2022/06/19 02:52:45] ppcls INFO: [Train][Epoch 179/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03167208, top1: 0.93905, CELoss: 0.17095, loss: 0.17095, batch_cost: 0.61544s, reader_cost: 0.04477, ips: 103.99067 samples/s, eta: 3:32:45
[2022/06/19 02:52:52] ppcls INFO: [Train][Epoch 179/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03164576, top1: 0.93929, CELoss: 0.16934, loss: 0.16934, batch_cost: 0.61636s, reader_cost: 0.04224, ips: 103.83576 samples/s, eta: 3:32:58
[2022/06/19 02:52:58] ppcls INFO: [Train][Epoch 179/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03161945, top1: 0.93938, CELoss: 0.16821, loss: 0.16821, batch_cost: 0.62106s, reader_cost: 0.03978, ips: 103.04962 samples/s, eta: 3:34:29
[2022/06/19 02:53:05] ppcls INFO: [Train][Epoch 179/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03159314, top1: 0.93822, CELoss: 0.17235, loss: 0.17235, batch_cost: 0.62313s, reader_cost: 0.03734, ips: 102.70721 samples/s, eta: 3:35:06
[2022/06/19 02:53:10] ppcls INFO: [Train][Epoch 179/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03156683, top1: 0.93818, CELoss: 0.17175, loss: 0.17175, batch_cost: 0.61424s, reader_cost: 0.03560, ips: 104.19321 samples/s, eta: 3:31:56
[2022/06/19 02:53:12] ppcls INFO: [Train][Epoch 179/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03154053, top1: 0.93824, CELoss: 0.17085, loss: 0.17085, batch_cost: 0.59009s, reader_cost: 0.03346, ips: 83.03876 samples/s, eta: 3:23:30
[2022/06/19 02:53:13] ppcls INFO: [Train][Epoch 179/300][Avg]top1: 0.93824, CELoss: 0.17085, loss: 0.17085
[2022/06/19 02:53:13] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:53:19] ppcls INFO: [Train][Epoch 180/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03153791, top1: 0.90625, CELoss: 0.20974, loss: 0.20974, batch_cost: 0.62759s, reader_cost: 0.06713, ips: 101.97770 samples/s, eta: 3:36:25
[2022/06/19 02:53:26] ppcls INFO: [Train][Epoch 180/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03151161, top1: 0.93608, CELoss: 0.16032, loss: 0.16032, batch_cost: 0.73376s, reader_cost: 0.04794, ips: 87.22187 samples/s, eta: 4:12:54
[2022/06/19 02:53:33] ppcls INFO: [Train][Epoch 180/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03148532, top1: 0.93750, CELoss: 0.17824, loss: 0.17824, batch_cost: 0.66350s, reader_cost: 0.02280, ips: 96.45885 samples/s, eta: 3:48:35
[2022/06/19 02:53:39] ppcls INFO: [Train][Epoch 180/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03145904, top1: 0.93952, CELoss: 0.16926, loss: 0.16926, batch_cost: 0.66179s, reader_cost: 0.02240, ips: 96.70692 samples/s, eta: 3:47:53
[2022/06/19 02:53:45] ppcls INFO: [Train][Epoch 180/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03143276, top1: 0.94398, CELoss: 0.16067, loss: 0.16067, batch_cost: 0.63102s, reader_cost: 0.02472, ips: 101.42388 samples/s, eta: 3:37:11
[2022/06/19 02:53:50] ppcls INFO: [Train][Epoch 180/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03140649, top1: 0.94700, CELoss: 0.15345, loss: 0.15345, batch_cost: 0.61896s, reader_cost: 0.02216, ips: 103.39860 samples/s, eta: 3:32:56
[2022/06/19 02:53:57] ppcls INFO: [Train][Epoch 180/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03138022, top1: 0.94595, CELoss: 0.15508, loss: 0.15508, batch_cost: 0.62316s, reader_cost: 0.02059, ips: 102.70168 samples/s, eta: 3:34:16
[2022/06/19 02:54:03] ppcls INFO: [Train][Epoch 180/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03135396, top1: 0.94498, CELoss: 0.16072, loss: 0.16072, batch_cost: 0.62895s, reader_cost: 0.02070, ips: 101.75704 samples/s, eta: 3:36:09
[2022/06/19 02:54:09] ppcls INFO: [Train][Epoch 180/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03132770, top1: 0.94657, CELoss: 0.15639, loss: 0.15639, batch_cost: 0.61846s, reader_cost: 0.02057, ips: 103.48332 samples/s, eta: 3:32:27
[2022/06/19 02:54:15] ppcls INFO: [Train][Epoch 180/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03130145, top1: 0.94643, CELoss: 0.15737, loss: 0.15737, batch_cost: 0.61871s, reader_cost: 0.01984, ips: 103.44158 samples/s, eta: 3:32:25
[2022/06/19 02:54:22] ppcls INFO: [Train][Epoch 180/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03127520, top1: 0.94678, CELoss: 0.15871, loss: 0.15871, batch_cost: 0.62317s, reader_cost: 0.01962, ips: 102.70054 samples/s, eta: 3:33:51
[2022/06/19 02:54:28] ppcls INFO: [Train][Epoch 180/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03124896, top1: 0.94707, CELoss: 0.15735, loss: 0.15735, batch_cost: 0.62372s, reader_cost: 0.01922, ips: 102.61057 samples/s, eta: 3:33:56
[2022/06/19 02:54:35] ppcls INFO: [Train][Epoch 180/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03122272, top1: 0.94693, CELoss: 0.15732, loss: 0.15732, batch_cost: 0.63284s, reader_cost: 0.01935, ips: 101.13171 samples/s, eta: 3:36:58
[2022/06/19 02:54:40] ppcls INFO: [Train][Epoch 180/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03119649, top1: 0.94668, CELoss: 0.15976, loss: 0.15976, batch_cost: 0.62322s, reader_cost: 0.01857, ips: 102.69250 samples/s, eta: 3:33:34
[2022/06/19 02:54:47] ppcls INFO: [Train][Epoch 180/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03117026, top1: 0.94659, CELoss: 0.15924, loss: 0.15924, batch_cost: 0.62584s, reader_cost: 0.01789, ips: 102.26305 samples/s, eta: 3:34:21
[2022/06/19 02:54:52] ppcls INFO: [Train][Epoch 180/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03114404, top1: 0.94754, CELoss: 0.15691, loss: 0.15691, batch_cost: 0.61873s, reader_cost: 0.01725, ips: 103.43741 samples/s, eta: 3:31:49
[2022/06/19 02:54:57] ppcls INFO: [Train][Epoch 180/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03111783, top1: 0.94740, CELoss: 0.15619, loss: 0.15619, batch_cost: 0.61009s, reader_cost: 0.01687, ips: 104.90217 samples/s, eta: 3:28:45
[2022/06/19 02:54:59] ppcls INFO: [Train][Epoch 180/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03109161, top1: 0.94766, CELoss: 0.15762, loss: 0.15762, batch_cost: 0.58664s, reader_cost: 0.01586, ips: 83.52685 samples/s, eta: 3:20:38
[2022/06/19 02:55:00] ppcls INFO: [Train][Epoch 180/300][Avg]top1: 0.94766, CELoss: 0.15762, loss: 0.15762
[2022/06/19 02:55:07] ppcls INFO: [Eval][Epoch 180][Iter: 0/16]CELoss: 0.94973, loss: 0.94973, top1: 0.78320, batch_cost: 6.79850s, reader_cost: 3.89520, ips: 9.41383 images/sec
[2022/06/19 02:55:15] ppcls INFO: [Eval][Epoch 180][Iter: 10/16]CELoss: 0.80657, loss: 0.80657, top1: 0.81055, batch_cost: 0.59575s, reader_cost: 0.01218, ips: 107.42845 images/sec
[2022/06/19 02:55:16] ppcls INFO: [Eval][Epoch 180][Avg]CELoss: 0.72170, loss: 0.72170, top1: 0.81532
[2022/06/19 02:55:16] ppcls INFO: [Eval][Epoch 180][best metric: 0.8171569108963013]
[2022/06/19 02:55:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_180
[2022/06/19 02:55:17] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:55:23] ppcls INFO: [Train][Epoch 181/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03108899, top1: 0.95312, CELoss: 0.19765, loss: 0.19765, batch_cost: 0.61964s, reader_cost: 0.04409, ips: 103.28551 samples/s, eta: 3:31:55
[2022/06/19 02:55:30] ppcls INFO: [Train][Epoch 181/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03106279, top1: 0.94460, CELoss: 0.18290, loss: 0.18290, batch_cost: 0.85104s, reader_cost: 0.02157, ips: 75.20178 samples/s, eta: 4:50:54
[2022/06/19 02:55:37] ppcls INFO: [Train][Epoch 181/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03103659, top1: 0.94048, CELoss: 0.18123, loss: 0.18123, batch_cost: 0.69951s, reader_cost: 0.02114, ips: 91.49253 samples/s, eta: 3:58:59
[2022/06/19 02:55:43] ppcls INFO: [Train][Epoch 181/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03101039, top1: 0.94052, CELoss: 0.17652, loss: 0.17652, batch_cost: 0.67292s, reader_cost: 0.01826, ips: 95.10843 samples/s, eta: 3:49:48
[2022/06/19 02:55:49] ppcls INFO: [Train][Epoch 181/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03098420, top1: 0.94245, CELoss: 0.17565, loss: 0.17565, batch_cost: 0.64200s, reader_cost: 0.01982, ips: 99.68912 samples/s, eta: 3:39:08
[2022/06/19 02:55:54] ppcls INFO: [Train][Epoch 181/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03095802, top1: 0.94393, CELoss: 0.16716, loss: 0.16716, batch_cost: 0.62349s, reader_cost: 0.01844, ips: 102.64726 samples/s, eta: 3:32:42
[2022/06/19 02:56:00] ppcls INFO: [Train][Epoch 181/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03093184, top1: 0.94390, CELoss: 0.16427, loss: 0.16427, batch_cost: 0.61436s, reader_cost: 0.01841, ips: 104.17362 samples/s, eta: 3:29:29
[2022/06/19 02:56:07] ppcls INFO: [Train][Epoch 181/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03090567, top1: 0.94256, CELoss: 0.16638, loss: 0.16638, batch_cost: 0.62705s, reader_cost: 0.01662, ips: 102.06448 samples/s, eta: 3:33:43
[2022/06/19 02:56:12] ppcls INFO: [Train][Epoch 181/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03087950, top1: 0.94252, CELoss: 0.16807, loss: 0.16807, batch_cost: 0.61703s, reader_cost: 0.01524, ips: 103.72311 samples/s, eta: 3:30:12
[2022/06/19 02:56:19] ppcls INFO: [Train][Epoch 181/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03085333, top1: 0.94196, CELoss: 0.16919, loss: 0.16919, batch_cost: 0.62530s, reader_cost: 0.01508, ips: 102.35145 samples/s, eta: 3:32:54
[2022/06/19 02:56:25] ppcls INFO: [Train][Epoch 181/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03082718, top1: 0.94230, CELoss: 0.16839, loss: 0.16839, batch_cost: 0.62166s, reader_cost: 0.01494, ips: 102.95041 samples/s, eta: 3:31:34
[2022/06/19 02:56:31] ppcls INFO: [Train][Epoch 181/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03080102, top1: 0.94271, CELoss: 0.16622, loss: 0.16622, batch_cost: 0.61591s, reader_cost: 0.01595, ips: 103.91138 samples/s, eta: 3:29:30
[2022/06/19 02:56:38] ppcls INFO: [Train][Epoch 181/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03077488, top1: 0.94099, CELoss: 0.16947, loss: 0.16947, batch_cost: 0.62551s, reader_cost: 0.01605, ips: 102.31663 samples/s, eta: 3:32:40
[2022/06/19 02:56:44] ppcls INFO: [Train][Epoch 181/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03074873, top1: 0.94084, CELoss: 0.16861, loss: 0.16861, batch_cost: 0.62039s, reader_cost: 0.01680, ips: 103.16172 samples/s, eta: 3:30:49
[2022/06/19 02:56:49] ppcls INFO: [Train][Epoch 181/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03072260, top1: 0.94094, CELoss: 0.16906, loss: 0.16906, batch_cost: 0.61528s, reader_cost: 0.01656, ips: 104.01832 samples/s, eta: 3:28:59
[2022/06/19 02:56:55] ppcls INFO: [Train][Epoch 181/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03069647, top1: 0.94123, CELoss: 0.16999, loss: 0.16999, batch_cost: 0.61283s, reader_cost: 0.01647, ips: 104.43367 samples/s, eta: 3:28:03
[2022/06/19 02:57:00] ppcls INFO: [Train][Epoch 181/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03067034, top1: 0.94128, CELoss: 0.16895, loss: 0.16895, batch_cost: 0.60687s, reader_cost: 0.01571, ips: 105.45839 samples/s, eta: 3:25:55
[2022/06/19 02:57:02] ppcls INFO: [Train][Epoch 181/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03064422, top1: 0.94016, CELoss: 0.17183, loss: 0.17183, batch_cost: 0.58311s, reader_cost: 0.01478, ips: 84.03209 samples/s, eta: 3:17:46
[2022/06/19 02:57:03] ppcls INFO: [Train][Epoch 181/300][Avg]top1: 0.94016, CELoss: 0.17183, loss: 0.17183
[2022/06/19 02:57:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:57:09] ppcls INFO: [Train][Epoch 182/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03064161, top1: 0.95312, CELoss: 0.15514, loss: 0.15514, batch_cost: 0.61517s, reader_cost: 0.03845, ips: 104.03705 samples/s, eta: 3:28:38
[2022/06/19 02:57:17] ppcls INFO: [Train][Epoch 182/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03061549, top1: 0.93040, CELoss: 0.18353, loss: 0.18353, batch_cost: 0.89504s, reader_cost: 0.00033, ips: 71.50536 samples/s, eta: 5:03:24
[2022/06/19 02:57:22] ppcls INFO: [Train][Epoch 182/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03058938, top1: 0.94345, CELoss: 0.15866, loss: 0.15866, batch_cost: 0.69214s, reader_cost: 0.01575, ips: 92.46680 samples/s, eta: 3:54:30
[2022/06/19 02:57:28] ppcls INFO: [Train][Epoch 182/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03056328, top1: 0.94355, CELoss: 0.15908, loss: 0.15908, batch_cost: 0.65259s, reader_cost: 0.01069, ips: 98.07142 samples/s, eta: 3:40:59
[2022/06/19 02:57:34] ppcls INFO: [Train][Epoch 182/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03053718, top1: 0.94360, CELoss: 0.15667, loss: 0.15667, batch_cost: 0.63771s, reader_cost: 0.01761, ips: 100.35839 samples/s, eta: 3:35:51
[2022/06/19 02:57:41] ppcls INFO: [Train][Epoch 182/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03051109, top1: 0.94148, CELoss: 0.16303, loss: 0.16303, batch_cost: 0.64528s, reader_cost: 0.01631, ips: 99.18243 samples/s, eta: 3:38:18
[2022/06/19 02:57:46] ppcls INFO: [Train][Epoch 182/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03048500, top1: 0.94442, CELoss: 0.16154, loss: 0.16154, batch_cost: 0.63000s, reader_cost: 0.01619, ips: 101.58781 samples/s, eta: 3:33:02
[2022/06/19 02:57:53] ppcls INFO: [Train][Epoch 182/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03045892, top1: 0.94388, CELoss: 0.16181, loss: 0.16181, batch_cost: 0.62827s, reader_cost: 0.01469, ips: 101.86703 samples/s, eta: 3:32:20
[2022/06/19 02:57:59] ppcls INFO: [Train][Epoch 182/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.03043284, top1: 0.94483, CELoss: 0.15874, loss: 0.15874, batch_cost: 0.63408s, reader_cost: 0.01496, ips: 100.93432 samples/s, eta: 3:34:12
[2022/06/19 02:58:05] ppcls INFO: [Train][Epoch 182/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.03040677, top1: 0.94420, CELoss: 0.16016, loss: 0.16016, batch_cost: 0.62545s, reader_cost: 0.01445, ips: 102.32556 samples/s, eta: 3:31:11
[2022/06/19 02:58:12] ppcls INFO: [Train][Epoch 182/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.03038070, top1: 0.94508, CELoss: 0.15705, loss: 0.15705, batch_cost: 0.63093s, reader_cost: 0.01458, ips: 101.43780 samples/s, eta: 3:32:55
[2022/06/19 02:58:18] ppcls INFO: [Train][Epoch 182/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.03035464, top1: 0.94524, CELoss: 0.15645, loss: 0.15645, batch_cost: 0.62707s, reader_cost: 0.01440, ips: 102.06141 samples/s, eta: 3:31:31
[2022/06/19 02:58:24] ppcls INFO: [Train][Epoch 182/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.03032859, top1: 0.94551, CELoss: 0.15697, loss: 0.15697, batch_cost: 0.62570s, reader_cost: 0.01433, ips: 102.28513 samples/s, eta: 3:30:57
[2022/06/19 02:58:31] ppcls INFO: [Train][Epoch 182/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.03030254, top1: 0.94549, CELoss: 0.15761, loss: 0.15761, batch_cost: 0.62976s, reader_cost: 0.01468, ips: 101.62542 samples/s, eta: 3:32:13
[2022/06/19 02:58:38] ppcls INFO: [Train][Epoch 182/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.03027650, top1: 0.94459, CELoss: 0.15930, loss: 0.15930, batch_cost: 0.63494s, reader_cost: 0.01402, ips: 100.79754 samples/s, eta: 3:33:51
[2022/06/19 02:58:43] ppcls INFO: [Train][Epoch 182/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.03025046, top1: 0.94412, CELoss: 0.16060, loss: 0.16060, batch_cost: 0.62855s, reader_cost: 0.01388, ips: 101.82196 samples/s, eta: 3:31:36
[2022/06/19 02:58:48] ppcls INFO: [Train][Epoch 182/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.03022443, top1: 0.94352, CELoss: 0.16170, loss: 0.16170, batch_cost: 0.62230s, reader_cost: 0.01308, ips: 102.84457 samples/s, eta: 3:29:23
[2022/06/19 02:58:51] ppcls INFO: [Train][Epoch 182/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.03019840, top1: 0.94373, CELoss: 0.16125, loss: 0.16125, batch_cost: 0.60073s, reader_cost: 0.01236, ips: 81.56771 samples/s, eta: 3:22:02
[2022/06/19 02:58:52] ppcls INFO: [Train][Epoch 182/300][Avg]top1: 0.94373, CELoss: 0.16125, loss: 0.16125
[2022/06/19 02:58:52] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 02:58:59] ppcls INFO: [Train][Epoch 183/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.03019580, top1: 0.93750, CELoss: 0.13443, loss: 0.13443, batch_cost: 0.63778s, reader_cost: 0.03431, ips: 100.34788 samples/s, eta: 3:34:29
[2022/06/19 02:59:05] ppcls INFO: [Train][Epoch 183/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.03016978, top1: 0.94034, CELoss: 0.15488, loss: 0.15488, batch_cost: 0.64951s, reader_cost: 0.01808, ips: 98.53506 samples/s, eta: 3:38:19
[2022/06/19 02:59:11] ppcls INFO: [Train][Epoch 183/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.03014376, top1: 0.94717, CELoss: 0.14633, loss: 0.14633, batch_cost: 0.64987s, reader_cost: 0.01009, ips: 98.48108 samples/s, eta: 3:38:20
[2022/06/19 02:59:18] ppcls INFO: [Train][Epoch 183/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.03011775, top1: 0.94607, CELoss: 0.15097, loss: 0.15097, batch_cost: 0.64228s, reader_cost: 0.00946, ips: 99.64495 samples/s, eta: 3:35:40
[2022/06/19 02:59:23] ppcls INFO: [Train][Epoch 183/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.03009175, top1: 0.94817, CELoss: 0.14320, loss: 0.14320, batch_cost: 0.62795s, reader_cost: 0.01056, ips: 101.91904 samples/s, eta: 3:30:45
[2022/06/19 02:59:29] ppcls INFO: [Train][Epoch 183/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.03006575, top1: 0.94700, CELoss: 0.14457, loss: 0.14457, batch_cost: 0.62203s, reader_cost: 0.01352, ips: 102.88811 samples/s, eta: 3:28:40
[2022/06/19 02:59:36] ppcls INFO: [Train][Epoch 183/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.03003975, top1: 0.94672, CELoss: 0.14798, loss: 0.14798, batch_cost: 0.62687s, reader_cost: 0.02284, ips: 102.09523 samples/s, eta: 3:30:11
[2022/06/19 02:59:41] ppcls INFO: [Train][Epoch 183/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.03001377, top1: 0.94586, CELoss: 0.14851, loss: 0.14851, batch_cost: 0.61373s, reader_cost: 0.02208, ips: 104.27985 samples/s, eta: 3:25:40
[2022/06/19 02:59:48] ppcls INFO: [Train][Epoch 183/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02998778, top1: 0.94406, CELoss: 0.15209, loss: 0.15209, batch_cost: 0.61851s, reader_cost: 0.02411, ips: 103.47390 samples/s, eta: 3:27:10
[2022/06/19 02:59:53] ppcls INFO: [Train][Epoch 183/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02996181, top1: 0.94385, CELoss: 0.15455, loss: 0.15455, batch_cost: 0.60825s, reader_cost: 0.02206, ips: 105.22058 samples/s, eta: 3:23:38
[2022/06/19 03:00:01] ppcls INFO: [Train][Epoch 183/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02993584, top1: 0.94400, CELoss: 0.15457, loss: 0.15457, batch_cost: 0.62491s, reader_cost: 0.02095, ips: 102.41411 samples/s, eta: 3:29:07
[2022/06/19 03:00:06] ppcls INFO: [Train][Epoch 183/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02990987, top1: 0.94313, CELoss: 0.16021, loss: 0.16021, batch_cost: 0.61345s, reader_cost: 0.02086, ips: 104.32842 samples/s, eta: 3:25:10
[2022/06/19 03:00:12] ppcls INFO: [Train][Epoch 183/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02988391, top1: 0.94292, CELoss: 0.16035, loss: 0.16035, batch_cost: 0.61658s, reader_cost: 0.02174, ips: 103.79794 samples/s, eta: 3:26:07
[2022/06/19 03:00:18] ppcls INFO: [Train][Epoch 183/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02985796, top1: 0.94275, CELoss: 0.16210, loss: 0.16210, batch_cost: 0.61278s, reader_cost: 0.02047, ips: 104.44166 samples/s, eta: 3:24:45
[2022/06/19 03:00:24] ppcls INFO: [Train][Epoch 183/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02983201, top1: 0.94337, CELoss: 0.16046, loss: 0.16046, batch_cost: 0.61376s, reader_cost: 0.01928, ips: 104.27453 samples/s, eta: 3:24:58
[2022/06/19 03:00:31] ppcls INFO: [Train][Epoch 183/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02980607, top1: 0.94247, CELoss: 0.16168, loss: 0.16168, batch_cost: 0.61415s, reader_cost: 0.01938, ips: 104.20974 samples/s, eta: 3:25:00
[2022/06/19 03:00:36] ppcls INFO: [Train][Epoch 183/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02978013, top1: 0.94284, CELoss: 0.16005, loss: 0.16005, batch_cost: 0.60691s, reader_cost: 0.01843, ips: 105.45238 samples/s, eta: 3:22:29
[2022/06/19 03:00:38] ppcls INFO: [Train][Epoch 183/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02975420, top1: 0.94245, CELoss: 0.16192, loss: 0.16192, batch_cost: 0.58302s, reader_cost: 0.01737, ips: 84.04494 samples/s, eta: 3:14:25
[2022/06/19 03:00:38] ppcls INFO: [Train][Epoch 183/300][Avg]top1: 0.94245, CELoss: 0.16192, loss: 0.16192
[2022/06/19 03:00:38] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:00:44] ppcls INFO: [Train][Epoch 184/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02975161, top1: 0.95312, CELoss: 0.11770, loss: 0.11770, batch_cost: 0.61488s, reader_cost: 0.04067, ips: 104.08541 samples/s, eta: 3:25:01
[2022/06/19 03:00:52] ppcls INFO: [Train][Epoch 184/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02972568, top1: 0.93892, CELoss: 0.16806, loss: 0.16806, batch_cost: 0.73338s, reader_cost: 0.02363, ips: 87.26753 samples/s, eta: 4:04:25
[2022/06/19 03:00:58] ppcls INFO: [Train][Epoch 184/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02969976, top1: 0.93452, CELoss: 0.17683, loss: 0.17683, batch_cost: 0.63860s, reader_cost: 0.01958, ips: 100.21932 samples/s, eta: 3:32:43
[2022/06/19 03:01:04] ppcls INFO: [Train][Epoch 184/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02967385, top1: 0.93851, CELoss: 0.16460, loss: 0.16460, batch_cost: 0.62707s, reader_cost: 0.01924, ips: 102.06209 samples/s, eta: 3:28:46
[2022/06/19 03:01:10] ppcls INFO: [Train][Epoch 184/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02964794, top1: 0.93864, CELoss: 0.16619, loss: 0.16619, batch_cost: 0.61930s, reader_cost: 0.01725, ips: 103.34211 samples/s, eta: 3:26:05
[2022/06/19 03:01:16] ppcls INFO: [Train][Epoch 184/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02962204, top1: 0.94118, CELoss: 0.16538, loss: 0.16538, batch_cost: 0.61986s, reader_cost: 0.01580, ips: 103.24883 samples/s, eta: 3:26:10
[2022/06/19 03:01:22] ppcls INFO: [Train][Epoch 184/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02959615, top1: 0.94083, CELoss: 0.17153, loss: 0.17153, batch_cost: 0.61604s, reader_cost: 0.01641, ips: 103.88916 samples/s, eta: 3:24:48
[2022/06/19 03:01:28] ppcls INFO: [Train][Epoch 184/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02957026, top1: 0.94190, CELoss: 0.16529, loss: 0.16529, batch_cost: 0.61213s, reader_cost: 0.01798, ips: 104.55355 samples/s, eta: 3:23:23
[2022/06/19 03:01:34] ppcls INFO: [Train][Epoch 184/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02954437, top1: 0.94213, CELoss: 0.16391, loss: 0.16391, batch_cost: 0.60925s, reader_cost: 0.01932, ips: 105.04712 samples/s, eta: 3:22:20
[2022/06/19 03:01:40] ppcls INFO: [Train][Epoch 184/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02951849, top1: 0.94231, CELoss: 0.16192, loss: 0.16192, batch_cost: 0.60904s, reader_cost: 0.02056, ips: 105.08300 samples/s, eta: 3:22:10
[2022/06/19 03:01:46] ppcls INFO: [Train][Epoch 184/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02949262, top1: 0.94168, CELoss: 0.16597, loss: 0.16597, batch_cost: 0.60713s, reader_cost: 0.02055, ips: 105.41468 samples/s, eta: 3:21:26
[2022/06/19 03:01:52] ppcls INFO: [Train][Epoch 184/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02946675, top1: 0.94130, CELoss: 0.16775, loss: 0.16775, batch_cost: 0.60646s, reader_cost: 0.01973, ips: 105.52967 samples/s, eta: 3:21:06
[2022/06/19 03:01:57] ppcls INFO: [Train][Epoch 184/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02944089, top1: 0.94150, CELoss: 0.16856, loss: 0.16856, batch_cost: 0.60088s, reader_cost: 0.01978, ips: 106.51129 samples/s, eta: 3:19:09
[2022/06/19 03:02:04] ppcls INFO: [Train][Epoch 184/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02941504, top1: 0.94191, CELoss: 0.16545, loss: 0.16545, batch_cost: 0.60960s, reader_cost: 0.01908, ips: 104.98741 samples/s, eta: 3:21:56
[2022/06/19 03:02:10] ppcls INFO: [Train][Epoch 184/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02938919, top1: 0.94293, CELoss: 0.16482, loss: 0.16482, batch_cost: 0.60724s, reader_cost: 0.01775, ips: 105.39516 samples/s, eta: 3:21:04
[2022/06/19 03:02:16] ppcls INFO: [Train][Epoch 184/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02936334, top1: 0.94350, CELoss: 0.16312, loss: 0.16312, batch_cost: 0.60465s, reader_cost: 0.01665, ips: 105.84559 samples/s, eta: 3:20:06
[2022/06/19 03:02:21] ppcls INFO: [Train][Epoch 184/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02933751, top1: 0.94303, CELoss: 0.16467, loss: 0.16467, batch_cost: 0.59641s, reader_cost: 0.01591, ips: 107.30900 samples/s, eta: 3:17:16
[2022/06/19 03:02:23] ppcls INFO: [Train][Epoch 184/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02931168, top1: 0.94309, CELoss: 0.16477, loss: 0.16477, batch_cost: 0.57424s, reader_cost: 0.01498, ips: 85.33060 samples/s, eta: 3:09:51
[2022/06/19 03:02:23] ppcls INFO: [Train][Epoch 184/300][Avg]top1: 0.94309, CELoss: 0.16477, loss: 0.16477
[2022/06/19 03:02:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:02:30] ppcls INFO: [Train][Epoch 185/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02930909, top1: 0.96875, CELoss: 0.15556, loss: 0.15556, batch_cost: 0.60981s, reader_cost: 0.04789, ips: 104.95023 samples/s, eta: 3:21:36
[2022/06/19 03:02:37] ppcls INFO: [Train][Epoch 185/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02928327, top1: 0.95597, CELoss: 0.14220, loss: 0.14220, batch_cost: 0.63549s, reader_cost: 0.00675, ips: 100.71033 samples/s, eta: 3:29:59
[2022/06/19 03:02:43] ppcls INFO: [Train][Epoch 185/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02925745, top1: 0.94940, CELoss: 0.15081, loss: 0.15081, batch_cost: 0.62585s, reader_cost: 0.01857, ips: 102.26131 samples/s, eta: 3:26:41
[2022/06/19 03:02:50] ppcls INFO: [Train][Epoch 185/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02923163, top1: 0.95111, CELoss: 0.14846, loss: 0.14846, batch_cost: 0.64711s, reader_cost: 0.01298, ips: 98.90105 samples/s, eta: 3:33:36
[2022/06/19 03:02:56] ppcls INFO: [Train][Epoch 185/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02920583, top1: 0.94893, CELoss: 0.15312, loss: 0.15312, batch_cost: 0.62838s, reader_cost: 0.01487, ips: 101.84850 samples/s, eta: 3:27:19
[2022/06/19 03:03:01] ppcls INFO: [Train][Epoch 185/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02918002, top1: 0.94700, CELoss: 0.15518, loss: 0.15518, batch_cost: 0.61759s, reader_cost: 0.01733, ips: 103.62883 samples/s, eta: 3:23:39
[2022/06/19 03:03:07] ppcls INFO: [Train][Epoch 185/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02915423, top1: 0.94544, CELoss: 0.15670, loss: 0.15670, batch_cost: 0.60695s, reader_cost: 0.01723, ips: 105.44600 samples/s, eta: 3:20:02
[2022/06/19 03:03:14] ppcls INFO: [Train][Epoch 185/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02912844, top1: 0.94256, CELoss: 0.16528, loss: 0.16528, batch_cost: 0.62881s, reader_cost: 0.01719, ips: 101.77994 samples/s, eta: 3:27:09
[2022/06/19 03:03:21] ppcls INFO: [Train][Epoch 185/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02910266, top1: 0.94290, CELoss: 0.16290, loss: 0.16290, batch_cost: 0.62614s, reader_cost: 0.01588, ips: 102.21387 samples/s, eta: 3:26:09
[2022/06/19 03:03:26] ppcls INFO: [Train][Epoch 185/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02907688, top1: 0.94128, CELoss: 0.16330, loss: 0.16330, batch_cost: 0.61847s, reader_cost: 0.01524, ips: 103.48092 samples/s, eta: 3:23:32
[2022/06/19 03:03:33] ppcls INFO: [Train][Epoch 185/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02905111, top1: 0.94168, CELoss: 0.16541, loss: 0.16541, batch_cost: 0.61983s, reader_cost: 0.01509, ips: 103.25454 samples/s, eta: 3:23:52
[2022/06/19 03:03:38] ppcls INFO: [Train][Epoch 185/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02902534, top1: 0.94130, CELoss: 0.16466, loss: 0.16466, batch_cost: 0.61782s, reader_cost: 0.01419, ips: 103.58988 samples/s, eta: 3:23:07
[2022/06/19 03:03:44] ppcls INFO: [Train][Epoch 185/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02899958, top1: 0.94099, CELoss: 0.16508, loss: 0.16508, batch_cost: 0.61466s, reader_cost: 0.01595, ips: 104.12325 samples/s, eta: 3:21:58
[2022/06/19 03:03:50] ppcls INFO: [Train][Epoch 185/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02897383, top1: 0.94203, CELoss: 0.16243, loss: 0.16243, batch_cost: 0.60936s, reader_cost: 0.01641, ips: 105.02839 samples/s, eta: 3:20:08
[2022/06/19 03:03:58] ppcls INFO: [Train][Epoch 185/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02894808, top1: 0.94249, CELoss: 0.16289, loss: 0.16289, batch_cost: 0.62372s, reader_cost: 0.01631, ips: 102.61021 samples/s, eta: 3:24:44
[2022/06/19 03:04:04] ppcls INFO: [Train][Epoch 185/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02892234, top1: 0.94216, CELoss: 0.16478, loss: 0.16478, batch_cost: 0.62173s, reader_cost: 0.01582, ips: 102.93929 samples/s, eta: 3:23:59
[2022/06/19 03:04:08] ppcls INFO: [Train][Epoch 185/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02889660, top1: 0.94226, CELoss: 0.16422, loss: 0.16422, batch_cost: 0.60576s, reader_cost: 0.01524, ips: 105.65192 samples/s, eta: 3:18:38
[2022/06/19 03:04:10] ppcls INFO: [Train][Epoch 185/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02887087, top1: 0.94236, CELoss: 0.16323, loss: 0.16323, batch_cost: 0.58194s, reader_cost: 0.01433, ips: 84.20106 samples/s, eta: 3:10:44
[2022/06/19 03:04:10] ppcls INFO: [Train][Epoch 185/300][Avg]top1: 0.94236, CELoss: 0.16323, loss: 0.16323
[2022/06/19 03:04:17] ppcls INFO: [Eval][Epoch 185][Iter: 0/16]CELoss: 0.94162, loss: 0.94162, top1: 0.78906, batch_cost: 7.08587s, reader_cost: 3.38431, ips: 9.03206 images/sec
[2022/06/19 03:04:25] ppcls INFO: [Eval][Epoch 185][Iter: 10/16]CELoss: 0.88397, loss: 0.88397, top1: 0.80824, batch_cost: 0.54426s, reader_cost: 0.00781, ips: 117.59162 images/sec
[2022/06/19 03:04:27] ppcls INFO: [Eval][Epoch 185][Avg]CELoss: 0.74147, loss: 0.74147, top1: 0.81593
[2022/06/19 03:04:27] ppcls INFO: [Eval][Epoch 185][best metric: 0.8171569108963013]
[2022/06/19 03:04:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:04:33] ppcls INFO: [Train][Epoch 186/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02886830, top1: 0.95312, CELoss: 0.13210, loss: 0.13210, batch_cost: 0.61577s, reader_cost: 0.04265, ips: 103.93503 samples/s, eta: 3:21:49
[2022/06/19 03:04:40] ppcls INFO: [Train][Epoch 186/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02884257, top1: 0.94460, CELoss: 0.14918, loss: 0.14918, batch_cost: 0.74819s, reader_cost: 0.02524, ips: 85.53983 samples/s, eta: 4:05:05
[2022/06/19 03:04:46] ppcls INFO: [Train][Epoch 186/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02881686, top1: 0.94643, CELoss: 0.14200, loss: 0.14200, batch_cost: 0.66885s, reader_cost: 0.01729, ips: 95.68644 samples/s, eta: 3:38:59
[2022/06/19 03:04:53] ppcls INFO: [Train][Epoch 186/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02879115, top1: 0.94506, CELoss: 0.14457, loss: 0.14457, batch_cost: 0.66009s, reader_cost: 0.01873, ips: 96.95695 samples/s, eta: 3:36:00
[2022/06/19 03:05:00] ppcls INFO: [Train][Epoch 186/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02876544, top1: 0.94550, CELoss: 0.14151, loss: 0.14151, batch_cost: 0.66865s, reader_cost: 0.02007, ips: 95.71537 samples/s, eta: 3:38:42
[2022/06/19 03:05:05] ppcls INFO: [Train][Epoch 186/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02873974, top1: 0.94608, CELoss: 0.14459, loss: 0.14459, batch_cost: 0.64283s, reader_cost: 0.02229, ips: 99.55930 samples/s, eta: 3:30:09
[2022/06/19 03:05:10] ppcls INFO: [Train][Epoch 186/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02871405, top1: 0.94698, CELoss: 0.14373, loss: 0.14373, batch_cost: 0.61729s, reader_cost: 0.02133, ips: 103.67842 samples/s, eta: 3:21:42
[2022/06/19 03:05:16] ppcls INFO: [Train][Epoch 186/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02868836, top1: 0.94586, CELoss: 0.14836, loss: 0.14836, batch_cost: 0.60879s, reader_cost: 0.02042, ips: 105.12573 samples/s, eta: 3:18:49
[2022/06/19 03:05:23] ppcls INFO: [Train][Epoch 186/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02866268, top1: 0.94715, CELoss: 0.14669, loss: 0.14669, batch_cost: 0.61942s, reader_cost: 0.01994, ips: 103.32286 samples/s, eta: 3:22:11
[2022/06/19 03:05:29] ppcls INFO: [Train][Epoch 186/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02863701, top1: 0.94746, CELoss: 0.14593, loss: 0.14593, batch_cost: 0.62161s, reader_cost: 0.01962, ips: 102.95783 samples/s, eta: 3:22:48
[2022/06/19 03:05:35] ppcls INFO: [Train][Epoch 186/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02861134, top1: 0.94678, CELoss: 0.14835, loss: 0.14835, batch_cost: 0.61416s, reader_cost: 0.01904, ips: 104.20654 samples/s, eta: 3:20:16
[2022/06/19 03:05:41] ppcls INFO: [Train][Epoch 186/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02858568, top1: 0.94721, CELoss: 0.14813, loss: 0.14813, batch_cost: 0.61671s, reader_cost: 0.01905, ips: 103.77575 samples/s, eta: 3:20:59
[2022/06/19 03:05:48] ppcls INFO: [Train][Epoch 186/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02856002, top1: 0.94693, CELoss: 0.15051, loss: 0.15051, batch_cost: 0.62571s, reader_cost: 0.01791, ips: 102.28383 samples/s, eta: 3:23:49
[2022/06/19 03:05:53] ppcls INFO: [Train][Epoch 186/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02853437, top1: 0.94656, CELoss: 0.15044, loss: 0.15044, batch_cost: 0.61471s, reader_cost: 0.01729, ips: 104.11437 samples/s, eta: 3:20:08
[2022/06/19 03:06:00] ppcls INFO: [Train][Epoch 186/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02850873, top1: 0.94548, CELoss: 0.15239, loss: 0.15239, batch_cost: 0.62048s, reader_cost: 0.01643, ips: 103.14676 samples/s, eta: 3:21:54
[2022/06/19 03:06:07] ppcls INFO: [Train][Epoch 186/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02848309, top1: 0.94609, CELoss: 0.15123, loss: 0.15123, batch_cost: 0.62315s, reader_cost: 0.01609, ips: 102.70355 samples/s, eta: 3:22:40
[2022/06/19 03:06:12] ppcls INFO: [Train][Epoch 186/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02845746, top1: 0.94565, CELoss: 0.15225, loss: 0.15225, batch_cost: 0.61475s, reader_cost: 0.01548, ips: 104.10766 samples/s, eta: 3:19:50
[2022/06/19 03:06:14] ppcls INFO: [Train][Epoch 186/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02843183, top1: 0.94592, CELoss: 0.15257, loss: 0.15257, batch_cost: 0.59031s, reader_cost: 0.01455, ips: 83.00766 samples/s, eta: 3:11:48
[2022/06/19 03:06:14] ppcls INFO: [Train][Epoch 186/300][Avg]top1: 0.94592, CELoss: 0.15257, loss: 0.15257
[2022/06/19 03:06:15] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:06:22] ppcls INFO: [Train][Epoch 187/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02842927, top1: 0.93750, CELoss: 0.18757, loss: 0.18757, batch_cost: 0.63205s, reader_cost: 0.05620, ips: 101.25731 samples/s, eta: 3:25:21
[2022/06/19 03:06:28] ppcls INFO: [Train][Epoch 187/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02840365, top1: 0.95312, CELoss: 0.14949, loss: 0.14949, batch_cost: 0.53584s, reader_cost: 0.00246, ips: 119.43773 samples/s, eta: 2:54:00
[2022/06/19 03:06:34] ppcls INFO: [Train][Epoch 187/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02837804, top1: 0.94940, CELoss: 0.14572, loss: 0.14572, batch_cost: 0.58749s, reader_cost: 0.01323, ips: 108.93785 samples/s, eta: 3:10:40
[2022/06/19 03:06:40] ppcls INFO: [Train][Epoch 187/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02835243, top1: 0.94355, CELoss: 0.15931, loss: 0.15931, batch_cost: 0.61140s, reader_cost: 0.01312, ips: 104.67858 samples/s, eta: 3:18:20
[2022/06/19 03:06:47] ppcls INFO: [Train][Epoch 187/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02832684, top1: 0.94436, CELoss: 0.15049, loss: 0.15049, batch_cost: 0.61916s, reader_cost: 0.01633, ips: 103.36589 samples/s, eta: 3:20:45
[2022/06/19 03:06:52] ppcls INFO: [Train][Epoch 187/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02830124, top1: 0.94363, CELoss: 0.15397, loss: 0.15397, batch_cost: 0.60837s, reader_cost: 0.01868, ips: 105.19945 samples/s, eta: 3:17:09
[2022/06/19 03:06:59] ppcls INFO: [Train][Epoch 187/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02827565, top1: 0.94339, CELoss: 0.15620, loss: 0.15620, batch_cost: 0.62135s, reader_cost: 0.01776, ips: 103.00197 samples/s, eta: 3:21:15
[2022/06/19 03:07:05] ppcls INFO: [Train][Epoch 187/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02825007, top1: 0.94410, CELoss: 0.15667, loss: 0.15667, batch_cost: 0.60926s, reader_cost: 0.01980, ips: 105.04584 samples/s, eta: 3:17:14
[2022/06/19 03:07:11] ppcls INFO: [Train][Epoch 187/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02822450, top1: 0.94502, CELoss: 0.15490, loss: 0.15490, batch_cost: 0.61041s, reader_cost: 0.01916, ips: 104.84824 samples/s, eta: 3:17:30
[2022/06/19 03:07:16] ppcls INFO: [Train][Epoch 187/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02819893, top1: 0.94591, CELoss: 0.15234, loss: 0.15234, batch_cost: 0.60116s, reader_cost: 0.01790, ips: 106.46056 samples/s, eta: 3:14:24
[2022/06/19 03:07:21] ppcls INFO: [Train][Epoch 187/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02817337, top1: 0.94539, CELoss: 0.15536, loss: 0.15536, batch_cost: 0.59588s, reader_cost: 0.01758, ips: 107.40350 samples/s, eta: 3:12:36
[2022/06/19 03:07:28] ppcls INFO: [Train][Epoch 187/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02814781, top1: 0.94440, CELoss: 0.15791, loss: 0.15791, batch_cost: 0.60080s, reader_cost: 0.02337, ips: 106.52494 samples/s, eta: 3:14:05
[2022/06/19 03:07:34] ppcls INFO: [Train][Epoch 187/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02812226, top1: 0.94551, CELoss: 0.15505, loss: 0.15505, batch_cost: 0.60422s, reader_cost: 0.02583, ips: 105.92192 samples/s, eta: 3:15:06
[2022/06/19 03:07:41] ppcls INFO: [Train][Epoch 187/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02809672, top1: 0.94609, CELoss: 0.15327, loss: 0.15327, batch_cost: 0.60954s, reader_cost: 0.02411, ips: 104.99761 samples/s, eta: 3:16:43
[2022/06/19 03:07:47] ppcls INFO: [Train][Epoch 187/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02807118, top1: 0.94614, CELoss: 0.15365, loss: 0.15365, batch_cost: 0.61164s, reader_cost: 0.03264, ips: 104.63619 samples/s, eta: 3:17:17
[2022/06/19 03:07:53] ppcls INFO: [Train][Epoch 187/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02804565, top1: 0.94599, CELoss: 0.15391, loss: 0.15391, batch_cost: 0.61083s, reader_cost: 0.03942, ips: 104.77508 samples/s, eta: 3:16:55
[2022/06/19 03:07:58] ppcls INFO: [Train][Epoch 187/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02802013, top1: 0.94662, CELoss: 0.15154, loss: 0.15154, batch_cost: 0.60294s, reader_cost: 0.04785, ips: 106.14621 samples/s, eta: 3:14:17
[2022/06/19 03:08:00] ppcls INFO: [Train][Epoch 187/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02799461, top1: 0.94629, CELoss: 0.15403, loss: 0.15403, batch_cost: 0.57922s, reader_cost: 0.04498, ips: 84.59641 samples/s, eta: 3:06:32
[2022/06/19 03:08:01] ppcls INFO: [Train][Epoch 187/300][Avg]top1: 0.94629, CELoss: 0.15403, loss: 0.15403
[2022/06/19 03:08:01] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:08:10] ppcls INFO: [Train][Epoch 188/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02799206, top1: 0.90625, CELoss: 0.28604, loss: 0.28604, batch_cost: 0.62574s, reader_cost: 0.07312, ips: 102.27837 samples/s, eta: 3:21:31
[2022/06/19 03:08:15] ppcls INFO: [Train][Epoch 188/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02796655, top1: 0.94318, CELoss: 0.16990, loss: 0.16990, batch_cost: 0.55474s, reader_cost: 0.00848, ips: 115.36890 samples/s, eta: 2:58:33
[2022/06/19 03:08:21] ppcls INFO: [Train][Epoch 188/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02794105, top1: 0.94345, CELoss: 0.16445, loss: 0.16445, batch_cost: 0.58357s, reader_cost: 0.01794, ips: 109.67060 samples/s, eta: 3:07:44
[2022/06/19 03:08:27] ppcls INFO: [Train][Epoch 188/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02791555, top1: 0.94304, CELoss: 0.16302, loss: 0.16302, batch_cost: 0.59044s, reader_cost: 0.02262, ips: 108.39411 samples/s, eta: 3:09:51
[2022/06/19 03:08:33] ppcls INFO: [Train][Epoch 188/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02789006, top1: 0.94245, CELoss: 0.16444, loss: 0.16444, batch_cost: 0.59325s, reader_cost: 0.02260, ips: 107.88048 samples/s, eta: 3:10:39
[2022/06/19 03:08:39] ppcls INFO: [Train][Epoch 188/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02786457, top1: 0.94455, CELoss: 0.16072, loss: 0.16072, batch_cost: 0.60116s, reader_cost: 0.02069, ips: 106.46084 samples/s, eta: 3:13:06
[2022/06/19 03:08:45] ppcls INFO: [Train][Epoch 188/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02783909, top1: 0.94467, CELoss: 0.15808, loss: 0.15808, batch_cost: 0.60648s, reader_cost: 0.01941, ips: 105.52773 samples/s, eta: 3:14:42
[2022/06/19 03:08:51] ppcls INFO: [Train][Epoch 188/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02781362, top1: 0.94608, CELoss: 0.15682, loss: 0.15682, batch_cost: 0.60254s, reader_cost: 0.01844, ips: 106.21712 samples/s, eta: 3:13:20
[2022/06/19 03:08:57] ppcls INFO: [Train][Epoch 188/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02778816, top1: 0.94772, CELoss: 0.15658, loss: 0.15658, batch_cost: 0.60306s, reader_cost: 0.01782, ips: 106.12492 samples/s, eta: 3:13:24
[2022/06/19 03:09:04] ppcls INFO: [Train][Epoch 188/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02776270, top1: 0.94849, CELoss: 0.15473, loss: 0.15473, batch_cost: 0.61000s, reader_cost: 0.01736, ips: 104.91854 samples/s, eta: 3:15:32
[2022/06/19 03:09:10] ppcls INFO: [Train][Epoch 188/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02773725, top1: 0.94848, CELoss: 0.15449, loss: 0.15449, batch_cost: 0.61298s, reader_cost: 0.01652, ips: 104.40765 samples/s, eta: 3:16:23
[2022/06/19 03:09:16] ppcls INFO: [Train][Epoch 188/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02771180, top1: 0.94947, CELoss: 0.15254, loss: 0.15254, batch_cost: 0.60784s, reader_cost: 0.01618, ips: 105.29071 samples/s, eta: 3:14:38
[2022/06/19 03:09:21] ppcls INFO: [Train][Epoch 188/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02768636, top1: 0.94809, CELoss: 0.15351, loss: 0.15351, batch_cost: 0.60397s, reader_cost: 0.01929, ips: 105.96571 samples/s, eta: 3:13:18
[2022/06/19 03:09:27] ppcls INFO: [Train][Epoch 188/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02766093, top1: 0.94692, CELoss: 0.15677, loss: 0.15677, batch_cost: 0.60211s, reader_cost: 0.01947, ips: 106.29221 samples/s, eta: 3:12:36
[2022/06/19 03:09:34] ppcls INFO: [Train][Epoch 188/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02763550, top1: 0.94770, CELoss: 0.15563, loss: 0.15563, batch_cost: 0.60643s, reader_cost: 0.01823, ips: 105.53651 samples/s, eta: 3:13:53
[2022/06/19 03:09:39] ppcls INFO: [Train][Epoch 188/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02761008, top1: 0.94681, CELoss: 0.15722, loss: 0.15722, batch_cost: 0.60320s, reader_cost: 0.01722, ips: 106.10152 samples/s, eta: 3:12:45
[2022/06/19 03:09:45] ppcls INFO: [Train][Epoch 188/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02758467, top1: 0.94633, CELoss: 0.15770, loss: 0.15770, batch_cost: 0.59973s, reader_cost: 0.02457, ips: 106.71451 samples/s, eta: 3:11:32
[2022/06/19 03:09:47] ppcls INFO: [Train][Epoch 188/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02755926, top1: 0.94675, CELoss: 0.15719, loss: 0.15719, batch_cost: 0.57650s, reader_cost: 0.02326, ips: 84.99595 samples/s, eta: 3:04:01
[2022/06/19 03:09:48] ppcls INFO: [Train][Epoch 188/300][Avg]top1: 0.94675, CELoss: 0.15719, loss: 0.15719
[2022/06/19 03:09:48] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:09:55] ppcls INFO: [Train][Epoch 189/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02755672, top1: 0.93750, CELoss: 0.16040, loss: 0.16040, batch_cost: 0.61502s, reader_cost: 0.04890, ips: 104.06094 samples/s, eta: 3:16:18
[2022/06/19 03:10:02] ppcls INFO: [Train][Epoch 189/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02753132, top1: 0.95597, CELoss: 0.14953, loss: 0.14953, batch_cost: 0.66353s, reader_cost: 0.03240, ips: 96.45437 samples/s, eta: 3:31:41
[2022/06/19 03:10:07] ppcls INFO: [Train][Epoch 189/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02750592, top1: 0.95982, CELoss: 0.13138, loss: 0.13138, batch_cost: 0.61845s, reader_cost: 0.02543, ips: 103.48443 samples/s, eta: 3:17:12
[2022/06/19 03:10:13] ppcls INFO: [Train][Epoch 189/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02748054, top1: 0.95312, CELoss: 0.14924, loss: 0.14924, batch_cost: 0.60799s, reader_cost: 0.03200, ips: 105.26418 samples/s, eta: 3:13:46
[2022/06/19 03:10:20] ppcls INFO: [Train][Epoch 189/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02745516, top1: 0.95046, CELoss: 0.14247, loss: 0.14247, batch_cost: 0.62204s, reader_cost: 0.02520, ips: 102.88786 samples/s, eta: 3:18:08
[2022/06/19 03:10:27] ppcls INFO: [Train][Epoch 189/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02742978, top1: 0.94945, CELoss: 0.14375, loss: 0.14375, batch_cost: 0.63693s, reader_cost: 0.02180, ips: 100.48150 samples/s, eta: 3:22:46
[2022/06/19 03:10:32] ppcls INFO: [Train][Epoch 189/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02740442, top1: 0.94928, CELoss: 0.14572, loss: 0.14572, batch_cost: 0.61423s, reader_cost: 0.01944, ips: 104.19619 samples/s, eta: 3:15:26
[2022/06/19 03:10:37] ppcls INFO: [Train][Epoch 189/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02737906, top1: 0.94894, CELoss: 0.14581, loss: 0.14581, batch_cost: 0.60284s, reader_cost: 0.01750, ips: 106.16360 samples/s, eta: 3:11:43
[2022/06/19 03:10:43] ppcls INFO: [Train][Epoch 189/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02735370, top1: 0.94907, CELoss: 0.14281, loss: 0.14281, batch_cost: 0.60360s, reader_cost: 0.01765, ips: 106.03120 samples/s, eta: 3:11:51
[2022/06/19 03:10:50] ppcls INFO: [Train][Epoch 189/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02732835, top1: 0.94780, CELoss: 0.14788, loss: 0.14788, batch_cost: 0.60696s, reader_cost: 0.01645, ips: 105.44360 samples/s, eta: 3:12:49
[2022/06/19 03:10:55] ppcls INFO: [Train][Epoch 189/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02730301, top1: 0.94864, CELoss: 0.14761, loss: 0.14761, batch_cost: 0.59990s, reader_cost: 0.01708, ips: 106.68416 samples/s, eta: 3:10:29
[2022/06/19 03:11:01] ppcls INFO: [Train][Epoch 189/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02727768, top1: 0.94707, CELoss: 0.14971, loss: 0.14971, batch_cost: 0.60273s, reader_cost: 0.01725, ips: 106.18273 samples/s, eta: 3:11:17
[2022/06/19 03:11:07] ppcls INFO: [Train][Epoch 189/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02725235, top1: 0.94744, CELoss: 0.14971, loss: 0.14971, batch_cost: 0.60164s, reader_cost: 0.01695, ips: 106.37603 samples/s, eta: 3:10:50
[2022/06/19 03:11:13] ppcls INFO: [Train][Epoch 189/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02722703, top1: 0.94776, CELoss: 0.15041, loss: 0.15041, batch_cost: 0.59581s, reader_cost: 0.01594, ips: 107.41688 samples/s, eta: 3:08:53
[2022/06/19 03:11:19] ppcls INFO: [Train][Epoch 189/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02720172, top1: 0.94814, CELoss: 0.15007, loss: 0.15007, batch_cost: 0.59608s, reader_cost: 0.02118, ips: 107.36769 samples/s, eta: 3:08:52
[2022/06/19 03:11:25] ppcls INFO: [Train][Epoch 189/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02717641, top1: 0.94805, CELoss: 0.14924, loss: 0.14924, batch_cost: 0.59765s, reader_cost: 0.02813, ips: 107.08562 samples/s, eta: 3:09:16
[2022/06/19 03:11:30] ppcls INFO: [Train][Epoch 189/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02715111, top1: 0.94779, CELoss: 0.15092, loss: 0.15092, batch_cost: 0.59103s, reader_cost: 0.03147, ips: 108.28512 samples/s, eta: 3:07:04
[2022/06/19 03:11:32] ppcls INFO: [Train][Epoch 189/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02712582, top1: 0.94803, CELoss: 0.15083, loss: 0.15083, batch_cost: 0.56857s, reader_cost: 0.02958, ips: 86.18037 samples/s, eta: 2:59:52
[2022/06/19 03:11:33] ppcls INFO: [Train][Epoch 189/300][Avg]top1: 0.94803, CELoss: 0.15083, loss: 0.15083
[2022/06/19 03:11:33] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:11:39] ppcls INFO: [Train][Epoch 190/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02712329, top1: 0.95312, CELoss: 0.19011, loss: 0.19011, batch_cost: 0.60062s, reader_cost: 0.05470, ips: 106.55705 samples/s, eta: 3:10:00
[2022/06/19 03:11:46] ppcls INFO: [Train][Epoch 190/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02709800, top1: 0.94602, CELoss: 0.16725, loss: 0.16725, batch_cost: 0.61830s, reader_cost: 0.01567, ips: 103.50970 samples/s, eta: 3:15:29
[2022/06/19 03:11:52] ppcls INFO: [Train][Epoch 190/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02707272, top1: 0.94643, CELoss: 0.15414, loss: 0.15414, batch_cost: 0.62469s, reader_cost: 0.01927, ips: 102.45155 samples/s, eta: 3:17:24
[2022/06/19 03:11:58] ppcls INFO: [Train][Epoch 190/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02704745, top1: 0.94859, CELoss: 0.15064, loss: 0.15064, batch_cost: 0.61936s, reader_cost: 0.01483, ips: 103.33285 samples/s, eta: 3:15:37
[2022/06/19 03:12:04] ppcls INFO: [Train][Epoch 190/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02702218, top1: 0.94817, CELoss: 0.16021, loss: 0.16021, batch_cost: 0.62152s, reader_cost: 0.01404, ips: 102.97320 samples/s, eta: 3:16:12
[2022/06/19 03:12:11] ppcls INFO: [Train][Epoch 190/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02699692, top1: 0.94761, CELoss: 0.15803, loss: 0.15803, batch_cost: 0.62369s, reader_cost: 0.01652, ips: 102.61470 samples/s, eta: 3:16:47
[2022/06/19 03:12:17] ppcls INFO: [Train][Epoch 190/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02697167, top1: 0.94749, CELoss: 0.15653, loss: 0.15653, batch_cost: 0.62837s, reader_cost: 0.01475, ips: 101.85022 samples/s, eta: 3:18:09
[2022/06/19 03:12:24] ppcls INFO: [Train][Epoch 190/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02694642, top1: 0.94894, CELoss: 0.15226, loss: 0.15226, batch_cost: 0.63295s, reader_cost: 0.01444, ips: 101.11450 samples/s, eta: 3:19:29
[2022/06/19 03:12:30] ppcls INFO: [Train][Epoch 190/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02692118, top1: 0.94907, CELoss: 0.15129, loss: 0.15129, batch_cost: 0.62503s, reader_cost: 0.01423, ips: 102.39539 samples/s, eta: 3:16:53
[2022/06/19 03:12:36] ppcls INFO: [Train][Epoch 190/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02689595, top1: 0.94883, CELoss: 0.15119, loss: 0.15119, batch_cost: 0.62677s, reader_cost: 0.01465, ips: 102.11030 samples/s, eta: 3:17:20
[2022/06/19 03:12:43] ppcls INFO: [Train][Epoch 190/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02687072, top1: 0.94817, CELoss: 0.15332, loss: 0.15332, batch_cost: 0.63721s, reader_cost: 0.01540, ips: 100.43863 samples/s, eta: 3:20:31
[2022/06/19 03:12:48] ppcls INFO: [Train][Epoch 190/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02684550, top1: 0.94890, CELoss: 0.15320, loss: 0.15320, batch_cost: 0.62532s, reader_cost: 0.01466, ips: 102.34729 samples/s, eta: 3:16:40
[2022/06/19 03:12:54] ppcls INFO: [Train][Epoch 190/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02682029, top1: 0.94938, CELoss: 0.15273, loss: 0.15273, batch_cost: 0.62240s, reader_cost: 0.01518, ips: 102.82700 samples/s, eta: 3:15:39
[2022/06/19 03:13:01] ppcls INFO: [Train][Epoch 190/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02679509, top1: 0.94990, CELoss: 0.15134, loss: 0.15134, batch_cost: 0.63004s, reader_cost: 0.01476, ips: 101.58061 samples/s, eta: 3:17:56
[2022/06/19 03:13:07] ppcls INFO: [Train][Epoch 190/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02676989, top1: 0.94969, CELoss: 0.14957, loss: 0.14957, batch_cost: 0.62120s, reader_cost: 0.01407, ips: 103.02596 samples/s, eta: 3:15:04
[2022/06/19 03:13:13] ppcls INFO: [Train][Epoch 190/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02674470, top1: 0.94857, CELoss: 0.15302, loss: 0.15302, batch_cost: 0.62373s, reader_cost: 0.01373, ips: 102.60868 samples/s, eta: 3:15:45
[2022/06/19 03:13:19] ppcls INFO: [Train][Epoch 190/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02671951, top1: 0.94924, CELoss: 0.15201, loss: 0.15201, batch_cost: 0.61991s, reader_cost: 0.01347, ips: 103.23996 samples/s, eta: 3:14:27
[2022/06/19 03:13:21] ppcls INFO: [Train][Epoch 190/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02669433, top1: 0.94977, CELoss: 0.15144, loss: 0.15144, batch_cost: 0.59504s, reader_cost: 0.01267, ips: 82.34772 samples/s, eta: 3:06:33
[2022/06/19 03:13:22] ppcls INFO: [Train][Epoch 190/300][Avg]top1: 0.94977, CELoss: 0.15144, loss: 0.15144
[2022/06/19 03:13:28] ppcls INFO: [Eval][Epoch 190][Iter: 0/16]CELoss: 1.09414, loss: 1.09414, top1: 0.79102, batch_cost: 6.66992s, reader_cost: 3.58845, ips: 9.59531 images/sec
[2022/06/19 03:13:36] ppcls INFO: [Eval][Epoch 190][Iter: 10/16]CELoss: 1.05973, loss: 1.05973, top1: 0.80735, batch_cost: 0.59679s, reader_cost: 0.00356, ips: 107.23986 images/sec
[2022/06/19 03:13:38] ppcls INFO: [Eval][Epoch 190][Avg]CELoss: 0.82160, loss: 0.82160, top1: 0.81348
[2022/06/19 03:13:38] ppcls INFO: [Eval][Epoch 190][best metric: 0.8171569108963013]
[2022/06/19 03:13:38] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_190
[2022/06/19 03:13:38] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:13:44] ppcls INFO: [Train][Epoch 191/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02669182, top1: 0.90625, CELoss: 0.18634, loss: 0.18634, batch_cost: 0.62513s, reader_cost: 0.04088, ips: 102.37937 samples/s, eta: 3:15:58
[2022/06/19 03:13:51] ppcls INFO: [Train][Epoch 191/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02666665, top1: 0.95312, CELoss: 0.13094, loss: 0.13094, batch_cost: 0.75135s, reader_cost: 0.01992, ips: 85.17965 samples/s, eta: 3:55:25
[2022/06/19 03:13:57] ppcls INFO: [Train][Epoch 191/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02664148, top1: 0.94940, CELoss: 0.14431, loss: 0.14431, batch_cost: 0.66368s, reader_cost: 0.01951, ips: 96.43203 samples/s, eta: 3:27:50
[2022/06/19 03:14:04] ppcls INFO: [Train][Epoch 191/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02661633, top1: 0.94808, CELoss: 0.14762, loss: 0.14762, batch_cost: 0.65243s, reader_cost: 0.01662, ips: 98.09474 samples/s, eta: 3:24:12
[2022/06/19 03:14:09] ppcls INFO: [Train][Epoch 191/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02659118, top1: 0.94970, CELoss: 0.14461, loss: 0.14461, batch_cost: 0.63735s, reader_cost: 0.01851, ips: 100.41522 samples/s, eta: 3:19:23
[2022/06/19 03:14:18] ppcls INFO: [Train][Epoch 191/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02656603, top1: 0.94792, CELoss: 0.15041, loss: 0.15041, batch_cost: 0.67624s, reader_cost: 0.01641, ips: 94.64136 samples/s, eta: 3:31:26
[2022/06/19 03:14:22] ppcls INFO: [Train][Epoch 191/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02654090, top1: 0.94749, CELoss: 0.14956, loss: 0.14956, batch_cost: 0.62909s, reader_cost: 0.01522, ips: 101.73426 samples/s, eta: 3:16:35
[2022/06/19 03:14:28] ppcls INFO: [Train][Epoch 191/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02651577, top1: 0.94630, CELoss: 0.14932, loss: 0.14932, batch_cost: 0.62301s, reader_cost: 0.01453, ips: 102.72635 samples/s, eta: 3:14:35
[2022/06/19 03:14:33] ppcls INFO: [Train][Epoch 191/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02649065, top1: 0.94715, CELoss: 0.14731, loss: 0.14731, batch_cost: 0.61601s, reader_cost: 0.01647, ips: 103.89431 samples/s, eta: 3:12:17
[2022/06/19 03:14:40] ppcls INFO: [Train][Epoch 191/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02646553, top1: 0.94729, CELoss: 0.14826, loss: 0.14826, batch_cost: 0.62038s, reader_cost: 0.01536, ips: 103.16292 samples/s, eta: 3:13:33
[2022/06/19 03:14:46] ppcls INFO: [Train][Epoch 191/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02644042, top1: 0.94740, CELoss: 0.14699, loss: 0.14699, batch_cost: 0.61951s, reader_cost: 0.01565, ips: 103.30668 samples/s, eta: 3:13:11
[2022/06/19 03:14:52] ppcls INFO: [Train][Epoch 191/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02641532, top1: 0.94749, CELoss: 0.14692, loss: 0.14692, batch_cost: 0.61952s, reader_cost: 0.01506, ips: 103.30501 samples/s, eta: 3:13:05
[2022/06/19 03:14:59] ppcls INFO: [Train][Epoch 191/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02639023, top1: 0.94628, CELoss: 0.14868, loss: 0.14868, batch_cost: 0.62452s, reader_cost: 0.01478, ips: 102.47866 samples/s, eta: 3:14:32
[2022/06/19 03:15:05] ppcls INFO: [Train][Epoch 191/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02636514, top1: 0.94513, CELoss: 0.15132, loss: 0.15132, batch_cost: 0.62112s, reader_cost: 0.01462, ips: 103.03959 samples/s, eta: 3:13:22
[2022/06/19 03:15:12] ppcls INFO: [Train][Epoch 191/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02634006, top1: 0.94481, CELoss: 0.15446, loss: 0.15446, batch_cost: 0.62846s, reader_cost: 0.01487, ips: 101.83630 samples/s, eta: 3:15:33
[2022/06/19 03:15:18] ppcls INFO: [Train][Epoch 191/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02631498, top1: 0.94433, CELoss: 0.15529, loss: 0.15529, batch_cost: 0.62366s, reader_cost: 0.01485, ips: 102.62032 samples/s, eta: 3:13:57
[2022/06/19 03:15:22] ppcls INFO: [Train][Epoch 191/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02628992, top1: 0.94420, CELoss: 0.15515, loss: 0.15515, batch_cost: 0.61367s, reader_cost: 0.01411, ips: 104.29023 samples/s, eta: 3:10:44
[2022/06/19 03:15:24] ppcls INFO: [Train][Epoch 191/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02626486, top1: 0.94300, CELoss: 0.15797, loss: 0.15797, batch_cost: 0.58945s, reader_cost: 0.01327, ips: 83.12846 samples/s, eta: 3:03:07
[2022/06/19 03:15:25] ppcls INFO: [Train][Epoch 191/300][Avg]top1: 0.94300, CELoss: 0.15797, loss: 0.15797
[2022/06/19 03:15:25] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:15:32] ppcls INFO: [Train][Epoch 192/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02626235, top1: 0.93750, CELoss: 0.18940, loss: 0.18940, batch_cost: 0.62499s, reader_cost: 0.04038, ips: 102.40143 samples/s, eta: 3:14:09
[2022/06/19 03:15:38] ppcls INFO: [Train][Epoch 192/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02623730, top1: 0.94460, CELoss: 0.15586, loss: 0.15586, batch_cost: 0.61401s, reader_cost: 0.03362, ips: 104.23303 samples/s, eta: 3:10:38
[2022/06/19 03:15:44] ppcls INFO: [Train][Epoch 192/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02621226, top1: 0.94940, CELoss: 0.14544, loss: 0.14544, batch_cost: 0.64271s, reader_cost: 0.05687, ips: 99.57814 samples/s, eta: 3:19:26
[2022/06/19 03:15:51] ppcls INFO: [Train][Epoch 192/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02618722, top1: 0.94960, CELoss: 0.14218, loss: 0.14218, batch_cost: 0.65372s, reader_cost: 0.09467, ips: 97.90091 samples/s, eta: 3:22:45
[2022/06/19 03:15:57] ppcls INFO: [Train][Epoch 192/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02616219, top1: 0.94893, CELoss: 0.14663, loss: 0.14663, batch_cost: 0.64077s, reader_cost: 0.07608, ips: 99.88050 samples/s, eta: 3:18:37
[2022/06/19 03:16:04] ppcls INFO: [Train][Epoch 192/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02613717, top1: 0.94638, CELoss: 0.15288, loss: 0.15288, batch_cost: 0.64077s, reader_cost: 0.07493, ips: 99.87968 samples/s, eta: 3:18:31
[2022/06/19 03:16:10] ppcls INFO: [Train][Epoch 192/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02611215, top1: 0.94544, CELoss: 0.15627, loss: 0.15627, batch_cost: 0.63708s, reader_cost: 0.06949, ips: 100.45852 samples/s, eta: 3:17:16
[2022/06/19 03:16:16] ppcls INFO: [Train][Epoch 192/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02608714, top1: 0.94608, CELoss: 0.15494, loss: 0.15494, batch_cost: 0.62860s, reader_cost: 0.06286, ips: 101.81366 samples/s, eta: 3:14:32
[2022/06/19 03:16:22] ppcls INFO: [Train][Epoch 192/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02606214, top1: 0.94618, CELoss: 0.15654, loss: 0.15654, batch_cost: 0.63517s, reader_cost: 0.05691, ips: 100.76052 samples/s, eta: 3:16:28
[2022/06/19 03:16:27] ppcls INFO: [Train][Epoch 192/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02603714, top1: 0.94729, CELoss: 0.15412, loss: 0.15412, batch_cost: 0.61946s, reader_cost: 0.05179, ips: 103.31515 samples/s, eta: 3:11:30
[2022/06/19 03:16:34] ppcls INFO: [Train][Epoch 192/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02601215, top1: 0.94725, CELoss: 0.15459, loss: 0.15459, batch_cost: 0.62145s, reader_cost: 0.04773, ips: 102.98459 samples/s, eta: 3:12:01
[2022/06/19 03:16:40] ppcls INFO: [Train][Epoch 192/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02598717, top1: 0.94764, CELoss: 0.15175, loss: 0.15175, batch_cost: 0.62507s, reader_cost: 0.04533, ips: 102.38906 samples/s, eta: 3:13:01
[2022/06/19 03:16:46] ppcls INFO: [Train][Epoch 192/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02596220, top1: 0.94809, CELoss: 0.15237, loss: 0.15237, batch_cost: 0.62128s, reader_cost: 0.04332, ips: 103.01300 samples/s, eta: 3:11:45
[2022/06/19 03:16:52] ppcls INFO: [Train][Epoch 192/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02593723, top1: 0.94835, CELoss: 0.15175, loss: 0.15175, batch_cost: 0.61955s, reader_cost: 0.04104, ips: 103.30062 samples/s, eta: 3:11:07
[2022/06/19 03:16:59] ppcls INFO: [Train][Epoch 192/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02591227, top1: 0.94781, CELoss: 0.15278, loss: 0.15278, batch_cost: 0.61972s, reader_cost: 0.03856, ips: 103.27304 samples/s, eta: 3:11:04
[2022/06/19 03:17:04] ppcls INFO: [Train][Epoch 192/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02588732, top1: 0.94754, CELoss: 0.15335, loss: 0.15335, batch_cost: 0.61214s, reader_cost: 0.03730, ips: 104.55051 samples/s, eta: 3:08:37
[2022/06/19 03:17:09] ppcls INFO: [Train][Epoch 192/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02586238, top1: 0.94876, CELoss: 0.15036, loss: 0.15036, batch_cost: 0.60687s, reader_cost: 0.03995, ips: 105.45913 samples/s, eta: 3:06:54
[2022/06/19 03:17:11] ppcls INFO: [Train][Epoch 192/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02583744, top1: 0.94876, CELoss: 0.15037, loss: 0.15037, batch_cost: 0.58328s, reader_cost: 0.03776, ips: 84.00717 samples/s, eta: 2:59:32
[2022/06/19 03:17:12] ppcls INFO: [Train][Epoch 192/300][Avg]top1: 0.94876, CELoss: 0.15037, loss: 0.15037
[2022/06/19 03:17:12] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:17:18] ppcls INFO: [Train][Epoch 193/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02583495, top1: 0.96875, CELoss: 0.16857, loss: 0.16857, batch_cost: 0.61467s, reader_cost: 0.06086, ips: 104.12143 samples/s, eta: 3:09:11
[2022/06/19 03:17:24] ppcls INFO: [Train][Epoch 193/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02581002, top1: 0.94176, CELoss: 0.17126, loss: 0.17126, batch_cost: 0.66869s, reader_cost: 0.00102, ips: 95.70975 samples/s, eta: 3:25:42
[2022/06/19 03:17:31] ppcls INFO: [Train][Epoch 193/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02578509, top1: 0.94494, CELoss: 0.15865, loss: 0.15865, batch_cost: 0.70708s, reader_cost: 0.10876, ips: 90.51306 samples/s, eta: 3:37:24
[2022/06/19 03:17:38] ppcls INFO: [Train][Epoch 193/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02576018, top1: 0.94254, CELoss: 0.15894, loss: 0.15894, batch_cost: 0.68488s, reader_cost: 0.11248, ips: 93.44640 samples/s, eta: 3:30:27
[2022/06/19 03:17:44] ppcls INFO: [Train][Epoch 193/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02573527, top1: 0.94436, CELoss: 0.15480, loss: 0.15480, batch_cost: 0.66739s, reader_cost: 0.10162, ips: 95.89526 samples/s, eta: 3:24:58
[2022/06/19 03:17:50] ppcls INFO: [Train][Epoch 193/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02571037, top1: 0.94516, CELoss: 0.15228, loss: 0.15228, batch_cost: 0.65891s, reader_cost: 0.08105, ips: 97.13061 samples/s, eta: 3:22:15
[2022/06/19 03:17:56] ppcls INFO: [Train][Epoch 193/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02568547, top1: 0.94518, CELoss: 0.15036, loss: 0.15036, batch_cost: 0.65043s, reader_cost: 0.06981, ips: 98.39687 samples/s, eta: 3:19:33
[2022/06/19 03:18:02] ppcls INFO: [Train][Epoch 193/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02566059, top1: 0.94542, CELoss: 0.15003, loss: 0.15003, batch_cost: 0.63644s, reader_cost: 0.06179, ips: 100.55929 samples/s, eta: 3:15:09
[2022/06/19 03:18:08] ppcls INFO: [Train][Epoch 193/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02563571, top1: 0.94502, CELoss: 0.15656, loss: 0.15656, batch_cost: 0.63425s, reader_cost: 0.05500, ips: 100.90643 samples/s, eta: 3:14:22
[2022/06/19 03:18:15] ppcls INFO: [Train][Epoch 193/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02561083, top1: 0.94540, CELoss: 0.15700, loss: 0.15700, batch_cost: 0.63728s, reader_cost: 0.05134, ips: 100.42684 samples/s, eta: 3:15:11
[2022/06/19 03:18:21] ppcls INFO: [Train][Epoch 193/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02558597, top1: 0.94570, CELoss: 0.15683, loss: 0.15683, batch_cost: 0.63121s, reader_cost: 0.04698, ips: 101.39264 samples/s, eta: 3:13:14
[2022/06/19 03:18:26] ppcls INFO: [Train][Epoch 193/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02556111, top1: 0.94651, CELoss: 0.15418, loss: 0.15418, batch_cost: 0.62366s, reader_cost: 0.04474, ips: 102.61962 samples/s, eta: 3:10:49
[2022/06/19 03:18:32] ppcls INFO: [Train][Epoch 193/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02553626, top1: 0.94744, CELoss: 0.15248, loss: 0.15248, batch_cost: 0.62173s, reader_cost: 0.04147, ips: 102.93843 samples/s, eta: 3:10:07
[2022/06/19 03:18:39] ppcls INFO: [Train][Epoch 193/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02551142, top1: 0.94812, CELoss: 0.15217, loss: 0.15217, batch_cost: 0.62869s, reader_cost: 0.03858, ips: 101.79968 samples/s, eta: 3:12:08
[2022/06/19 03:18:46] ppcls INFO: [Train][Epoch 193/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02548658, top1: 0.94758, CELoss: 0.15375, loss: 0.15375, batch_cost: 0.63082s, reader_cost: 0.03681, ips: 101.45584 samples/s, eta: 3:12:41
[2022/06/19 03:18:51] ppcls INFO: [Train][Epoch 193/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02546175, top1: 0.94785, CELoss: 0.15321, loss: 0.15321, batch_cost: 0.62664s, reader_cost: 0.03570, ips: 102.13217 samples/s, eta: 3:11:18
[2022/06/19 03:18:56] ppcls INFO: [Train][Epoch 193/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02543693, top1: 0.94779, CELoss: 0.15273, loss: 0.15273, batch_cost: 0.61565s, reader_cost: 0.03376, ips: 103.95501 samples/s, eta: 3:07:51
[2022/06/19 03:18:58] ppcls INFO: [Train][Epoch 193/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02541212, top1: 0.94785, CELoss: 0.15316, loss: 0.15316, batch_cost: 0.59172s, reader_cost: 0.03175, ips: 82.81001 samples/s, eta: 3:00:27
[2022/06/19 03:18:59] ppcls INFO: [Train][Epoch 193/300][Avg]top1: 0.94785, CELoss: 0.15316, loss: 0.15316
[2022/06/19 03:18:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:19:06] ppcls INFO: [Train][Epoch 194/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02540964, top1: 0.96875, CELoss: 0.13918, loss: 0.13918, batch_cost: 0.62836s, reader_cost: 0.05860, ips: 101.85254 samples/s, eta: 3:11:37
[2022/06/19 03:19:12] ppcls INFO: [Train][Epoch 194/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02538483, top1: 0.95170, CELoss: 0.16217, loss: 0.16217, batch_cost: 0.66752s, reader_cost: 0.02951, ips: 95.87713 samples/s, eta: 3:23:26
[2022/06/19 03:19:19] ppcls INFO: [Train][Epoch 194/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02536003, top1: 0.95238, CELoss: 0.14519, loss: 0.14519, batch_cost: 0.63832s, reader_cost: 0.02497, ips: 100.26256 samples/s, eta: 3:14:26
[2022/06/19 03:19:24] ppcls INFO: [Train][Epoch 194/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02533524, top1: 0.94859, CELoss: 0.15149, loss: 0.15149, batch_cost: 0.61540s, reader_cost: 0.02313, ips: 103.99773 samples/s, eta: 3:07:21
[2022/06/19 03:19:31] ppcls INFO: [Train][Epoch 194/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02531046, top1: 0.94855, CELoss: 0.15052, loss: 0.15052, batch_cost: 0.63548s, reader_cost: 0.05402, ips: 100.71116 samples/s, eta: 3:13:21
[2022/06/19 03:19:36] ppcls INFO: [Train][Epoch 194/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02528568, top1: 0.94975, CELoss: 0.14898, loss: 0.14898, batch_cost: 0.60659s, reader_cost: 0.04524, ips: 105.50851 samples/s, eta: 3:04:28
[2022/06/19 03:19:42] ppcls INFO: [Train][Epoch 194/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02526092, top1: 0.94903, CELoss: 0.14987, loss: 0.14987, batch_cost: 0.60493s, reader_cost: 0.04510, ips: 105.79793 samples/s, eta: 3:03:52
[2022/06/19 03:19:49] ppcls INFO: [Train][Epoch 194/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02523615, top1: 0.94630, CELoss: 0.15553, loss: 0.15553, batch_cost: 0.61216s, reader_cost: 0.04210, ips: 104.54841 samples/s, eta: 3:05:57
[2022/06/19 03:19:54] ppcls INFO: [Train][Epoch 194/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02521140, top1: 0.94599, CELoss: 0.15474, loss: 0.15474, batch_cost: 0.60430s, reader_cost: 0.03904, ips: 105.90760 samples/s, eta: 3:03:28
[2022/06/19 03:20:01] ppcls INFO: [Train][Epoch 194/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02518665, top1: 0.94694, CELoss: 0.15408, loss: 0.15408, batch_cost: 0.61519s, reader_cost: 0.03529, ips: 104.03354 samples/s, eta: 3:06:40
[2022/06/19 03:20:08] ppcls INFO: [Train][Epoch 194/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02516191, top1: 0.94756, CELoss: 0.15106, loss: 0.15106, batch_cost: 0.61608s, reader_cost: 0.03365, ips: 103.88343 samples/s, eta: 3:06:50
[2022/06/19 03:20:13] ppcls INFO: [Train][Epoch 194/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02513718, top1: 0.94834, CELoss: 0.14939, loss: 0.14939, batch_cost: 0.61150s, reader_cost: 0.03268, ips: 104.65997 samples/s, eta: 3:05:21
[2022/06/19 03:20:19] ppcls INFO: [Train][Epoch 194/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02511246, top1: 0.94886, CELoss: 0.14879, loss: 0.14879, batch_cost: 0.60964s, reader_cost: 0.03028, ips: 104.98058 samples/s, eta: 3:04:41
[2022/06/19 03:20:25] ppcls INFO: [Train][Epoch 194/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02508774, top1: 0.94967, CELoss: 0.14736, loss: 0.14736, batch_cost: 0.60734s, reader_cost: 0.02951, ips: 105.37834 samples/s, eta: 3:03:53
[2022/06/19 03:20:33] ppcls INFO: [Train][Epoch 194/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02506303, top1: 0.94958, CELoss: 0.14721, loss: 0.14721, batch_cost: 0.62054s, reader_cost: 0.02782, ips: 103.13589 samples/s, eta: 3:07:47
[2022/06/19 03:20:38] ppcls INFO: [Train][Epoch 194/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02503833, top1: 0.94868, CELoss: 0.14873, loss: 0.14873, batch_cost: 0.60967s, reader_cost: 0.02697, ips: 104.97473 samples/s, eta: 3:04:23
[2022/06/19 03:20:43] ppcls INFO: [Train][Epoch 194/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02501364, top1: 0.94866, CELoss: 0.14938, loss: 0.14938, batch_cost: 0.60592s, reader_cost: 0.02563, ips: 105.62466 samples/s, eta: 3:03:09
[2022/06/19 03:20:45] ppcls INFO: [Train][Epoch 194/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02498895, top1: 0.94839, CELoss: 0.14839, loss: 0.14839, batch_cost: 0.58190s, reader_cost: 0.02410, ips: 84.20681 samples/s, eta: 2:55:48
[2022/06/19 03:20:46] ppcls INFO: [Train][Epoch 194/300][Avg]top1: 0.94839, CELoss: 0.14839, loss: 0.14839
[2022/06/19 03:20:46] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:20:52] ppcls INFO: [Train][Epoch 195/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02498648, top1: 0.98438, CELoss: 0.07439, loss: 0.07439, batch_cost: 0.61596s, reader_cost: 0.05251, ips: 103.90280 samples/s, eta: 3:06:04
[2022/06/19 03:21:00] ppcls INFO: [Train][Epoch 195/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02496180, top1: 0.93466, CELoss: 0.16705, loss: 0.16705, batch_cost: 0.86355s, reader_cost: 0.00658, ips: 74.11242 samples/s, eta: 4:20:44
[2022/06/19 03:21:06] ppcls INFO: [Train][Epoch 195/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02493713, top1: 0.94271, CELoss: 0.15980, loss: 0.15980, batch_cost: 0.66100s, reader_cost: 0.01007, ips: 96.82259 samples/s, eta: 3:19:28
[2022/06/19 03:21:12] ppcls INFO: [Train][Epoch 195/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02491247, top1: 0.94556, CELoss: 0.15472, loss: 0.15472, batch_cost: 0.64887s, reader_cost: 0.01299, ips: 98.63348 samples/s, eta: 3:15:41
[2022/06/19 03:21:18] ppcls INFO: [Train][Epoch 195/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02488781, top1: 0.94512, CELoss: 0.15182, loss: 0.15182, batch_cost: 0.64678s, reader_cost: 0.01488, ips: 98.95156 samples/s, eta: 3:14:57
[2022/06/19 03:21:24] ppcls INFO: [Train][Epoch 195/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02486316, top1: 0.94301, CELoss: 0.15393, loss: 0.15393, batch_cost: 0.63188s, reader_cost: 0.01449, ips: 101.28460 samples/s, eta: 3:10:21
[2022/06/19 03:21:30] ppcls INFO: [Train][Epoch 195/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02483852, top1: 0.94442, CELoss: 0.15011, loss: 0.15011, batch_cost: 0.62112s, reader_cost: 0.01455, ips: 103.03981 samples/s, eta: 3:07:01
[2022/06/19 03:21:36] ppcls INFO: [Train][Epoch 195/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02481389, top1: 0.94542, CELoss: 0.14850, loss: 0.14850, batch_cost: 0.61325s, reader_cost: 0.01649, ips: 104.36229 samples/s, eta: 3:04:32
[2022/06/19 03:21:42] ppcls INFO: [Train][Epoch 195/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02478926, top1: 0.94406, CELoss: 0.15182, loss: 0.15182, batch_cost: 0.62076s, reader_cost: 0.01670, ips: 103.09916 samples/s, eta: 3:06:42
[2022/06/19 03:21:48] ppcls INFO: [Train][Epoch 195/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02476464, top1: 0.94643, CELoss: 0.14887, loss: 0.14887, batch_cost: 0.61831s, reader_cost: 0.01723, ips: 103.50769 samples/s, eta: 3:05:51
[2022/06/19 03:21:55] ppcls INFO: [Train][Epoch 195/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02474003, top1: 0.94585, CELoss: 0.14935, loss: 0.14935, batch_cost: 0.61958s, reader_cost: 0.01601, ips: 103.29548 samples/s, eta: 3:06:08
[2022/06/19 03:22:00] ppcls INFO: [Train][Epoch 195/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02471543, top1: 0.94749, CELoss: 0.14566, loss: 0.14566, batch_cost: 0.61593s, reader_cost: 0.01510, ips: 103.90740 samples/s, eta: 3:04:56
[2022/06/19 03:22:07] ppcls INFO: [Train][Epoch 195/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02469084, top1: 0.94899, CELoss: 0.14321, loss: 0.14321, batch_cost: 0.61786s, reader_cost: 0.01440, ips: 103.58373 samples/s, eta: 3:05:25
[2022/06/19 03:22:13] ppcls INFO: [Train][Epoch 195/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02466625, top1: 0.94871, CELoss: 0.14517, loss: 0.14517, batch_cost: 0.61719s, reader_cost: 0.01398, ips: 103.69500 samples/s, eta: 3:05:07
[2022/06/19 03:22:19] ppcls INFO: [Train][Epoch 195/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02464167, top1: 0.94902, CELoss: 0.14459, loss: 0.14459, batch_cost: 0.61511s, reader_cost: 0.01380, ips: 104.04602 samples/s, eta: 3:04:23
[2022/06/19 03:22:24] ppcls INFO: [Train][Epoch 195/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02461709, top1: 0.94899, CELoss: 0.14435, loss: 0.14435, batch_cost: 0.61081s, reader_cost: 0.01349, ips: 104.77925 samples/s, eta: 3:02:59
[2022/06/19 03:22:30] ppcls INFO: [Train][Epoch 195/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02459253, top1: 0.94963, CELoss: 0.14325, loss: 0.14325, batch_cost: 0.61021s, reader_cost: 0.01292, ips: 104.88277 samples/s, eta: 3:02:42
[2022/06/19 03:22:32] ppcls INFO: [Train][Epoch 195/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02456797, top1: 0.94968, CELoss: 0.14313, loss: 0.14313, batch_cost: 0.58613s, reader_cost: 0.01218, ips: 83.59894 samples/s, eta: 2:55:24
[2022/06/19 03:22:33] ppcls INFO: [Train][Epoch 195/300][Avg]top1: 0.94968, CELoss: 0.14313, loss: 0.14313
[2022/06/19 03:22:40] ppcls INFO: [Eval][Epoch 195][Iter: 0/16]CELoss: 1.15360, loss: 1.15360, top1: 0.78906, batch_cost: 6.89021s, reader_cost: 3.53921, ips: 9.28854 images/sec
[2022/06/19 03:22:48] ppcls INFO: [Eval][Epoch 195][Iter: 10/16]CELoss: 0.98196, loss: 0.98196, top1: 0.80451, batch_cost: 0.59042s, reader_cost: 0.00279, ips: 108.39762 images/sec
[2022/06/19 03:22:50] ppcls INFO: [Eval][Epoch 195][Avg]CELoss: 0.82320, loss: 0.82320, top1: 0.81434
[2022/06/19 03:22:50] ppcls INFO: [Eval][Epoch 195][best metric: 0.8171569108963013]
[2022/06/19 03:22:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:22:56] ppcls INFO: [Train][Epoch 196/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02456552, top1: 0.95312, CELoss: 0.12013, loss: 0.12013, batch_cost: 0.61701s, reader_cost: 0.04276, ips: 103.72570 samples/s, eta: 3:04:38
[2022/06/19 03:23:03] ppcls INFO: [Train][Epoch 196/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02454097, top1: 0.95170, CELoss: 0.12808, loss: 0.12808, batch_cost: 0.85385s, reader_cost: 0.24657, ips: 74.95492 samples/s, eta: 4:15:22
[2022/06/19 03:23:09] ppcls INFO: [Train][Epoch 196/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02451643, top1: 0.94420, CELoss: 0.14614, loss: 0.14614, batch_cost: 0.71155s, reader_cost: 0.10626, ips: 89.94467 samples/s, eta: 3:32:41
[2022/06/19 03:23:16] ppcls INFO: [Train][Epoch 196/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02449189, top1: 0.94456, CELoss: 0.14897, loss: 0.14897, batch_cost: 0.67350s, reader_cost: 0.07239, ips: 95.02582 samples/s, eta: 3:21:12
[2022/06/19 03:23:22] ppcls INFO: [Train][Epoch 196/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02446737, top1: 0.94284, CELoss: 0.15953, loss: 0.15953, batch_cost: 0.66925s, reader_cost: 0.05821, ips: 95.62921 samples/s, eta: 3:19:49
[2022/06/19 03:23:27] ppcls INFO: [Train][Epoch 196/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02444285, top1: 0.94363, CELoss: 0.15330, loss: 0.15330, batch_cost: 0.63727s, reader_cost: 0.04829, ips: 100.42827 samples/s, eta: 3:10:10
[2022/06/19 03:23:33] ppcls INFO: [Train][Epoch 196/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02441834, top1: 0.94390, CELoss: 0.15198, loss: 0.15198, batch_cost: 0.62458s, reader_cost: 0.05317, ips: 102.46890 samples/s, eta: 3:06:16
[2022/06/19 03:23:39] ppcls INFO: [Train][Epoch 196/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02439384, top1: 0.94476, CELoss: 0.15313, loss: 0.15313, batch_cost: 0.62540s, reader_cost: 0.04663, ips: 102.33498 samples/s, eta: 3:06:25
[2022/06/19 03:23:45] ppcls INFO: [Train][Epoch 196/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02436934, top1: 0.94560, CELoss: 0.15004, loss: 0.15004, batch_cost: 0.61803s, reader_cost: 0.04379, ips: 103.55431 samples/s, eta: 3:04:07
[2022/06/19 03:23:52] ppcls INFO: [Train][Epoch 196/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02434485, top1: 0.94420, CELoss: 0.15410, loss: 0.15410, batch_cost: 0.63138s, reader_cost: 0.04094, ips: 101.36490 samples/s, eta: 3:07:59
[2022/06/19 03:23:58] ppcls INFO: [Train][Epoch 196/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02432037, top1: 0.94369, CELoss: 0.15476, loss: 0.15476, batch_cost: 0.62489s, reader_cost: 0.03704, ips: 102.41884 samples/s, eta: 3:05:57
[2022/06/19 03:24:04] ppcls INFO: [Train][Epoch 196/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02429590, top1: 0.94299, CELoss: 0.15609, loss: 0.15609, batch_cost: 0.61949s, reader_cost: 0.03394, ips: 103.31019 samples/s, eta: 3:04:14
[2022/06/19 03:24:10] ppcls INFO: [Train][Epoch 196/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02427144, top1: 0.94331, CELoss: 0.15538, loss: 0.15538, batch_cost: 0.62320s, reader_cost: 0.03227, ips: 102.69643 samples/s, eta: 3:05:14
[2022/06/19 03:24:16] ppcls INFO: [Train][Epoch 196/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02424698, top1: 0.94382, CELoss: 0.15303, loss: 0.15303, batch_cost: 0.61957s, reader_cost: 0.03057, ips: 103.29693 samples/s, eta: 3:04:03
[2022/06/19 03:24:22] ppcls INFO: [Train][Epoch 196/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02422253, top1: 0.94492, CELoss: 0.15234, loss: 0.15234, batch_cost: 0.61891s, reader_cost: 0.03156, ips: 103.40776 samples/s, eta: 3:03:45
[2022/06/19 03:24:28] ppcls INFO: [Train][Epoch 196/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02419809, top1: 0.94557, CELoss: 0.15094, loss: 0.15094, batch_cost: 0.61819s, reader_cost: 0.03015, ips: 103.52768 samples/s, eta: 3:03:26
[2022/06/19 03:24:33] ppcls INFO: [Train][Epoch 196/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02417366, top1: 0.94575, CELoss: 0.15103, loss: 0.15103, batch_cost: 0.60836s, reader_cost: 0.02957, ips: 105.20014 samples/s, eta: 3:00:25
[2022/06/19 03:24:35] ppcls INFO: [Train][Epoch 196/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02414924, top1: 0.94611, CELoss: 0.15008, loss: 0.15008, batch_cost: 0.58456s, reader_cost: 0.02780, ips: 83.82392 samples/s, eta: 2:53:16
[2022/06/19 03:24:36] ppcls INFO: [Train][Epoch 196/300][Avg]top1: 0.94611, CELoss: 0.15008, loss: 0.15008
[2022/06/19 03:24:36] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:24:43] ppcls INFO: [Train][Epoch 197/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02414679, top1: 0.98438, CELoss: 0.06235, loss: 0.06235, batch_cost: 0.62381s, reader_cost: 0.05889, ips: 102.59499 samples/s, eta: 3:04:53
[2022/06/19 03:24:49] ppcls INFO: [Train][Epoch 197/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02412238, top1: 0.95028, CELoss: 0.12007, loss: 0.12007, batch_cost: 0.62924s, reader_cost: 0.03401, ips: 101.71053 samples/s, eta: 3:06:24
[2022/06/19 03:24:55] ppcls INFO: [Train][Epoch 197/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02409797, top1: 0.94866, CELoss: 0.13262, loss: 0.13262, batch_cost: 0.61676s, reader_cost: 0.02363, ips: 103.76876 samples/s, eta: 3:02:36
[2022/06/19 03:25:02] ppcls INFO: [Train][Epoch 197/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02407357, top1: 0.95161, CELoss: 0.13352, loss: 0.13352, batch_cost: 0.61760s, reader_cost: 0.02064, ips: 103.62738 samples/s, eta: 3:02:44
[2022/06/19 03:25:08] ppcls INFO: [Train][Epoch 197/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02404918, top1: 0.95351, CELoss: 0.12917, loss: 0.12917, batch_cost: 0.61313s, reader_cost: 0.02089, ips: 104.38269 samples/s, eta: 3:01:19
[2022/06/19 03:25:14] ppcls INFO: [Train][Epoch 197/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02402479, top1: 0.95129, CELoss: 0.13123, loss: 0.13123, batch_cost: 0.61883s, reader_cost: 0.01996, ips: 103.42133 samples/s, eta: 3:02:54
[2022/06/19 03:25:20] ppcls INFO: [Train][Epoch 197/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02400041, top1: 0.95082, CELoss: 0.13629, loss: 0.13629, batch_cost: 0.61566s, reader_cost: 0.01895, ips: 103.95424 samples/s, eta: 3:01:51
[2022/06/19 03:25:26] ppcls INFO: [Train][Epoch 197/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02397604, top1: 0.95136, CELoss: 0.13984, loss: 0.13984, batch_cost: 0.61476s, reader_cost: 0.01886, ips: 104.10574 samples/s, eta: 3:01:29
[2022/06/19 03:25:32] ppcls INFO: [Train][Epoch 197/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02395168, top1: 0.95062, CELoss: 0.14167, loss: 0.14167, batch_cost: 0.61133s, reader_cost: 0.02069, ips: 104.69054 samples/s, eta: 3:00:22
[2022/06/19 03:25:37] ppcls INFO: [Train][Epoch 197/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02392733, top1: 0.95021, CELoss: 0.14511, loss: 0.14511, batch_cost: 0.59974s, reader_cost: 0.01932, ips: 106.71264 samples/s, eta: 2:56:51
[2022/06/19 03:25:44] ppcls INFO: [Train][Epoch 197/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02390298, top1: 0.94988, CELoss: 0.14566, loss: 0.14566, batch_cost: 0.60923s, reader_cost: 0.01810, ips: 105.04990 samples/s, eta: 2:59:33
[2022/06/19 03:25:50] ppcls INFO: [Train][Epoch 197/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02387865, top1: 0.95045, CELoss: 0.14536, loss: 0.14536, batch_cost: 0.60615s, reader_cost: 0.01777, ips: 105.58394 samples/s, eta: 2:58:33
[2022/06/19 03:25:55] ppcls INFO: [Train][Epoch 197/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02385432, top1: 0.95003, CELoss: 0.14514, loss: 0.14514, batch_cost: 0.60225s, reader_cost: 0.01730, ips: 106.26864 samples/s, eta: 2:57:18
[2022/06/19 03:26:01] ppcls INFO: [Train][Epoch 197/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02382999, top1: 0.95026, CELoss: 0.14617, loss: 0.14617, batch_cost: 0.59809s, reader_cost: 0.01648, ips: 107.00745 samples/s, eta: 2:55:58
[2022/06/19 03:26:09] ppcls INFO: [Train][Epoch 197/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02380568, top1: 0.94914, CELoss: 0.14762, loss: 0.14762, batch_cost: 0.60990s, reader_cost: 0.01615, ips: 104.93509 samples/s, eta: 2:59:21
[2022/06/19 03:26:14] ppcls INFO: [Train][Epoch 197/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02378138, top1: 0.94868, CELoss: 0.14972, loss: 0.14972, batch_cost: 0.60531s, reader_cost: 0.01651, ips: 105.73053 samples/s, eta: 2:57:54
[2022/06/19 03:26:19] ppcls INFO: [Train][Epoch 197/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02375708, top1: 0.94847, CELoss: 0.15016, loss: 0.15016, batch_cost: 0.59732s, reader_cost: 0.01581, ips: 107.14596 samples/s, eta: 2:55:27
[2022/06/19 03:26:21] ppcls INFO: [Train][Epoch 197/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02373279, top1: 0.94830, CELoss: 0.14954, loss: 0.14954, batch_cost: 0.57420s, reader_cost: 0.01489, ips: 85.33540 samples/s, eta: 2:48:34
[2022/06/19 03:26:22] ppcls INFO: [Train][Epoch 197/300][Avg]top1: 0.94830, CELoss: 0.14954, loss: 0.14954
[2022/06/19 03:26:22] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:26:28] ppcls INFO: [Train][Epoch 198/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02373036, top1: 1.00000, CELoss: 0.05758, loss: 0.05758, batch_cost: 0.60772s, reader_cost: 0.04106, ips: 105.31219 samples/s, eta: 2:58:23
[2022/06/19 03:26:35] ppcls INFO: [Train][Epoch 198/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02370608, top1: 0.96165, CELoss: 0.13936, loss: 0.13936, batch_cost: 0.60141s, reader_cost: 0.00742, ips: 106.41674 samples/s, eta: 2:56:26
[2022/06/19 03:26:41] ppcls INFO: [Train][Epoch 198/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02368180, top1: 0.95238, CELoss: 0.14701, loss: 0.14701, batch_cost: 0.63606s, reader_cost: 0.01752, ips: 100.61988 samples/s, eta: 3:06:30
[2022/06/19 03:26:47] ppcls INFO: [Train][Epoch 198/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02365754, top1: 0.95161, CELoss: 0.15501, loss: 0.15501, batch_cost: 0.61520s, reader_cost: 0.01493, ips: 104.03147 samples/s, eta: 3:00:17
[2022/06/19 03:26:53] ppcls INFO: [Train][Epoch 198/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02363328, top1: 0.95389, CELoss: 0.14632, loss: 0.14632, batch_cost: 0.62429s, reader_cost: 0.04711, ips: 102.51585 samples/s, eta: 3:02:50
[2022/06/19 03:26:59] ppcls INFO: [Train][Epoch 198/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02360903, top1: 0.95159, CELoss: 0.14658, loss: 0.14658, batch_cost: 0.61506s, reader_cost: 0.03805, ips: 104.05445 samples/s, eta: 3:00:02
[2022/06/19 03:27:05] ppcls INFO: [Train][Epoch 198/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02358479, top1: 0.95210, CELoss: 0.14319, loss: 0.14319, batch_cost: 0.60988s, reader_cost: 0.03472, ips: 104.93803 samples/s, eta: 2:58:25
[2022/06/19 03:27:11] ppcls INFO: [Train][Epoch 198/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02356056, top1: 0.95268, CELoss: 0.14068, loss: 0.14068, batch_cost: 0.60695s, reader_cost: 0.03017, ips: 105.44513 samples/s, eta: 2:57:27
[2022/06/19 03:27:17] ppcls INFO: [Train][Epoch 198/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02353633, top1: 0.95216, CELoss: 0.14158, loss: 0.14158, batch_cost: 0.60235s, reader_cost: 0.02705, ips: 106.25001 samples/s, eta: 2:56:01
[2022/06/19 03:27:23] ppcls INFO: [Train][Epoch 198/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02351212, top1: 0.95158, CELoss: 0.14286, loss: 0.14286, batch_cost: 0.61001s, reader_cost: 0.02502, ips: 104.91679 samples/s, eta: 2:58:09
[2022/06/19 03:27:29] ppcls INFO: [Train][Epoch 198/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02348791, top1: 0.95034, CELoss: 0.14516, loss: 0.14516, batch_cost: 0.60785s, reader_cost: 0.02350, ips: 105.28932 samples/s, eta: 2:57:25
[2022/06/19 03:27:35] ppcls INFO: [Train][Epoch 198/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02346371, top1: 0.95017, CELoss: 0.14452, loss: 0.14452, batch_cost: 0.60811s, reader_cost: 0.02294, ips: 105.24334 samples/s, eta: 2:57:23
[2022/06/19 03:27:42] ppcls INFO: [Train][Epoch 198/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02343951, top1: 0.95132, CELoss: 0.14356, loss: 0.14356, batch_cost: 0.60992s, reader_cost: 0.02265, ips: 104.93138 samples/s, eta: 2:57:49
[2022/06/19 03:27:47] ppcls INFO: [Train][Epoch 198/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02341533, top1: 0.94955, CELoss: 0.14711, loss: 0.14711, batch_cost: 0.60515s, reader_cost: 0.02245, ips: 105.75958 samples/s, eta: 2:56:19
[2022/06/19 03:27:53] ppcls INFO: [Train][Epoch 198/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02339115, top1: 0.94991, CELoss: 0.14544, loss: 0.14544, batch_cost: 0.60205s, reader_cost: 0.02115, ips: 106.30298 samples/s, eta: 2:55:19
[2022/06/19 03:28:00] ppcls INFO: [Train][Epoch 198/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02336698, top1: 0.95023, CELoss: 0.14410, loss: 0.14410, batch_cost: 0.60798s, reader_cost: 0.01977, ips: 105.26719 samples/s, eta: 2:56:57
[2022/06/19 03:28:05] ppcls INFO: [Train][Epoch 198/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02334282, top1: 0.95021, CELoss: 0.14356, loss: 0.14356, batch_cost: 0.60012s, reader_cost: 0.01879, ips: 106.64557 samples/s, eta: 2:54:33
[2022/06/19 03:28:07] ppcls INFO: [Train][Epoch 198/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02331867, top1: 0.95059, CELoss: 0.14324, loss: 0.14324, batch_cost: 0.57680s, reader_cost: 0.01771, ips: 84.95186 samples/s, eta: 2:47:41
[2022/06/19 03:28:07] ppcls INFO: [Train][Epoch 198/300][Avg]top1: 0.95059, CELoss: 0.14324, loss: 0.14324
[2022/06/19 03:28:07] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:28:14] ppcls INFO: [Train][Epoch 199/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02331626, top1: 1.00000, CELoss: 0.03336, loss: 0.03336, batch_cost: 0.61506s, reader_cost: 0.04436, ips: 104.05439 samples/s, eta: 2:58:47
[2022/06/19 03:28:21] ppcls INFO: [Train][Epoch 199/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02329211, top1: 0.96449, CELoss: 0.09748, loss: 0.09748, batch_cost: 0.73685s, reader_cost: 0.00148, ips: 86.85632 samples/s, eta: 3:34:04
[2022/06/19 03:28:28] ppcls INFO: [Train][Epoch 199/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02326798, top1: 0.95015, CELoss: 0.13803, loss: 0.13803, batch_cost: 0.67043s, reader_cost: 0.00607, ips: 95.46170 samples/s, eta: 3:14:40
[2022/06/19 03:28:34] ppcls INFO: [Train][Epoch 199/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02324385, top1: 0.95111, CELoss: 0.13567, loss: 0.13567, batch_cost: 0.64207s, reader_cost: 0.01002, ips: 99.67793 samples/s, eta: 3:06:19
[2022/06/19 03:28:39] ppcls INFO: [Train][Epoch 199/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02321973, top1: 0.94931, CELoss: 0.13623, loss: 0.13623, batch_cost: 0.62473s, reader_cost: 0.00957, ips: 102.44412 samples/s, eta: 3:01:11
[2022/06/19 03:28:47] ppcls INFO: [Train][Epoch 199/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02319562, top1: 0.95067, CELoss: 0.13295, loss: 0.13295, batch_cost: 0.64551s, reader_cost: 0.01069, ips: 99.14568 samples/s, eta: 3:07:06
[2022/06/19 03:28:52] ppcls INFO: [Train][Epoch 199/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02317152, top1: 0.95133, CELoss: 0.13689, loss: 0.13689, batch_cost: 0.62527s, reader_cost: 0.01397, ips: 102.35546 samples/s, eta: 3:01:08
[2022/06/19 03:28:58] ppcls INFO: [Train][Epoch 199/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02314742, top1: 0.95070, CELoss: 0.13854, loss: 0.13854, batch_cost: 0.62127s, reader_cost: 0.01501, ips: 103.01541 samples/s, eta: 2:59:52
[2022/06/19 03:29:04] ppcls INFO: [Train][Epoch 199/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02312334, top1: 0.94985, CELoss: 0.13994, loss: 0.13994, batch_cost: 0.61832s, reader_cost: 0.01579, ips: 103.50576 samples/s, eta: 2:58:55
[2022/06/19 03:29:10] ppcls INFO: [Train][Epoch 199/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02309926, top1: 0.94900, CELoss: 0.14059, loss: 0.14059, batch_cost: 0.61180s, reader_cost: 0.01568, ips: 104.60894 samples/s, eta: 2:56:55
[2022/06/19 03:29:16] ppcls INFO: [Train][Epoch 199/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02307519, top1: 0.95019, CELoss: 0.13935, loss: 0.13935, batch_cost: 0.61242s, reader_cost: 0.01605, ips: 104.50283 samples/s, eta: 2:57:00
[2022/06/19 03:29:22] ppcls INFO: [Train][Epoch 199/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02305113, top1: 0.94932, CELoss: 0.14016, loss: 0.14016, batch_cost: 0.60958s, reader_cost: 0.01525, ips: 104.99081 samples/s, eta: 2:56:05
[2022/06/19 03:29:27] ppcls INFO: [Train][Epoch 199/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02302707, top1: 0.95067, CELoss: 0.13825, loss: 0.13825, batch_cost: 0.60660s, reader_cost: 0.01607, ips: 105.50588 samples/s, eta: 2:55:07
[2022/06/19 03:29:34] ppcls INFO: [Train][Epoch 199/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02300303, top1: 0.95169, CELoss: 0.13627, loss: 0.13627, batch_cost: 0.61164s, reader_cost: 0.02702, ips: 104.63637 samples/s, eta: 2:56:28
[2022/06/19 03:29:40] ppcls INFO: [Train][Epoch 199/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02297899, top1: 0.95069, CELoss: 0.13829, loss: 0.13829, batch_cost: 0.60770s, reader_cost: 0.02873, ips: 105.31594 samples/s, eta: 2:55:14
[2022/06/19 03:29:46] ppcls INFO: [Train][Epoch 199/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02295496, top1: 0.95075, CELoss: 0.13920, loss: 0.13920, batch_cost: 0.61133s, reader_cost: 0.03580, ips: 104.69014 samples/s, eta: 2:56:11
[2022/06/19 03:29:51] ppcls INFO: [Train][Epoch 199/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02293094, top1: 0.95060, CELoss: 0.13996, loss: 0.13996, batch_cost: 0.60240s, reader_cost: 0.03513, ips: 106.24135 samples/s, eta: 2:53:30
[2022/06/19 03:29:53] ppcls INFO: [Train][Epoch 199/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02290693, top1: 0.95013, CELoss: 0.14198, loss: 0.14198, batch_cost: 0.57921s, reader_cost: 0.03304, ips: 84.59732 samples/s, eta: 2:46:44
[2022/06/19 03:29:54] ppcls INFO: [Train][Epoch 199/300][Avg]top1: 0.95013, CELoss: 0.14198, loss: 0.14198
[2022/06/19 03:29:54] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:30:00] ppcls INFO: [Train][Epoch 200/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02290453, top1: 0.92188, CELoss: 0.19005, loss: 0.19005, batch_cost: 0.61213s, reader_cost: 0.06371, ips: 104.55230 samples/s, eta: 2:56:12
[2022/06/19 03:30:07] ppcls INFO: [Train][Epoch 200/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02288053, top1: 0.94744, CELoss: 0.14411, loss: 0.14411, batch_cost: 0.66941s, reader_cost: 0.00057, ips: 95.60621 samples/s, eta: 3:12:34
[2022/06/19 03:30:13] ppcls INFO: [Train][Epoch 200/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02285653, top1: 0.95312, CELoss: 0.14218, loss: 0.14218, batch_cost: 0.65662s, reader_cost: 0.00614, ips: 97.46909 samples/s, eta: 3:08:47
[2022/06/19 03:30:20] ppcls INFO: [Train][Epoch 200/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02283255, top1: 0.95312, CELoss: 0.13885, loss: 0.13885, batch_cost: 0.64611s, reader_cost: 0.01061, ips: 99.05489 samples/s, eta: 3:05:39
[2022/06/19 03:30:26] ppcls INFO: [Train][Epoch 200/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02280857, top1: 0.95770, CELoss: 0.12986, loss: 0.12986, batch_cost: 0.64710s, reader_cost: 0.01024, ips: 98.90222 samples/s, eta: 3:05:50
[2022/06/19 03:30:32] ppcls INFO: [Train][Epoch 200/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02278460, top1: 0.95833, CELoss: 0.12813, loss: 0.12813, batch_cost: 0.63670s, reader_cost: 0.01238, ips: 100.51781 samples/s, eta: 3:02:44
[2022/06/19 03:30:38] ppcls INFO: [Train][Epoch 200/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02276064, top1: 0.95825, CELoss: 0.12784, loss: 0.12784, batch_cost: 0.63227s, reader_cost: 0.01378, ips: 101.22207 samples/s, eta: 3:01:22
[2022/06/19 03:30:44] ppcls INFO: [Train][Epoch 200/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02273668, top1: 0.95709, CELoss: 0.12859, loss: 0.12859, batch_cost: 0.62310s, reader_cost: 0.01665, ips: 102.71283 samples/s, eta: 2:58:37
[2022/06/19 03:30:50] ppcls INFO: [Train][Epoch 200/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02271274, top1: 0.95660, CELoss: 0.12763, loss: 0.12763, batch_cost: 0.61614s, reader_cost: 0.01599, ips: 103.87227 samples/s, eta: 2:56:32
[2022/06/19 03:30:55] ppcls INFO: [Train][Epoch 200/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02268880, top1: 0.95519, CELoss: 0.13041, loss: 0.13041, batch_cost: 0.60636s, reader_cost: 0.01629, ips: 105.54801 samples/s, eta: 2:53:37
[2022/06/19 03:31:01] ppcls INFO: [Train][Epoch 200/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02266487, top1: 0.95498, CELoss: 0.13073, loss: 0.13073, batch_cost: 0.60965s, reader_cost: 0.01706, ips: 104.97880 samples/s, eta: 2:54:28
[2022/06/19 03:31:07] ppcls INFO: [Train][Epoch 200/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02264095, top1: 0.95538, CELoss: 0.12901, loss: 0.12901, batch_cost: 0.60800s, reader_cost: 0.01604, ips: 105.26321 samples/s, eta: 2:53:53
[2022/06/19 03:31:13] ppcls INFO: [Train][Epoch 200/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02261704, top1: 0.95493, CELoss: 0.13184, loss: 0.13184, batch_cost: 0.60217s, reader_cost: 0.01668, ips: 106.28268 samples/s, eta: 2:52:07
[2022/06/19 03:31:18] ppcls INFO: [Train][Epoch 200/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02259314, top1: 0.95456, CELoss: 0.13468, loss: 0.13468, batch_cost: 0.59645s, reader_cost: 0.01586, ips: 107.30157 samples/s, eta: 2:50:23
[2022/06/19 03:31:24] ppcls INFO: [Train][Epoch 200/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02256925, top1: 0.95401, CELoss: 0.13606, loss: 0.13606, batch_cost: 0.59962s, reader_cost: 0.01493, ips: 106.73432 samples/s, eta: 2:51:12
[2022/06/19 03:31:31] ppcls INFO: [Train][Epoch 200/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02254536, top1: 0.95354, CELoss: 0.13612, loss: 0.13612, batch_cost: 0.60037s, reader_cost: 0.01404, ips: 106.60031 samples/s, eta: 2:51:18
[2022/06/19 03:31:36] ppcls INFO: [Train][Epoch 200/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02252148, top1: 0.95312, CELoss: 0.13732, loss: 0.13732, batch_cost: 0.59741s, reader_cost: 0.01319, ips: 107.12858 samples/s, eta: 2:50:22
[2022/06/19 03:31:38] ppcls INFO: [Train][Epoch 200/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02249761, top1: 0.95297, CELoss: 0.13836, loss: 0.13836, batch_cost: 0.57440s, reader_cost: 0.01240, ips: 85.30601 samples/s, eta: 2:43:42
[2022/06/19 03:31:39] ppcls INFO: [Train][Epoch 200/300][Avg]top1: 0.95297, CELoss: 0.13836, loss: 0.13836
[2022/06/19 03:31:46] ppcls INFO: [Eval][Epoch 200][Iter: 0/16]CELoss: 0.89916, loss: 0.89916, top1: 0.82422, batch_cost: 6.77990s, reader_cost: 3.63447, ips: 9.43966 images/sec
[2022/06/19 03:31:54] ppcls INFO: [Eval][Epoch 200][Iter: 10/16]CELoss: 1.01057, loss: 1.01057, top1: 0.81658, batch_cost: 0.60069s, reader_cost: 0.00107, ips: 106.54365 images/sec
[2022/06/19 03:31:55] ppcls INFO: [Eval][Epoch 200][Avg]CELoss: 0.78887, loss: 0.78887, top1: 0.82022
[2022/06/19 03:31:55] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 03:31:55] ppcls INFO: [Eval][Epoch 200][best metric: 0.8202206492424011]
[2022/06/19 03:31:55] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_200
[2022/06/19 03:31:56] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:32:02] ppcls INFO: [Train][Epoch 201/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02249523, top1: 0.95312, CELoss: 0.13741, loss: 0.13741, batch_cost: 0.60684s, reader_cost: 0.04330, ips: 105.46516 samples/s, eta: 2:52:56
[2022/06/19 03:32:09] ppcls INFO: [Train][Epoch 201/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02247137, top1: 0.94034, CELoss: 0.14867, loss: 0.14867, batch_cost: 0.81791s, reader_cost: 0.00194, ips: 78.24788 samples/s, eta: 3:52:58
[2022/06/19 03:32:15] ppcls INFO: [Train][Epoch 201/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02244752, top1: 0.94792, CELoss: 0.14036, loss: 0.14036, batch_cost: 0.69371s, reader_cost: 0.00408, ips: 92.25768 samples/s, eta: 3:17:28
[2022/06/19 03:32:21] ppcls INFO: [Train][Epoch 201/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02242367, top1: 0.94556, CELoss: 0.15017, loss: 0.15017, batch_cost: 0.63915s, reader_cost: 0.00797, ips: 100.13288 samples/s, eta: 3:01:50
[2022/06/19 03:32:27] ppcls INFO: [Train][Epoch 201/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02239984, top1: 0.94322, CELoss: 0.15406, loss: 0.15406, batch_cost: 0.63273s, reader_cost: 0.01347, ips: 101.14943 samples/s, eta: 2:59:54
[2022/06/19 03:32:33] ppcls INFO: [Train][Epoch 201/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02237601, top1: 0.94547, CELoss: 0.14780, loss: 0.14780, batch_cost: 0.62370s, reader_cost: 0.01161, ips: 102.61335 samples/s, eta: 2:57:14
[2022/06/19 03:32:40] ppcls INFO: [Train][Epoch 201/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02235219, top1: 0.94570, CELoss: 0.14671, loss: 0.14671, batch_cost: 0.63587s, reader_cost: 0.01383, ips: 100.64910 samples/s, eta: 3:00:35
[2022/06/19 03:32:45] ppcls INFO: [Train][Epoch 201/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02232839, top1: 0.94806, CELoss: 0.14287, loss: 0.14287, batch_cost: 0.61365s, reader_cost: 0.01395, ips: 104.29344 samples/s, eta: 2:54:10
[2022/06/19 03:32:52] ppcls INFO: [Train][Epoch 201/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02230459, top1: 0.95042, CELoss: 0.13812, loss: 0.13812, batch_cost: 0.62208s, reader_cost: 0.01391, ips: 102.88141 samples/s, eta: 2:56:27
[2022/06/19 03:32:58] ppcls INFO: [Train][Epoch 201/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02228079, top1: 0.95021, CELoss: 0.13863, loss: 0.13863, batch_cost: 0.62311s, reader_cost: 0.01279, ips: 102.71067 samples/s, eta: 2:56:39
[2022/06/19 03:33:03] ppcls INFO: [Train][Epoch 201/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02225701, top1: 0.95111, CELoss: 0.13676, loss: 0.13676, batch_cost: 0.61334s, reader_cost: 0.01244, ips: 104.34589 samples/s, eta: 2:53:46
[2022/06/19 03:33:10] ppcls INFO: [Train][Epoch 201/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02223323, top1: 0.95242, CELoss: 0.13667, loss: 0.13667, batch_cost: 0.61681s, reader_cost: 0.01205, ips: 103.75925 samples/s, eta: 2:54:39
[2022/06/19 03:33:16] ppcls INFO: [Train][Epoch 201/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02220947, top1: 0.95248, CELoss: 0.13730, loss: 0.13730, batch_cost: 0.61986s, reader_cost: 0.01168, ips: 103.24968 samples/s, eta: 2:55:25
[2022/06/19 03:33:23] ppcls INFO: [Train][Epoch 201/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02218571, top1: 0.95217, CELoss: 0.13880, loss: 0.13880, batch_cost: 0.62058s, reader_cost: 0.01202, ips: 103.12884 samples/s, eta: 2:55:31
[2022/06/19 03:33:28] ppcls INFO: [Train][Epoch 201/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02216196, top1: 0.95213, CELoss: 0.14025, loss: 0.14025, batch_cost: 0.61755s, reader_cost: 0.01161, ips: 103.63506 samples/s, eta: 2:54:33
[2022/06/19 03:33:34] ppcls INFO: [Train][Epoch 201/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02213822, top1: 0.95137, CELoss: 0.14209, loss: 0.14209, batch_cost: 0.61201s, reader_cost: 0.01160, ips: 104.57379 samples/s, eta: 2:52:53
[2022/06/19 03:33:41] ppcls INFO: [Train][Epoch 201/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02211449, top1: 0.95148, CELoss: 0.14189, loss: 0.14189, batch_cost: 0.61993s, reader_cost: 0.01140, ips: 103.23810 samples/s, eta: 2:55:01
[2022/06/19 03:33:44] ppcls INFO: [Train][Epoch 201/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02209076, top1: 0.95160, CELoss: 0.14240, loss: 0.14240, batch_cost: 0.59759s, reader_cost: 0.01077, ips: 81.99597 samples/s, eta: 2:48:37
[2022/06/19 03:33:44] ppcls INFO: [Train][Epoch 201/300][Avg]top1: 0.95160, CELoss: 0.14240, loss: 0.14240
[2022/06/19 03:33:44] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:33:53] ppcls INFO: [Train][Epoch 202/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02208839, top1: 0.95312, CELoss: 0.17649, loss: 0.17649, batch_cost: 0.64757s, reader_cost: 0.04512, ips: 98.83165 samples/s, eta: 3:02:42
[2022/06/19 03:33:58] ppcls INFO: [Train][Epoch 202/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02206468, top1: 0.94034, CELoss: 0.16935, loss: 0.16935, batch_cost: 0.61551s, reader_cost: 0.00689, ips: 103.97941 samples/s, eta: 2:53:33
[2022/06/19 03:34:04] ppcls INFO: [Train][Epoch 202/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02204097, top1: 0.94345, CELoss: 0.15854, loss: 0.15854, batch_cost: 0.58839s, reader_cost: 0.01181, ips: 108.77082 samples/s, eta: 2:45:49
[2022/06/19 03:34:11] ppcls INFO: [Train][Epoch 202/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02201728, top1: 0.94153, CELoss: 0.16185, loss: 0.16185, batch_cost: 0.61170s, reader_cost: 0.01790, ips: 104.62663 samples/s, eta: 2:52:17
[2022/06/19 03:34:17] ppcls INFO: [Train][Epoch 202/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02199359, top1: 0.94398, CELoss: 0.16090, loss: 0.16090, batch_cost: 0.61398s, reader_cost: 0.02186, ips: 104.23824 samples/s, eta: 2:52:49
[2022/06/19 03:34:24] ppcls INFO: [Train][Epoch 202/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02196991, top1: 0.94700, CELoss: 0.15392, loss: 0.15392, batch_cost: 0.63502s, reader_cost: 0.02223, ips: 100.78477 samples/s, eta: 2:58:38
[2022/06/19 03:34:30] ppcls INFO: [Train][Epoch 202/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02194624, top1: 0.94365, CELoss: 0.15926, loss: 0.15926, batch_cost: 0.63793s, reader_cost: 0.02173, ips: 100.32415 samples/s, eta: 2:59:21
[2022/06/19 03:34:36] ppcls INFO: [Train][Epoch 202/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02192257, top1: 0.94498, CELoss: 0.15754, loss: 0.15754, batch_cost: 0.62320s, reader_cost: 0.02031, ips: 102.69581 samples/s, eta: 2:55:06
[2022/06/19 03:34:42] ppcls INFO: [Train][Epoch 202/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02189892, top1: 0.94715, CELoss: 0.15235, loss: 0.15235, batch_cost: 0.62130s, reader_cost: 0.01955, ips: 103.01044 samples/s, eta: 2:54:28
[2022/06/19 03:34:48] ppcls INFO: [Train][Epoch 202/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02187528, top1: 0.94849, CELoss: 0.15031, loss: 0.15031, batch_cost: 0.61987s, reader_cost: 0.01883, ips: 103.24819 samples/s, eta: 2:53:57
[2022/06/19 03:34:54] ppcls INFO: [Train][Epoch 202/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02185164, top1: 0.94941, CELoss: 0.14703, loss: 0.14703, batch_cost: 0.61874s, reader_cost: 0.02020, ips: 103.43665 samples/s, eta: 2:53:32
[2022/06/19 03:35:00] ppcls INFO: [Train][Epoch 202/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02182801, top1: 0.95003, CELoss: 0.14507, loss: 0.14507, batch_cost: 0.61223s, reader_cost: 0.02087, ips: 104.53524 samples/s, eta: 2:51:37
[2022/06/19 03:35:06] ppcls INFO: [Train][Epoch 202/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02180439, top1: 0.95170, CELoss: 0.14183, loss: 0.14183, batch_cost: 0.61481s, reader_cost: 0.02058, ips: 104.09686 samples/s, eta: 2:52:14
[2022/06/19 03:35:12] ppcls INFO: [Train][Epoch 202/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02178078, top1: 0.95134, CELoss: 0.14246, loss: 0.14246, batch_cost: 0.61425s, reader_cost: 0.02083, ips: 104.19214 samples/s, eta: 2:51:58
[2022/06/19 03:35:19] ppcls INFO: [Train][Epoch 202/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02175718, top1: 0.95091, CELoss: 0.14354, loss: 0.14354, batch_cost: 0.61832s, reader_cost: 0.01957, ips: 103.50565 samples/s, eta: 2:53:01
[2022/06/19 03:35:25] ppcls INFO: [Train][Epoch 202/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02173359, top1: 0.95023, CELoss: 0.14504, loss: 0.14504, batch_cost: 0.61559s, reader_cost: 0.01874, ips: 103.96481 samples/s, eta: 2:52:09
[2022/06/19 03:35:29] ppcls INFO: [Train][Epoch 202/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02171000, top1: 0.94983, CELoss: 0.14468, loss: 0.14468, batch_cost: 0.60454s, reader_cost: 0.01786, ips: 105.86603 samples/s, eta: 2:48:57
[2022/06/19 03:35:31] ppcls INFO: [Train][Epoch 202/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02168643, top1: 0.94949, CELoss: 0.14661, loss: 0.14661, batch_cost: 0.58135s, reader_cost: 0.01681, ips: 84.28712 samples/s, eta: 2:42:22
[2022/06/19 03:35:32] ppcls INFO: [Train][Epoch 202/300][Avg]top1: 0.94949, CELoss: 0.14661, loss: 0.14661
[2022/06/19 03:35:32] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:35:40] ppcls INFO: [Train][Epoch 203/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02168407, top1: 0.95312, CELoss: 0.09367, loss: 0.09367, batch_cost: 0.62534s, reader_cost: 0.04148, ips: 102.34407 samples/s, eta: 2:54:39
[2022/06/19 03:35:46] ppcls INFO: [Train][Epoch 203/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02166050, top1: 0.95739, CELoss: 0.12702, loss: 0.12702, batch_cost: 0.55366s, reader_cost: 0.01605, ips: 115.59530 samples/s, eta: 2:34:32
[2022/06/19 03:35:51] ppcls INFO: [Train][Epoch 203/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02163695, top1: 0.95685, CELoss: 0.12902, loss: 0.12902, batch_cost: 0.57562s, reader_cost: 0.01802, ips: 111.18430 samples/s, eta: 2:40:34
[2022/06/19 03:35:58] ppcls INFO: [Train][Epoch 203/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02161340, top1: 0.95665, CELoss: 0.12860, loss: 0.12860, batch_cost: 0.60398s, reader_cost: 0.02123, ips: 105.96297 samples/s, eta: 2:48:23
[2022/06/19 03:36:05] ppcls INFO: [Train][Epoch 203/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02158986, top1: 0.95274, CELoss: 0.13850, loss: 0.13850, batch_cost: 0.63622s, reader_cost: 0.01967, ips: 100.59339 samples/s, eta: 2:57:16
[2022/06/19 03:36:11] ppcls INFO: [Train][Epoch 203/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02156633, top1: 0.95343, CELoss: 0.13948, loss: 0.13948, batch_cost: 0.62194s, reader_cost: 0.01841, ips: 102.90382 samples/s, eta: 2:53:11
[2022/06/19 03:36:17] ppcls INFO: [Train][Epoch 203/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02154281, top1: 0.95312, CELoss: 0.14310, loss: 0.14310, batch_cost: 0.62834s, reader_cost: 0.01677, ips: 101.85631 samples/s, eta: 2:54:51
[2022/06/19 03:36:23] ppcls INFO: [Train][Epoch 203/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02151929, top1: 0.95202, CELoss: 0.14251, loss: 0.14251, batch_cost: 0.61673s, reader_cost: 0.01554, ips: 103.77278 samples/s, eta: 2:51:32
[2022/06/19 03:36:29] ppcls INFO: [Train][Epoch 203/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02149579, top1: 0.95100, CELoss: 0.14180, loss: 0.14180, batch_cost: 0.61983s, reader_cost: 0.01450, ips: 103.25388 samples/s, eta: 2:52:17
[2022/06/19 03:36:35] ppcls INFO: [Train][Epoch 203/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02147229, top1: 0.95124, CELoss: 0.14374, loss: 0.14374, batch_cost: 0.61407s, reader_cost: 0.01519, ips: 104.22278 samples/s, eta: 2:50:35
[2022/06/19 03:36:42] ppcls INFO: [Train][Epoch 203/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02144881, top1: 0.95096, CELoss: 0.14357, loss: 0.14357, batch_cost: 0.61867s, reader_cost: 0.01503, ips: 103.44812 samples/s, eta: 2:51:45
[2022/06/19 03:36:47] ppcls INFO: [Train][Epoch 203/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02142533, top1: 0.95228, CELoss: 0.14020, loss: 0.14020, batch_cost: 0.61598s, reader_cost: 0.01588, ips: 103.89985 samples/s, eta: 2:50:54
[2022/06/19 03:36:53] ppcls INFO: [Train][Epoch 203/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02140186, top1: 0.95196, CELoss: 0.13968, loss: 0.13968, batch_cost: 0.61049s, reader_cost: 0.01621, ips: 104.83423 samples/s, eta: 2:49:17
[2022/06/19 03:36:59] ppcls INFO: [Train][Epoch 203/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02137840, top1: 0.95289, CELoss: 0.13607, loss: 0.13607, batch_cost: 0.60817s, reader_cost: 0.01549, ips: 105.23308 samples/s, eta: 2:48:32
[2022/06/19 03:37:04] ppcls INFO: [Train][Epoch 203/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02135495, top1: 0.95257, CELoss: 0.13726, loss: 0.13726, batch_cost: 0.60452s, reader_cost: 0.01512, ips: 105.86874 samples/s, eta: 2:47:25
[2022/06/19 03:37:12] ppcls INFO: [Train][Epoch 203/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02133151, top1: 0.95106, CELoss: 0.14409, loss: 0.14409, batch_cost: 0.61124s, reader_cost: 0.01521, ips: 104.70500 samples/s, eta: 2:49:11
[2022/06/19 03:37:17] ppcls INFO: [Train][Epoch 203/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02130807, top1: 0.95089, CELoss: 0.14361, loss: 0.14361, batch_cost: 0.60581s, reader_cost: 0.01533, ips: 105.64424 samples/s, eta: 2:47:35
[2022/06/19 03:37:19] ppcls INFO: [Train][Epoch 203/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02128465, top1: 0.95086, CELoss: 0.14413, loss: 0.14413, batch_cost: 0.58339s, reader_cost: 0.01447, ips: 83.99131 samples/s, eta: 2:41:17
[2022/06/19 03:37:20] ppcls INFO: [Train][Epoch 203/300][Avg]top1: 0.95086, CELoss: 0.14413, loss: 0.14413
[2022/06/19 03:37:20] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:37:26] ppcls INFO: [Train][Epoch 204/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02128231, top1: 0.92188, CELoss: 0.18431, loss: 0.18431, batch_cost: 0.61590s, reader_cost: 0.04136, ips: 103.91380 samples/s, eta: 2:50:15
[2022/06/19 03:37:34] ppcls INFO: [Train][Epoch 204/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02125889, top1: 0.94318, CELoss: 0.15419, loss: 0.15419, batch_cost: 0.71808s, reader_cost: 0.00083, ips: 89.12668 samples/s, eta: 3:18:23
[2022/06/19 03:37:40] ppcls INFO: [Train][Epoch 204/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02123548, top1: 0.94792, CELoss: 0.14083, loss: 0.14083, batch_cost: 0.67514s, reader_cost: 0.01320, ips: 94.79539 samples/s, eta: 3:06:25
[2022/06/19 03:37:46] ppcls INFO: [Train][Epoch 204/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02121209, top1: 0.94708, CELoss: 0.14677, loss: 0.14677, batch_cost: 0.64132s, reader_cost: 0.01186, ips: 99.79424 samples/s, eta: 2:56:58
[2022/06/19 03:37:52] ppcls INFO: [Train][Epoch 204/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02118870, top1: 0.94931, CELoss: 0.14342, loss: 0.14342, batch_cost: 0.62148s, reader_cost: 0.01197, ips: 102.98067 samples/s, eta: 2:51:23
[2022/06/19 03:37:58] ppcls INFO: [Train][Epoch 204/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02116532, top1: 0.95251, CELoss: 0.14033, loss: 0.14033, batch_cost: 0.61909s, reader_cost: 0.01345, ips: 103.37680 samples/s, eta: 2:50:37
[2022/06/19 03:38:04] ppcls INFO: [Train][Epoch 204/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02114195, top1: 0.95056, CELoss: 0.14151, loss: 0.14151, batch_cost: 0.61362s, reader_cost: 0.02278, ips: 104.29874 samples/s, eta: 2:49:01
[2022/06/19 03:38:10] ppcls INFO: [Train][Epoch 204/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02111859, top1: 0.95224, CELoss: 0.13981, loss: 0.13981, batch_cost: 0.61348s, reader_cost: 0.03558, ips: 104.32326 samples/s, eta: 2:48:52
[2022/06/19 03:38:16] ppcls INFO: [Train][Epoch 204/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02109524, top1: 0.95274, CELoss: 0.14237, loss: 0.14237, batch_cost: 0.61654s, reader_cost: 0.04330, ips: 103.80474 samples/s, eta: 2:49:37
[2022/06/19 03:38:25] ppcls INFO: [Train][Epoch 204/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02107189, top1: 0.95312, CELoss: 0.14081, loss: 0.14081, batch_cost: 0.64069s, reader_cost: 0.08181, ips: 99.89200 samples/s, eta: 2:56:09
[2022/06/19 03:38:29] ppcls INFO: [Train][Epoch 204/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02104856, top1: 0.95142, CELoss: 0.14185, loss: 0.14185, batch_cost: 0.61844s, reader_cost: 0.07610, ips: 103.48539 samples/s, eta: 2:49:56
[2022/06/19 03:38:35] ppcls INFO: [Train][Epoch 204/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02102523, top1: 0.95059, CELoss: 0.14336, loss: 0.14336, batch_cost: 0.61564s, reader_cost: 0.06990, ips: 103.95680 samples/s, eta: 2:49:03
[2022/06/19 03:38:41] ppcls INFO: [Train][Epoch 204/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02100192, top1: 0.95132, CELoss: 0.14066, loss: 0.14066, batch_cost: 0.61263s, reader_cost: 0.06478, ips: 104.46710 samples/s, eta: 2:48:08
[2022/06/19 03:38:47] ppcls INFO: [Train][Epoch 204/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02097861, top1: 0.95229, CELoss: 0.13952, loss: 0.13952, batch_cost: 0.61239s, reader_cost: 0.06056, ips: 104.50903 samples/s, eta: 2:47:58
[2022/06/19 03:38:52] ppcls INFO: [Train][Epoch 204/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02095531, top1: 0.95180, CELoss: 0.14128, loss: 0.14128, batch_cost: 0.60778s, reader_cost: 0.05662, ips: 105.30108 samples/s, eta: 2:46:36
[2022/06/19 03:38:59] ppcls INFO: [Train][Epoch 204/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02093202, top1: 0.95188, CELoss: 0.14014, loss: 0.14014, batch_cost: 0.61496s, reader_cost: 0.05314, ips: 104.07208 samples/s, eta: 2:48:28
[2022/06/19 03:39:04] ppcls INFO: [Train][Epoch 204/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02090874, top1: 0.95148, CELoss: 0.14190, loss: 0.14190, batch_cost: 0.60834s, reader_cost: 0.05005, ips: 105.20494 samples/s, eta: 2:46:33
[2022/06/19 03:39:07] ppcls INFO: [Train][Epoch 204/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02088547, top1: 0.95114, CELoss: 0.14250, loss: 0.14250, batch_cost: 0.58419s, reader_cost: 0.04704, ips: 83.87614 samples/s, eta: 2:39:50
[2022/06/19 03:39:07] ppcls INFO: [Train][Epoch 204/300][Avg]top1: 0.95114, CELoss: 0.14250, loss: 0.14250
[2022/06/19 03:39:07] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:39:14] ppcls INFO: [Train][Epoch 205/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02088314, top1: 0.98438, CELoss: 0.06942, loss: 0.06942, batch_cost: 0.62375s, reader_cost: 0.07732, ips: 102.60559 samples/s, eta: 2:50:39
[2022/06/19 03:39:21] ppcls INFO: [Train][Epoch 205/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02085988, top1: 0.96023, CELoss: 0.11230, loss: 0.11230, batch_cost: 0.63746s, reader_cost: 0.00609, ips: 100.39883 samples/s, eta: 2:54:18
[2022/06/19 03:39:27] ppcls INFO: [Train][Epoch 205/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02083663, top1: 0.94792, CELoss: 0.14049, loss: 0.14049, batch_cost: 0.62470s, reader_cost: 0.01219, ips: 102.44993 samples/s, eta: 2:50:42
[2022/06/19 03:39:33] ppcls INFO: [Train][Epoch 205/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02081338, top1: 0.94456, CELoss: 0.13988, loss: 0.13988, batch_cost: 0.61832s, reader_cost: 0.01516, ips: 103.50677 samples/s, eta: 2:48:51
[2022/06/19 03:39:39] ppcls INFO: [Train][Epoch 205/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02079015, top1: 0.94627, CELoss: 0.13777, loss: 0.13777, batch_cost: 0.61638s, reader_cost: 0.01967, ips: 103.83178 samples/s, eta: 2:48:13
[2022/06/19 03:39:46] ppcls INFO: [Train][Epoch 205/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02076692, top1: 0.95037, CELoss: 0.13355, loss: 0.13355, batch_cost: 0.62389s, reader_cost: 0.01738, ips: 102.58142 samples/s, eta: 2:50:10
[2022/06/19 03:39:51] ppcls INFO: [Train][Epoch 205/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02074371, top1: 0.94903, CELoss: 0.13659, loss: 0.13659, batch_cost: 0.61604s, reader_cost: 0.01645, ips: 103.88883 samples/s, eta: 2:47:56
[2022/06/19 03:39:57] ppcls INFO: [Train][Epoch 205/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02072050, top1: 0.94938, CELoss: 0.13689, loss: 0.13689, batch_cost: 0.60704s, reader_cost: 0.01539, ips: 105.43005 samples/s, eta: 2:45:22
[2022/06/19 03:40:04] ppcls INFO: [Train][Epoch 205/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02069730, top1: 0.94985, CELoss: 0.13805, loss: 0.13805, batch_cost: 0.62470s, reader_cost: 0.04181, ips: 102.44883 samples/s, eta: 2:50:05
[2022/06/19 03:40:09] ppcls INFO: [Train][Epoch 205/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02067411, top1: 0.94849, CELoss: 0.14452, loss: 0.14452, batch_cost: 0.61121s, reader_cost: 0.03736, ips: 104.71044 samples/s, eta: 2:46:18
[2022/06/19 03:40:16] ppcls INFO: [Train][Epoch 205/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02065093, top1: 0.94879, CELoss: 0.14291, loss: 0.14291, batch_cost: 0.61411s, reader_cost: 0.03732, ips: 104.21670 samples/s, eta: 2:46:59
[2022/06/19 03:40:21] ppcls INFO: [Train][Epoch 205/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02062776, top1: 0.94947, CELoss: 0.14176, loss: 0.14176, batch_cost: 0.60901s, reader_cost: 0.03460, ips: 105.08827 samples/s, eta: 2:45:30
[2022/06/19 03:40:28] ppcls INFO: [Train][Epoch 205/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02060460, top1: 0.94990, CELoss: 0.13993, loss: 0.13993, batch_cost: 0.61175s, reader_cost: 0.04040, ips: 104.61850 samples/s, eta: 2:46:09
[2022/06/19 03:40:35] ppcls INFO: [Train][Epoch 205/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02058145, top1: 0.94895, CELoss: 0.14370, loss: 0.14370, batch_cost: 0.61793s, reader_cost: 0.03848, ips: 103.57159 samples/s, eta: 2:47:43
[2022/06/19 03:40:40] ppcls INFO: [Train][Epoch 205/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02055831, top1: 0.94880, CELoss: 0.14529, loss: 0.14529, batch_cost: 0.61434s, reader_cost: 0.03591, ips: 104.17739 samples/s, eta: 2:46:38
[2022/06/19 03:40:46] ppcls INFO: [Train][Epoch 205/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02053517, top1: 0.94888, CELoss: 0.14558, loss: 0.14558, batch_cost: 0.60785s, reader_cost: 0.03371, ips: 105.28958 samples/s, eta: 2:44:47
[2022/06/19 03:40:51] ppcls INFO: [Train][Epoch 205/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02051205, top1: 0.94934, CELoss: 0.14498, loss: 0.14498, batch_cost: 0.60275s, reader_cost: 0.03190, ips: 106.18055 samples/s, eta: 2:43:18
[2022/06/19 03:40:53] ppcls INFO: [Train][Epoch 205/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02048893, top1: 0.94858, CELoss: 0.14651, loss: 0.14651, batch_cost: 0.57916s, reader_cost: 0.02998, ips: 84.60528 samples/s, eta: 2:36:49
[2022/06/19 03:40:54] ppcls INFO: [Train][Epoch 205/300][Avg]top1: 0.94858, CELoss: 0.14651, loss: 0.14651
[2022/06/19 03:41:01] ppcls INFO: [Eval][Epoch 205][Iter: 0/16]CELoss: 1.01811, loss: 1.01811, top1: 0.80469, batch_cost: 6.90843s, reader_cost: 3.84797, ips: 9.26404 images/sec
[2022/06/19 03:41:09] ppcls INFO: [Eval][Epoch 205][Iter: 10/16]CELoss: 0.82437, loss: 0.82437, top1: 0.81303, batch_cost: 0.60302s, reader_cost: 0.00528, ips: 106.13240 images/sec
[2022/06/19 03:41:10] ppcls INFO: [Eval][Epoch 205][Avg]CELoss: 0.76756, loss: 0.76756, top1: 0.82181
[2022/06/19 03:41:10] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 03:41:10] ppcls INFO: [Eval][Epoch 205][best metric: 0.8218137621879578]
[2022/06/19 03:41:11] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:41:17] ppcls INFO: [Train][Epoch 206/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02048662, top1: 0.98438, CELoss: 0.03914, loss: 0.03914, batch_cost: 0.61378s, reader_cost: 0.06245, ips: 104.27168 samples/s, eta: 2:46:10
[2022/06/19 03:41:24] ppcls INFO: [Train][Epoch 206/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02046352, top1: 0.95739, CELoss: 0.14187, loss: 0.14187, batch_cost: 0.66642s, reader_cost: 0.00422, ips: 96.03519 samples/s, eta: 3:00:19
[2022/06/19 03:41:30] ppcls INFO: [Train][Epoch 206/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02044042, top1: 0.94940, CELoss: 0.16532, loss: 0.16532, batch_cost: 0.65754s, reader_cost: 0.00964, ips: 97.33311 samples/s, eta: 2:57:48
[2022/06/19 03:41:37] ppcls INFO: [Train][Epoch 206/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02041733, top1: 0.95565, CELoss: 0.14516, loss: 0.14516, batch_cost: 0.65793s, reader_cost: 0.01318, ips: 97.27527 samples/s, eta: 2:57:48
[2022/06/19 03:41:43] ppcls INFO: [Train][Epoch 206/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02039425, top1: 0.95503, CELoss: 0.13915, loss: 0.13915, batch_cost: 0.63860s, reader_cost: 0.01252, ips: 100.21863 samples/s, eta: 2:52:28
[2022/06/19 03:41:49] ppcls INFO: [Train][Epoch 206/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.02037119, top1: 0.95251, CELoss: 0.14202, loss: 0.14202, batch_cost: 0.63052s, reader_cost: 0.01455, ips: 101.50377 samples/s, eta: 2:50:11
[2022/06/19 03:41:55] ppcls INFO: [Train][Epoch 206/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.02034813, top1: 0.95312, CELoss: 0.14038, loss: 0.14038, batch_cost: 0.62984s, reader_cost: 0.01513, ips: 101.61288 samples/s, eta: 2:49:53
[2022/06/19 03:42:01] ppcls INFO: [Train][Epoch 206/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.02032508, top1: 0.95489, CELoss: 0.13594, loss: 0.13594, batch_cost: 0.62677s, reader_cost: 0.01375, ips: 102.11132 samples/s, eta: 2:48:57
[2022/06/19 03:42:07] ppcls INFO: [Train][Epoch 206/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.02030204, top1: 0.95505, CELoss: 0.13367, loss: 0.13367, batch_cost: 0.62085s, reader_cost: 0.01329, ips: 103.08387 samples/s, eta: 2:47:16
[2022/06/19 03:42:14] ppcls INFO: [Train][Epoch 206/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.02027900, top1: 0.95501, CELoss: 0.13246, loss: 0.13246, batch_cost: 0.62868s, reader_cost: 0.01231, ips: 101.80084 samples/s, eta: 2:49:16
[2022/06/19 03:42:19] ppcls INFO: [Train][Epoch 206/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.02025598, top1: 0.95436, CELoss: 0.13510, loss: 0.13510, batch_cost: 0.62074s, reader_cost: 0.01192, ips: 103.10320 samples/s, eta: 2:47:01
[2022/06/19 03:42:25] ppcls INFO: [Train][Epoch 206/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.02023297, top1: 0.95481, CELoss: 0.13365, loss: 0.13365, batch_cost: 0.61874s, reader_cost: 0.01172, ips: 103.43584 samples/s, eta: 2:46:23
[2022/06/19 03:42:32] ppcls INFO: [Train][Epoch 206/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.02020996, top1: 0.95532, CELoss: 0.13188, loss: 0.13188, batch_cost: 0.62215s, reader_cost: 0.01127, ips: 102.86912 samples/s, eta: 2:47:12
[2022/06/19 03:42:38] ppcls INFO: [Train][Epoch 206/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.02018697, top1: 0.95479, CELoss: 0.13367, loss: 0.13367, batch_cost: 0.62280s, reader_cost: 0.01142, ips: 102.76149 samples/s, eta: 2:47:16
[2022/06/19 03:42:43] ppcls INFO: [Train][Epoch 206/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.02016398, top1: 0.95401, CELoss: 0.13515, loss: 0.13515, batch_cost: 0.61514s, reader_cost: 0.01136, ips: 104.04128 samples/s, eta: 2:45:06
[2022/06/19 03:42:50] ppcls INFO: [Train][Epoch 206/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.02014101, top1: 0.95447, CELoss: 0.13276, loss: 0.13276, batch_cost: 0.62052s, reader_cost: 0.01153, ips: 103.13934 samples/s, eta: 2:46:27
[2022/06/19 03:42:55] ppcls INFO: [Train][Epoch 206/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.02011804, top1: 0.95429, CELoss: 0.13311, loss: 0.13311, batch_cost: 0.61312s, reader_cost: 0.01168, ips: 104.38356 samples/s, eta: 2:44:22
[2022/06/19 03:42:58] ppcls INFO: [Train][Epoch 206/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.02009509, top1: 0.95361, CELoss: 0.13431, loss: 0.13431, batch_cost: 0.58877s, reader_cost: 0.01098, ips: 83.22503 samples/s, eta: 2:37:44
[2022/06/19 03:42:58] ppcls INFO: [Train][Epoch 206/300][Avg]top1: 0.95361, CELoss: 0.13431, loss: 0.13431
[2022/06/19 03:42:58] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:43:05] ppcls INFO: [Train][Epoch 207/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.02009279, top1: 0.96875, CELoss: 0.05351, loss: 0.05351, batch_cost: 0.62643s, reader_cost: 0.04311, ips: 102.16544 samples/s, eta: 2:47:49
[2022/06/19 03:43:12] ppcls INFO: [Train][Epoch 207/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.02006984, top1: 0.96023, CELoss: 0.10363, loss: 0.10363, batch_cost: 0.70321s, reader_cost: 0.02990, ips: 91.01163 samples/s, eta: 3:08:16
[2022/06/19 03:43:18] ppcls INFO: [Train][Epoch 207/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.02004691, top1: 0.95833, CELoss: 0.11376, loss: 0.11376, batch_cost: 0.62571s, reader_cost: 0.02420, ips: 102.28310 samples/s, eta: 2:47:25
[2022/06/19 03:43:24] ppcls INFO: [Train][Epoch 207/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.02002398, top1: 0.95766, CELoss: 0.11641, loss: 0.11641, batch_cost: 0.63071s, reader_cost: 0.03802, ips: 101.47312 samples/s, eta: 2:48:39
[2022/06/19 03:43:30] ppcls INFO: [Train][Epoch 207/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.02000106, top1: 0.95427, CELoss: 0.12531, loss: 0.12531, batch_cost: 0.62489s, reader_cost: 0.03049, ips: 102.41752 samples/s, eta: 2:46:59
[2022/06/19 03:43:37] ppcls INFO: [Train][Epoch 207/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01997815, top1: 0.95466, CELoss: 0.12912, loss: 0.12912, batch_cost: 0.63944s, reader_cost: 0.05744, ips: 100.08802 samples/s, eta: 2:50:46
[2022/06/19 03:43:43] ppcls INFO: [Train][Epoch 207/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01995525, top1: 0.95415, CELoss: 0.13062, loss: 0.13062, batch_cost: 0.62892s, reader_cost: 0.06042, ips: 101.76158 samples/s, eta: 2:47:51
[2022/06/19 03:43:49] ppcls INFO: [Train][Epoch 207/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01993236, top1: 0.95335, CELoss: 0.13326, loss: 0.13326, batch_cost: 0.62723s, reader_cost: 0.05379, ips: 102.03662 samples/s, eta: 2:47:18
[2022/06/19 03:43:55] ppcls INFO: [Train][Epoch 207/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01990948, top1: 0.95370, CELoss: 0.13226, loss: 0.13226, batch_cost: 0.62112s, reader_cost: 0.04861, ips: 103.03928 samples/s, eta: 2:45:34
[2022/06/19 03:44:02] ppcls INFO: [Train][Epoch 207/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01988660, top1: 0.95398, CELoss: 0.13197, loss: 0.13197, batch_cost: 0.62770s, reader_cost: 0.04440, ips: 101.95975 samples/s, eta: 2:47:13
[2022/06/19 03:44:07] ppcls INFO: [Train][Epoch 207/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01986374, top1: 0.95483, CELoss: 0.12954, loss: 0.12954, batch_cost: 0.61772s, reader_cost: 0.04210, ips: 103.60655 samples/s, eta: 2:44:27
[2022/06/19 03:44:13] ppcls INFO: [Train][Epoch 207/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01984089, top1: 0.95538, CELoss: 0.12846, loss: 0.12846, batch_cost: 0.61311s, reader_cost: 0.03936, ips: 104.38584 samples/s, eta: 2:43:07
[2022/06/19 03:44:20] ppcls INFO: [Train][Epoch 207/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01981805, top1: 0.95519, CELoss: 0.13038, loss: 0.13038, batch_cost: 0.62310s, reader_cost: 0.03697, ips: 102.71276 samples/s, eta: 2:45:40
[2022/06/19 03:44:25] ppcls INFO: [Train][Epoch 207/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01979521, top1: 0.95527, CELoss: 0.13003, loss: 0.13003, batch_cost: 0.61573s, reader_cost: 0.03569, ips: 103.94201 samples/s, eta: 2:43:37
[2022/06/19 03:44:31] ppcls INFO: [Train][Epoch 207/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01977239, top1: 0.95578, CELoss: 0.12849, loss: 0.12849, batch_cost: 0.61034s, reader_cost: 0.03404, ips: 104.85979 samples/s, eta: 2:42:05
[2022/06/19 03:44:37] ppcls INFO: [Train][Epoch 207/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01974957, top1: 0.95561, CELoss: 0.12805, loss: 0.12805, batch_cost: 0.61161s, reader_cost: 0.03248, ips: 104.64232 samples/s, eta: 2:42:19
[2022/06/19 03:44:44] ppcls INFO: [Train][Epoch 207/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01972677, top1: 0.95604, CELoss: 0.12706, loss: 0.12706, batch_cost: 0.61294s, reader_cost: 0.03645, ips: 104.41456 samples/s, eta: 2:42:34
[2022/06/19 03:44:46] ppcls INFO: [Train][Epoch 207/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01970397, top1: 0.95617, CELoss: 0.12746, loss: 0.12746, batch_cost: 0.58873s, reader_cost: 0.03427, ips: 83.23042 samples/s, eta: 2:36:03
[2022/06/19 03:44:46] ppcls INFO: [Train][Epoch 207/300][Avg]top1: 0.95617, CELoss: 0.12746, loss: 0.12746
[2022/06/19 03:44:46] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:44:52] ppcls INFO: [Train][Epoch 208/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01970169, top1: 0.89062, CELoss: 0.24678, loss: 0.24678, batch_cost: 0.62114s, reader_cost: 0.05679, ips: 103.03690 samples/s, eta: 2:44:37
[2022/06/19 03:45:00] ppcls INFO: [Train][Epoch 208/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01967890, top1: 0.94886, CELoss: 0.13820, loss: 0.13820, batch_cost: 0.81566s, reader_cost: 0.00475, ips: 78.46377 samples/s, eta: 3:36:03
[2022/06/19 03:45:06] ppcls INFO: [Train][Epoch 208/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01965613, top1: 0.95238, CELoss: 0.12278, loss: 0.12278, batch_cost: 0.67757s, reader_cost: 0.01585, ips: 94.45516 samples/s, eta: 2:59:21
[2022/06/19 03:45:12] ppcls INFO: [Train][Epoch 208/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01963336, top1: 0.95665, CELoss: 0.12356, loss: 0.12356, batch_cost: 0.65424s, reader_cost: 0.02583, ips: 97.82271 samples/s, eta: 2:53:04
[2022/06/19 03:45:19] ppcls INFO: [Train][Epoch 208/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01961060, top1: 0.95694, CELoss: 0.12328, loss: 0.12328, batch_cost: 0.64994s, reader_cost: 0.02177, ips: 98.47013 samples/s, eta: 2:51:50
[2022/06/19 03:45:25] ppcls INFO: [Train][Epoch 208/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01958786, top1: 0.95558, CELoss: 0.12691, loss: 0.12691, batch_cost: 0.64090s, reader_cost: 0.02006, ips: 99.85885 samples/s, eta: 2:49:20
[2022/06/19 03:45:31] ppcls INFO: [Train][Epoch 208/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01956512, top1: 0.95876, CELoss: 0.12715, loss: 0.12715, batch_cost: 0.64288s, reader_cost: 0.01795, ips: 99.55250 samples/s, eta: 2:49:45
[2022/06/19 03:45:37] ppcls INFO: [Train][Epoch 208/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01954239, top1: 0.95775, CELoss: 0.12781, loss: 0.12781, batch_cost: 0.63456s, reader_cost: 0.01859, ips: 100.85762 samples/s, eta: 2:47:26
[2022/06/19 03:45:44] ppcls INFO: [Train][Epoch 208/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01951967, top1: 0.95930, CELoss: 0.12487, loss: 0.12487, batch_cost: 0.63951s, reader_cost: 0.01676, ips: 100.07673 samples/s, eta: 2:48:38
[2022/06/19 03:45:50] ppcls INFO: [Train][Epoch 208/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01949696, top1: 0.95879, CELoss: 0.12518, loss: 0.12518, batch_cost: 0.63931s, reader_cost: 0.01740, ips: 100.10772 samples/s, eta: 2:48:29
[2022/06/19 03:45:56] ppcls INFO: [Train][Epoch 208/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01947426, top1: 0.95730, CELoss: 0.12738, loss: 0.12738, batch_cost: 0.63506s, reader_cost: 0.01681, ips: 100.77803 samples/s, eta: 2:47:15
[2022/06/19 03:46:02] ppcls INFO: [Train][Epoch 208/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01945157, top1: 0.95650, CELoss: 0.12790, loss: 0.12790, batch_cost: 0.62914s, reader_cost: 0.01694, ips: 101.72593 samples/s, eta: 2:45:36
[2022/06/19 03:46:08] ppcls INFO: [Train][Epoch 208/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01942889, top1: 0.95674, CELoss: 0.12949, loss: 0.12949, batch_cost: 0.62991s, reader_cost: 0.01727, ips: 101.60102 samples/s, eta: 2:45:41
[2022/06/19 03:46:14] ppcls INFO: [Train][Epoch 208/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01940622, top1: 0.95623, CELoss: 0.12833, loss: 0.12833, batch_cost: 0.62587s, reader_cost: 0.01742, ips: 102.25825 samples/s, eta: 2:44:31
[2022/06/19 03:46:20] ppcls INFO: [Train][Epoch 208/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01938355, top1: 0.95534, CELoss: 0.13005, loss: 0.13005, batch_cost: 0.62546s, reader_cost: 0.01809, ips: 102.32448 samples/s, eta: 2:44:19
[2022/06/19 03:46:26] ppcls INFO: [Train][Epoch 208/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01936090, top1: 0.95602, CELoss: 0.12922, loss: 0.12922, batch_cost: 0.62103s, reader_cost: 0.01809, ips: 103.05432 samples/s, eta: 2:43:03
[2022/06/19 03:46:31] ppcls INFO: [Train][Epoch 208/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01933826, top1: 0.95604, CELoss: 0.13052, loss: 0.13052, batch_cost: 0.61574s, reader_cost: 0.01715, ips: 103.93993 samples/s, eta: 2:41:33
[2022/06/19 03:46:34] ppcls INFO: [Train][Epoch 208/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01931563, top1: 0.95544, CELoss: 0.13102, loss: 0.13102, batch_cost: 0.59156s, reader_cost: 0.01612, ips: 82.83169 samples/s, eta: 2:35:07
[2022/06/19 03:46:34] ppcls INFO: [Train][Epoch 208/300][Avg]top1: 0.95544, CELoss: 0.13102, loss: 0.13102
[2022/06/19 03:46:34] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:46:41] ppcls INFO: [Train][Epoch 209/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01931336, top1: 0.95312, CELoss: 0.08809, loss: 0.08809, batch_cost: 0.62928s, reader_cost: 0.05076, ips: 101.70305 samples/s, eta: 2:44:59
[2022/06/19 03:46:49] ppcls INFO: [Train][Epoch 209/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01929074, top1: 0.95028, CELoss: 0.12092, loss: 0.12092, batch_cost: 0.88289s, reader_cost: 0.38494, ips: 72.48952 samples/s, eta: 3:51:20
[2022/06/19 03:46:55] ppcls INFO: [Train][Epoch 209/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01926813, top1: 0.94940, CELoss: 0.13083, loss: 0.13083, batch_cost: 0.66310s, reader_cost: 0.14902, ips: 96.51646 samples/s, eta: 2:53:38
[2022/06/19 03:47:01] ppcls INFO: [Train][Epoch 209/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01924553, top1: 0.95060, CELoss: 0.13587, loss: 0.13587, batch_cost: 0.65794s, reader_cost: 0.09540, ips: 97.27392 samples/s, eta: 2:52:10
[2022/06/19 03:47:07] ppcls INFO: [Train][Epoch 209/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01922293, top1: 0.95122, CELoss: 0.13598, loss: 0.13598, batch_cost: 0.62848s, reader_cost: 0.07327, ips: 101.83289 samples/s, eta: 2:44:22
[2022/06/19 03:47:12] ppcls INFO: [Train][Epoch 209/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01920035, top1: 0.95037, CELoss: 0.13812, loss: 0.13812, batch_cost: 0.61991s, reader_cost: 0.06308, ips: 103.23999 samples/s, eta: 2:42:01
[2022/06/19 03:47:18] ppcls INFO: [Train][Epoch 209/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01917777, top1: 0.94928, CELoss: 0.14047, loss: 0.14047, batch_cost: 0.61272s, reader_cost: 0.05428, ips: 104.45283 samples/s, eta: 2:40:02
[2022/06/19 03:47:25] ppcls INFO: [Train][Epoch 209/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01915521, top1: 0.95070, CELoss: 0.13885, loss: 0.13885, batch_cost: 0.62433s, reader_cost: 0.05111, ips: 102.50943 samples/s, eta: 2:42:58
[2022/06/19 03:47:31] ppcls INFO: [Train][Epoch 209/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01913266, top1: 0.94927, CELoss: 0.14254, loss: 0.14254, batch_cost: 0.62355s, reader_cost: 0.04633, ips: 102.63802 samples/s, eta: 2:42:39
[2022/06/19 03:47:37] ppcls INFO: [Train][Epoch 209/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01911011, top1: 0.94986, CELoss: 0.14105, loss: 0.14105, batch_cost: 0.61988s, reader_cost: 0.04427, ips: 103.24559 samples/s, eta: 2:41:36
[2022/06/19 03:47:44] ppcls INFO: [Train][Epoch 209/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01908758, top1: 0.94926, CELoss: 0.14301, loss: 0.14301, batch_cost: 0.62409s, reader_cost: 0.04093, ips: 102.54873 samples/s, eta: 2:42:35
[2022/06/19 03:47:50] ppcls INFO: [Train][Epoch 209/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01906505, top1: 0.95031, CELoss: 0.14133, loss: 0.14133, batch_cost: 0.62722s, reader_cost: 0.03981, ips: 102.03792 samples/s, eta: 2:43:18
[2022/06/19 03:47:56] ppcls INFO: [Train][Epoch 209/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01904253, top1: 0.95106, CELoss: 0.13970, loss: 0.13970, batch_cost: 0.62078s, reader_cost: 0.03760, ips: 103.09685 samples/s, eta: 2:41:31
[2022/06/19 03:48:02] ppcls INFO: [Train][Epoch 209/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01902003, top1: 0.95157, CELoss: 0.14029, loss: 0.14029, batch_cost: 0.62235s, reader_cost: 0.03571, ips: 102.83577 samples/s, eta: 2:41:49
[2022/06/19 03:48:08] ppcls INFO: [Train][Epoch 209/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01899753, top1: 0.95146, CELoss: 0.14004, loss: 0.14004, batch_cost: 0.61908s, reader_cost: 0.03398, ips: 103.37895 samples/s, eta: 2:40:52
[2022/06/19 03:48:14] ppcls INFO: [Train][Epoch 209/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01897505, top1: 0.95168, CELoss: 0.13944, loss: 0.13944, batch_cost: 0.61499s, reader_cost: 0.03193, ips: 104.06705 samples/s, eta: 2:39:42
[2022/06/19 03:48:18] ppcls INFO: [Train][Epoch 209/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01895257, top1: 0.95235, CELoss: 0.13812, loss: 0.13812, batch_cost: 0.60461s, reader_cost: 0.03052, ips: 105.85251 samples/s, eta: 2:36:55
[2022/06/19 03:48:21] ppcls INFO: [Train][Epoch 209/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01893010, top1: 0.95233, CELoss: 0.13717, loss: 0.13717, batch_cost: 0.58264s, reader_cost: 0.02872, ips: 84.10009 samples/s, eta: 2:31:07
[2022/06/19 03:48:21] ppcls INFO: [Train][Epoch 209/300][Avg]top1: 0.95233, CELoss: 0.13717, loss: 0.13717
[2022/06/19 03:48:22] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:48:28] ppcls INFO: [Train][Epoch 210/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01892785, top1: 0.92188, CELoss: 0.11158, loss: 0.11158, batch_cost: 0.61713s, reader_cost: 0.05223, ips: 103.70620 samples/s, eta: 2:40:03
[2022/06/19 03:48:35] ppcls INFO: [Train][Epoch 210/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01890540, top1: 0.95739, CELoss: 0.11687, loss: 0.11687, batch_cost: 0.65333s, reader_cost: 0.00695, ips: 97.95986 samples/s, eta: 2:49:19
[2022/06/19 03:48:41] ppcls INFO: [Train][Epoch 210/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01888295, top1: 0.95461, CELoss: 0.12461, loss: 0.12461, batch_cost: 0.63655s, reader_cost: 0.01724, ips: 100.54180 samples/s, eta: 2:44:52
[2022/06/19 03:48:47] ppcls INFO: [Train][Epoch 210/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01886052, top1: 0.95010, CELoss: 0.14031, loss: 0.14031, batch_cost: 0.63099s, reader_cost: 0.01278, ips: 101.42726 samples/s, eta: 2:43:19
[2022/06/19 03:48:54] ppcls INFO: [Train][Epoch 210/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01883809, top1: 0.95236, CELoss: 0.13396, loss: 0.13396, batch_cost: 0.63637s, reader_cost: 0.01208, ips: 100.57053 samples/s, eta: 2:44:37
[2022/06/19 03:49:00] ppcls INFO: [Train][Epoch 210/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01881567, top1: 0.95496, CELoss: 0.12616, loss: 0.12616, batch_cost: 0.62410s, reader_cost: 0.01128, ips: 102.54750 samples/s, eta: 2:41:20
[2022/06/19 03:49:06] ppcls INFO: [Train][Epoch 210/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01879326, top1: 0.95569, CELoss: 0.13010, loss: 0.13010, batch_cost: 0.62310s, reader_cost: 0.01219, ips: 102.71221 samples/s, eta: 2:40:58
[2022/06/19 03:49:12] ppcls INFO: [Train][Epoch 210/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01877087, top1: 0.95775, CELoss: 0.12474, loss: 0.12474, batch_cost: 0.61509s, reader_cost: 0.01370, ips: 104.05051 samples/s, eta: 2:38:48
[2022/06/19 03:49:18] ppcls INFO: [Train][Epoch 210/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01874848, top1: 0.95833, CELoss: 0.12518, loss: 0.12518, batch_cost: 0.61826s, reader_cost: 0.01382, ips: 103.51582 samples/s, eta: 2:39:31
[2022/06/19 03:49:23] ppcls INFO: [Train][Epoch 210/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01872610, top1: 0.95879, CELoss: 0.12312, loss: 0.12312, batch_cost: 0.60829s, reader_cost: 0.01380, ips: 105.21347 samples/s, eta: 2:36:50
[2022/06/19 03:49:30] ppcls INFO: [Train][Epoch 210/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01870373, top1: 0.95808, CELoss: 0.12565, loss: 0.12565, batch_cost: 0.61755s, reader_cost: 0.01959, ips: 103.63611 samples/s, eta: 2:39:07
[2022/06/19 03:49:37] ppcls INFO: [Train][Epoch 210/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01868138, top1: 0.95735, CELoss: 0.12612, loss: 0.12612, batch_cost: 0.61954s, reader_cost: 0.01997, ips: 103.30220 samples/s, eta: 2:39:32
[2022/06/19 03:49:43] ppcls INFO: [Train][Epoch 210/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01865903, top1: 0.95752, CELoss: 0.12676, loss: 0.12676, batch_cost: 0.61966s, reader_cost: 0.01973, ips: 103.28169 samples/s, eta: 2:39:28
[2022/06/19 03:49:49] ppcls INFO: [Train][Epoch 210/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01863669, top1: 0.95754, CELoss: 0.12768, loss: 0.12768, batch_cost: 0.61563s, reader_cost: 0.01870, ips: 103.95801 samples/s, eta: 2:38:19
[2022/06/19 03:49:54] ppcls INFO: [Train][Epoch 210/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01861436, top1: 0.95645, CELoss: 0.13029, loss: 0.13029, batch_cost: 0.60877s, reader_cost: 0.01841, ips: 105.12989 samples/s, eta: 2:36:27
[2022/06/19 03:50:01] ppcls INFO: [Train][Epoch 210/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01859204, top1: 0.95613, CELoss: 0.13163, loss: 0.13163, batch_cost: 0.61773s, reader_cost: 0.01776, ips: 103.60586 samples/s, eta: 2:38:39
[2022/06/19 03:50:07] ppcls INFO: [Train][Epoch 210/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01856973, top1: 0.95604, CELoss: 0.13167, loss: 0.13167, batch_cost: 0.61222s, reader_cost: 0.01724, ips: 104.53736 samples/s, eta: 2:37:08
[2022/06/19 03:50:09] ppcls INFO: [Train][Epoch 210/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01854743, top1: 0.95608, CELoss: 0.13068, loss: 0.13068, batch_cost: 0.58811s, reader_cost: 0.01621, ips: 83.31842 samples/s, eta: 2:30:51
[2022/06/19 03:50:09] ppcls INFO: [Train][Epoch 210/300][Avg]top1: 0.95608, CELoss: 0.13068, loss: 0.13068
[2022/06/19 03:50:16] ppcls INFO: [Eval][Epoch 210][Iter: 0/16]CELoss: 1.04784, loss: 1.04784, top1: 0.81055, batch_cost: 7.01743s, reader_cost: 3.36313, ips: 9.12015 images/sec
[2022/06/19 03:50:24] ppcls INFO: [Eval][Epoch 210][Iter: 10/16]CELoss: 0.88703, loss: 0.88703, top1: 0.82102, batch_cost: 0.58314s, reader_cost: 0.00018, ips: 109.75105 images/sec
[2022/06/19 03:50:26] ppcls INFO: [Eval][Epoch 210][Avg]CELoss: 0.79518, loss: 0.79518, top1: 0.82757
[2022/06/19 03:50:26] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 03:50:26] ppcls INFO: [Eval][Epoch 210][best metric: 0.8275735974311829]
[2022/06/19 03:50:26] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_210
[2022/06/19 03:50:26] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:50:33] ppcls INFO: [Train][Epoch 211/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01854521, top1: 0.89062, CELoss: 0.21060, loss: 0.21060, batch_cost: 0.62707s, reader_cost: 0.05386, ips: 102.06153 samples/s, eta: 2:40:50
[2022/06/19 03:50:39] ppcls INFO: [Train][Epoch 211/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01852292, top1: 0.95170, CELoss: 0.14594, loss: 0.14594, batch_cost: 0.60309s, reader_cost: 0.00346, ips: 106.12101 samples/s, eta: 2:34:35
[2022/06/19 03:50:46] ppcls INFO: [Train][Epoch 211/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01850064, top1: 0.95312, CELoss: 0.14281, loss: 0.14281, batch_cost: 0.65035s, reader_cost: 0.01400, ips: 98.40855 samples/s, eta: 2:46:35
[2022/06/19 03:50:52] ppcls INFO: [Train][Epoch 211/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01847837, top1: 0.95262, CELoss: 0.14259, loss: 0.14259, batch_cost: 0.62814s, reader_cost: 0.03382, ips: 101.88812 samples/s, eta: 2:40:48
[2022/06/19 03:50:58] ppcls INFO: [Train][Epoch 211/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01845611, top1: 0.95770, CELoss: 0.13349, loss: 0.13349, batch_cost: 0.62861s, reader_cost: 0.03969, ips: 101.81220 samples/s, eta: 2:40:49
[2022/06/19 03:51:05] ppcls INFO: [Train][Epoch 211/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01843387, top1: 0.95558, CELoss: 0.13608, loss: 0.13608, batch_cost: 0.63365s, reader_cost: 0.04560, ips: 101.00142 samples/s, eta: 2:42:00
[2022/06/19 03:51:11] ppcls INFO: [Train][Epoch 211/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01841163, top1: 0.95671, CELoss: 0.13094, loss: 0.13094, batch_cost: 0.63352s, reader_cost: 0.05837, ips: 101.02364 samples/s, eta: 2:41:51
[2022/06/19 03:51:17] ppcls INFO: [Train][Epoch 211/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01838940, top1: 0.95621, CELoss: 0.13176, loss: 0.13176, batch_cost: 0.62324s, reader_cost: 0.06286, ips: 102.68902 samples/s, eta: 2:39:08
[2022/06/19 03:51:22] ppcls INFO: [Train][Epoch 211/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01836718, top1: 0.95814, CELoss: 0.12768, loss: 0.12768, batch_cost: 0.61250s, reader_cost: 0.05657, ips: 104.48907 samples/s, eta: 2:36:17
[2022/06/19 03:51:30] ppcls INFO: [Train][Epoch 211/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01834497, top1: 0.95862, CELoss: 0.12843, loss: 0.12843, batch_cost: 0.63079s, reader_cost: 0.07948, ips: 101.45992 samples/s, eta: 2:40:51
[2022/06/19 03:51:36] ppcls INFO: [Train][Epoch 211/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01832277, top1: 0.95916, CELoss: 0.12902, loss: 0.12902, batch_cost: 0.62461s, reader_cost: 0.07788, ips: 102.46412 samples/s, eta: 2:39:10
[2022/06/19 03:51:42] ppcls INFO: [Train][Epoch 211/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01830059, top1: 0.95876, CELoss: 0.12978, loss: 0.12978, batch_cost: 0.62101s, reader_cost: 0.07649, ips: 103.05766 samples/s, eta: 2:38:09
[2022/06/19 03:51:49] ppcls INFO: [Train][Epoch 211/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01827841, top1: 0.95829, CELoss: 0.12945, loss: 0.12945, batch_cost: 0.63382s, reader_cost: 0.09223, ips: 100.97469 samples/s, eta: 2:41:18
[2022/06/19 03:51:54] ppcls INFO: [Train][Epoch 211/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01825624, top1: 0.95897, CELoss: 0.12750, loss: 0.12750, batch_cost: 0.62334s, reader_cost: 0.08546, ips: 102.67309 samples/s, eta: 2:38:32
[2022/06/19 03:52:01] ppcls INFO: [Train][Epoch 211/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01823408, top1: 0.95822, CELoss: 0.12812, loss: 0.12812, batch_cost: 0.62743s, reader_cost: 0.09457, ips: 102.00325 samples/s, eta: 2:39:28
[2022/06/19 03:52:07] ppcls INFO: [Train][Epoch 211/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01821193, top1: 0.95830, CELoss: 0.12697, loss: 0.12697, batch_cost: 0.62284s, reader_cost: 0.09235, ips: 102.75491 samples/s, eta: 2:38:12
[2022/06/19 03:52:12] ppcls INFO: [Train][Epoch 211/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01818980, top1: 0.95817, CELoss: 0.12673, loss: 0.12673, batch_cost: 0.61795s, reader_cost: 0.09172, ips: 103.56796 samples/s, eta: 2:36:51
[2022/06/19 03:52:14] ppcls INFO: [Train][Epoch 211/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01816767, top1: 0.95745, CELoss: 0.12846, loss: 0.12846, batch_cost: 0.59341s, reader_cost: 0.08620, ips: 82.57322 samples/s, eta: 2:30:31
[2022/06/19 03:52:15] ppcls INFO: [Train][Epoch 211/300][Avg]top1: 0.95745, CELoss: 0.12846, loss: 0.12846
[2022/06/19 03:52:15] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:52:22] ppcls INFO: [Train][Epoch 212/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01816546, top1: 0.96875, CELoss: 0.09327, loss: 0.09327, batch_cost: 0.63237s, reader_cost: 0.11692, ips: 101.20594 samples/s, eta: 2:40:24
[2022/06/19 03:52:28] ppcls INFO: [Train][Epoch 212/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01814334, top1: 0.96449, CELoss: 0.12903, loss: 0.12903, batch_cost: 0.54751s, reader_cost: 0.00889, ips: 116.89198 samples/s, eta: 2:18:47
[2022/06/19 03:52:35] ppcls INFO: [Train][Epoch 212/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01812123, top1: 0.95387, CELoss: 0.14791, loss: 0.14791, batch_cost: 0.61753s, reader_cost: 0.01350, ips: 103.63934 samples/s, eta: 2:36:25
[2022/06/19 03:52:41] ppcls INFO: [Train][Epoch 212/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01809914, top1: 0.94960, CELoss: 0.15391, loss: 0.15391, batch_cost: 0.61995s, reader_cost: 0.01378, ips: 103.23488 samples/s, eta: 2:36:56
[2022/06/19 03:52:47] ppcls INFO: [Train][Epoch 212/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01807705, top1: 0.95084, CELoss: 0.14913, loss: 0.14913, batch_cost: 0.61348s, reader_cost: 0.01523, ips: 104.32213 samples/s, eta: 2:35:12
[2022/06/19 03:52:53] ppcls INFO: [Train][Epoch 212/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01805497, top1: 0.95129, CELoss: 0.14900, loss: 0.14900, batch_cost: 0.61019s, reader_cost: 0.01672, ips: 104.88507 samples/s, eta: 2:34:15
[2022/06/19 03:53:00] ppcls INFO: [Train][Epoch 212/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01803291, top1: 0.95184, CELoss: 0.14615, loss: 0.14615, batch_cost: 0.61620s, reader_cost: 0.01743, ips: 103.86277 samples/s, eta: 2:35:40
[2022/06/19 03:53:06] ppcls INFO: [Train][Epoch 212/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01801085, top1: 0.95379, CELoss: 0.14139, loss: 0.14139, batch_cost: 0.62082s, reader_cost: 0.01751, ips: 103.08953 samples/s, eta: 2:36:44
[2022/06/19 03:53:13] ppcls INFO: [Train][Epoch 212/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01798880, top1: 0.95428, CELoss: 0.14043, loss: 0.14043, batch_cost: 0.63167s, reader_cost: 0.01654, ips: 101.31820 samples/s, eta: 2:39:22
[2022/06/19 03:53:19] ppcls INFO: [Train][Epoch 212/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01796677, top1: 0.95570, CELoss: 0.13855, loss: 0.13855, batch_cost: 0.62181s, reader_cost: 0.01616, ips: 102.92568 samples/s, eta: 2:36:47
[2022/06/19 03:53:24] ppcls INFO: [Train][Epoch 212/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01794474, top1: 0.95483, CELoss: 0.14054, loss: 0.14054, batch_cost: 0.61465s, reader_cost: 0.01516, ips: 104.12481 samples/s, eta: 2:34:52
[2022/06/19 03:53:30] ppcls INFO: [Train][Epoch 212/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01792273, top1: 0.95566, CELoss: 0.13787, loss: 0.13787, batch_cost: 0.61499s, reader_cost: 0.01561, ips: 104.06675 samples/s, eta: 2:34:51
[2022/06/19 03:53:36] ppcls INFO: [Train][Epoch 212/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01790072, top1: 0.95661, CELoss: 0.13541, loss: 0.13541, batch_cost: 0.61098s, reader_cost: 0.01526, ips: 104.74894 samples/s, eta: 2:33:45
[2022/06/19 03:53:43] ppcls INFO: [Train][Epoch 212/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01787872, top1: 0.95611, CELoss: 0.13590, loss: 0.13590, batch_cost: 0.61638s, reader_cost: 0.01597, ips: 103.83248 samples/s, eta: 2:35:00
[2022/06/19 03:53:48] ppcls INFO: [Train][Epoch 212/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01785674, top1: 0.95656, CELoss: 0.13546, loss: 0.13546, batch_cost: 0.61100s, reader_cost: 0.01522, ips: 104.74686 samples/s, eta: 2:33:33
[2022/06/19 03:53:56] ppcls INFO: [Train][Epoch 212/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01783476, top1: 0.95644, CELoss: 0.13598, loss: 0.13598, batch_cost: 0.62060s, reader_cost: 0.01541, ips: 103.12543 samples/s, eta: 2:35:51
[2022/06/19 03:54:00] ppcls INFO: [Train][Epoch 212/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01781280, top1: 0.95604, CELoss: 0.13687, loss: 0.13687, batch_cost: 0.60626s, reader_cost: 0.01517, ips: 105.56537 samples/s, eta: 2:32:09
[2022/06/19 03:54:02] ppcls INFO: [Train][Epoch 212/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01779084, top1: 0.95544, CELoss: 0.13841, loss: 0.13841, batch_cost: 0.58239s, reader_cost: 0.01426, ips: 84.13634 samples/s, eta: 2:26:04
[2022/06/19 03:54:02] ppcls INFO: [Train][Epoch 212/300][Avg]top1: 0.95544, CELoss: 0.13841, loss: 0.13841
[2022/06/19 03:54:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:54:09] ppcls INFO: [Train][Epoch 213/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01778865, top1: 0.95312, CELoss: 0.16638, loss: 0.16638, batch_cost: 0.61723s, reader_cost: 0.04841, ips: 103.68984 samples/s, eta: 2:34:48
[2022/06/19 03:54:15] ppcls INFO: [Train][Epoch 213/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01776671, top1: 0.96023, CELoss: 0.13183, loss: 0.13183, batch_cost: 0.58338s, reader_cost: 0.01841, ips: 109.70562 samples/s, eta: 2:26:12
[2022/06/19 03:54:22] ppcls INFO: [Train][Epoch 213/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01774477, top1: 0.95610, CELoss: 0.12677, loss: 0.12677, batch_cost: 0.61287s, reader_cost: 0.03090, ips: 104.42753 samples/s, eta: 2:33:30
[2022/06/19 03:54:28] ppcls INFO: [Train][Epoch 213/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01772285, top1: 0.95413, CELoss: 0.13629, loss: 0.13629, batch_cost: 0.60441s, reader_cost: 0.02467, ips: 105.88819 samples/s, eta: 2:31:17
[2022/06/19 03:54:34] ppcls INFO: [Train][Epoch 213/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01770094, top1: 0.95617, CELoss: 0.13190, loss: 0.13190, batch_cost: 0.62577s, reader_cost: 0.01969, ips: 102.27444 samples/s, eta: 2:36:31
[2022/06/19 03:54:40] ppcls INFO: [Train][Epoch 213/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01767903, top1: 0.95466, CELoss: 0.13320, loss: 0.13320, batch_cost: 0.60751s, reader_cost: 0.01789, ips: 105.34817 samples/s, eta: 2:31:51
[2022/06/19 03:54:47] ppcls INFO: [Train][Epoch 213/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01765714, top1: 0.95364, CELoss: 0.13584, loss: 0.13584, batch_cost: 0.62349s, reader_cost: 0.03976, ips: 102.64733 samples/s, eta: 2:35:44
[2022/06/19 03:54:52] ppcls INFO: [Train][Epoch 213/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01763526, top1: 0.95180, CELoss: 0.14047, loss: 0.14047, batch_cost: 0.61543s, reader_cost: 0.03563, ips: 103.99273 samples/s, eta: 2:33:37
[2022/06/19 03:54:59] ppcls INFO: [Train][Epoch 213/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01761339, top1: 0.95042, CELoss: 0.14297, loss: 0.14297, batch_cost: 0.61465s, reader_cost: 0.03205, ips: 104.12373 samples/s, eta: 2:33:20
[2022/06/19 03:55:05] ppcls INFO: [Train][Epoch 213/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01759153, top1: 0.95244, CELoss: 0.13834, loss: 0.13834, batch_cost: 0.61760s, reader_cost: 0.03055, ips: 103.62644 samples/s, eta: 2:33:58
[2022/06/19 03:55:12] ppcls INFO: [Train][Epoch 213/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01756968, top1: 0.95158, CELoss: 0.13889, loss: 0.13889, batch_cost: 0.62717s, reader_cost: 0.02939, ips: 102.04525 samples/s, eta: 2:36:14
[2022/06/19 03:55:17] ppcls INFO: [Train][Epoch 213/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01754783, top1: 0.95228, CELoss: 0.13757, loss: 0.13757, batch_cost: 0.61431s, reader_cost: 0.02751, ips: 104.18192 samples/s, eta: 2:32:56
[2022/06/19 03:55:22] ppcls INFO: [Train][Epoch 213/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01752600, top1: 0.95235, CELoss: 0.13510, loss: 0.13510, batch_cost: 0.60881s, reader_cost: 0.02698, ips: 105.12346 samples/s, eta: 2:31:28
[2022/06/19 03:55:29] ppcls INFO: [Train][Epoch 213/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01750418, top1: 0.95348, CELoss: 0.13324, loss: 0.13324, batch_cost: 0.61115s, reader_cost: 0.02552, ips: 104.72089 samples/s, eta: 2:31:57
[2022/06/19 03:55:35] ppcls INFO: [Train][Epoch 213/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01748237, top1: 0.95434, CELoss: 0.13057, loss: 0.13057, batch_cost: 0.61254s, reader_cost: 0.02483, ips: 104.48374 samples/s, eta: 2:32:11
[2022/06/19 03:55:42] ppcls INFO: [Train][Epoch 213/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01746057, top1: 0.95457, CELoss: 0.13034, loss: 0.13034, batch_cost: 0.61796s, reader_cost: 0.02343, ips: 103.56740 samples/s, eta: 2:33:26
[2022/06/19 03:55:46] ppcls INFO: [Train][Epoch 213/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01743878, top1: 0.95507, CELoss: 0.12947, loss: 0.12947, batch_cost: 0.60579s, reader_cost: 0.02313, ips: 105.64786 samples/s, eta: 2:30:18
[2022/06/19 03:55:48] ppcls INFO: [Train][Epoch 213/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01741701, top1: 0.95517, CELoss: 0.13035, loss: 0.13035, batch_cost: 0.58193s, reader_cost: 0.02176, ips: 84.20296 samples/s, eta: 2:24:17
[2022/06/19 03:55:49] ppcls INFO: [Train][Epoch 213/300][Avg]top1: 0.95517, CELoss: 0.13035, loss: 0.13035
[2022/06/19 03:55:49] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:55:56] ppcls INFO: [Train][Epoch 214/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01741483, top1: 0.92188, CELoss: 0.17401, loss: 0.17401, batch_cost: 0.61672s, reader_cost: 0.05518, ips: 103.77527 samples/s, eta: 2:32:54
[2022/06/19 03:56:03] ppcls INFO: [Train][Epoch 214/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01739306, top1: 0.94744, CELoss: 0.13089, loss: 0.13089, batch_cost: 0.76657s, reader_cost: 0.07138, ips: 83.48825 samples/s, eta: 3:09:56
[2022/06/19 03:56:09] ppcls INFO: [Train][Epoch 214/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01737130, top1: 0.95238, CELoss: 0.12531, loss: 0.12531, batch_cost: 0.67533s, reader_cost: 0.03834, ips: 94.76861 samples/s, eta: 2:47:13
[2022/06/19 03:56:15] ppcls INFO: [Train][Epoch 214/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01734956, top1: 0.95917, CELoss: 0.12133, loss: 0.12133, batch_cost: 0.63806s, reader_cost: 0.02550, ips: 100.30466 samples/s, eta: 2:37:53
[2022/06/19 03:56:21] ppcls INFO: [Train][Epoch 214/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01732782, top1: 0.95960, CELoss: 0.11893, loss: 0.11893, batch_cost: 0.61950s, reader_cost: 0.02143, ips: 103.30985 samples/s, eta: 2:33:11
[2022/06/19 03:56:28] ppcls INFO: [Train][Epoch 214/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01730609, top1: 0.95925, CELoss: 0.12129, loss: 0.12129, batch_cost: 0.63678s, reader_cost: 0.05097, ips: 100.50636 samples/s, eta: 2:37:21
[2022/06/19 03:56:33] ppcls INFO: [Train][Epoch 214/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01728438, top1: 0.95850, CELoss: 0.12303, loss: 0.12303, batch_cost: 0.61463s, reader_cost: 0.04505, ips: 104.12728 samples/s, eta: 2:31:47
[2022/06/19 03:56:39] ppcls INFO: [Train][Epoch 214/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01726267, top1: 0.95885, CELoss: 0.12467, loss: 0.12467, batch_cost: 0.61818s, reader_cost: 0.04044, ips: 103.52950 samples/s, eta: 2:32:33
[2022/06/19 03:56:45] ppcls INFO: [Train][Epoch 214/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01724098, top1: 0.95698, CELoss: 0.12629, loss: 0.12629, batch_cost: 0.61457s, reader_cost: 0.03702, ips: 104.13728 samples/s, eta: 2:31:33
[2022/06/19 03:56:52] ppcls INFO: [Train][Epoch 214/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01721929, top1: 0.95707, CELoss: 0.12763, loss: 0.12763, batch_cost: 0.61522s, reader_cost: 0.03509, ips: 104.02725 samples/s, eta: 2:31:37
[2022/06/19 03:56:58] ppcls INFO: [Train][Epoch 214/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01719762, top1: 0.95792, CELoss: 0.12465, loss: 0.12465, batch_cost: 0.61657s, reader_cost: 0.03573, ips: 103.79980 samples/s, eta: 2:31:51
[2022/06/19 03:57:04] ppcls INFO: [Train][Epoch 214/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01717595, top1: 0.95819, CELoss: 0.12258, loss: 0.12258, batch_cost: 0.61894s, reader_cost: 0.04216, ips: 103.40274 samples/s, eta: 2:32:19
[2022/06/19 03:57:11] ppcls INFO: [Train][Epoch 214/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01715430, top1: 0.95726, CELoss: 0.12576, loss: 0.12576, batch_cost: 0.62155s, reader_cost: 0.04847, ips: 102.96767 samples/s, eta: 2:32:52
[2022/06/19 03:57:16] ppcls INFO: [Train][Epoch 214/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01713266, top1: 0.95754, CELoss: 0.12498, loss: 0.12498, batch_cost: 0.61585s, reader_cost: 0.04556, ips: 103.92215 samples/s, eta: 2:31:21
[2022/06/19 03:57:22] ppcls INFO: [Train][Epoch 214/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01711103, top1: 0.95723, CELoss: 0.12521, loss: 0.12521, batch_cost: 0.61460s, reader_cost: 0.04961, ips: 104.13252 samples/s, eta: 2:30:57
[2022/06/19 03:57:29] ppcls INFO: [Train][Epoch 214/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01708940, top1: 0.95799, CELoss: 0.12381, loss: 0.12381, batch_cost: 0.61514s, reader_cost: 0.05651, ips: 104.04188 samples/s, eta: 2:30:59
[2022/06/19 03:57:34] ppcls INFO: [Train][Epoch 214/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01706779, top1: 0.95807, CELoss: 0.12299, loss: 0.12299, batch_cost: 0.61230s, reader_cost: 0.05706, ips: 104.52419 samples/s, eta: 2:30:11
[2022/06/19 03:57:36] ppcls INFO: [Train][Epoch 214/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01704619, top1: 0.95754, CELoss: 0.12402, loss: 0.12402, batch_cost: 0.58799s, reader_cost: 0.05364, ips: 83.33457 samples/s, eta: 2:24:07
[2022/06/19 03:57:37] ppcls INFO: [Train][Epoch 214/300][Avg]top1: 0.95754, CELoss: 0.12402, loss: 0.12402
[2022/06/19 03:57:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:57:44] ppcls INFO: [Train][Epoch 215/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01704403, top1: 0.98438, CELoss: 0.04790, loss: 0.04790, batch_cost: 0.62356s, reader_cost: 0.08460, ips: 102.63687 samples/s, eta: 2:32:50
[2022/06/19 03:57:51] ppcls INFO: [Train][Epoch 215/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01702244, top1: 0.95597, CELoss: 0.15297, loss: 0.15297, batch_cost: 0.73307s, reader_cost: 0.02887, ips: 87.30408 samples/s, eta: 2:59:33
[2022/06/19 03:57:57] ppcls INFO: [Train][Epoch 215/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01700086, top1: 0.95685, CELoss: 0.13612, loss: 0.13612, batch_cost: 0.65685s, reader_cost: 0.01916, ips: 97.43490 samples/s, eta: 2:40:46
[2022/06/19 03:58:03] ppcls INFO: [Train][Epoch 215/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01697929, top1: 0.95968, CELoss: 0.12995, loss: 0.12995, batch_cost: 0.63959s, reader_cost: 0.01410, ips: 100.06438 samples/s, eta: 2:36:26
[2022/06/19 03:58:09] ppcls INFO: [Train][Epoch 215/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01695774, top1: 0.96037, CELoss: 0.12723, loss: 0.12723, batch_cost: 0.63409s, reader_cost: 0.01276, ips: 100.93214 samples/s, eta: 2:34:59
[2022/06/19 03:58:16] ppcls INFO: [Train][Epoch 215/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01693619, top1: 0.96262, CELoss: 0.12043, loss: 0.12043, batch_cost: 0.63737s, reader_cost: 0.01180, ips: 100.41324 samples/s, eta: 2:35:41
[2022/06/19 03:58:21] ppcls INFO: [Train][Epoch 215/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01691465, top1: 0.96491, CELoss: 0.11519, loss: 0.11519, batch_cost: 0.62700s, reader_cost: 0.01086, ips: 102.07355 samples/s, eta: 2:33:03
[2022/06/19 03:58:27] ppcls INFO: [Train][Epoch 215/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01689312, top1: 0.96501, CELoss: 0.11534, loss: 0.11534, batch_cost: 0.61523s, reader_cost: 0.01300, ips: 104.02622 samples/s, eta: 2:30:04
[2022/06/19 03:58:34] ppcls INFO: [Train][Epoch 215/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01687161, top1: 0.96412, CELoss: 0.11728, loss: 0.11728, batch_cost: 0.62491s, reader_cost: 0.01300, ips: 102.41477 samples/s, eta: 2:32:19
[2022/06/19 03:58:40] ppcls INFO: [Train][Epoch 215/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01685010, top1: 0.96205, CELoss: 0.12230, loss: 0.12230, batch_cost: 0.62586s, reader_cost: 0.01318, ips: 102.25959 samples/s, eta: 2:32:27
[2022/06/19 03:58:47] ppcls INFO: [Train][Epoch 215/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01682861, top1: 0.96194, CELoss: 0.12119, loss: 0.12119, batch_cost: 0.62919s, reader_cost: 0.01421, ips: 101.71827 samples/s, eta: 2:33:09
[2022/06/19 03:58:52] ppcls INFO: [Train][Epoch 215/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01680712, top1: 0.96171, CELoss: 0.12128, loss: 0.12128, batch_cost: 0.61794s, reader_cost: 0.01350, ips: 103.56961 samples/s, eta: 2:30:19
[2022/06/19 03:58:57] ppcls INFO: [Train][Epoch 215/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01678565, top1: 0.96139, CELoss: 0.12214, loss: 0.12214, batch_cost: 0.61285s, reader_cost: 0.01376, ips: 104.42962 samples/s, eta: 2:28:59
[2022/06/19 03:59:03] ppcls INFO: [Train][Epoch 215/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01676419, top1: 0.96112, CELoss: 0.12251, loss: 0.12251, batch_cost: 0.61026s, reader_cost: 0.01373, ips: 104.87318 samples/s, eta: 2:28:15
[2022/06/19 03:59:10] ppcls INFO: [Train][Epoch 215/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01674273, top1: 0.96055, CELoss: 0.12448, loss: 0.12448, batch_cost: 0.61617s, reader_cost: 0.01358, ips: 103.86800 samples/s, eta: 2:29:35
[2022/06/19 03:59:17] ppcls INFO: [Train][Epoch 215/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01672129, top1: 0.96140, CELoss: 0.12282, loss: 0.12282, batch_cost: 0.62060s, reader_cost: 0.01357, ips: 103.12547 samples/s, eta: 2:30:33
[2022/06/19 03:59:21] ppcls INFO: [Train][Epoch 215/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01669986, top1: 0.96079, CELoss: 0.12352, loss: 0.12352, batch_cost: 0.60750s, reader_cost: 0.01332, ips: 105.34962 samples/s, eta: 2:27:16
[2022/06/19 03:59:23] ppcls INFO: [Train][Epoch 215/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01667844, top1: 0.96093, CELoss: 0.12206, loss: 0.12206, batch_cost: 0.58364s, reader_cost: 0.01255, ips: 83.95563 samples/s, eta: 2:21:23
[2022/06/19 03:59:24] ppcls INFO: [Train][Epoch 215/300][Avg]top1: 0.96093, CELoss: 0.12206, loss: 0.12206
[2022/06/19 03:59:31] ppcls INFO: [Eval][Epoch 215][Iter: 0/16]CELoss: 1.10117, loss: 1.10117, top1: 0.79883, batch_cost: 7.11968s, reader_cost: 3.19082, ips: 8.98917 images/sec
[2022/06/19 03:59:39] ppcls INFO: [Eval][Epoch 215][Iter: 10/16]CELoss: 0.94943, loss: 0.94943, top1: 0.81552, batch_cost: 0.56165s, reader_cost: 0.00089, ips: 113.94955 images/sec
[2022/06/19 03:59:40] ppcls INFO: [Eval][Epoch 215][Avg]CELoss: 0.79184, loss: 0.79184, top1: 0.82426
[2022/06/19 03:59:40] ppcls INFO: [Eval][Epoch 215][best metric: 0.8275735974311829]
[2022/06/19 03:59:41] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 03:59:47] ppcls INFO: [Train][Epoch 216/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01667630, top1: 0.92188, CELoss: 0.20559, loss: 0.20559, batch_cost: 0.61871s, reader_cost: 0.03900, ips: 103.44113 samples/s, eta: 2:29:52
[2022/06/19 03:59:53] ppcls INFO: [Train][Epoch 216/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01665489, top1: 0.95312, CELoss: 0.14248, loss: 0.14248, batch_cost: 0.58544s, reader_cost: 0.01492, ips: 109.31885 samples/s, eta: 2:21:43
[2022/06/19 03:59:59] ppcls INFO: [Train][Epoch 216/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01663349, top1: 0.95164, CELoss: 0.13316, loss: 0.13316, batch_cost: 0.60055s, reader_cost: 0.00581, ips: 106.56868 samples/s, eta: 2:25:17
[2022/06/19 04:00:05] ppcls INFO: [Train][Epoch 216/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01661210, top1: 0.95312, CELoss: 0.12777, loss: 0.12777, batch_cost: 0.59240s, reader_cost: 0.00722, ips: 108.03454 samples/s, eta: 2:23:12
[2022/06/19 04:00:11] ppcls INFO: [Train][Epoch 216/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01659073, top1: 0.95465, CELoss: 0.12813, loss: 0.12813, batch_cost: 0.60556s, reader_cost: 0.00883, ips: 105.68709 samples/s, eta: 2:26:17
[2022/06/19 04:00:17] ppcls INFO: [Train][Epoch 216/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01656936, top1: 0.95527, CELoss: 0.12849, loss: 0.12849, batch_cost: 0.60688s, reader_cost: 0.00878, ips: 105.45763 samples/s, eta: 2:26:30
[2022/06/19 04:00:23] ppcls INFO: [Train][Epoch 216/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01654800, top1: 0.95389, CELoss: 0.13329, loss: 0.13329, batch_cost: 0.60058s, reader_cost: 0.00946, ips: 106.56386 samples/s, eta: 2:24:53
[2022/06/19 04:00:29] ppcls INFO: [Train][Epoch 216/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01652666, top1: 0.95489, CELoss: 0.12935, loss: 0.12935, batch_cost: 0.59156s, reader_cost: 0.01183, ips: 108.18861 samples/s, eta: 2:22:36
[2022/06/19 04:00:35] ppcls INFO: [Train][Epoch 216/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01650533, top1: 0.95544, CELoss: 0.12823, loss: 0.12823, batch_cost: 0.59670s, reader_cost: 0.01282, ips: 107.25741 samples/s, eta: 2:23:45
[2022/06/19 04:00:41] ppcls INFO: [Train][Epoch 216/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01648400, top1: 0.95587, CELoss: 0.12605, loss: 0.12605, batch_cost: 0.59788s, reader_cost: 0.01322, ips: 107.04493 samples/s, eta: 2:23:56
[2022/06/19 04:00:47] ppcls INFO: [Train][Epoch 216/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01646269, top1: 0.95746, CELoss: 0.12356, loss: 0.12356, batch_cost: 0.59932s, reader_cost: 0.01235, ips: 106.78738 samples/s, eta: 2:24:11
[2022/06/19 04:00:54] ppcls INFO: [Train][Epoch 216/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01644139, top1: 0.95833, CELoss: 0.12219, loss: 0.12219, batch_cost: 0.60233s, reader_cost: 0.01213, ips: 106.25381 samples/s, eta: 2:24:48
[2022/06/19 04:00:59] ppcls INFO: [Train][Epoch 216/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01642009, top1: 0.95790, CELoss: 0.12347, loss: 0.12347, batch_cost: 0.59766s, reader_cost: 0.01275, ips: 107.08493 samples/s, eta: 2:23:35
[2022/06/19 04:01:06] ppcls INFO: [Train][Epoch 216/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01639881, top1: 0.95849, CELoss: 0.12184, loss: 0.12184, batch_cost: 0.60493s, reader_cost: 0.01235, ips: 105.79696 samples/s, eta: 2:25:14
[2022/06/19 04:01:11] ppcls INFO: [Train][Epoch 216/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01637754, top1: 0.95855, CELoss: 0.12155, loss: 0.12155, batch_cost: 0.59676s, reader_cost: 0.01184, ips: 107.24523 samples/s, eta: 2:23:10
[2022/06/19 04:01:17] ppcls INFO: [Train][Epoch 216/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01635628, top1: 0.95902, CELoss: 0.12031, loss: 0.12031, batch_cost: 0.59642s, reader_cost: 0.01117, ips: 107.30737 samples/s, eta: 2:22:59
[2022/06/19 04:01:27] ppcls INFO: [Train][Epoch 216/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01633504, top1: 0.95856, CELoss: 0.12137, loss: 0.12137, batch_cost: 0.62270s, reader_cost: 0.01051, ips: 102.77762 samples/s, eta: 2:29:11
[2022/06/19 04:01:31] ppcls INFO: [Train][Epoch 216/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01631380, top1: 0.95873, CELoss: 0.12099, loss: 0.12099, batch_cost: 0.60759s, reader_cost: 0.00991, ips: 80.64676 samples/s, eta: 2:25:28
[2022/06/19 04:01:31] ppcls INFO: [Train][Epoch 216/300][Avg]top1: 0.95873, CELoss: 0.12099, loss: 0.12099
[2022/06/19 04:01:31] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:01:37] ppcls INFO: [Train][Epoch 217/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01631167, top1: 0.90625, CELoss: 0.21554, loss: 0.21554, batch_cost: 0.64022s, reader_cost: 0.04132, ips: 99.96623 samples/s, eta: 2:33:16
[2022/06/19 04:01:44] ppcls INFO: [Train][Epoch 217/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01629045, top1: 0.94886, CELoss: 0.12497, loss: 0.12497, batch_cost: 0.63159s, reader_cost: 0.01436, ips: 101.33139 samples/s, eta: 2:31:05
[2022/06/19 04:01:50] ppcls INFO: [Train][Epoch 217/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01626923, top1: 0.95015, CELoss: 0.13380, loss: 0.13380, batch_cost: 0.63023s, reader_cost: 0.01322, ips: 101.55020 samples/s, eta: 2:30:40
[2022/06/19 04:01:56] ppcls INFO: [Train][Epoch 217/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01624803, top1: 0.95212, CELoss: 0.13096, loss: 0.13096, batch_cost: 0.61763s, reader_cost: 0.01929, ips: 103.62225 samples/s, eta: 2:27:33
[2022/06/19 04:02:02] ppcls INFO: [Train][Epoch 217/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01622683, top1: 0.95427, CELoss: 0.12887, loss: 0.12887, batch_cost: 0.61854s, reader_cost: 0.01953, ips: 103.46950 samples/s, eta: 2:27:39
[2022/06/19 04:02:08] ppcls INFO: [Train][Epoch 217/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01620565, top1: 0.95619, CELoss: 0.12614, loss: 0.12614, batch_cost: 0.61921s, reader_cost: 0.02158, ips: 103.35791 samples/s, eta: 2:27:43
[2022/06/19 04:02:15] ppcls INFO: [Train][Epoch 217/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01618448, top1: 0.95748, CELoss: 0.12633, loss: 0.12633, batch_cost: 0.62278s, reader_cost: 0.03981, ips: 102.76565 samples/s, eta: 2:28:28
[2022/06/19 04:02:21] ppcls INFO: [Train][Epoch 217/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01616332, top1: 0.95907, CELoss: 0.12382, loss: 0.12382, batch_cost: 0.61628s, reader_cost: 0.03461, ips: 103.84931 samples/s, eta: 2:26:49
[2022/06/19 04:02:26] ppcls INFO: [Train][Epoch 217/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01614217, top1: 0.96026, CELoss: 0.11971, loss: 0.11971, batch_cost: 0.60848s, reader_cost: 0.03202, ips: 105.18014 samples/s, eta: 2:24:51
[2022/06/19 04:02:31] ppcls INFO: [Train][Epoch 217/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01612103, top1: 0.95913, CELoss: 0.12229, loss: 0.12229, batch_cost: 0.59942s, reader_cost: 0.02905, ips: 106.76932 samples/s, eta: 2:22:36
[2022/06/19 04:02:38] ppcls INFO: [Train][Epoch 217/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01609990, top1: 0.95854, CELoss: 0.12148, loss: 0.12148, batch_cost: 0.60244s, reader_cost: 0.02741, ips: 106.23520 samples/s, eta: 2:23:13
[2022/06/19 04:02:45] ppcls INFO: [Train][Epoch 217/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01607878, top1: 0.95693, CELoss: 0.12321, loss: 0.12321, batch_cost: 0.61073s, reader_cost: 0.04488, ips: 104.79213 samples/s, eta: 2:25:05
[2022/06/19 04:02:51] ppcls INFO: [Train][Epoch 217/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01605767, top1: 0.95764, CELoss: 0.12305, loss: 0.12305, batch_cost: 0.61147s, reader_cost: 0.04793, ips: 104.66663 samples/s, eta: 2:25:09
[2022/06/19 04:02:56] ppcls INFO: [Train][Epoch 217/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01603658, top1: 0.95766, CELoss: 0.12327, loss: 0.12327, batch_cost: 0.60663s, reader_cost: 0.04587, ips: 105.50049 samples/s, eta: 2:23:54
[2022/06/19 04:03:03] ppcls INFO: [Train][Epoch 217/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01601549, top1: 0.95789, CELoss: 0.12325, loss: 0.12325, batch_cost: 0.61000s, reader_cost: 0.05552, ips: 104.91825 samples/s, eta: 2:24:36
[2022/06/19 04:03:08] ppcls INFO: [Train][Epoch 217/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01599442, top1: 0.95747, CELoss: 0.12388, loss: 0.12388, batch_cost: 0.60497s, reader_cost: 0.05207, ips: 105.79035 samples/s, eta: 2:23:19
[2022/06/19 04:03:13] ppcls INFO: [Train][Epoch 217/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01597335, top1: 0.95652, CELoss: 0.12637, loss: 0.12637, batch_cost: 0.60022s, reader_cost: 0.05803, ips: 106.62669 samples/s, eta: 2:22:05
[2022/06/19 04:03:16] ppcls INFO: [Train][Epoch 217/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01595230, top1: 0.95681, CELoss: 0.12694, loss: 0.12694, batch_cost: 0.57679s, reader_cost: 0.05458, ips: 84.95238 samples/s, eta: 2:16:27
[2022/06/19 04:03:16] ppcls INFO: [Train][Epoch 217/300][Avg]top1: 0.95681, CELoss: 0.12694, loss: 0.12694
[2022/06/19 04:03:16] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:03:25] ppcls INFO: [Train][Epoch 218/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01595019, top1: 0.96875, CELoss: 0.12099, loss: 0.12099, batch_cost: 0.62301s, reader_cost: 0.07884, ips: 102.72730 samples/s, eta: 2:27:22
[2022/06/19 04:03:30] ppcls INFO: [Train][Epoch 218/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01592915, top1: 0.95028, CELoss: 0.15578, loss: 0.15578, batch_cost: 0.56897s, reader_cost: 0.01596, ips: 112.48464 samples/s, eta: 2:14:29
[2022/06/19 04:03:36] ppcls INFO: [Train][Epoch 218/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01590812, top1: 0.95015, CELoss: 0.15997, loss: 0.15997, batch_cost: 0.58078s, reader_cost: 0.01009, ips: 110.19617 samples/s, eta: 2:17:11
[2022/06/19 04:03:42] ppcls INFO: [Train][Epoch 218/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01588710, top1: 0.95464, CELoss: 0.14508, loss: 0.14508, batch_cost: 0.58847s, reader_cost: 0.00782, ips: 108.75644 samples/s, eta: 2:18:54
[2022/06/19 04:03:48] ppcls INFO: [Train][Epoch 218/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01586610, top1: 0.95655, CELoss: 0.14068, loss: 0.14068, batch_cost: 0.59777s, reader_cost: 0.00979, ips: 107.06409 samples/s, eta: 2:21:00
[2022/06/19 04:03:55] ppcls INFO: [Train][Epoch 218/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01584510, top1: 0.95833, CELoss: 0.13524, loss: 0.13524, batch_cost: 0.62164s, reader_cost: 0.01135, ips: 102.95350 samples/s, eta: 2:26:31
[2022/06/19 04:04:01] ppcls INFO: [Train][Epoch 218/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01582411, top1: 0.95850, CELoss: 0.13217, loss: 0.13217, batch_cost: 0.60923s, reader_cost: 0.01353, ips: 105.05143 samples/s, eta: 2:23:30
[2022/06/19 04:04:07] ppcls INFO: [Train][Epoch 218/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01580314, top1: 0.95863, CELoss: 0.12984, loss: 0.12984, batch_cost: 0.61538s, reader_cost: 0.01531, ips: 104.00068 samples/s, eta: 2:24:51
[2022/06/19 04:04:13] ppcls INFO: [Train][Epoch 218/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01578217, top1: 0.95795, CELoss: 0.13280, loss: 0.13280, batch_cost: 0.61044s, reader_cost: 0.01491, ips: 104.84187 samples/s, eta: 2:23:35
[2022/06/19 04:04:19] ppcls INFO: [Train][Epoch 218/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01576122, top1: 0.95913, CELoss: 0.12834, loss: 0.12834, batch_cost: 0.60907s, reader_cost: 0.01456, ips: 105.07885 samples/s, eta: 2:23:09
[2022/06/19 04:04:25] ppcls INFO: [Train][Epoch 218/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01574028, top1: 0.95761, CELoss: 0.12995, loss: 0.12995, batch_cost: 0.60827s, reader_cost: 0.01431, ips: 105.21661 samples/s, eta: 2:22:52
[2022/06/19 04:04:31] ppcls INFO: [Train][Epoch 218/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01571935, top1: 0.95819, CELoss: 0.12847, loss: 0.12847, batch_cost: 0.61196s, reader_cost: 0.01482, ips: 104.58236 samples/s, eta: 2:23:38
[2022/06/19 04:04:37] ppcls INFO: [Train][Epoch 218/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01569842, top1: 0.95816, CELoss: 0.12834, loss: 0.12834, batch_cost: 0.60779s, reader_cost: 0.01478, ips: 105.29906 samples/s, eta: 2:22:33
[2022/06/19 04:04:44] ppcls INFO: [Train][Epoch 218/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01567752, top1: 0.95742, CELoss: 0.12805, loss: 0.12805, batch_cost: 0.61721s, reader_cost: 0.01451, ips: 103.69242 samples/s, eta: 2:24:39
[2022/06/19 04:04:49] ppcls INFO: [Train][Epoch 218/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01565662, top1: 0.95767, CELoss: 0.12614, loss: 0.12614, batch_cost: 0.60661s, reader_cost: 0.01415, ips: 105.50357 samples/s, eta: 2:22:04
[2022/06/19 04:04:55] ppcls INFO: [Train][Epoch 218/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01563573, top1: 0.95809, CELoss: 0.12555, loss: 0.12555, batch_cost: 0.60539s, reader_cost: 0.01361, ips: 105.71723 samples/s, eta: 2:21:41
[2022/06/19 04:05:01] ppcls INFO: [Train][Epoch 218/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01561485, top1: 0.95798, CELoss: 0.12591, loss: 0.12591, batch_cost: 0.60325s, reader_cost: 0.01397, ips: 106.09265 samples/s, eta: 2:21:05
[2022/06/19 04:05:03] ppcls INFO: [Train][Epoch 218/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01559399, top1: 0.95837, CELoss: 0.12546, loss: 0.12546, batch_cost: 0.57948s, reader_cost: 0.01314, ips: 84.55791 samples/s, eta: 2:15:26
[2022/06/19 04:05:03] ppcls INFO: [Train][Epoch 218/300][Avg]top1: 0.95837, CELoss: 0.12546, loss: 0.12546
[2022/06/19 04:05:04] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:05:11] ppcls INFO: [Train][Epoch 219/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01559190, top1: 0.96875, CELoss: 0.11142, loss: 0.11142, batch_cost: 0.61786s, reader_cost: 0.04838, ips: 103.58378 samples/s, eta: 2:24:23
[2022/06/19 04:05:17] ppcls INFO: [Train][Epoch 219/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01557105, top1: 0.95312, CELoss: 0.12193, loss: 0.12193, batch_cost: 0.65446s, reader_cost: 0.00861, ips: 97.79053 samples/s, eta: 2:32:50
[2022/06/19 04:05:24] ppcls INFO: [Train][Epoch 219/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01555021, top1: 0.95461, CELoss: 0.12375, loss: 0.12375, batch_cost: 0.66184s, reader_cost: 0.01142, ips: 96.69969 samples/s, eta: 2:34:27
[2022/06/19 04:05:30] ppcls INFO: [Train][Epoch 219/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01552937, top1: 0.95413, CELoss: 0.14302, loss: 0.14302, batch_cost: 0.63085s, reader_cost: 0.01226, ips: 101.44985 samples/s, eta: 2:27:06
[2022/06/19 04:05:36] ppcls INFO: [Train][Epoch 219/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01550855, top1: 0.95655, CELoss: 0.13910, loss: 0.13910, batch_cost: 0.61674s, reader_cost: 0.01070, ips: 103.77072 samples/s, eta: 2:23:43
[2022/06/19 04:05:41] ppcls INFO: [Train][Epoch 219/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01548774, top1: 0.95680, CELoss: 0.13690, loss: 0.13690, batch_cost: 0.60849s, reader_cost: 0.01190, ips: 105.17917 samples/s, eta: 2:21:41
[2022/06/19 04:05:48] ppcls INFO: [Train][Epoch 219/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01546695, top1: 0.95902, CELoss: 0.13455, loss: 0.13455, batch_cost: 0.62481s, reader_cost: 0.01596, ips: 102.43145 samples/s, eta: 2:25:23
[2022/06/19 04:05:55] ppcls INFO: [Train][Epoch 219/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01544616, top1: 0.95753, CELoss: 0.13567, loss: 0.13567, batch_cost: 0.62383s, reader_cost: 0.01459, ips: 102.59222 samples/s, eta: 2:25:03
[2022/06/19 04:06:01] ppcls INFO: [Train][Epoch 219/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01542538, top1: 0.95737, CELoss: 0.13505, loss: 0.13505, batch_cost: 0.61968s, reader_cost: 0.01479, ips: 103.27834 samples/s, eta: 2:23:59
[2022/06/19 04:06:07] ppcls INFO: [Train][Epoch 219/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01540462, top1: 0.95553, CELoss: 0.13700, loss: 0.13700, batch_cost: 0.62400s, reader_cost: 0.01448, ips: 102.56445 samples/s, eta: 2:24:53
[2022/06/19 04:06:14] ppcls INFO: [Train][Epoch 219/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01538386, top1: 0.95498, CELoss: 0.13505, loss: 0.13505, batch_cost: 0.63287s, reader_cost: 0.01501, ips: 101.12591 samples/s, eta: 2:26:50
[2022/06/19 04:06:20] ppcls INFO: [Train][Epoch 219/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01536312, top1: 0.95453, CELoss: 0.13707, loss: 0.13707, batch_cost: 0.62597s, reader_cost: 0.01534, ips: 102.24060 samples/s, eta: 2:25:08
[2022/06/19 04:06:25] ppcls INFO: [Train][Epoch 219/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01534239, top1: 0.95506, CELoss: 0.13487, loss: 0.13487, batch_cost: 0.62046s, reader_cost: 0.01784, ips: 103.14954 samples/s, eta: 2:23:45
[2022/06/19 04:06:33] ppcls INFO: [Train][Epoch 219/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01532167, top1: 0.95563, CELoss: 0.13242, loss: 0.13242, batch_cost: 0.62923s, reader_cost: 0.01815, ips: 101.71202 samples/s, eta: 2:25:41
[2022/06/19 04:06:38] ppcls INFO: [Train][Epoch 219/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01530096, top1: 0.95634, CELoss: 0.13076, loss: 0.13076, batch_cost: 0.62176s, reader_cost: 0.01870, ips: 102.93346 samples/s, eta: 2:23:51
[2022/06/19 04:06:44] ppcls INFO: [Train][Epoch 219/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01528026, top1: 0.95571, CELoss: 0.13114, loss: 0.13114, batch_cost: 0.62042s, reader_cost: 0.01803, ips: 103.15570 samples/s, eta: 2:23:26
[2022/06/19 04:06:49] ppcls INFO: [Train][Epoch 219/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01525958, top1: 0.95662, CELoss: 0.12946, loss: 0.12946, batch_cost: 0.61220s, reader_cost: 0.01749, ips: 104.54130 samples/s, eta: 2:21:26
[2022/06/19 04:06:51] ppcls INFO: [Train][Epoch 219/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01523890, top1: 0.95709, CELoss: 0.12866, loss: 0.12866, batch_cost: 0.58918s, reader_cost: 0.01652, ips: 83.16627 samples/s, eta: 2:16:01
[2022/06/19 04:06:52] ppcls INFO: [Train][Epoch 219/300][Avg]top1: 0.95709, CELoss: 0.12866, loss: 0.12866
[2022/06/19 04:06:52] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:06:58] ppcls INFO: [Train][Epoch 220/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01523683, top1: 0.96875, CELoss: 0.08185, loss: 0.08185, batch_cost: 0.62112s, reader_cost: 0.04535, ips: 103.03967 samples/s, eta: 2:23:23
[2022/06/19 04:07:05] ppcls INFO: [Train][Epoch 220/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01521617, top1: 0.95881, CELoss: 0.12368, loss: 0.12368, batch_cost: 0.79999s, reader_cost: 0.00792, ips: 80.00145 samples/s, eta: 3:04:32
[2022/06/19 04:07:12] ppcls INFO: [Train][Epoch 220/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01519552, top1: 0.95685, CELoss: 0.12926, loss: 0.12926, batch_cost: 0.73723s, reader_cost: 0.01122, ips: 86.81094 samples/s, eta: 2:49:56
[2022/06/19 04:07:19] ppcls INFO: [Train][Epoch 220/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01517487, top1: 0.95968, CELoss: 0.12760, loss: 0.12760, batch_cost: 0.68822s, reader_cost: 0.01196, ips: 92.99343 samples/s, eta: 2:38:31
[2022/06/19 04:07:25] ppcls INFO: [Train][Epoch 220/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01515424, top1: 0.96189, CELoss: 0.12116, loss: 0.12116, batch_cost: 0.66930s, reader_cost: 0.03122, ips: 95.62247 samples/s, eta: 2:34:03
[2022/06/19 04:07:31] ppcls INFO: [Train][Epoch 220/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01513363, top1: 0.96048, CELoss: 0.12308, loss: 0.12308, batch_cost: 0.65029s, reader_cost: 0.02781, ips: 98.41707 samples/s, eta: 2:29:34
[2022/06/19 04:07:36] ppcls INFO: [Train][Epoch 220/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01511302, top1: 0.96260, CELoss: 0.11866, loss: 0.11866, batch_cost: 0.63382s, reader_cost: 0.02533, ips: 100.97505 samples/s, eta: 2:25:41
[2022/06/19 04:07:42] ppcls INFO: [Train][Epoch 220/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01509242, top1: 0.96369, CELoss: 0.11693, loss: 0.11693, batch_cost: 0.62715s, reader_cost: 0.02323, ips: 102.04867 samples/s, eta: 2:24:02
[2022/06/19 04:07:48] ppcls INFO: [Train][Epoch 220/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01507184, top1: 0.96238, CELoss: 0.12379, loss: 0.12379, batch_cost: 0.61980s, reader_cost: 0.02081, ips: 103.25885 samples/s, eta: 2:22:15
[2022/06/19 04:07:54] ppcls INFO: [Train][Epoch 220/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01505126, top1: 0.96188, CELoss: 0.12373, loss: 0.12373, batch_cost: 0.62077s, reader_cost: 0.01989, ips: 103.09697 samples/s, eta: 2:22:22
[2022/06/19 04:08:01] ppcls INFO: [Train][Epoch 220/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01503070, top1: 0.96086, CELoss: 0.12577, loss: 0.12577, batch_cost: 0.62593s, reader_cost: 0.03498, ips: 102.24784 samples/s, eta: 2:23:27
[2022/06/19 04:08:06] ppcls INFO: [Train][Epoch 220/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01501015, top1: 0.96199, CELoss: 0.12379, loss: 0.12379, batch_cost: 0.61900s, reader_cost: 0.03277, ips: 103.39268 samples/s, eta: 2:21:45
[2022/06/19 04:08:12] ppcls INFO: [Train][Epoch 220/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01498961, top1: 0.96113, CELoss: 0.12552, loss: 0.12552, batch_cost: 0.61710s, reader_cost: 0.03659, ips: 103.71026 samples/s, eta: 2:21:13
[2022/06/19 04:08:18] ppcls INFO: [Train][Epoch 220/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01496908, top1: 0.96159, CELoss: 0.12305, loss: 0.12305, batch_cost: 0.61333s, reader_cost: 0.03508, ips: 104.34873 samples/s, eta: 2:20:15
[2022/06/19 04:08:24] ppcls INFO: [Train][Epoch 220/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01494856, top1: 0.96110, CELoss: 0.12525, loss: 0.12525, batch_cost: 0.61321s, reader_cost: 0.03800, ips: 104.36884 samples/s, eta: 2:20:07
[2022/06/19 04:08:30] ppcls INFO: [Train][Epoch 220/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01492805, top1: 0.96120, CELoss: 0.12518, loss: 0.12518, batch_cost: 0.61369s, reader_cost: 0.03559, ips: 104.28711 samples/s, eta: 2:20:08
[2022/06/19 04:08:35] ppcls INFO: [Train][Epoch 220/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01490756, top1: 0.96108, CELoss: 0.12481, loss: 0.12481, batch_cost: 0.60563s, reader_cost: 0.03340, ips: 105.67505 samples/s, eta: 2:18:11
[2022/06/19 04:08:37] ppcls INFO: [Train][Epoch 220/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01488707, top1: 0.96038, CELoss: 0.12579, loss: 0.12579, batch_cost: 0.58312s, reader_cost: 0.03242, ips: 84.03026 samples/s, eta: 2:12:57
[2022/06/19 04:08:38] ppcls INFO: [Train][Epoch 220/300][Avg]top1: 0.96038, CELoss: 0.12579, loss: 0.12579
[2022/06/19 04:08:45] ppcls INFO: [Eval][Epoch 220][Iter: 0/16]CELoss: 1.05077, loss: 1.05077, top1: 0.79688, batch_cost: 6.99902s, reader_cost: 3.38763, ips: 9.14413 images/sec
[2022/06/19 04:08:53] ppcls INFO: [Eval][Epoch 220][Iter: 10/16]CELoss: 0.97493, loss: 0.97493, top1: 0.81587, batch_cost: 0.55606s, reader_cost: 0.00147, ips: 115.09536 images/sec
[2022/06/19 04:08:54] ppcls INFO: [Eval][Epoch 220][Avg]CELoss: 0.82416, loss: 0.82416, top1: 0.82488
[2022/06/19 04:08:54] ppcls INFO: [Eval][Epoch 220][best metric: 0.8275735974311829]
[2022/06/19 04:08:55] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_220
[2022/06/19 04:08:55] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:09:02] ppcls INFO: [Train][Epoch 221/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01488503, top1: 0.98438, CELoss: 0.06943, loss: 0.06943, batch_cost: 0.62435s, reader_cost: 0.06626, ips: 102.50725 samples/s, eta: 2:22:21
[2022/06/19 04:09:09] ppcls INFO: [Train][Epoch 221/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01486456, top1: 0.97443, CELoss: 0.09052, loss: 0.09052, batch_cost: 0.71084s, reader_cost: 0.01810, ips: 90.03423 samples/s, eta: 2:41:57
[2022/06/19 04:09:14] ppcls INFO: [Train][Epoch 221/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01484410, top1: 0.96726, CELoss: 0.10657, loss: 0.10657, batch_cost: 0.63555s, reader_cost: 0.01608, ips: 100.69942 samples/s, eta: 2:24:41
[2022/06/19 04:09:21] ppcls INFO: [Train][Epoch 221/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01482365, top1: 0.96018, CELoss: 0.12212, loss: 0.12212, batch_cost: 0.62284s, reader_cost: 0.01568, ips: 102.75507 samples/s, eta: 2:21:41
[2022/06/19 04:09:27] ppcls INFO: [Train][Epoch 221/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01480321, top1: 0.95998, CELoss: 0.12108, loss: 0.12108, batch_cost: 0.62417s, reader_cost: 0.01560, ips: 102.53671 samples/s, eta: 2:21:53
[2022/06/19 04:09:32] ppcls INFO: [Train][Epoch 221/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01478278, top1: 0.96140, CELoss: 0.11884, loss: 0.11884, batch_cost: 0.61244s, reader_cost: 0.01551, ips: 104.49943 samples/s, eta: 2:19:07
[2022/06/19 04:09:38] ppcls INFO: [Train][Epoch 221/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01476237, top1: 0.96055, CELoss: 0.12157, loss: 0.12157, batch_cost: 0.60634s, reader_cost: 0.01359, ips: 105.55089 samples/s, eta: 2:17:38
[2022/06/19 04:09:45] ppcls INFO: [Train][Epoch 221/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01474196, top1: 0.96083, CELoss: 0.11913, loss: 0.11913, batch_cost: 0.61484s, reader_cost: 0.01265, ips: 104.09178 samples/s, eta: 2:19:27
[2022/06/19 04:09:51] ppcls INFO: [Train][Epoch 221/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01472157, top1: 0.96007, CELoss: 0.12141, loss: 0.12141, batch_cost: 0.60780s, reader_cost: 0.01259, ips: 105.29798 samples/s, eta: 2:17:46
[2022/06/19 04:09:57] ppcls INFO: [Train][Epoch 221/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01470119, top1: 0.96016, CELoss: 0.12081, loss: 0.12081, batch_cost: 0.60587s, reader_cost: 0.01358, ips: 105.63280 samples/s, eta: 2:17:13
[2022/06/19 04:10:02] ppcls INFO: [Train][Epoch 221/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01468082, top1: 0.95978, CELoss: 0.12134, loss: 0.12134, batch_cost: 0.60499s, reader_cost: 0.01423, ips: 105.78695 samples/s, eta: 2:16:55
[2022/06/19 04:10:09] ppcls INFO: [Train][Epoch 221/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01466046, top1: 0.96030, CELoss: 0.12112, loss: 0.12112, batch_cost: 0.60651s, reader_cost: 0.01431, ips: 105.52122 samples/s, eta: 2:17:10
[2022/06/19 04:10:15] ppcls INFO: [Train][Epoch 221/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01464012, top1: 0.95984, CELoss: 0.12128, loss: 0.12128, batch_cost: 0.60507s, reader_cost: 0.01375, ips: 105.77304 samples/s, eta: 2:16:44
[2022/06/19 04:10:20] ppcls INFO: [Train][Epoch 221/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01461978, top1: 0.95957, CELoss: 0.12137, loss: 0.12137, batch_cost: 0.60147s, reader_cost: 0.01348, ips: 106.40541 samples/s, eta: 2:15:49
[2022/06/19 04:10:27] ppcls INFO: [Train][Epoch 221/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01459946, top1: 0.95988, CELoss: 0.12172, loss: 0.12172, batch_cost: 0.60807s, reader_cost: 0.01320, ips: 105.25171 samples/s, eta: 2:17:13
[2022/06/19 04:10:33] ppcls INFO: [Train][Epoch 221/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01457914, top1: 0.95964, CELoss: 0.12004, loss: 0.12004, batch_cost: 0.60825s, reader_cost: 0.01281, ips: 105.22032 samples/s, eta: 2:17:09
[2022/06/19 04:10:38] ppcls INFO: [Train][Epoch 221/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01455884, top1: 0.96031, CELoss: 0.11870, loss: 0.11870, batch_cost: 0.60077s, reader_cost: 0.01236, ips: 106.52958 samples/s, eta: 2:15:22
[2022/06/19 04:10:40] ppcls INFO: [Train][Epoch 221/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01453855, top1: 0.95992, CELoss: 0.11891, loss: 0.11891, batch_cost: 0.57729s, reader_cost: 0.01162, ips: 84.87914 samples/s, eta: 2:09:59
[2022/06/19 04:10:41] ppcls INFO: [Train][Epoch 221/300][Avg]top1: 0.95992, CELoss: 0.11891, loss: 0.11891
[2022/06/19 04:10:41] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:10:46] ppcls INFO: [Train][Epoch 222/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01453652, top1: 0.93750, CELoss: 0.16354, loss: 0.16354, batch_cost: 0.60573s, reader_cost: 0.03383, ips: 105.65792 samples/s, eta: 2:16:22
[2022/06/19 04:10:54] ppcls INFO: [Train][Epoch 222/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01451625, top1: 0.95455, CELoss: 0.12870, loss: 0.12870, batch_cost: 0.66683s, reader_cost: 0.01462, ips: 95.97586 samples/s, eta: 2:30:01
[2022/06/19 04:11:01] ppcls INFO: [Train][Epoch 222/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01449598, top1: 0.95833, CELoss: 0.12767, loss: 0.12767, batch_cost: 0.64457s, reader_cost: 0.01928, ips: 99.29069 samples/s, eta: 2:24:54
[2022/06/19 04:11:07] ppcls INFO: [Train][Epoch 222/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01447573, top1: 0.95817, CELoss: 0.13003, loss: 0.13003, batch_cost: 0.64521s, reader_cost: 0.01880, ips: 99.19193 samples/s, eta: 2:24:56
[2022/06/19 04:11:13] ppcls INFO: [Train][Epoch 222/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01445548, top1: 0.95998, CELoss: 0.12123, loss: 0.12123, batch_cost: 0.63830s, reader_cost: 0.02215, ips: 100.26695 samples/s, eta: 2:23:17
[2022/06/19 04:11:19] ppcls INFO: [Train][Epoch 222/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01443525, top1: 0.95803, CELoss: 0.12285, loss: 0.12285, batch_cost: 0.62571s, reader_cost: 0.02256, ips: 102.28433 samples/s, eta: 2:20:21
[2022/06/19 04:11:25] ppcls INFO: [Train][Epoch 222/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01441503, top1: 0.95876, CELoss: 0.12334, loss: 0.12334, batch_cost: 0.62336s, reader_cost: 0.02136, ips: 102.67009 samples/s, eta: 2:19:43
[2022/06/19 04:11:32] ppcls INFO: [Train][Epoch 222/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01439482, top1: 0.95885, CELoss: 0.12316, loss: 0.12316, batch_cost: 0.62402s, reader_cost: 0.02123, ips: 102.56015 samples/s, eta: 2:19:46
[2022/06/19 04:11:37] ppcls INFO: [Train][Epoch 222/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01437463, top1: 0.95853, CELoss: 0.12249, loss: 0.12249, batch_cost: 0.61544s, reader_cost: 0.01921, ips: 103.99125 samples/s, eta: 2:17:44
[2022/06/19 04:11:43] ppcls INFO: [Train][Epoch 222/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01435444, top1: 0.95913, CELoss: 0.12065, loss: 0.12065, batch_cost: 0.60778s, reader_cost: 0.01871, ips: 105.30059 samples/s, eta: 2:15:55
[2022/06/19 04:11:48] ppcls INFO: [Train][Epoch 222/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01433427, top1: 0.95808, CELoss: 0.12193, loss: 0.12193, batch_cost: 0.60098s, reader_cost: 0.01856, ips: 106.49358 samples/s, eta: 2:14:18
[2022/06/19 04:11:55] ppcls INFO: [Train][Epoch 222/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01431411, top1: 0.95805, CELoss: 0.12369, loss: 0.12369, batch_cost: 0.60660s, reader_cost: 0.01856, ips: 105.50694 samples/s, eta: 2:15:27
[2022/06/19 04:12:02] ppcls INFO: [Train][Epoch 222/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01429395, top1: 0.95855, CELoss: 0.12341, loss: 0.12341, batch_cost: 0.61266s, reader_cost: 0.01780, ips: 104.46178 samples/s, eta: 2:16:42
[2022/06/19 04:12:08] ppcls INFO: [Train][Epoch 222/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01427381, top1: 0.95837, CELoss: 0.12269, loss: 0.12269, batch_cost: 0.61336s, reader_cost: 0.01681, ips: 104.34386 samples/s, eta: 2:16:46
[2022/06/19 04:12:14] ppcls INFO: [Train][Epoch 222/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01425369, top1: 0.95878, CELoss: 0.12076, loss: 0.12076, batch_cost: 0.61234s, reader_cost: 0.01641, ips: 104.51768 samples/s, eta: 2:16:26
[2022/06/19 04:12:19] ppcls INFO: [Train][Epoch 222/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01423357, top1: 0.95944, CELoss: 0.11944, loss: 0.11944, batch_cost: 0.60815s, reader_cost: 0.01671, ips: 105.23706 samples/s, eta: 2:15:24
[2022/06/19 04:12:24] ppcls INFO: [Train][Epoch 222/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01421346, top1: 0.95963, CELoss: 0.11811, loss: 0.11811, batch_cost: 0.60170s, reader_cost: 0.01586, ips: 106.36467 samples/s, eta: 2:13:52
[2022/06/19 04:12:27] ppcls INFO: [Train][Epoch 222/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01419337, top1: 0.95883, CELoss: 0.11946, loss: 0.11946, batch_cost: 0.57870s, reader_cost: 0.01501, ips: 84.67315 samples/s, eta: 2:08:39
[2022/06/19 04:12:27] ppcls INFO: [Train][Epoch 222/300][Avg]top1: 0.95883, CELoss: 0.11946, loss: 0.11946
[2022/06/19 04:12:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:12:34] ppcls INFO: [Train][Epoch 223/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01419136, top1: 0.93750, CELoss: 0.21552, loss: 0.21552, batch_cost: 0.61638s, reader_cost: 0.04750, ips: 103.83147 samples/s, eta: 2:17:01
[2022/06/19 04:12:40] ppcls INFO: [Train][Epoch 223/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01417128, top1: 0.96733, CELoss: 0.11369, loss: 0.11369, batch_cost: 0.58018s, reader_cost: 0.00263, ips: 110.31008 samples/s, eta: 2:08:52
[2022/06/19 04:12:46] ppcls INFO: [Train][Epoch 223/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01415121, top1: 0.96503, CELoss: 0.11006, loss: 0.11006, batch_cost: 0.59913s, reader_cost: 0.01310, ips: 106.82233 samples/s, eta: 2:12:59
[2022/06/19 04:12:53] ppcls INFO: [Train][Epoch 223/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01413116, top1: 0.96270, CELoss: 0.11166, loss: 0.11166, batch_cost: 0.62196s, reader_cost: 0.01592, ips: 102.90103 samples/s, eta: 2:17:57
[2022/06/19 04:12:59] ppcls INFO: [Train][Epoch 223/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01411111, top1: 0.96532, CELoss: 0.10600, loss: 0.10600, batch_cost: 0.61328s, reader_cost: 0.01447, ips: 104.35732 samples/s, eta: 2:15:55
[2022/06/19 04:13:05] ppcls INFO: [Train][Epoch 223/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01409108, top1: 0.96477, CELoss: 0.10624, loss: 0.10624, batch_cost: 0.61048s, reader_cost: 0.03493, ips: 104.83631 samples/s, eta: 2:15:11
[2022/06/19 04:13:11] ppcls INFO: [Train][Epoch 223/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01407105, top1: 0.96337, CELoss: 0.10751, loss: 0.10751, batch_cost: 0.61709s, reader_cost: 0.02975, ips: 103.71248 samples/s, eta: 2:16:33
[2022/06/19 04:13:18] ppcls INFO: [Train][Epoch 223/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01405104, top1: 0.96171, CELoss: 0.11290, loss: 0.11290, batch_cost: 0.62028s, reader_cost: 0.04588, ips: 103.17933 samples/s, eta: 2:17:09
[2022/06/19 04:13:25] ppcls INFO: [Train][Epoch 223/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01403104, top1: 0.96084, CELoss: 0.11426, loss: 0.11426, batch_cost: 0.63862s, reader_cost: 0.07572, ips: 100.21589 samples/s, eta: 2:21:06
[2022/06/19 04:13:30] ppcls INFO: [Train][Epoch 223/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01401105, top1: 0.95913, CELoss: 0.11838, loss: 0.11838, batch_cost: 0.61680s, reader_cost: 0.06794, ips: 103.76211 samples/s, eta: 2:16:11
[2022/06/19 04:13:36] ppcls INFO: [Train][Epoch 223/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01399108, top1: 0.95900, CELoss: 0.11874, loss: 0.11874, batch_cost: 0.61407s, reader_cost: 0.06303, ips: 104.22341 samples/s, eta: 2:15:28
[2022/06/19 04:13:41] ppcls INFO: [Train][Epoch 223/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01397111, top1: 0.95693, CELoss: 0.12278, loss: 0.12278, batch_cost: 0.60817s, reader_cost: 0.05838, ips: 105.23332 samples/s, eta: 2:14:04
[2022/06/19 04:13:47] ppcls INFO: [Train][Epoch 223/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01395116, top1: 0.95635, CELoss: 0.12465, loss: 0.12465, batch_cost: 0.60643s, reader_cost: 0.05573, ips: 105.53635 samples/s, eta: 2:13:35
[2022/06/19 04:13:55] ppcls INFO: [Train][Epoch 223/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01393122, top1: 0.95706, CELoss: 0.12320, loss: 0.12320, batch_cost: 0.61768s, reader_cost: 0.05861, ips: 103.61353 samples/s, eta: 2:15:58
[2022/06/19 04:14:00] ppcls INFO: [Train][Epoch 223/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01391129, top1: 0.95767, CELoss: 0.12176, loss: 0.12176, batch_cost: 0.60900s, reader_cost: 0.05440, ips: 105.09042 samples/s, eta: 2:13:57
[2022/06/19 04:14:06] ppcls INFO: [Train][Epoch 223/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01389137, top1: 0.95747, CELoss: 0.12309, loss: 0.12309, batch_cost: 0.61263s, reader_cost: 0.05265, ips: 104.46796 samples/s, eta: 2:14:39
[2022/06/19 04:14:12] ppcls INFO: [Train][Epoch 223/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01387146, top1: 0.95817, CELoss: 0.12228, loss: 0.12228, batch_cost: 0.60931s, reader_cost: 0.05578, ips: 105.03677 samples/s, eta: 2:13:49
[2022/06/19 04:14:14] ppcls INFO: [Train][Epoch 223/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01385157, top1: 0.95846, CELoss: 0.12185, loss: 0.12185, batch_cost: 0.58539s, reader_cost: 0.05243, ips: 83.70481 samples/s, eta: 2:08:28
[2022/06/19 04:14:15] ppcls INFO: [Train][Epoch 223/300][Avg]top1: 0.95846, CELoss: 0.12185, loss: 0.12185
[2022/06/19 04:14:15] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:14:22] ppcls INFO: [Train][Epoch 224/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01384958, top1: 0.93750, CELoss: 0.14846, loss: 0.14846, batch_cost: 0.62387s, reader_cost: 0.07554, ips: 102.58623 samples/s, eta: 2:16:54
[2022/06/19 04:14:29] ppcls INFO: [Train][Epoch 224/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01382970, top1: 0.96165, CELoss: 0.13023, loss: 0.13023, batch_cost: 0.83098s, reader_cost: 0.00493, ips: 77.01756 samples/s, eta: 3:02:13
[2022/06/19 04:14:35] ppcls INFO: [Train][Epoch 224/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01380983, top1: 0.96057, CELoss: 0.12440, loss: 0.12440, batch_cost: 0.68697s, reader_cost: 0.01299, ips: 93.16320 samples/s, eta: 2:30:31
[2022/06/19 04:14:41] ppcls INFO: [Train][Epoch 224/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01378997, top1: 0.95817, CELoss: 0.12384, loss: 0.12384, batch_cost: 0.66506s, reader_cost: 0.02180, ips: 96.23256 samples/s, eta: 2:25:36
[2022/06/19 04:14:47] ppcls INFO: [Train][Epoch 224/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01377012, top1: 0.95922, CELoss: 0.12330, loss: 0.12330, batch_cost: 0.63889s, reader_cost: 0.01848, ips: 100.17389 samples/s, eta: 2:19:46
[2022/06/19 04:14:53] ppcls INFO: [Train][Epoch 224/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01375029, top1: 0.95864, CELoss: 0.12517, loss: 0.12517, batch_cost: 0.62401s, reader_cost: 0.01632, ips: 102.56192 samples/s, eta: 2:16:25
[2022/06/19 04:14:59] ppcls INFO: [Train][Epoch 224/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01373046, top1: 0.96081, CELoss: 0.12055, loss: 0.12055, batch_cost: 0.62453s, reader_cost: 0.01504, ips: 102.47788 samples/s, eta: 2:16:25
[2022/06/19 04:15:05] ppcls INFO: [Train][Epoch 224/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01371065, top1: 0.96061, CELoss: 0.12201, loss: 0.12201, batch_cost: 0.62078s, reader_cost: 0.01786, ips: 103.09552 samples/s, eta: 2:15:30
[2022/06/19 04:15:11] ppcls INFO: [Train][Epoch 224/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01369085, top1: 0.96065, CELoss: 0.12211, loss: 0.12211, batch_cost: 0.62197s, reader_cost: 0.01642, ips: 102.89916 samples/s, eta: 2:15:39
[2022/06/19 04:15:18] ppcls INFO: [Train][Epoch 224/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01367106, top1: 0.96102, CELoss: 0.12219, loss: 0.12219, batch_cost: 0.62418s, reader_cost: 0.02354, ips: 102.53382 samples/s, eta: 2:16:02
[2022/06/19 04:15:24] ppcls INFO: [Train][Epoch 224/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01365129, top1: 0.96101, CELoss: 0.12012, loss: 0.12012, batch_cost: 0.62069s, reader_cost: 0.02247, ips: 103.11174 samples/s, eta: 2:15:10
[2022/06/19 04:15:30] ppcls INFO: [Train][Epoch 224/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01363152, top1: 0.96044, CELoss: 0.12147, loss: 0.12147, batch_cost: 0.62520s, reader_cost: 0.02096, ips: 102.36776 samples/s, eta: 2:16:03
[2022/06/19 04:15:36] ppcls INFO: [Train][Epoch 224/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01361177, top1: 0.96049, CELoss: 0.12060, loss: 0.12060, batch_cost: 0.62224s, reader_cost: 0.02212, ips: 102.85385 samples/s, eta: 2:15:18
[2022/06/19 04:15:42] ppcls INFO: [Train][Epoch 224/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01359203, top1: 0.95933, CELoss: 0.12302, loss: 0.12302, batch_cost: 0.62030s, reader_cost: 0.02143, ips: 103.17633 samples/s, eta: 2:14:46
[2022/06/19 04:15:49] ppcls INFO: [Train][Epoch 224/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01357230, top1: 0.95944, CELoss: 0.12230, loss: 0.12230, batch_cost: 0.62468s, reader_cost: 0.02049, ips: 102.45197 samples/s, eta: 2:15:37
[2022/06/19 04:15:54] ppcls INFO: [Train][Epoch 224/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01355258, top1: 0.95840, CELoss: 0.12335, loss: 0.12335, batch_cost: 0.61832s, reader_cost: 0.01921, ips: 103.50693 samples/s, eta: 2:14:08
[2022/06/19 04:15:59] ppcls INFO: [Train][Epoch 224/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01353288, top1: 0.95798, CELoss: 0.12392, loss: 0.12392, batch_cost: 0.60978s, reader_cost: 0.01834, ips: 104.95608 samples/s, eta: 2:12:11
[2022/06/19 04:16:01] ppcls INFO: [Train][Epoch 224/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01351318, top1: 0.95828, CELoss: 0.12313, loss: 0.12313, batch_cost: 0.58587s, reader_cost: 0.01730, ips: 83.63684 samples/s, eta: 2:06:54
[2022/06/19 04:16:02] ppcls INFO: [Train][Epoch 224/300][Avg]top1: 0.95828, CELoss: 0.12313, loss: 0.12313
[2022/06/19 04:16:02] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:16:09] ppcls INFO: [Train][Epoch 225/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01351121, top1: 0.92188, CELoss: 0.14100, loss: 0.14100, batch_cost: 0.62083s, reader_cost: 0.04608, ips: 103.08860 samples/s, eta: 2:14:28
[2022/06/19 04:16:16] ppcls INFO: [Train][Epoch 225/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01349153, top1: 0.95170, CELoss: 0.12258, loss: 0.12258, batch_cost: 0.65269s, reader_cost: 0.00477, ips: 98.05609 samples/s, eta: 2:21:15
[2022/06/19 04:16:23] ppcls INFO: [Train][Epoch 225/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01347186, top1: 0.95312, CELoss: 0.13165, loss: 0.13165, batch_cost: 0.65680s, reader_cost: 0.01948, ips: 97.44282 samples/s, eta: 2:22:02
[2022/06/19 04:16:29] ppcls INFO: [Train][Epoch 225/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01345220, top1: 0.96119, CELoss: 0.11415, loss: 0.11415, batch_cost: 0.63116s, reader_cost: 0.01628, ips: 101.40098 samples/s, eta: 2:16:23
[2022/06/19 04:16:35] ppcls INFO: [Train][Epoch 225/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01343256, top1: 0.96341, CELoss: 0.10799, loss: 0.10799, batch_cost: 0.62263s, reader_cost: 0.01576, ips: 102.78931 samples/s, eta: 2:14:26
[2022/06/19 04:16:41] ppcls INFO: [Train][Epoch 225/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01341293, top1: 0.96232, CELoss: 0.11050, loss: 0.11050, batch_cost: 0.62149s, reader_cost: 0.01727, ips: 102.97861 samples/s, eta: 2:14:05
[2022/06/19 04:16:47] ppcls INFO: [Train][Epoch 225/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01339330, top1: 0.96209, CELoss: 0.11032, loss: 0.11032, batch_cost: 0.61945s, reader_cost: 0.01689, ips: 103.31728 samples/s, eta: 2:13:33
[2022/06/19 04:16:52] ppcls INFO: [Train][Epoch 225/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01337369, top1: 0.96215, CELoss: 0.11233, loss: 0.11233, batch_cost: 0.60885s, reader_cost: 0.01569, ips: 105.11553 samples/s, eta: 2:11:10
[2022/06/19 04:16:59] ppcls INFO: [Train][Epoch 225/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01335410, top1: 0.96123, CELoss: 0.11309, loss: 0.11309, batch_cost: 0.60929s, reader_cost: 0.01426, ips: 105.04000 samples/s, eta: 2:11:09
[2022/06/19 04:17:05] ppcls INFO: [Train][Epoch 225/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01333451, top1: 0.96154, CELoss: 0.11311, loss: 0.11311, batch_cost: 0.61633s, reader_cost: 0.01417, ips: 103.84131 samples/s, eta: 2:12:34
[2022/06/19 04:17:12] ppcls INFO: [Train][Epoch 225/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01331493, top1: 0.96117, CELoss: 0.11263, loss: 0.11263, batch_cost: 0.62489s, reader_cost: 0.01477, ips: 102.41878 samples/s, eta: 2:14:18
[2022/06/19 04:17:18] ppcls INFO: [Train][Epoch 225/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01329537, top1: 0.96242, CELoss: 0.11171, loss: 0.11171, batch_cost: 0.61774s, reader_cost: 0.01550, ips: 103.60415 samples/s, eta: 2:12:40
[2022/06/19 04:17:24] ppcls INFO: [Train][Epoch 225/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01327582, top1: 0.96139, CELoss: 0.11184, loss: 0.11184, batch_cost: 0.61538s, reader_cost: 0.01558, ips: 104.00097 samples/s, eta: 2:12:03
[2022/06/19 04:17:29] ppcls INFO: [Train][Epoch 225/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01325628, top1: 0.96135, CELoss: 0.11249, loss: 0.11249, batch_cost: 0.61034s, reader_cost: 0.01483, ips: 104.85881 samples/s, eta: 2:10:52
[2022/06/19 04:17:36] ppcls INFO: [Train][Epoch 225/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01323676, top1: 0.96066, CELoss: 0.11362, loss: 0.11362, batch_cost: 0.61389s, reader_cost: 0.02247, ips: 104.25337 samples/s, eta: 2:11:32
[2022/06/19 04:17:43] ppcls INFO: [Train][Epoch 225/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01321724, top1: 0.95964, CELoss: 0.11634, loss: 0.11634, batch_cost: 0.62164s, reader_cost: 0.04160, ips: 102.95350 samples/s, eta: 2:13:05
[2022/06/19 04:17:48] ppcls INFO: [Train][Epoch 225/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01319774, top1: 0.96002, CELoss: 0.11528, loss: 0.11528, batch_cost: 0.61146s, reader_cost: 0.03961, ips: 104.66832 samples/s, eta: 2:10:48
[2022/06/19 04:17:50] ppcls INFO: [Train][Epoch 225/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01317825, top1: 0.95928, CELoss: 0.11633, loss: 0.11633, batch_cost: 0.58756s, reader_cost: 0.03726, ips: 83.39628 samples/s, eta: 2:05:35
[2022/06/19 04:17:50] ppcls INFO: [Train][Epoch 225/300][Avg]top1: 0.95928, CELoss: 0.11633, loss: 0.11633
[2022/06/19 04:17:57] ppcls INFO: [Eval][Epoch 225][Iter: 0/16]CELoss: 1.01013, loss: 1.01013, top1: 0.80859, batch_cost: 6.59633s, reader_cost: 3.93263, ips: 9.70236 images/sec
[2022/06/19 04:18:05] ppcls INFO: [Eval][Epoch 225][Iter: 10/16]CELoss: 0.83975, loss: 0.83975, top1: 0.81481, batch_cost: 0.59810s, reader_cost: 0.00539, ips: 107.00572 images/sec
[2022/06/19 04:18:07] ppcls INFO: [Eval][Epoch 225][Avg]CELoss: 0.78255, loss: 0.78255, top1: 0.82255
[2022/06/19 04:18:07] ppcls INFO: [Eval][Epoch 225][best metric: 0.8275735974311829]
[2022/06/19 04:18:07] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:18:14] ppcls INFO: [Train][Epoch 226/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01317630, top1: 0.98438, CELoss: 0.04575, loss: 0.04575, batch_cost: 0.62420s, reader_cost: 0.06401, ips: 102.53199 samples/s, eta: 2:13:25
[2022/06/19 04:18:20] ppcls INFO: [Train][Epoch 226/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01315682, top1: 0.97301, CELoss: 0.09459, loss: 0.09459, batch_cost: 0.60347s, reader_cost: 0.01071, ips: 106.05288 samples/s, eta: 2:08:53
[2022/06/19 04:18:26] ppcls INFO: [Train][Epoch 226/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01313735, top1: 0.96503, CELoss: 0.10332, loss: 0.10332, batch_cost: 0.61231s, reader_cost: 0.01318, ips: 104.52192 samples/s, eta: 2:10:40
[2022/06/19 04:18:32] ppcls INFO: [Train][Epoch 226/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01311790, top1: 0.96421, CELoss: 0.10714, loss: 0.10714, batch_cost: 0.61532s, reader_cost: 0.00945, ips: 104.01059 samples/s, eta: 2:11:13
[2022/06/19 04:18:39] ppcls INFO: [Train][Epoch 226/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01309846, top1: 0.96608, CELoss: 0.10270, loss: 0.10270, batch_cost: 0.62502s, reader_cost: 0.01024, ips: 102.39678 samples/s, eta: 2:13:10
[2022/06/19 04:18:45] ppcls INFO: [Train][Epoch 226/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01307903, top1: 0.96722, CELoss: 0.09900, loss: 0.09900, batch_cost: 0.61982s, reader_cost: 0.00973, ips: 103.25512 samples/s, eta: 2:11:58
[2022/06/19 04:18:50] ppcls INFO: [Train][Epoch 226/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01305961, top1: 0.96568, CELoss: 0.10466, loss: 0.10466, batch_cost: 0.60001s, reader_cost: 0.00978, ips: 106.66567 samples/s, eta: 2:07:39
[2022/06/19 04:18:57] ppcls INFO: [Train][Epoch 226/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01304020, top1: 0.96633, CELoss: 0.10646, loss: 0.10646, batch_cost: 0.61353s, reader_cost: 0.01074, ips: 104.31465 samples/s, eta: 2:10:25
[2022/06/19 04:19:03] ppcls INFO: [Train][Epoch 226/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01302081, top1: 0.96624, CELoss: 0.10660, loss: 0.10660, batch_cost: 0.61323s, reader_cost: 0.01118, ips: 104.36575 samples/s, eta: 2:10:15
[2022/06/19 04:19:10] ppcls INFO: [Train][Epoch 226/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01300143, top1: 0.96549, CELoss: 0.10826, loss: 0.10826, batch_cost: 0.62751s, reader_cost: 0.01148, ips: 101.99018 samples/s, eta: 2:13:11
[2022/06/19 04:19:15] ppcls INFO: [Train][Epoch 226/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01298206, top1: 0.96535, CELoss: 0.10774, loss: 0.10774, batch_cost: 0.61239s, reader_cost: 0.01091, ips: 104.50828 samples/s, eta: 2:09:52
[2022/06/19 04:19:21] ppcls INFO: [Train][Epoch 226/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01296270, top1: 0.96622, CELoss: 0.10568, loss: 0.10568, batch_cost: 0.61020s, reader_cost: 0.01163, ips: 104.88388 samples/s, eta: 2:09:18
[2022/06/19 04:19:27] ppcls INFO: [Train][Epoch 226/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01294335, top1: 0.96604, CELoss: 0.10669, loss: 0.10669, batch_cost: 0.61091s, reader_cost: 0.01194, ips: 104.76243 samples/s, eta: 2:09:21
[2022/06/19 04:19:32] ppcls INFO: [Train][Epoch 226/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01292402, top1: 0.96589, CELoss: 0.10656, loss: 0.10656, batch_cost: 0.60288s, reader_cost: 0.01156, ips: 106.15742 samples/s, eta: 2:07:33
[2022/06/19 04:19:39] ppcls INFO: [Train][Epoch 226/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01290470, top1: 0.96554, CELoss: 0.10824, loss: 0.10824, batch_cost: 0.60934s, reader_cost: 0.01275, ips: 105.03135 samples/s, eta: 2:08:49
[2022/06/19 04:19:46] ppcls INFO: [Train][Epoch 226/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01288539, top1: 0.96451, CELoss: 0.11031, loss: 0.11031, batch_cost: 0.61217s, reader_cost: 0.01266, ips: 104.54629 samples/s, eta: 2:09:19
[2022/06/19 04:19:50] ppcls INFO: [Train][Epoch 226/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01286609, top1: 0.96438, CELoss: 0.11074, loss: 0.11074, batch_cost: 0.60317s, reader_cost: 0.01244, ips: 106.10693 samples/s, eta: 2:07:19
[2022/06/19 04:19:53] ppcls INFO: [Train][Epoch 226/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01284680, top1: 0.96367, CELoss: 0.11310, loss: 0.11310, batch_cost: 0.58118s, reader_cost: 0.01172, ips: 84.31188 samples/s, eta: 2:02:34
[2022/06/19 04:19:54] ppcls INFO: [Train][Epoch 226/300][Avg]top1: 0.96367, CELoss: 0.11310, loss: 0.11310
[2022/06/19 04:19:54] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:20:00] ppcls INFO: [Train][Epoch 227/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01284487, top1: 0.95312, CELoss: 0.13744, loss: 0.13744, batch_cost: 0.61622s, reader_cost: 0.04363, ips: 103.85819 samples/s, eta: 2:09:57
[2022/06/19 04:20:07] ppcls INFO: [Train][Epoch 227/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01282560, top1: 0.96591, CELoss: 0.10529, loss: 0.10529, batch_cost: 0.64961s, reader_cost: 0.00321, ips: 98.52086 samples/s, eta: 2:16:53
[2022/06/19 04:20:13] ppcls INFO: [Train][Epoch 227/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01280634, top1: 0.97024, CELoss: 0.09110, loss: 0.09110, batch_cost: 0.67466s, reader_cost: 0.01762, ips: 94.86238 samples/s, eta: 2:22:03
[2022/06/19 04:20:19] ppcls INFO: [Train][Epoch 227/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01278709, top1: 0.96976, CELoss: 0.09282, loss: 0.09282, batch_cost: 0.64556s, reader_cost: 0.01653, ips: 99.13905 samples/s, eta: 2:15:49
[2022/06/19 04:20:25] ppcls INFO: [Train][Epoch 227/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01276785, top1: 0.96761, CELoss: 0.10378, loss: 0.10378, batch_cost: 0.63517s, reader_cost: 0.01565, ips: 100.75975 samples/s, eta: 2:13:32
[2022/06/19 04:20:32] ppcls INFO: [Train][Epoch 227/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01274863, top1: 0.96691, CELoss: 0.10648, loss: 0.10648, batch_cost: 0.62996s, reader_cost: 0.01630, ips: 101.59433 samples/s, eta: 2:12:19
[2022/06/19 04:20:39] ppcls INFO: [Train][Epoch 227/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01272942, top1: 0.96491, CELoss: 0.10810, loss: 0.10810, batch_cost: 0.64422s, reader_cost: 0.04764, ips: 99.34504 samples/s, eta: 2:15:13
[2022/06/19 04:20:45] ppcls INFO: [Train][Epoch 227/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01271022, top1: 0.96457, CELoss: 0.10857, loss: 0.10857, batch_cost: 0.63886s, reader_cost: 0.04263, ips: 100.17918 samples/s, eta: 2:13:59
[2022/06/19 04:20:50] ppcls INFO: [Train][Epoch 227/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01269103, top1: 0.96316, CELoss: 0.11169, loss: 0.11169, batch_cost: 0.62942s, reader_cost: 0.03933, ips: 101.68151 samples/s, eta: 2:11:54
[2022/06/19 04:20:56] ppcls INFO: [Train][Epoch 227/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01267185, top1: 0.96205, CELoss: 0.11361, loss: 0.11361, batch_cost: 0.61779s, reader_cost: 0.03575, ips: 103.59529 samples/s, eta: 2:09:21
[2022/06/19 04:21:02] ppcls INFO: [Train][Epoch 227/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01265269, top1: 0.96132, CELoss: 0.11494, loss: 0.11494, batch_cost: 0.61693s, reader_cost: 0.03302, ips: 103.73910 samples/s, eta: 2:09:04
[2022/06/19 04:21:08] ppcls INFO: [Train][Epoch 227/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01263354, top1: 0.96129, CELoss: 0.11338, loss: 0.11338, batch_cost: 0.61990s, reader_cost: 0.04308, ips: 103.24194 samples/s, eta: 2:09:36
[2022/06/19 04:21:15] ppcls INFO: [Train][Epoch 227/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01261440, top1: 0.96204, CELoss: 0.11149, loss: 0.11149, batch_cost: 0.61927s, reader_cost: 0.04303, ips: 103.34831 samples/s, eta: 2:09:21
[2022/06/19 04:21:21] ppcls INFO: [Train][Epoch 227/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01259527, top1: 0.96135, CELoss: 0.11294, loss: 0.11294, batch_cost: 0.62241s, reader_cost: 0.04068, ips: 102.82681 samples/s, eta: 2:09:55
[2022/06/19 04:21:27] ppcls INFO: [Train][Epoch 227/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01257616, top1: 0.96055, CELoss: 0.11511, loss: 0.11511, batch_cost: 0.62073s, reader_cost: 0.03907, ips: 103.10503 samples/s, eta: 2:09:27
[2022/06/19 04:21:33] ppcls INFO: [Train][Epoch 227/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01255705, top1: 0.96130, CELoss: 0.11448, loss: 0.11448, batch_cost: 0.61580s, reader_cost: 0.03775, ips: 103.93038 samples/s, eta: 2:08:19
[2022/06/19 04:21:38] ppcls INFO: [Train][Epoch 227/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01253796, top1: 0.96050, CELoss: 0.11640, loss: 0.11640, batch_cost: 0.60898s, reader_cost: 0.03586, ips: 105.09361 samples/s, eta: 2:06:48
[2022/06/19 04:21:41] ppcls INFO: [Train][Epoch 227/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01251888, top1: 0.96029, CELoss: 0.11678, loss: 0.11678, batch_cost: 0.59032s, reader_cost: 0.03391, ips: 83.00642 samples/s, eta: 2:02:49
[2022/06/19 04:21:41] ppcls INFO: [Train][Epoch 227/300][Avg]top1: 0.96029, CELoss: 0.11678, loss: 0.11678
[2022/06/19 04:21:42] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:21:48] ppcls INFO: [Train][Epoch 228/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01251698, top1: 0.98438, CELoss: 0.04630, loss: 0.04630, batch_cost: 0.62852s, reader_cost: 0.07116, ips: 101.82584 samples/s, eta: 2:10:45
[2022/06/19 04:21:55] ppcls INFO: [Train][Epoch 228/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01249791, top1: 0.96449, CELoss: 0.09576, loss: 0.09576, batch_cost: 0.61842s, reader_cost: 0.01742, ips: 103.48893 samples/s, eta: 2:08:33
[2022/06/19 04:22:01] ppcls INFO: [Train][Epoch 228/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01247886, top1: 0.96577, CELoss: 0.09978, loss: 0.09978, batch_cost: 0.60000s, reader_cost: 0.01788, ips: 106.66636 samples/s, eta: 2:04:37
[2022/06/19 04:22:07] ppcls INFO: [Train][Epoch 228/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01245982, top1: 0.96321, CELoss: 0.10385, loss: 0.10385, batch_cost: 0.61472s, reader_cost: 0.01651, ips: 104.11196 samples/s, eta: 2:07:35
[2022/06/19 04:22:15] ppcls INFO: [Train][Epoch 228/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01244079, top1: 0.96303, CELoss: 0.10579, loss: 0.10579, batch_cost: 0.65502s, reader_cost: 0.01539, ips: 97.70647 samples/s, eta: 2:15:50
[2022/06/19 04:22:20] ppcls INFO: [Train][Epoch 228/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01242177, top1: 0.96385, CELoss: 0.10849, loss: 0.10849, batch_cost: 0.63654s, reader_cost: 0.01363, ips: 100.54397 samples/s, eta: 2:11:54
[2022/06/19 04:22:27] ppcls INFO: [Train][Epoch 228/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01240277, top1: 0.96363, CELoss: 0.10768, loss: 0.10768, batch_cost: 0.63736s, reader_cost: 0.01358, ips: 100.41373 samples/s, eta: 2:11:57
[2022/06/19 04:22:32] ppcls INFO: [Train][Epoch 228/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01238377, top1: 0.96369, CELoss: 0.10788, loss: 0.10788, batch_cost: 0.62719s, reader_cost: 0.01267, ips: 102.04300 samples/s, eta: 2:09:45
[2022/06/19 04:22:39] ppcls INFO: [Train][Epoch 228/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01236479, top1: 0.96277, CELoss: 0.11177, loss: 0.11177, batch_cost: 0.63012s, reader_cost: 0.01359, ips: 101.56783 samples/s, eta: 2:10:15
[2022/06/19 04:22:45] ppcls INFO: [Train][Epoch 228/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01234583, top1: 0.96188, CELoss: 0.11471, loss: 0.11471, batch_cost: 0.62306s, reader_cost: 0.01239, ips: 102.71924 samples/s, eta: 2:08:41
[2022/06/19 04:22:51] ppcls INFO: [Train][Epoch 228/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01232687, top1: 0.96040, CELoss: 0.11830, loss: 0.11830, batch_cost: 0.62795s, reader_cost: 0.02191, ips: 101.91915 samples/s, eta: 2:09:35
[2022/06/19 04:22:56] ppcls INFO: [Train][Epoch 228/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01230793, top1: 0.95861, CELoss: 0.12314, loss: 0.12314, batch_cost: 0.61668s, reader_cost: 0.02105, ips: 103.78210 samples/s, eta: 2:07:10
[2022/06/19 04:23:04] ppcls INFO: [Train][Epoch 228/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01228900, top1: 0.95764, CELoss: 0.12387, loss: 0.12387, batch_cost: 0.62556s, reader_cost: 0.02847, ips: 102.30830 samples/s, eta: 2:08:53
[2022/06/19 04:23:09] ppcls INFO: [Train][Epoch 228/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01227008, top1: 0.95849, CELoss: 0.12210, loss: 0.12210, batch_cost: 0.61964s, reader_cost: 0.02664, ips: 103.28511 samples/s, eta: 2:07:34
[2022/06/19 04:23:16] ppcls INFO: [Train][Epoch 228/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01225117, top1: 0.95944, CELoss: 0.12088, loss: 0.12088, batch_cost: 0.62474s, reader_cost: 0.02608, ips: 102.44214 samples/s, eta: 2:08:31
[2022/06/19 04:23:21] ppcls INFO: [Train][Epoch 228/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01223228, top1: 0.95923, CELoss: 0.12108, loss: 0.12108, batch_cost: 0.61977s, reader_cost: 0.02458, ips: 103.26485 samples/s, eta: 2:07:23
[2022/06/19 04:23:27] ppcls INFO: [Train][Epoch 228/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01221340, top1: 0.95972, CELoss: 0.11949, loss: 0.11949, batch_cost: 0.61240s, reader_cost: 0.02415, ips: 104.50659 samples/s, eta: 2:05:46
[2022/06/19 04:23:29] ppcls INFO: [Train][Epoch 228/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01219453, top1: 0.95992, CELoss: 0.11802, loss: 0.11802, batch_cost: 0.58812s, reader_cost: 0.02275, ips: 83.31695 samples/s, eta: 2:00:41
[2022/06/19 04:23:29] ppcls INFO: [Train][Epoch 228/300][Avg]top1: 0.95992, CELoss: 0.11802, loss: 0.11802
[2022/06/19 04:23:29] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:23:35] ppcls INFO: [Train][Epoch 229/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01219264, top1: 0.98438, CELoss: 0.07721, loss: 0.07721, batch_cost: 0.61754s, reader_cost: 0.04650, ips: 103.63759 samples/s, eta: 2:06:43
[2022/06/19 04:23:43] ppcls INFO: [Train][Epoch 229/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01217378, top1: 0.97017, CELoss: 0.09263, loss: 0.09263, batch_cost: 0.67034s, reader_cost: 0.00956, ips: 95.47429 samples/s, eta: 2:17:26
[2022/06/19 04:23:49] ppcls INFO: [Train][Epoch 229/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01215494, top1: 0.96577, CELoss: 0.10497, loss: 0.10497, batch_cost: 0.63847s, reader_cost: 0.01704, ips: 100.24019 samples/s, eta: 2:10:48
[2022/06/19 04:23:55] ppcls INFO: [Train][Epoch 229/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01213611, top1: 0.96421, CELoss: 0.10571, loss: 0.10571, batch_cost: 0.61992s, reader_cost: 0.01321, ips: 103.23994 samples/s, eta: 2:06:53
[2022/06/19 04:24:01] ppcls INFO: [Train][Epoch 229/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01211729, top1: 0.96189, CELoss: 0.11083, loss: 0.11083, batch_cost: 0.61111s, reader_cost: 0.01500, ips: 104.72790 samples/s, eta: 2:04:59
[2022/06/19 04:24:07] ppcls INFO: [Train][Epoch 229/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01209848, top1: 0.96140, CELoss: 0.11194, loss: 0.11194, batch_cost: 0.60673s, reader_cost: 0.01388, ips: 105.48337 samples/s, eta: 2:03:59
[2022/06/19 04:24:13] ppcls INFO: [Train][Epoch 229/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01207969, top1: 0.96132, CELoss: 0.11265, loss: 0.11265, batch_cost: 0.61076s, reader_cost: 0.01283, ips: 104.78781 samples/s, eta: 2:04:43
[2022/06/19 04:24:20] ppcls INFO: [Train][Epoch 229/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01206091, top1: 0.96237, CELoss: 0.11205, loss: 0.11205, batch_cost: 0.61667s, reader_cost: 0.01227, ips: 103.78288 samples/s, eta: 2:05:49
[2022/06/19 04:24:26] ppcls INFO: [Train][Epoch 229/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01204214, top1: 0.96200, CELoss: 0.11344, loss: 0.11344, batch_cost: 0.61696s, reader_cost: 0.01230, ips: 103.73369 samples/s, eta: 2:05:46
[2022/06/19 04:24:32] ppcls INFO: [Train][Epoch 229/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01202338, top1: 0.96051, CELoss: 0.11713, loss: 0.11713, batch_cost: 0.61967s, reader_cost: 0.01209, ips: 103.28148 samples/s, eta: 2:06:13
[2022/06/19 04:24:38] ppcls INFO: [Train][Epoch 229/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01200463, top1: 0.96086, CELoss: 0.11634, loss: 0.11634, batch_cost: 0.61771s, reader_cost: 0.01272, ips: 103.60903 samples/s, eta: 2:05:43
[2022/06/19 04:24:45] ppcls INFO: [Train][Epoch 229/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01198590, top1: 0.96030, CELoss: 0.11721, loss: 0.11721, batch_cost: 0.61702s, reader_cost: 0.01749, ips: 103.72479 samples/s, eta: 2:05:28
[2022/06/19 04:24:51] ppcls INFO: [Train][Epoch 229/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01196718, top1: 0.96126, CELoss: 0.11503, loss: 0.11503, batch_cost: 0.61974s, reader_cost: 0.01722, ips: 103.26891 samples/s, eta: 2:05:55
[2022/06/19 04:24:56] ppcls INFO: [Train][Epoch 229/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01194847, top1: 0.96076, CELoss: 0.11520, loss: 0.11520, batch_cost: 0.61353s, reader_cost: 0.01777, ips: 104.31486 samples/s, eta: 2:04:33
[2022/06/19 04:25:03] ppcls INFO: [Train][Epoch 229/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01192978, top1: 0.96099, CELoss: 0.11406, loss: 0.11406, batch_cost: 0.61527s, reader_cost: 0.01731, ips: 104.01924 samples/s, eta: 2:04:49
[2022/06/19 04:25:09] ppcls INFO: [Train][Epoch 229/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01191109, top1: 0.96058, CELoss: 0.11535, loss: 0.11535, batch_cost: 0.61646s, reader_cost: 0.01643, ips: 103.81816 samples/s, eta: 2:04:57
[2022/06/19 04:25:15] ppcls INFO: [Train][Epoch 229/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01189242, top1: 0.95963, CELoss: 0.11777, loss: 0.11777, batch_cost: 0.61200s, reader_cost: 0.01552, ips: 104.57471 samples/s, eta: 2:03:57
[2022/06/19 04:25:17] ppcls INFO: [Train][Epoch 229/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01187377, top1: 0.95983, CELoss: 0.11709, loss: 0.11709, batch_cost: 0.58784s, reader_cost: 0.01459, ips: 83.35616 samples/s, eta: 1:58:57
[2022/06/19 04:25:17] ppcls INFO: [Train][Epoch 229/300][Avg]top1: 0.95983, CELoss: 0.11709, loss: 0.11709
[2022/06/19 04:25:18] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:25:24] ppcls INFO: [Train][Epoch 230/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01187190, top1: 0.98438, CELoss: 0.06101, loss: 0.06101, batch_cost: 0.62281s, reader_cost: 0.04386, ips: 102.76080 samples/s, eta: 2:06:01
[2022/06/19 04:25:32] ppcls INFO: [Train][Epoch 230/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01185326, top1: 0.96591, CELoss: 0.08749, loss: 0.08749, batch_cost: 0.66404s, reader_cost: 0.02761, ips: 96.37973 samples/s, eta: 2:14:15
[2022/06/19 04:25:38] ppcls INFO: [Train][Epoch 230/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01183462, top1: 0.96205, CELoss: 0.10409, loss: 0.10409, batch_cost: 0.63789s, reader_cost: 0.02558, ips: 100.33148 samples/s, eta: 2:08:51
[2022/06/19 04:25:45] ppcls INFO: [Train][Epoch 230/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01181600, top1: 0.96421, CELoss: 0.10304, loss: 0.10304, batch_cost: 0.66857s, reader_cost: 0.02423, ips: 95.72664 samples/s, eta: 2:14:57
[2022/06/19 04:25:51] ppcls INFO: [Train][Epoch 230/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01179740, top1: 0.96494, CELoss: 0.10572, loss: 0.10572, batch_cost: 0.64147s, reader_cost: 0.02025, ips: 99.77122 samples/s, eta: 2:09:22
[2022/06/19 04:25:57] ppcls INFO: [Train][Epoch 230/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01177880, top1: 0.96140, CELoss: 0.11467, loss: 0.11467, batch_cost: 0.63231s, reader_cost: 0.01810, ips: 101.21687 samples/s, eta: 2:07:25
[2022/06/19 04:26:03] ppcls INFO: [Train][Epoch 230/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01176022, top1: 0.95978, CELoss: 0.11711, loss: 0.11711, batch_cost: 0.63927s, reader_cost: 0.01871, ips: 100.11438 samples/s, eta: 2:08:43
[2022/06/19 04:26:10] ppcls INFO: [Train][Epoch 230/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01174165, top1: 0.96017, CELoss: 0.11796, loss: 0.11796, batch_cost: 0.63510s, reader_cost: 0.01909, ips: 100.77119 samples/s, eta: 2:07:46
[2022/06/19 04:26:15] ppcls INFO: [Train][Epoch 230/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01172309, top1: 0.95872, CELoss: 0.12040, loss: 0.12040, batch_cost: 0.62649s, reader_cost: 0.01717, ips: 102.15675 samples/s, eta: 2:05:56
[2022/06/19 04:26:21] ppcls INFO: [Train][Epoch 230/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01170455, top1: 0.96016, CELoss: 0.11801, loss: 0.11801, batch_cost: 0.62331s, reader_cost: 0.01728, ips: 102.67729 samples/s, eta: 2:05:11
[2022/06/19 04:26:28] ppcls INFO: [Train][Epoch 230/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01168602, top1: 0.96194, CELoss: 0.11275, loss: 0.11275, batch_cost: 0.62316s, reader_cost: 0.01764, ips: 102.70172 samples/s, eta: 2:05:03
[2022/06/19 04:26:35] ppcls INFO: [Train][Epoch 230/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01166750, top1: 0.96199, CELoss: 0.11179, loss: 0.11179, batch_cost: 0.63403s, reader_cost: 0.01793, ips: 100.94235 samples/s, eta: 2:07:07
[2022/06/19 04:26:40] ppcls INFO: [Train][Epoch 230/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01164899, top1: 0.96229, CELoss: 0.11082, loss: 0.11082, batch_cost: 0.62499s, reader_cost: 0.01708, ips: 102.40118 samples/s, eta: 2:05:13
[2022/06/19 04:26:47] ppcls INFO: [Train][Epoch 230/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01163049, top1: 0.96159, CELoss: 0.11187, loss: 0.11187, batch_cost: 0.62615s, reader_cost: 0.01643, ips: 102.21245 samples/s, eta: 2:05:20
[2022/06/19 04:26:53] ppcls INFO: [Train][Epoch 230/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01161201, top1: 0.96266, CELoss: 0.10934, loss: 0.10934, batch_cost: 0.62776s, reader_cost: 0.01581, ips: 101.95028 samples/s, eta: 2:05:33
[2022/06/19 04:27:00] ppcls INFO: [Train][Epoch 230/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01159354, top1: 0.96244, CELoss: 0.10989, loss: 0.10989, batch_cost: 0.63078s, reader_cost: 0.01507, ips: 101.46196 samples/s, eta: 2:06:03
[2022/06/19 04:27:05] ppcls INFO: [Train][Epoch 230/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01157508, top1: 0.96273, CELoss: 0.10895, loss: 0.10895, batch_cost: 0.62185s, reader_cost: 0.01445, ips: 102.91824 samples/s, eta: 2:04:10
[2022/06/19 04:27:07] ppcls INFO: [Train][Epoch 230/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01155664, top1: 0.96313, CELoss: 0.10788, loss: 0.10788, batch_cost: 0.59710s, reader_cost: 0.01359, ips: 82.06271 samples/s, eta: 1:59:07
[2022/06/19 04:27:07] ppcls INFO: [Train][Epoch 230/300][Avg]top1: 0.96313, CELoss: 0.10788, loss: 0.10788
[2022/06/19 04:27:15] ppcls INFO: [Eval][Epoch 230][Iter: 0/16]CELoss: 1.00936, loss: 1.00936, top1: 0.80664, batch_cost: 7.07254s, reader_cost: 3.53428, ips: 9.04908 images/sec
[2022/06/19 04:27:23] ppcls INFO: [Eval][Epoch 230][Iter: 10/16]CELoss: 0.99477, loss: 0.99477, top1: 0.81871, batch_cost: 0.57494s, reader_cost: 0.00741, ips: 111.31540 images/sec
[2022/06/19 04:27:24] ppcls INFO: [Eval][Epoch 230][Avg]CELoss: 0.82003, loss: 0.82003, top1: 0.82733
[2022/06/19 04:27:24] ppcls INFO: [Eval][Epoch 230][best metric: 0.8275735974311829]
[2022/06/19 04:27:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_230
[2022/06/19 04:27:25] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:27:31] ppcls INFO: [Train][Epoch 231/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01155480, top1: 0.92188, CELoss: 0.13448, loss: 0.13448, batch_cost: 0.63381s, reader_cost: 0.04481, ips: 100.97610 samples/s, eta: 2:06:26
[2022/06/19 04:27:38] ppcls INFO: [Train][Epoch 231/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01153636, top1: 0.97159, CELoss: 0.09118, loss: 0.09118, batch_cost: 0.60062s, reader_cost: 0.02073, ips: 106.55612 samples/s, eta: 1:59:43
[2022/06/19 04:27:45] ppcls INFO: [Train][Epoch 231/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01151795, top1: 0.96652, CELoss: 0.10131, loss: 0.10131, batch_cost: 0.62588s, reader_cost: 0.02229, ips: 102.25562 samples/s, eta: 2:04:39
[2022/06/19 04:27:50] ppcls INFO: [Train][Epoch 231/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01149954, top1: 0.96673, CELoss: 0.10449, loss: 0.10449, batch_cost: 0.60817s, reader_cost: 0.02088, ips: 105.23376 samples/s, eta: 2:01:01
[2022/06/19 04:27:57] ppcls INFO: [Train][Epoch 231/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01148115, top1: 0.96418, CELoss: 0.11081, loss: 0.11081, batch_cost: 0.62569s, reader_cost: 0.01679, ips: 102.28643 samples/s, eta: 2:04:24
[2022/06/19 04:28:03] ppcls INFO: [Train][Epoch 231/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01146277, top1: 0.96415, CELoss: 0.10913, loss: 0.10913, batch_cost: 0.62235s, reader_cost: 0.01548, ips: 102.83608 samples/s, eta: 2:03:38
[2022/06/19 04:28:09] ppcls INFO: [Train][Epoch 231/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01144440, top1: 0.96337, CELoss: 0.11046, loss: 0.11046, batch_cost: 0.60741s, reader_cost: 0.01391, ips: 105.36609 samples/s, eta: 2:00:34
[2022/06/19 04:28:14] ppcls INFO: [Train][Epoch 231/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01142604, top1: 0.96215, CELoss: 0.11101, loss: 0.11101, batch_cost: 0.60321s, reader_cost: 0.01522, ips: 106.09961 samples/s, eta: 1:59:38
[2022/06/19 04:28:20] ppcls INFO: [Train][Epoch 231/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01140770, top1: 0.96373, CELoss: 0.10838, loss: 0.10838, batch_cost: 0.59877s, reader_cost: 0.01537, ips: 106.88554 samples/s, eta: 1:58:39
[2022/06/19 04:28:27] ppcls INFO: [Train][Epoch 231/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01138937, top1: 0.96137, CELoss: 0.11398, loss: 0.11398, batch_cost: 0.60563s, reader_cost: 0.01588, ips: 105.67446 samples/s, eta: 1:59:54
[2022/06/19 04:28:33] ppcls INFO: [Train][Epoch 231/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01137105, top1: 0.96009, CELoss: 0.11629, loss: 0.11629, batch_cost: 0.60411s, reader_cost: 0.01522, ips: 105.94110 samples/s, eta: 1:59:30
[2022/06/19 04:28:40] ppcls INFO: [Train][Epoch 231/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01135275, top1: 0.95890, CELoss: 0.11978, loss: 0.11978, batch_cost: 0.61670s, reader_cost: 0.01422, ips: 103.77846 samples/s, eta: 2:01:54
[2022/06/19 04:28:47] ppcls INFO: [Train][Epoch 231/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01133445, top1: 0.95945, CELoss: 0.11832, loss: 0.11832, batch_cost: 0.62524s, reader_cost: 0.01369, ips: 102.36082 samples/s, eta: 2:03:29
[2022/06/19 04:28:53] ppcls INFO: [Train][Epoch 231/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01131617, top1: 0.95992, CELoss: 0.11780, loss: 0.11780, batch_cost: 0.62055s, reader_cost: 0.01411, ips: 103.13490 samples/s, eta: 2:02:27
[2022/06/19 04:28:58] ppcls INFO: [Train][Epoch 231/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01129791, top1: 0.96022, CELoss: 0.11877, loss: 0.11877, batch_cost: 0.61534s, reader_cost: 0.01550, ips: 104.00711 samples/s, eta: 2:01:19
[2022/06/19 04:29:05] ppcls INFO: [Train][Epoch 231/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01127965, top1: 0.96037, CELoss: 0.11784, loss: 0.11784, batch_cost: 0.61825s, reader_cost: 0.01482, ips: 103.51764 samples/s, eta: 2:01:47
[2022/06/19 04:29:10] ppcls INFO: [Train][Epoch 231/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01126141, top1: 0.96031, CELoss: 0.11734, loss: 0.11734, batch_cost: 0.61220s, reader_cost: 0.01603, ips: 104.54140 samples/s, eta: 2:00:30
[2022/06/19 04:29:12] ppcls INFO: [Train][Epoch 231/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01124318, top1: 0.96084, CELoss: 0.11582, loss: 0.11582, batch_cost: 0.58898s, reader_cost: 0.01547, ips: 83.19418 samples/s, eta: 1:55:50
[2022/06/19 04:29:13] ppcls INFO: [Train][Epoch 231/300][Avg]top1: 0.96084, CELoss: 0.11582, loss: 0.11582
[2022/06/19 04:29:13] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:29:20] ppcls INFO: [Train][Epoch 232/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01124136, top1: 0.93750, CELoss: 0.14846, loss: 0.14846, batch_cost: 0.62474s, reader_cost: 0.04971, ips: 102.44229 samples/s, eta: 2:02:51
[2022/06/19 04:29:26] ppcls INFO: [Train][Epoch 232/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01122314, top1: 0.96165, CELoss: 0.09776, loss: 0.09776, batch_cost: 0.64921s, reader_cost: 0.03469, ips: 98.58150 samples/s, eta: 2:07:33
[2022/06/19 04:29:32] ppcls INFO: [Train][Epoch 232/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01120494, top1: 0.95908, CELoss: 0.10103, loss: 0.10103, batch_cost: 0.60690s, reader_cost: 0.01733, ips: 105.45368 samples/s, eta: 1:59:08
[2022/06/19 04:29:39] ppcls INFO: [Train][Epoch 232/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01118675, top1: 0.96018, CELoss: 0.11104, loss: 0.11104, batch_cost: 0.62665s, reader_cost: 0.01542, ips: 102.13004 samples/s, eta: 2:02:55
[2022/06/19 04:29:45] ppcls INFO: [Train][Epoch 232/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01116857, top1: 0.96037, CELoss: 0.11414, loss: 0.11414, batch_cost: 0.61372s, reader_cost: 0.01534, ips: 104.28184 samples/s, eta: 2:00:16
[2022/06/19 04:29:51] ppcls INFO: [Train][Epoch 232/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01115041, top1: 0.96078, CELoss: 0.11206, loss: 0.11206, batch_cost: 0.62193s, reader_cost: 0.01513, ips: 102.90569 samples/s, eta: 2:01:47
[2022/06/19 04:29:58] ppcls INFO: [Train][Epoch 232/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01113225, top1: 0.96337, CELoss: 0.10670, loss: 0.10670, batch_cost: 0.62727s, reader_cost: 0.01583, ips: 102.03014 samples/s, eta: 2:02:43
[2022/06/19 04:30:04] ppcls INFO: [Train][Epoch 232/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01111412, top1: 0.96237, CELoss: 0.10866, loss: 0.10866, batch_cost: 0.62322s, reader_cost: 0.01486, ips: 102.69207 samples/s, eta: 2:01:49
[2022/06/19 04:30:10] ppcls INFO: [Train][Epoch 232/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01109599, top1: 0.96200, CELoss: 0.11180, loss: 0.11180, batch_cost: 0.62354s, reader_cost: 0.01464, ips: 102.63957 samples/s, eta: 2:01:47
[2022/06/19 04:30:16] ppcls INFO: [Train][Epoch 232/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01107787, top1: 0.96308, CELoss: 0.10761, loss: 0.10761, batch_cost: 0.61877s, reader_cost: 0.01376, ips: 103.43147 samples/s, eta: 2:00:45
[2022/06/19 04:30:23] ppcls INFO: [Train][Epoch 232/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01105977, top1: 0.96349, CELoss: 0.10541, loss: 0.10541, batch_cost: 0.62724s, reader_cost: 0.01384, ips: 102.03491 samples/s, eta: 2:02:18
[2022/06/19 04:30:28] ppcls INFO: [Train][Epoch 232/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01104169, top1: 0.96410, CELoss: 0.10337, loss: 0.10337, batch_cost: 0.61977s, reader_cost: 0.01510, ips: 103.26347 samples/s, eta: 2:00:44
[2022/06/19 04:30:35] ppcls INFO: [Train][Epoch 232/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01102361, top1: 0.96397, CELoss: 0.10310, loss: 0.10310, batch_cost: 0.62930s, reader_cost: 0.01440, ips: 101.70101 samples/s, eta: 2:02:29
[2022/06/19 04:30:41] ppcls INFO: [Train][Epoch 232/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01100555, top1: 0.96255, CELoss: 0.10448, loss: 0.10448, batch_cost: 0.61988s, reader_cost: 0.01570, ips: 103.24647 samples/s, eta: 2:00:33
[2022/06/19 04:30:47] ppcls INFO: [Train][Epoch 232/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01098750, top1: 0.96221, CELoss: 0.10585, loss: 0.10585, batch_cost: 0.62216s, reader_cost: 0.01488, ips: 102.86677 samples/s, eta: 2:00:53
[2022/06/19 04:30:53] ppcls INFO: [Train][Epoch 232/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01096946, top1: 0.96233, CELoss: 0.10634, loss: 0.10634, batch_cost: 0.61850s, reader_cost: 0.01438, ips: 103.47673 samples/s, eta: 2:00:04
[2022/06/19 04:30:58] ppcls INFO: [Train][Epoch 232/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01095143, top1: 0.96244, CELoss: 0.10553, loss: 0.10553, batch_cost: 0.61360s, reader_cost: 0.01417, ips: 104.30310 samples/s, eta: 1:59:01
[2022/06/19 04:31:00] ppcls INFO: [Train][Epoch 232/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01093342, top1: 0.96276, CELoss: 0.10575, loss: 0.10575, batch_cost: 0.58956s, reader_cost: 0.01337, ips: 83.11215 samples/s, eta: 1:54:16
[2022/06/19 04:31:01] ppcls INFO: [Train][Epoch 232/300][Avg]top1: 0.96276, CELoss: 0.10575, loss: 0.10575
[2022/06/19 04:31:01] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:31:07] ppcls INFO: [Train][Epoch 233/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01093162, top1: 0.93750, CELoss: 0.26308, loss: 0.26308, batch_cost: 0.62357s, reader_cost: 0.04708, ips: 102.63560 samples/s, eta: 2:00:50
[2022/06/19 04:31:14] ppcls INFO: [Train][Epoch 233/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01091362, top1: 0.96875, CELoss: 0.10508, loss: 0.10508, batch_cost: 0.56930s, reader_cost: 0.01601, ips: 112.41782 samples/s, eta: 1:50:14
[2022/06/19 04:31:21] ppcls INFO: [Train][Epoch 233/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01089564, top1: 0.96875, CELoss: 0.09342, loss: 0.09342, batch_cost: 0.60697s, reader_cost: 0.01460, ips: 105.44157 samples/s, eta: 1:57:25
[2022/06/19 04:31:26] ppcls INFO: [Train][Epoch 233/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01087767, top1: 0.96623, CELoss: 0.09545, loss: 0.09545, batch_cost: 0.59621s, reader_cost: 0.01322, ips: 107.34533 samples/s, eta: 1:55:14
[2022/06/19 04:31:33] ppcls INFO: [Train][Epoch 233/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01085971, top1: 0.96646, CELoss: 0.09318, loss: 0.09318, batch_cost: 0.61903s, reader_cost: 0.03624, ips: 103.38715 samples/s, eta: 1:59:33
[2022/06/19 04:31:40] ppcls INFO: [Train][Epoch 233/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01084176, top1: 0.96783, CELoss: 0.09191, loss: 0.09191, batch_cost: 0.64139s, reader_cost: 0.03505, ips: 99.78298 samples/s, eta: 2:03:46
[2022/06/19 04:31:46] ppcls INFO: [Train][Epoch 233/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01082383, top1: 0.96875, CELoss: 0.09008, loss: 0.09008, batch_cost: 0.61946s, reader_cost: 0.03374, ips: 103.31525 samples/s, eta: 1:59:25
[2022/06/19 04:31:52] ppcls INFO: [Train][Epoch 233/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01080590, top1: 0.96721, CELoss: 0.09363, loss: 0.09363, batch_cost: 0.61827s, reader_cost: 0.03174, ips: 103.51397 samples/s, eta: 1:59:06
[2022/06/19 04:31:58] ppcls INFO: [Train][Epoch 233/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01078800, top1: 0.96644, CELoss: 0.09424, loss: 0.09424, batch_cost: 0.61591s, reader_cost: 0.02950, ips: 103.91044 samples/s, eta: 1:58:32
[2022/06/19 04:32:04] ppcls INFO: [Train][Epoch 233/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01077010, top1: 0.96360, CELoss: 0.10108, loss: 0.10108, batch_cost: 0.61171s, reader_cost: 0.02823, ips: 104.62528 samples/s, eta: 1:57:37
[2022/06/19 04:32:10] ppcls INFO: [Train][Epoch 233/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01075222, top1: 0.96442, CELoss: 0.10159, loss: 0.10159, batch_cost: 0.61572s, reader_cost: 0.03446, ips: 103.94385 samples/s, eta: 1:58:17
[2022/06/19 04:32:16] ppcls INFO: [Train][Epoch 233/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01073435, top1: 0.96481, CELoss: 0.10169, loss: 0.10169, batch_cost: 0.61669s, reader_cost: 0.03152, ips: 103.78002 samples/s, eta: 1:58:23
[2022/06/19 04:32:22] ppcls INFO: [Train][Epoch 233/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01071649, top1: 0.96488, CELoss: 0.10314, loss: 0.10314, batch_cost: 0.60939s, reader_cost: 0.02948, ips: 105.02299 samples/s, eta: 1:56:52
[2022/06/19 04:32:29] ppcls INFO: [Train][Epoch 233/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01069865, top1: 0.96529, CELoss: 0.10313, loss: 0.10313, batch_cost: 0.61902s, reader_cost: 0.02889, ips: 103.38853 samples/s, eta: 1:58:37
[2022/06/19 04:32:35] ppcls INFO: [Train][Epoch 233/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01068082, top1: 0.96554, CELoss: 0.10182, loss: 0.10182, batch_cost: 0.61630s, reader_cost: 0.02708, ips: 103.84484 samples/s, eta: 1:58:00
[2022/06/19 04:32:40] ppcls INFO: [Train][Epoch 233/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01066300, top1: 0.96596, CELoss: 0.10103, loss: 0.10103, batch_cost: 0.61233s, reader_cost: 0.02639, ips: 104.51884 samples/s, eta: 1:57:08
[2022/06/19 04:32:47] ppcls INFO: [Train][Epoch 233/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01064519, top1: 0.96671, CELoss: 0.09980, loss: 0.09980, batch_cost: 0.61286s, reader_cost: 0.02920, ips: 104.42757 samples/s, eta: 1:57:08
[2022/06/19 04:32:49] ppcls INFO: [Train][Epoch 233/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01062740, top1: 0.96624, CELoss: 0.10098, loss: 0.10098, batch_cost: 0.58862s, reader_cost: 0.02748, ips: 83.24618 samples/s, eta: 1:52:24
[2022/06/19 04:32:50] ppcls INFO: [Train][Epoch 233/300][Avg]top1: 0.96624, CELoss: 0.10098, loss: 0.10098
[2022/06/19 04:32:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:32:56] ppcls INFO: [Train][Epoch 234/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01062562, top1: 0.96875, CELoss: 0.13798, loss: 0.13798, batch_cost: 0.62436s, reader_cost: 0.05089, ips: 102.50578 samples/s, eta: 1:59:13
[2022/06/19 04:33:03] ppcls INFO: [Train][Epoch 234/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01060784, top1: 0.96733, CELoss: 0.12210, loss: 0.12210, batch_cost: 0.62732s, reader_cost: 0.01368, ips: 102.02049 samples/s, eta: 1:59:40
[2022/06/19 04:33:09] ppcls INFO: [Train][Epoch 234/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01059008, top1: 0.96131, CELoss: 0.12864, loss: 0.12864, batch_cost: 0.63682s, reader_cost: 0.00702, ips: 100.49917 samples/s, eta: 2:01:23
[2022/06/19 04:33:15] ppcls INFO: [Train][Epoch 234/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01057233, top1: 0.95917, CELoss: 0.12300, loss: 0.12300, batch_cost: 0.61019s, reader_cost: 0.00721, ips: 104.88537 samples/s, eta: 1:56:12
[2022/06/19 04:33:21] ppcls INFO: [Train][Epoch 234/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01055459, top1: 0.96189, CELoss: 0.12153, loss: 0.12153, batch_cost: 0.59688s, reader_cost: 0.00935, ips: 107.22412 samples/s, eta: 1:53:34
[2022/06/19 04:33:28] ppcls INFO: [Train][Epoch 234/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01053686, top1: 0.96354, CELoss: 0.11654, loss: 0.11654, batch_cost: 0.62094s, reader_cost: 0.03385, ips: 103.06877 samples/s, eta: 1:58:03
[2022/06/19 04:33:33] ppcls INFO: [Train][Epoch 234/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01051914, top1: 0.96491, CELoss: 0.11223, loss: 0.11223, batch_cost: 0.60654s, reader_cost: 0.02954, ips: 105.51708 samples/s, eta: 1:55:12
[2022/06/19 04:33:39] ppcls INFO: [Train][Epoch 234/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01050144, top1: 0.96479, CELoss: 0.11460, loss: 0.11460, batch_cost: 0.60867s, reader_cost: 0.02812, ips: 105.14766 samples/s, eta: 1:55:30
[2022/06/19 04:33:45] ppcls INFO: [Train][Epoch 234/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01048376, top1: 0.96431, CELoss: 0.11405, loss: 0.11405, batch_cost: 0.59996s, reader_cost: 0.02700, ips: 106.67323 samples/s, eta: 1:53:45
[2022/06/19 04:33:51] ppcls INFO: [Train][Epoch 234/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01046608, top1: 0.96446, CELoss: 0.11470, loss: 0.11470, batch_cost: 0.59866s, reader_cost: 0.02466, ips: 106.90545 samples/s, eta: 1:53:24
[2022/06/19 04:33:57] ppcls INFO: [Train][Epoch 234/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01044842, top1: 0.96411, CELoss: 0.11496, loss: 0.11496, batch_cost: 0.59975s, reader_cost: 0.02337, ips: 106.71159 samples/s, eta: 1:53:31
[2022/06/19 04:34:03] ppcls INFO: [Train][Epoch 234/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01043077, top1: 0.96410, CELoss: 0.11405, loss: 0.11405, batch_cost: 0.60190s, reader_cost: 0.02238, ips: 106.33083 samples/s, eta: 1:53:49
[2022/06/19 04:34:09] ppcls INFO: [Train][Epoch 234/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01041313, top1: 0.96307, CELoss: 0.11511, loss: 0.11511, batch_cost: 0.60063s, reader_cost: 0.02205, ips: 106.55457 samples/s, eta: 1:53:29
[2022/06/19 04:34:15] ppcls INFO: [Train][Epoch 234/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01039551, top1: 0.96302, CELoss: 0.11548, loss: 0.11548, batch_cost: 0.59842s, reader_cost: 0.02200, ips: 106.94874 samples/s, eta: 1:52:58
[2022/06/19 04:34:20] ppcls INFO: [Train][Epoch 234/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01037790, top1: 0.96254, CELoss: 0.11611, loss: 0.11611, batch_cost: 0.59538s, reader_cost: 0.02097, ips: 107.49496 samples/s, eta: 1:52:17
[2022/06/19 04:34:27] ppcls INFO: [Train][Epoch 234/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01036030, top1: 0.96192, CELoss: 0.11653, loss: 0.11653, batch_cost: 0.60042s, reader_cost: 0.02012, ips: 106.59177 samples/s, eta: 1:53:08
[2022/06/19 04:34:31] ppcls INFO: [Train][Epoch 234/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01034272, top1: 0.96128, CELoss: 0.11705, loss: 0.11705, batch_cost: 0.59056s, reader_cost: 0.01894, ips: 108.37115 samples/s, eta: 1:51:11
[2022/06/19 04:34:33] ppcls INFO: [Train][Epoch 234/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01032515, top1: 0.96175, CELoss: 0.11681, loss: 0.11681, batch_cost: 0.56781s, reader_cost: 0.01788, ips: 86.29673 samples/s, eta: 1:46:48
[2022/06/19 04:34:34] ppcls INFO: [Train][Epoch 234/300][Avg]top1: 0.96175, CELoss: 0.11681, loss: 0.11681
[2022/06/19 04:34:34] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:34:41] ppcls INFO: [Train][Epoch 235/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01032339, top1: 0.96875, CELoss: 0.07284, loss: 0.07284, batch_cost: 0.60381s, reader_cost: 0.04923, ips: 105.99361 samples/s, eta: 1:53:34
[2022/06/19 04:34:47] ppcls INFO: [Train][Epoch 235/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01030583, top1: 0.96733, CELoss: 0.08422, loss: 0.08422, batch_cost: 0.63918s, reader_cost: 0.00279, ips: 100.12890 samples/s, eta: 2:00:07
[2022/06/19 04:34:55] ppcls INFO: [Train][Epoch 235/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.01028829, top1: 0.96503, CELoss: 0.09275, loss: 0.09275, batch_cost: 0.71412s, reader_cost: 0.16644, ips: 89.62045 samples/s, eta: 2:14:05
[2022/06/19 04:35:01] ppcls INFO: [Train][Epoch 235/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.01027076, top1: 0.96573, CELoss: 0.09389, loss: 0.09389, batch_cost: 0.66203s, reader_cost: 0.12097, ips: 96.67221 samples/s, eta: 2:04:11
[2022/06/19 04:35:07] ppcls INFO: [Train][Epoch 235/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.01025324, top1: 0.96608, CELoss: 0.09542, loss: 0.09542, batch_cost: 0.64204s, reader_cost: 0.09250, ips: 99.68184 samples/s, eta: 2:00:20
[2022/06/19 04:35:13] ppcls INFO: [Train][Epoch 235/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.01023574, top1: 0.96569, CELoss: 0.09501, loss: 0.09501, batch_cost: 0.63755s, reader_cost: 0.07416, ips: 100.38407 samples/s, eta: 1:59:23
[2022/06/19 04:35:19] ppcls INFO: [Train][Epoch 235/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.01021825, top1: 0.96644, CELoss: 0.09570, loss: 0.09570, batch_cost: 0.63951s, reader_cost: 0.08666, ips: 100.07602 samples/s, eta: 1:59:39
[2022/06/19 04:35:25] ppcls INFO: [Train][Epoch 235/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.01020077, top1: 0.96677, CELoss: 0.09466, loss: 0.09466, batch_cost: 0.62576s, reader_cost: 0.07668, ips: 102.27502 samples/s, eta: 1:56:58
[2022/06/19 04:35:31] ppcls INFO: [Train][Epoch 235/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.01018330, top1: 0.96508, CELoss: 0.10223, loss: 0.10223, batch_cost: 0.62131s, reader_cost: 0.07110, ips: 103.00886 samples/s, eta: 1:56:02
[2022/06/19 04:35:38] ppcls INFO: [Train][Epoch 235/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.01016585, top1: 0.96463, CELoss: 0.10413, loss: 0.10413, batch_cost: 0.63633s, reader_cost: 0.06614, ips: 100.57662 samples/s, eta: 1:58:44
[2022/06/19 04:35:44] ppcls INFO: [Train][Epoch 235/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.01014841, top1: 0.96473, CELoss: 0.10608, loss: 0.10608, batch_cost: 0.62819s, reader_cost: 0.06136, ips: 101.88034 samples/s, eta: 1:57:06
[2022/06/19 04:35:50] ppcls INFO: [Train][Epoch 235/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.01013098, top1: 0.96439, CELoss: 0.10593, loss: 0.10593, batch_cost: 0.62732s, reader_cost: 0.05737, ips: 102.02132 samples/s, eta: 1:56:50
[2022/06/19 04:35:57] ppcls INFO: [Train][Epoch 235/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.01011357, top1: 0.96423, CELoss: 0.10538, loss: 0.10538, batch_cost: 0.62859s, reader_cost: 0.05545, ips: 101.81513 samples/s, eta: 1:56:58
[2022/06/19 04:36:02] ppcls INFO: [Train][Epoch 235/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.01009617, top1: 0.96422, CELoss: 0.10603, loss: 0.10603, batch_cost: 0.62536s, reader_cost: 0.05271, ips: 102.34182 samples/s, eta: 1:56:16
[2022/06/19 04:36:08] ppcls INFO: [Train][Epoch 235/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.01007878, top1: 0.96465, CELoss: 0.10437, loss: 0.10437, batch_cost: 0.62039s, reader_cost: 0.04934, ips: 103.16106 samples/s, eta: 1:55:14
[2022/06/19 04:36:14] ppcls INFO: [Train][Epoch 235/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.01006141, top1: 0.96544, CELoss: 0.10431, loss: 0.10431, batch_cost: 0.61972s, reader_cost: 0.04630, ips: 103.27272 samples/s, eta: 1:55:01
[2022/06/19 04:36:19] ppcls INFO: [Train][Epoch 235/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.01004405, top1: 0.96526, CELoss: 0.10474, loss: 0.10474, batch_cost: 0.61001s, reader_cost: 0.04394, ips: 104.91548 samples/s, eta: 1:53:07
[2022/06/19 04:36:21] ppcls INFO: [Train][Epoch 235/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.01002670, top1: 0.96541, CELoss: 0.10437, loss: 0.10437, batch_cost: 0.58630s, reader_cost: 0.04155, ips: 83.57465 samples/s, eta: 1:48:37
[2022/06/19 04:36:22] ppcls INFO: [Train][Epoch 235/300][Avg]top1: 0.96541, CELoss: 0.10437, loss: 0.10437
[2022/06/19 04:36:28] ppcls INFO: [Eval][Epoch 235][Iter: 0/16]CELoss: 1.05307, loss: 1.05307, top1: 0.80273, batch_cost: 6.63754s, reader_cost: 3.54789, ips: 9.64212 images/sec
[2022/06/19 04:36:36] ppcls INFO: [Eval][Epoch 235][Iter: 10/16]CELoss: 1.03383, loss: 1.03383, top1: 0.82013, batch_cost: 0.60533s, reader_cost: 0.00888, ips: 105.72710 images/sec
[2022/06/19 04:36:38] ppcls INFO: [Eval][Epoch 235][Avg]CELoss: 0.82063, loss: 0.82063, top1: 0.82684
[2022/06/19 04:36:38] ppcls INFO: [Eval][Epoch 235][best metric: 0.8275735974311829]
[2022/06/19 04:36:38] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:36:45] ppcls INFO: [Train][Epoch 236/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.01002496, top1: 0.98438, CELoss: 0.04862, loss: 0.04862, batch_cost: 0.62603s, reader_cost: 0.07320, ips: 102.23157 samples/s, eta: 1:55:58
[2022/06/19 04:36:52] ppcls INFO: [Train][Epoch 236/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.01000763, top1: 0.95881, CELoss: 0.13183, loss: 0.13183, batch_cost: 0.63548s, reader_cost: 0.00309, ips: 100.71206 samples/s, eta: 1:57:36
[2022/06/19 04:36:58] ppcls INFO: [Train][Epoch 236/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00999031, top1: 0.95312, CELoss: 0.13485, loss: 0.13485, batch_cost: 0.62575s, reader_cost: 0.00864, ips: 102.27696 samples/s, eta: 1:55:42
[2022/06/19 04:37:03] ppcls INFO: [Train][Epoch 236/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00997300, top1: 0.95615, CELoss: 0.12299, loss: 0.12299, batch_cost: 0.60372s, reader_cost: 0.01307, ips: 106.00956 samples/s, eta: 1:51:32
[2022/06/19 04:37:09] ppcls INFO: [Train][Epoch 236/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00995571, top1: 0.95846, CELoss: 0.12053, loss: 0.12053, batch_cost: 0.60105s, reader_cost: 0.01328, ips: 106.48019 samples/s, eta: 1:50:56
[2022/06/19 04:37:15] ppcls INFO: [Train][Epoch 236/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00993843, top1: 0.95987, CELoss: 0.11512, loss: 0.11512, batch_cost: 0.59770s, reader_cost: 0.01501, ips: 107.07779 samples/s, eta: 1:50:13
[2022/06/19 04:37:22] ppcls INFO: [Train][Epoch 236/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00992116, top1: 0.96286, CELoss: 0.10985, loss: 0.10985, batch_cost: 0.60537s, reader_cost: 0.01373, ips: 105.72067 samples/s, eta: 1:51:32
[2022/06/19 04:37:28] ppcls INFO: [Train][Epoch 236/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00990390, top1: 0.96105, CELoss: 0.11207, loss: 0.11207, batch_cost: 0.60648s, reader_cost: 0.01284, ips: 105.52736 samples/s, eta: 1:51:38
[2022/06/19 04:37:34] ppcls INFO: [Train][Epoch 236/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00988666, top1: 0.96181, CELoss: 0.11239, loss: 0.11239, batch_cost: 0.61446s, reader_cost: 0.01368, ips: 104.15593 samples/s, eta: 1:53:00
[2022/06/19 04:37:40] ppcls INFO: [Train][Epoch 236/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00986943, top1: 0.96326, CELoss: 0.10981, loss: 0.10981, batch_cost: 0.61173s, reader_cost: 0.01286, ips: 104.62138 samples/s, eta: 1:52:24
[2022/06/19 04:37:47] ppcls INFO: [Train][Epoch 236/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00985222, top1: 0.96380, CELoss: 0.10923, loss: 0.10923, batch_cost: 0.61241s, reader_cost: 0.01177, ips: 104.50536 samples/s, eta: 1:52:25
[2022/06/19 04:37:53] ppcls INFO: [Train][Epoch 236/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00983502, top1: 0.96425, CELoss: 0.10773, loss: 0.10773, batch_cost: 0.61136s, reader_cost: 0.01167, ips: 104.68480 samples/s, eta: 1:52:08
[2022/06/19 04:37:58] ppcls INFO: [Train][Epoch 236/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00981783, top1: 0.96462, CELoss: 0.10648, loss: 0.10648, batch_cost: 0.60532s, reader_cost: 0.01196, ips: 105.72842 samples/s, eta: 1:50:55
[2022/06/19 04:38:04] ppcls INFO: [Train][Epoch 236/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00980065, top1: 0.96469, CELoss: 0.10678, loss: 0.10678, batch_cost: 0.60564s, reader_cost: 0.01290, ips: 105.67409 samples/s, eta: 1:50:52
[2022/06/19 04:38:10] ppcls INFO: [Train][Epoch 236/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00978349, top1: 0.96465, CELoss: 0.10672, loss: 0.10672, batch_cost: 0.60084s, reader_cost: 0.01252, ips: 106.51753 samples/s, eta: 1:49:54
[2022/06/19 04:38:16] ppcls INFO: [Train][Epoch 236/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00976634, top1: 0.96389, CELoss: 0.10771, loss: 0.10771, batch_cost: 0.60477s, reader_cost: 0.01200, ips: 105.82505 samples/s, eta: 1:50:31
[2022/06/19 04:38:22] ppcls INFO: [Train][Epoch 236/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00974921, top1: 0.96409, CELoss: 0.10672, loss: 0.10672, batch_cost: 0.60236s, reader_cost: 0.01603, ips: 106.24868 samples/s, eta: 1:49:58
[2022/06/19 04:38:24] ppcls INFO: [Train][Epoch 236/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00973208, top1: 0.96468, CELoss: 0.10504, loss: 0.10504, batch_cost: 0.57883s, reader_cost: 0.01518, ips: 84.65327 samples/s, eta: 1:45:35
[2022/06/19 04:38:25] ppcls INFO: [Train][Epoch 236/300][Avg]top1: 0.96468, CELoss: 0.10504, loss: 0.10504
[2022/06/19 04:38:25] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:38:31] ppcls INFO: [Train][Epoch 237/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00973037, top1: 0.98438, CELoss: 0.04377, loss: 0.04377, batch_cost: 0.61278s, reader_cost: 0.04591, ips: 104.44198 samples/s, eta: 1:51:46
[2022/06/19 04:38:38] ppcls INFO: [Train][Epoch 237/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00971326, top1: 0.97159, CELoss: 0.08397, loss: 0.08397, batch_cost: 0.67034s, reader_cost: 0.00602, ips: 95.47456 samples/s, eta: 2:02:09
[2022/06/19 04:38:44] ppcls INFO: [Train][Epoch 237/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00969617, top1: 0.96875, CELoss: 0.09513, loss: 0.09513, batch_cost: 0.64363s, reader_cost: 0.02258, ips: 99.43618 samples/s, eta: 1:57:11
[2022/06/19 04:38:51] ppcls INFO: [Train][Epoch 237/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00967909, top1: 0.96774, CELoss: 0.09521, loss: 0.09521, batch_cost: 0.66169s, reader_cost: 0.01900, ips: 96.72206 samples/s, eta: 2:00:21
[2022/06/19 04:38:57] ppcls INFO: [Train][Epoch 237/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00966202, top1: 0.96532, CELoss: 0.10364, loss: 0.10364, batch_cost: 0.65344s, reader_cost: 0.02099, ips: 97.94314 samples/s, eta: 1:58:45
[2022/06/19 04:39:04] ppcls INFO: [Train][Epoch 237/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00964496, top1: 0.96293, CELoss: 0.10915, loss: 0.10915, batch_cost: 0.65422s, reader_cost: 0.02009, ips: 97.82624 samples/s, eta: 1:58:47
[2022/06/19 04:39:09] ppcls INFO: [Train][Epoch 237/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00962792, top1: 0.96311, CELoss: 0.11030, loss: 0.11030, batch_cost: 0.63255s, reader_cost: 0.01792, ips: 101.17710 samples/s, eta: 1:54:44
[2022/06/19 04:39:15] ppcls INFO: [Train][Epoch 237/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00961089, top1: 0.96347, CELoss: 0.10920, loss: 0.10920, batch_cost: 0.63190s, reader_cost: 0.01643, ips: 101.28228 samples/s, eta: 1:54:31
[2022/06/19 04:39:21] ppcls INFO: [Train][Epoch 237/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00959388, top1: 0.96393, CELoss: 0.10773, loss: 0.10773, batch_cost: 0.62664s, reader_cost: 0.01515, ips: 102.13263 samples/s, eta: 1:53:27
[2022/06/19 04:39:27] ppcls INFO: [Train][Epoch 237/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00957687, top1: 0.96429, CELoss: 0.10716, loss: 0.10716, batch_cost: 0.61740s, reader_cost: 0.01518, ips: 103.66044 samples/s, eta: 1:51:41
[2022/06/19 04:39:32] ppcls INFO: [Train][Epoch 237/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00955989, top1: 0.96241, CELoss: 0.11009, loss: 0.11009, batch_cost: 0.61050s, reader_cost: 0.01411, ips: 104.83225 samples/s, eta: 1:50:20
[2022/06/19 04:39:38] ppcls INFO: [Train][Epoch 237/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00954291, top1: 0.96129, CELoss: 0.11191, loss: 0.11191, batch_cost: 0.60549s, reader_cost: 0.01319, ips: 105.69974 samples/s, eta: 1:49:19
[2022/06/19 04:39:46] ppcls INFO: [Train][Epoch 237/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00952595, top1: 0.96178, CELoss: 0.11191, loss: 0.11191, batch_cost: 0.62398s, reader_cost: 0.01246, ips: 102.56797 samples/s, eta: 1:52:33
[2022/06/19 04:39:52] ppcls INFO: [Train][Epoch 237/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00950900, top1: 0.96147, CELoss: 0.11202, loss: 0.11202, batch_cost: 0.62197s, reader_cost: 0.01249, ips: 102.89850 samples/s, eta: 1:52:06
[2022/06/19 04:39:56] ppcls INFO: [Train][Epoch 237/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00949206, top1: 0.96099, CELoss: 0.11326, loss: 0.11326, batch_cost: 0.60602s, reader_cost: 0.01207, ips: 105.60693 samples/s, eta: 1:49:07
[2022/06/19 04:40:04] ppcls INFO: [Train][Epoch 237/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00947514, top1: 0.96120, CELoss: 0.11305, loss: 0.11305, batch_cost: 0.61971s, reader_cost: 0.01283, ips: 103.27359 samples/s, eta: 1:51:29
[2022/06/19 04:40:09] ppcls INFO: [Train][Epoch 237/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00945823, top1: 0.96167, CELoss: 0.11154, loss: 0.11154, batch_cost: 0.61248s, reader_cost: 0.01225, ips: 104.49273 samples/s, eta: 1:50:05
[2022/06/19 04:40:11] ppcls INFO: [Train][Epoch 237/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00944134, top1: 0.96139, CELoss: 0.11120, loss: 0.11120, batch_cost: 0.58818s, reader_cost: 0.01153, ips: 83.30749 samples/s, eta: 1:45:37
[2022/06/19 04:40:12] ppcls INFO: [Train][Epoch 237/300][Avg]top1: 0.96139, CELoss: 0.11120, loss: 0.11120
[2022/06/19 04:40:12] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:40:19] ppcls INFO: [Train][Epoch 238/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00943965, top1: 0.96875, CELoss: 0.07783, loss: 0.07783, batch_cost: 0.62757s, reader_cost: 0.04771, ips: 101.98064 samples/s, eta: 1:52:40
[2022/06/19 04:40:25] ppcls INFO: [Train][Epoch 238/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00942277, top1: 0.97443, CELoss: 0.06884, loss: 0.06884, batch_cost: 0.58820s, reader_cost: 0.02014, ips: 108.80597 samples/s, eta: 1:45:30
[2022/06/19 04:40:32] ppcls INFO: [Train][Epoch 238/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00940590, top1: 0.96503, CELoss: 0.09893, loss: 0.09893, batch_cost: 0.62634s, reader_cost: 0.01736, ips: 102.18131 samples/s, eta: 1:52:15
[2022/06/19 04:40:39] ppcls INFO: [Train][Epoch 238/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00938904, top1: 0.96270, CELoss: 0.10191, loss: 0.10191, batch_cost: 0.65518s, reader_cost: 0.01558, ips: 97.68290 samples/s, eta: 1:57:18
[2022/06/19 04:40:45] ppcls INFO: [Train][Epoch 238/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00937220, top1: 0.96380, CELoss: 0.10149, loss: 0.10149, batch_cost: 0.65876s, reader_cost: 0.01592, ips: 97.15269 samples/s, eta: 1:57:50
[2022/06/19 04:40:52] ppcls INFO: [Train][Epoch 238/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00935538, top1: 0.96446, CELoss: 0.10115, loss: 0.10115, batch_cost: 0.66097s, reader_cost: 0.01464, ips: 96.82712 samples/s, eta: 1:58:07
[2022/06/19 04:40:58] ppcls INFO: [Train][Epoch 238/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00933856, top1: 0.96491, CELoss: 0.10133, loss: 0.10133, batch_cost: 0.64158s, reader_cost: 0.01482, ips: 99.75404 samples/s, eta: 1:54:33
[2022/06/19 04:41:03] ppcls INFO: [Train][Epoch 238/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00932176, top1: 0.96567, CELoss: 0.10141, loss: 0.10141, batch_cost: 0.63058s, reader_cost: 0.01710, ips: 101.49390 samples/s, eta: 1:52:29
[2022/06/19 04:41:10] ppcls INFO: [Train][Epoch 238/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00930497, top1: 0.96605, CELoss: 0.10096, loss: 0.10096, batch_cost: 0.63183s, reader_cost: 0.01780, ips: 101.29253 samples/s, eta: 1:52:36
[2022/06/19 04:41:15] ppcls INFO: [Train][Epoch 238/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00928820, top1: 0.96480, CELoss: 0.10280, loss: 0.10280, batch_cost: 0.62504s, reader_cost: 0.01746, ips: 102.39378 samples/s, eta: 1:51:17
[2022/06/19 04:41:21] ppcls INFO: [Train][Epoch 238/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00927144, top1: 0.96519, CELoss: 0.10398, loss: 0.10398, batch_cost: 0.62105s, reader_cost: 0.01995, ips: 103.05068 samples/s, eta: 1:50:28
[2022/06/19 04:41:27] ppcls INFO: [Train][Epoch 238/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00925469, top1: 0.96551, CELoss: 0.10470, loss: 0.10470, batch_cost: 0.61638s, reader_cost: 0.01984, ips: 103.83266 samples/s, eta: 1:49:32
[2022/06/19 04:41:34] ppcls INFO: [Train][Epoch 238/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00923796, top1: 0.96501, CELoss: 0.10480, loss: 0.10480, batch_cost: 0.61943s, reader_cost: 0.01995, ips: 103.32159 samples/s, eta: 1:49:58
[2022/06/19 04:41:40] ppcls INFO: [Train][Epoch 238/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00922124, top1: 0.96517, CELoss: 0.10414, loss: 0.10414, batch_cost: 0.61934s, reader_cost: 0.01890, ips: 103.33560 samples/s, eta: 1:49:51
[2022/06/19 04:41:46] ppcls INFO: [Train][Epoch 238/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00920453, top1: 0.96498, CELoss: 0.10529, loss: 0.10529, batch_cost: 0.61707s, reader_cost: 0.01872, ips: 103.71645 samples/s, eta: 1:49:21
[2022/06/19 04:41:51] ppcls INFO: [Train][Epoch 238/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00918783, top1: 0.96420, CELoss: 0.10741, loss: 0.10741, batch_cost: 0.61461s, reader_cost: 0.01781, ips: 104.13091 samples/s, eta: 1:48:49
[2022/06/19 04:41:57] ppcls INFO: [Train][Epoch 238/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00917115, top1: 0.96458, CELoss: 0.10562, loss: 0.10562, batch_cost: 0.61108s, reader_cost: 0.01734, ips: 104.73305 samples/s, eta: 1:48:05
[2022/06/19 04:41:59] ppcls INFO: [Train][Epoch 238/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00915449, top1: 0.96459, CELoss: 0.10427, loss: 0.10427, batch_cost: 0.58711s, reader_cost: 0.01631, ips: 83.46010 samples/s, eta: 1:43:45
[2022/06/19 04:42:00] ppcls INFO: [Train][Epoch 238/300][Avg]top1: 0.96459, CELoss: 0.10427, loss: 0.10427
[2022/06/19 04:42:00] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:42:06] ppcls INFO: [Train][Epoch 239/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00915282, top1: 0.93750, CELoss: 0.11623, loss: 0.11623, batch_cost: 0.61886s, reader_cost: 0.04123, ips: 103.41523 samples/s, eta: 1:49:21
[2022/06/19 04:42:14] ppcls INFO: [Train][Epoch 239/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00913617, top1: 0.96307, CELoss: 0.11007, loss: 0.11007, batch_cost: 0.63377s, reader_cost: 0.02711, ips: 100.98282 samples/s, eta: 1:51:52
[2022/06/19 04:42:20] ppcls INFO: [Train][Epoch 239/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00911953, top1: 0.96503, CELoss: 0.10314, loss: 0.10314, batch_cost: 0.62408s, reader_cost: 0.01634, ips: 102.55155 samples/s, eta: 1:50:03
[2022/06/19 04:42:26] ppcls INFO: [Train][Epoch 239/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00910291, top1: 0.96421, CELoss: 0.10775, loss: 0.10775, batch_cost: 0.61873s, reader_cost: 0.02309, ips: 103.43791 samples/s, eta: 1:49:01
[2022/06/19 04:42:32] ppcls INFO: [Train][Epoch 239/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00908629, top1: 0.96189, CELoss: 0.11501, loss: 0.11501, batch_cost: 0.61096s, reader_cost: 0.01882, ips: 104.75324 samples/s, eta: 1:47:32
[2022/06/19 04:42:38] ppcls INFO: [Train][Epoch 239/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00906970, top1: 0.96415, CELoss: 0.10742, loss: 0.10742, batch_cost: 0.61535s, reader_cost: 0.01864, ips: 104.00639 samples/s, eta: 1:48:13
[2022/06/19 04:42:44] ppcls INFO: [Train][Epoch 239/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00905311, top1: 0.96414, CELoss: 0.10902, loss: 0.10902, batch_cost: 0.60537s, reader_cost: 0.01722, ips: 105.72024 samples/s, eta: 1:46:21
[2022/06/19 04:42:51] ppcls INFO: [Train][Epoch 239/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00903654, top1: 0.96523, CELoss: 0.10623, loss: 0.10623, batch_cost: 0.61793s, reader_cost: 0.01612, ips: 103.57243 samples/s, eta: 1:48:27
[2022/06/19 04:42:56] ppcls INFO: [Train][Epoch 239/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00901998, top1: 0.96721, CELoss: 0.10143, loss: 0.10143, batch_cost: 0.60891s, reader_cost: 0.01740, ips: 105.10663 samples/s, eta: 1:46:46
[2022/06/19 04:43:02] ppcls INFO: [Train][Epoch 239/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00900344, top1: 0.96635, CELoss: 0.10419, loss: 0.10419, batch_cost: 0.60321s, reader_cost: 0.01785, ips: 106.09844 samples/s, eta: 1:45:40
[2022/06/19 04:43:07] ppcls INFO: [Train][Epoch 239/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00898691, top1: 0.96612, CELoss: 0.10230, loss: 0.10230, batch_cost: 0.60082s, reader_cost: 0.01826, ips: 106.52055 samples/s, eta: 1:45:09
[2022/06/19 04:43:14] ppcls INFO: [Train][Epoch 239/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00897039, top1: 0.96650, CELoss: 0.10173, loss: 0.10173, batch_cost: 0.60463s, reader_cost: 0.01808, ips: 105.84910 samples/s, eta: 1:45:43
[2022/06/19 04:43:20] ppcls INFO: [Train][Epoch 239/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00895389, top1: 0.96591, CELoss: 0.10487, loss: 0.10487, batch_cost: 0.60426s, reader_cost: 0.01719, ips: 105.91446 samples/s, eta: 1:45:33
[2022/06/19 04:43:25] ppcls INFO: [Train][Epoch 239/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00893740, top1: 0.96601, CELoss: 0.10483, loss: 0.10483, batch_cost: 0.60001s, reader_cost: 0.01785, ips: 106.66476 samples/s, eta: 1:44:43
[2022/06/19 04:43:31] ppcls INFO: [Train][Epoch 239/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00892092, top1: 0.96631, CELoss: 0.10366, loss: 0.10366, batch_cost: 0.60000s, reader_cost: 0.01699, ips: 106.66650 samples/s, eta: 1:44:37
[2022/06/19 04:43:37] ppcls INFO: [Train][Epoch 239/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00890446, top1: 0.96668, CELoss: 0.10290, loss: 0.10290, batch_cost: 0.59934s, reader_cost: 0.01666, ips: 106.78346 samples/s, eta: 1:44:24
[2022/06/19 04:43:43] ppcls INFO: [Train][Epoch 239/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00888801, top1: 0.96671, CELoss: 0.10266, loss: 0.10266, batch_cost: 0.59431s, reader_cost: 0.01672, ips: 107.68801 samples/s, eta: 1:43:25
[2022/06/19 04:43:45] ppcls INFO: [Train][Epoch 239/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00887157, top1: 0.96615, CELoss: 0.10430, loss: 0.10430, batch_cost: 0.57410s, reader_cost: 0.01577, ips: 85.35139 samples/s, eta: 1:39:48
[2022/06/19 04:43:46] ppcls INFO: [Train][Epoch 239/300][Avg]top1: 0.96615, CELoss: 0.10430, loss: 0.10430
[2022/06/19 04:43:46] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:43:52] ppcls INFO: [Train][Epoch 240/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00886993, top1: 0.93750, CELoss: 0.13410, loss: 0.13410, batch_cost: 0.60976s, reader_cost: 0.04085, ips: 104.96002 samples/s, eta: 1:46:00
[2022/06/19 04:43:59] ppcls INFO: [Train][Epoch 240/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00885351, top1: 0.96733, CELoss: 0.10251, loss: 0.10251, batch_cost: 0.61528s, reader_cost: 0.05488, ips: 104.01815 samples/s, eta: 1:46:51
[2022/06/19 04:44:05] ppcls INFO: [Train][Epoch 240/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00883710, top1: 0.96801, CELoss: 0.10051, loss: 0.10051, batch_cost: 0.63555s, reader_cost: 0.02955, ips: 100.70091 samples/s, eta: 1:50:16
[2022/06/19 04:44:11] ppcls INFO: [Train][Epoch 240/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00882071, top1: 0.96673, CELoss: 0.10232, loss: 0.10232, batch_cost: 0.62589s, reader_cost: 0.02380, ips: 102.25514 samples/s, eta: 1:48:29
[2022/06/19 04:44:18] ppcls INFO: [Train][Epoch 240/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00880432, top1: 0.96494, CELoss: 0.11060, loss: 0.11060, batch_cost: 0.63548s, reader_cost: 0.02001, ips: 100.71130 samples/s, eta: 1:50:03
[2022/06/19 04:44:24] ppcls INFO: [Train][Epoch 240/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00878796, top1: 0.96507, CELoss: 0.11149, loss: 0.11149, batch_cost: 0.62782s, reader_cost: 0.02128, ips: 101.94055 samples/s, eta: 1:48:37
[2022/06/19 04:44:29] ppcls INFO: [Train][Epoch 240/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00877160, top1: 0.96542, CELoss: 0.10690, loss: 0.10690, batch_cost: 0.61004s, reader_cost: 0.01996, ips: 104.91167 samples/s, eta: 1:45:26
[2022/06/19 04:44:34] ppcls INFO: [Train][Epoch 240/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00875526, top1: 0.96501, CELoss: 0.10733, loss: 0.10733, batch_cost: 0.59768s, reader_cost: 0.01896, ips: 107.08026 samples/s, eta: 1:43:12
[2022/06/19 04:44:43] ppcls INFO: [Train][Epoch 240/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00873894, top1: 0.96412, CELoss: 0.11211, loss: 0.11211, batch_cost: 0.63404s, reader_cost: 0.02922, ips: 100.93975 samples/s, eta: 1:49:22
[2022/06/19 04:44:48] ppcls INFO: [Train][Epoch 240/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00872263, top1: 0.96600, CELoss: 0.10955, loss: 0.10955, batch_cost: 0.61583s, reader_cost: 0.02679, ips: 103.92548 samples/s, eta: 1:46:08
[2022/06/19 04:44:54] ppcls INFO: [Train][Epoch 240/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00870633, top1: 0.96674, CELoss: 0.10735, loss: 0.10735, batch_cost: 0.61312s, reader_cost: 0.02461, ips: 104.38333 samples/s, eta: 1:45:34
[2022/06/19 04:45:00] ppcls INFO: [Train][Epoch 240/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00869004, top1: 0.96720, CELoss: 0.10524, loss: 0.10524, batch_cost: 0.61739s, reader_cost: 0.02317, ips: 103.66252 samples/s, eta: 1:46:12
[2022/06/19 04:45:07] ppcls INFO: [Train][Epoch 240/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00867377, top1: 0.96668, CELoss: 0.10419, loss: 0.10419, batch_cost: 0.61613s, reader_cost: 0.02289, ips: 103.87408 samples/s, eta: 1:45:52
[2022/06/19 04:45:13] ppcls INFO: [Train][Epoch 240/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00865751, top1: 0.96648, CELoss: 0.10351, loss: 0.10351, batch_cost: 0.61884s, reader_cost: 0.02225, ips: 103.41893 samples/s, eta: 1:46:14
[2022/06/19 04:45:18] ppcls INFO: [Train][Epoch 240/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00864127, top1: 0.96531, CELoss: 0.10450, loss: 0.10450, batch_cost: 0.61132s, reader_cost: 0.02218, ips: 104.69099 samples/s, eta: 1:44:51
[2022/06/19 04:45:24] ppcls INFO: [Train][Epoch 240/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00862504, top1: 0.96534, CELoss: 0.10392, loss: 0.10392, batch_cost: 0.61142s, reader_cost: 0.02177, ips: 104.67495 samples/s, eta: 1:44:45
[2022/06/19 04:45:29] ppcls INFO: [Train][Epoch 240/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00860882, top1: 0.96516, CELoss: 0.10377, loss: 0.10377, batch_cost: 0.60361s, reader_cost: 0.02187, ips: 106.02953 samples/s, eta: 1:43:19
[2022/06/19 04:45:31] ppcls INFO: [Train][Epoch 240/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00859262, top1: 0.96523, CELoss: 0.10413, loss: 0.10413, batch_cost: 0.58057s, reader_cost: 0.02057, ips: 84.39999 samples/s, eta: 1:39:17
[2022/06/19 04:45:32] ppcls INFO: [Train][Epoch 240/300][Avg]top1: 0.96523, CELoss: 0.10413, loss: 0.10413
[2022/06/19 04:45:39] ppcls INFO: [Eval][Epoch 240][Iter: 0/16]CELoss: 1.16961, loss: 1.16961, top1: 0.79883, batch_cost: 6.99284s, reader_cost: 3.77352, ips: 9.15222 images/sec
[2022/06/19 04:45:47] ppcls INFO: [Eval][Epoch 240][Iter: 10/16]CELoss: 1.20033, loss: 1.20033, top1: 0.81197, batch_cost: 0.58503s, reader_cost: 0.00315, ips: 109.39592 images/sec
[2022/06/19 04:45:49] ppcls INFO: [Eval][Epoch 240][Avg]CELoss: 0.87815, loss: 0.87815, top1: 0.82083
[2022/06/19 04:45:49] ppcls INFO: [Eval][Epoch 240][best metric: 0.8275735974311829]
[2022/06/19 04:45:49] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_240
[2022/06/19 04:45:49] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:45:55] ppcls INFO: [Train][Epoch 241/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00859100, top1: 0.98438, CELoss: 0.06585, loss: 0.06585, batch_cost: 0.61139s, reader_cost: 0.05048, ips: 104.67877 samples/s, eta: 1:44:32
[2022/06/19 04:46:02] ppcls INFO: [Train][Epoch 241/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00857481, top1: 0.96591, CELoss: 0.09417, loss: 0.09417, batch_cost: 0.68712s, reader_cost: 0.03099, ips: 93.14274 samples/s, eta: 1:57:22
[2022/06/19 04:46:08] ppcls INFO: [Train][Epoch 241/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00855863, top1: 0.96577, CELoss: 0.09312, loss: 0.09312, batch_cost: 0.62057s, reader_cost: 0.02625, ips: 103.13113 samples/s, eta: 1:45:54
[2022/06/19 04:46:14] ppcls INFO: [Train][Epoch 241/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00854247, top1: 0.96623, CELoss: 0.09766, loss: 0.09766, batch_cost: 0.63457s, reader_cost: 0.02111, ips: 100.85493 samples/s, eta: 1:48:11
[2022/06/19 04:46:20] ppcls INFO: [Train][Epoch 241/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00852632, top1: 0.96951, CELoss: 0.09071, loss: 0.09071, batch_cost: 0.63365s, reader_cost: 0.03648, ips: 101.00237 samples/s, eta: 1:47:55
[2022/06/19 04:46:26] ppcls INFO: [Train][Epoch 241/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00851019, top1: 0.96844, CELoss: 0.09407, loss: 0.09407, batch_cost: 0.61773s, reader_cost: 0.03282, ips: 103.60442 samples/s, eta: 1:45:07
[2022/06/19 04:46:32] ppcls INFO: [Train][Epoch 241/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00849407, top1: 0.96798, CELoss: 0.09849, loss: 0.09849, batch_cost: 0.61811s, reader_cost: 0.05091, ips: 103.54214 samples/s, eta: 1:45:04
[2022/06/19 04:46:38] ppcls INFO: [Train][Epoch 241/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00847796, top1: 0.96743, CELoss: 0.09908, loss: 0.09908, batch_cost: 0.61196s, reader_cost: 0.05242, ips: 104.58182 samples/s, eta: 1:43:55
[2022/06/19 04:46:45] ppcls INFO: [Train][Epoch 241/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00846187, top1: 0.96798, CELoss: 0.09928, loss: 0.09928, batch_cost: 0.62081s, reader_cost: 0.06310, ips: 103.09038 samples/s, eta: 1:45:19
[2022/06/19 04:46:50] ppcls INFO: [Train][Epoch 241/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00844579, top1: 0.96686, CELoss: 0.10180, loss: 0.10180, batch_cost: 0.61158s, reader_cost: 0.05810, ips: 104.64726 samples/s, eta: 1:43:39
[2022/06/19 04:46:57] ppcls INFO: [Train][Epoch 241/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00842973, top1: 0.96658, CELoss: 0.10179, loss: 0.10179, batch_cost: 0.62065s, reader_cost: 0.05247, ips: 103.11707 samples/s, eta: 1:45:05
[2022/06/19 04:47:03] ppcls INFO: [Train][Epoch 241/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00841367, top1: 0.96636, CELoss: 0.10214, loss: 0.10214, batch_cost: 0.61867s, reader_cost: 0.04886, ips: 103.44801 samples/s, eta: 1:44:39
[2022/06/19 04:47:10] ppcls INFO: [Train][Epoch 241/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00839764, top1: 0.96655, CELoss: 0.10259, loss: 0.10259, batch_cost: 0.62237s, reader_cost: 0.04526, ips: 102.83336 samples/s, eta: 1:45:10
[2022/06/19 04:47:15] ppcls INFO: [Train][Epoch 241/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00838161, top1: 0.96708, CELoss: 0.10202, loss: 0.10202, batch_cost: 0.61663s, reader_cost: 0.04228, ips: 103.78928 samples/s, eta: 1:44:06
[2022/06/19 04:47:22] ppcls INFO: [Train][Epoch 241/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00836560, top1: 0.96698, CELoss: 0.10335, loss: 0.10335, batch_cost: 0.61752s, reader_cost: 0.03975, ips: 103.63975 samples/s, eta: 1:44:09
[2022/06/19 04:47:27] ppcls INFO: [Train][Epoch 241/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00834961, top1: 0.96678, CELoss: 0.10389, loss: 0.10389, batch_cost: 0.61019s, reader_cost: 0.03849, ips: 104.88528 samples/s, eta: 1:42:49
[2022/06/19 04:47:32] ppcls INFO: [Train][Epoch 241/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00833362, top1: 0.96681, CELoss: 0.10372, loss: 0.10372, batch_cost: 0.60713s, reader_cost: 0.03643, ips: 105.41465 samples/s, eta: 1:42:11
[2022/06/19 04:47:34] ppcls INFO: [Train][Epoch 241/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00831765, top1: 0.96615, CELoss: 0.10519, loss: 0.10519, batch_cost: 0.58321s, reader_cost: 0.03429, ips: 84.01834 samples/s, eta: 1:38:04
[2022/06/19 04:47:35] ppcls INFO: [Train][Epoch 241/300][Avg]top1: 0.96615, CELoss: 0.10519, loss: 0.10519
[2022/06/19 04:47:35] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:47:41] ppcls INFO: [Train][Epoch 242/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00831606, top1: 0.95312, CELoss: 0.07362, loss: 0.07362, batch_cost: 0.61549s, reader_cost: 0.06134, ips: 103.98229 samples/s, eta: 1:43:29
[2022/06/19 04:47:48] ppcls INFO: [Train][Epoch 242/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00830010, top1: 0.96733, CELoss: 0.09532, loss: 0.09532, batch_cost: 0.71385s, reader_cost: 0.06271, ips: 89.65472 samples/s, eta: 1:59:54
[2022/06/19 04:47:55] ppcls INFO: [Train][Epoch 242/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00828416, top1: 0.96503, CELoss: 0.10685, loss: 0.10685, batch_cost: 0.66120s, reader_cost: 0.03167, ips: 96.79429 samples/s, eta: 1:50:57
[2022/06/19 04:48:01] ppcls INFO: [Train][Epoch 242/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00826824, top1: 0.96623, CELoss: 0.10847, loss: 0.10847, batch_cost: 0.65280s, reader_cost: 0.02198, ips: 98.03962 samples/s, eta: 1:49:26
[2022/06/19 04:48:07] ppcls INFO: [Train][Epoch 242/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00825232, top1: 0.96646, CELoss: 0.10582, loss: 0.10582, batch_cost: 0.65176s, reader_cost: 0.01860, ips: 98.19531 samples/s, eta: 1:49:09
[2022/06/19 04:48:14] ppcls INFO: [Train][Epoch 242/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00823642, top1: 0.96538, CELoss: 0.10641, loss: 0.10641, batch_cost: 0.64085s, reader_cost: 0.01786, ips: 99.86776 samples/s, eta: 1:47:13
[2022/06/19 04:48:20] ppcls INFO: [Train][Epoch 242/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00822054, top1: 0.96516, CELoss: 0.10699, loss: 0.10699, batch_cost: 0.63514s, reader_cost: 0.02052, ips: 100.76466 samples/s, eta: 1:46:09
[2022/06/19 04:48:25] ppcls INFO: [Train][Epoch 242/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00820467, top1: 0.96589, CELoss: 0.10398, loss: 0.10398, batch_cost: 0.62812s, reader_cost: 0.01937, ips: 101.89115 samples/s, eta: 1:44:53
[2022/06/19 04:48:31] ppcls INFO: [Train][Epoch 242/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00818881, top1: 0.96701, CELoss: 0.10113, loss: 0.10113, batch_cost: 0.62045s, reader_cost: 0.01855, ips: 103.15087 samples/s, eta: 1:43:30
[2022/06/19 04:48:38] ppcls INFO: [Train][Epoch 242/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00817297, top1: 0.96600, CELoss: 0.10409, loss: 0.10409, batch_cost: 0.62840s, reader_cost: 0.01764, ips: 101.84586 samples/s, eta: 1:44:43
[2022/06/19 04:48:44] ppcls INFO: [Train][Epoch 242/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00815714, top1: 0.96627, CELoss: 0.10371, loss: 0.10371, batch_cost: 0.62855s, reader_cost: 0.01691, ips: 101.82108 samples/s, eta: 1:44:38
[2022/06/19 04:48:50] ppcls INFO: [Train][Epoch 242/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00814132, top1: 0.96523, CELoss: 0.10386, loss: 0.10386, batch_cost: 0.62121s, reader_cost: 0.01639, ips: 103.02507 samples/s, eta: 1:43:19
[2022/06/19 04:48:55] ppcls INFO: [Train][Epoch 242/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00812552, top1: 0.96501, CELoss: 0.10466, loss: 0.10466, batch_cost: 0.61430s, reader_cost: 0.01648, ips: 104.18320 samples/s, eta: 1:42:03
[2022/06/19 04:49:02] ppcls INFO: [Train][Epoch 242/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00810973, top1: 0.96517, CELoss: 0.10474, loss: 0.10474, batch_cost: 0.61717s, reader_cost: 0.01691, ips: 103.69932 samples/s, eta: 1:42:26
[2022/06/19 04:49:07] ppcls INFO: [Train][Epoch 242/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00809395, top1: 0.96554, CELoss: 0.10394, loss: 0.10394, batch_cost: 0.61074s, reader_cost: 0.01695, ips: 104.79152 samples/s, eta: 1:41:16
[2022/06/19 04:49:14] ppcls INFO: [Train][Epoch 242/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00807819, top1: 0.96513, CELoss: 0.10457, loss: 0.10457, batch_cost: 0.61532s, reader_cost: 0.01613, ips: 104.01172 samples/s, eta: 1:41:55
[2022/06/19 04:49:19] ppcls INFO: [Train][Epoch 242/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00806245, top1: 0.96477, CELoss: 0.10695, loss: 0.10695, batch_cost: 0.60719s, reader_cost: 0.01544, ips: 105.40333 samples/s, eta: 1:40:28
[2022/06/19 04:49:21] ppcls INFO: [Train][Epoch 242/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00804671, top1: 0.96459, CELoss: 0.10688, loss: 0.10688, batch_cost: 0.58412s, reader_cost: 0.01453, ips: 83.88676 samples/s, eta: 1:36:33
[2022/06/19 04:49:22] ppcls INFO: [Train][Epoch 242/300][Avg]top1: 0.96459, CELoss: 0.10688, loss: 0.10688
[2022/06/19 04:49:22] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:49:30] ppcls INFO: [Train][Epoch 243/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00804514, top1: 0.95312, CELoss: 0.12385, loss: 0.12385, batch_cost: 0.62819s, reader_cost: 0.04105, ips: 101.88010 samples/s, eta: 1:43:50
[2022/06/19 04:49:36] ppcls INFO: [Train][Epoch 243/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00802942, top1: 0.97159, CELoss: 0.08224, loss: 0.08224, batch_cost: 0.62077s, reader_cost: 0.02018, ips: 103.09703 samples/s, eta: 1:42:30
[2022/06/19 04:49:42] ppcls INFO: [Train][Epoch 243/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00801372, top1: 0.96652, CELoss: 0.09546, loss: 0.09546, batch_cost: 0.64365s, reader_cost: 0.01238, ips: 99.43312 samples/s, eta: 1:46:10
[2022/06/19 04:49:49] ppcls INFO: [Train][Epoch 243/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00799803, top1: 0.96472, CELoss: 0.10289, loss: 0.10289, batch_cost: 0.65366s, reader_cost: 0.01009, ips: 97.91060 samples/s, eta: 1:47:43
[2022/06/19 04:49:55] ppcls INFO: [Train][Epoch 243/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00798235, top1: 0.96532, CELoss: 0.10147, loss: 0.10147, batch_cost: 0.64224s, reader_cost: 0.00990, ips: 99.65107 samples/s, eta: 1:45:44
[2022/06/19 04:50:01] ppcls INFO: [Train][Epoch 243/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00796669, top1: 0.96538, CELoss: 0.09956, loss: 0.09956, batch_cost: 0.63936s, reader_cost: 0.01323, ips: 100.10087 samples/s, eta: 1:45:09
[2022/06/19 04:50:07] ppcls INFO: [Train][Epoch 243/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00795104, top1: 0.96721, CELoss: 0.09731, loss: 0.09731, batch_cost: 0.63405s, reader_cost: 0.01522, ips: 100.93848 samples/s, eta: 1:44:10
[2022/06/19 04:50:14] ppcls INFO: [Train][Epoch 243/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00793541, top1: 0.96677, CELoss: 0.09740, loss: 0.09740, batch_cost: 0.63140s, reader_cost: 0.01438, ips: 101.36200 samples/s, eta: 1:43:38
[2022/06/19 04:50:22] ppcls INFO: [Train][Epoch 243/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00791979, top1: 0.96586, CELoss: 0.10215, loss: 0.10215, batch_cost: 0.65945s, reader_cost: 0.01371, ips: 97.05049 samples/s, eta: 1:48:07
[2022/06/19 04:50:27] ppcls INFO: [Train][Epoch 243/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00790418, top1: 0.96463, CELoss: 0.10763, loss: 0.10763, batch_cost: 0.63715s, reader_cost: 0.01285, ips: 100.44776 samples/s, eta: 1:44:21
[2022/06/19 04:50:32] ppcls INFO: [Train][Epoch 243/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00788859, top1: 0.96457, CELoss: 0.10791, loss: 0.10791, batch_cost: 0.62887s, reader_cost: 0.01227, ips: 101.77050 samples/s, eta: 1:42:54
[2022/06/19 04:50:38] ppcls INFO: [Train][Epoch 243/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00787301, top1: 0.96467, CELoss: 0.10764, loss: 0.10764, batch_cost: 0.62355s, reader_cost: 0.01257, ips: 102.63776 samples/s, eta: 1:41:55
[2022/06/19 04:50:45] ppcls INFO: [Train][Epoch 243/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00785744, top1: 0.96358, CELoss: 0.10730, loss: 0.10730, batch_cost: 0.62818s, reader_cost: 0.01621, ips: 101.88145 samples/s, eta: 1:42:34
[2022/06/19 04:50:50] ppcls INFO: [Train][Epoch 243/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00784189, top1: 0.96350, CELoss: 0.10722, loss: 0.10722, batch_cost: 0.62217s, reader_cost: 0.01733, ips: 102.86505 samples/s, eta: 1:41:29
[2022/06/19 04:50:57] ppcls INFO: [Train][Epoch 243/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00782635, top1: 0.96421, CELoss: 0.10548, loss: 0.10548, batch_cost: 0.62473s, reader_cost: 0.01683, ips: 102.44498 samples/s, eta: 1:41:48
[2022/06/19 04:51:02] ppcls INFO: [Train][Epoch 243/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00781083, top1: 0.96471, CELoss: 0.10473, loss: 0.10473, batch_cost: 0.61488s, reader_cost: 0.01581, ips: 104.08570 samples/s, eta: 1:40:06
[2022/06/19 04:51:08] ppcls INFO: [Train][Epoch 243/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00779532, top1: 0.96506, CELoss: 0.10374, loss: 0.10374, batch_cost: 0.61557s, reader_cost: 0.01505, ips: 103.96902 samples/s, eta: 1:40:06
[2022/06/19 04:51:10] ppcls INFO: [Train][Epoch 243/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00777983, top1: 0.96569, CELoss: 0.10320, loss: 0.10320, batch_cost: 0.59139s, reader_cost: 0.01417, ips: 82.85535 samples/s, eta: 1:36:04
[2022/06/19 04:51:11] ppcls INFO: [Train][Epoch 243/300][Avg]top1: 0.96569, CELoss: 0.10320, loss: 0.10320
[2022/06/19 04:51:11] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:51:17] ppcls INFO: [Train][Epoch 244/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00777828, top1: 0.93750, CELoss: 0.10705, loss: 0.10705, batch_cost: 0.62279s, reader_cost: 0.04475, ips: 102.76402 samples/s, eta: 1:41:10
[2022/06/19 04:51:24] ppcls INFO: [Train][Epoch 244/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00776280, top1: 0.95312, CELoss: 0.14481, loss: 0.14481, batch_cost: 0.71459s, reader_cost: 0.01881, ips: 89.56187 samples/s, eta: 1:55:57
[2022/06/19 04:51:31] ppcls INFO: [Train][Epoch 244/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00774733, top1: 0.95982, CELoss: 0.11432, loss: 0.11432, batch_cost: 0.69949s, reader_cost: 0.04552, ips: 91.49547 samples/s, eta: 1:53:23
[2022/06/19 04:51:37] ppcls INFO: [Train][Epoch 244/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00773188, top1: 0.95917, CELoss: 0.11441, loss: 0.11441, batch_cost: 0.64972s, reader_cost: 0.03304, ips: 98.50415 samples/s, eta: 1:45:13
[2022/06/19 04:51:43] ppcls INFO: [Train][Epoch 244/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00771644, top1: 0.96075, CELoss: 0.10935, loss: 0.10935, batch_cost: 0.63607s, reader_cost: 0.03427, ips: 100.61780 samples/s, eta: 1:42:54
[2022/06/19 04:51:49] ppcls INFO: [Train][Epoch 244/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00770102, top1: 0.95956, CELoss: 0.11303, loss: 0.11303, batch_cost: 0.63512s, reader_cost: 0.03277, ips: 100.76802 samples/s, eta: 1:42:38
[2022/06/19 04:51:55] ppcls INFO: [Train][Epoch 244/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00768561, top1: 0.95825, CELoss: 0.11567, loss: 0.11567, batch_cost: 0.62482s, reader_cost: 0.03046, ips: 102.42940 samples/s, eta: 1:40:52
[2022/06/19 04:52:01] ppcls INFO: [Train][Epoch 244/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00767021, top1: 0.95995, CELoss: 0.11522, loss: 0.11522, batch_cost: 0.62410s, reader_cost: 0.03725, ips: 102.54699 samples/s, eta: 1:40:39
[2022/06/19 04:52:09] ppcls INFO: [Train][Epoch 244/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00765483, top1: 0.95872, CELoss: 0.11602, loss: 0.11602, batch_cost: 0.64194s, reader_cost: 0.03708, ips: 99.69755 samples/s, eta: 1:43:25
[2022/06/19 04:52:15] ppcls INFO: [Train][Epoch 244/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00763946, top1: 0.95982, CELoss: 0.11322, loss: 0.11322, batch_cost: 0.63960s, reader_cost: 0.03376, ips: 100.06209 samples/s, eta: 1:42:56
[2022/06/19 04:52:21] ppcls INFO: [Train][Epoch 244/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00762411, top1: 0.95947, CELoss: 0.11422, loss: 0.11422, batch_cost: 0.63435s, reader_cost: 0.03150, ips: 100.89040 samples/s, eta: 1:41:59
[2022/06/19 04:52:27] ppcls INFO: [Train][Epoch 244/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00760877, top1: 0.95960, CELoss: 0.11425, loss: 0.11425, batch_cost: 0.63027s, reader_cost: 0.02980, ips: 101.54429 samples/s, eta: 1:41:13
[2022/06/19 04:52:33] ppcls INFO: [Train][Epoch 244/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00759344, top1: 0.96023, CELoss: 0.11328, loss: 0.11328, batch_cost: 0.62480s, reader_cost: 0.02830, ips: 102.43267 samples/s, eta: 1:40:14
[2022/06/19 04:52:38] ppcls INFO: [Train][Epoch 244/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00757813, top1: 0.96040, CELoss: 0.11282, loss: 0.11282, batch_cost: 0.61973s, reader_cost: 0.02889, ips: 103.27159 samples/s, eta: 1:39:19
[2022/06/19 04:52:45] ppcls INFO: [Train][Epoch 244/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00756283, top1: 0.96121, CELoss: 0.11134, loss: 0.11134, batch_cost: 0.62333s, reader_cost: 0.03070, ips: 102.67416 samples/s, eta: 1:39:48
[2022/06/19 04:52:52] ppcls INFO: [Train][Epoch 244/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00754755, top1: 0.96161, CELoss: 0.11173, loss: 0.11173, batch_cost: 0.62668s, reader_cost: 0.02886, ips: 102.12474 samples/s, eta: 1:40:14
[2022/06/19 04:52:56] ppcls INFO: [Train][Epoch 244/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00753228, top1: 0.96196, CELoss: 0.11090, loss: 0.11090, batch_cost: 0.61782s, reader_cost: 0.02742, ips: 103.59010 samples/s, eta: 1:38:43
[2022/06/19 04:52:59] ppcls INFO: [Train][Epoch 244/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00751702, top1: 0.96230, CELoss: 0.11059, loss: 0.11059, batch_cost: 0.59342s, reader_cost: 0.02580, ips: 82.57206 samples/s, eta: 1:34:43
[2022/06/19 04:52:59] ppcls INFO: [Train][Epoch 244/300][Avg]top1: 0.96230, CELoss: 0.11059, loss: 0.11059
[2022/06/19 04:52:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:53:06] ppcls INFO: [Train][Epoch 245/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00751549, top1: 0.98438, CELoss: 0.06208, loss: 0.06208, batch_cost: 0.62886s, reader_cost: 0.05146, ips: 101.77197 samples/s, eta: 1:40:21
[2022/06/19 04:53:13] ppcls INFO: [Train][Epoch 245/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00750025, top1: 0.96875, CELoss: 0.09053, loss: 0.09053, batch_cost: 0.75332s, reader_cost: 0.01149, ips: 84.95763 samples/s, eta: 2:00:06
[2022/06/19 04:53:19] ppcls INFO: [Train][Epoch 245/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00748503, top1: 0.97098, CELoss: 0.08729, loss: 0.08729, batch_cost: 0.67481s, reader_cost: 0.01255, ips: 94.84133 samples/s, eta: 1:47:28
[2022/06/19 04:53:25] ppcls INFO: [Train][Epoch 245/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00746982, top1: 0.97077, CELoss: 0.09097, loss: 0.09097, batch_cost: 0.64929s, reader_cost: 0.00962, ips: 98.56852 samples/s, eta: 1:43:18
[2022/06/19 04:53:32] ppcls INFO: [Train][Epoch 245/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00745462, top1: 0.96837, CELoss: 0.09448, loss: 0.09448, batch_cost: 0.64399s, reader_cost: 0.00931, ips: 99.38114 samples/s, eta: 1:42:21
[2022/06/19 04:53:37] ppcls INFO: [Train][Epoch 245/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00743943, top1: 0.96783, CELoss: 0.09277, loss: 0.09277, batch_cost: 0.62783s, reader_cost: 0.01024, ips: 101.93900 samples/s, eta: 1:39:40
[2022/06/19 04:53:43] ppcls INFO: [Train][Epoch 245/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00742426, top1: 0.96875, CELoss: 0.09212, loss: 0.09212, batch_cost: 0.61618s, reader_cost: 0.00958, ips: 103.86574 samples/s, eta: 1:37:43
[2022/06/19 04:53:49] ppcls INFO: [Train][Epoch 245/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00740911, top1: 0.96787, CELoss: 0.09415, loss: 0.09415, batch_cost: 0.61959s, reader_cost: 0.01123, ips: 103.29476 samples/s, eta: 1:38:09
[2022/06/19 04:53:56] ppcls INFO: [Train][Epoch 245/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00739397, top1: 0.96779, CELoss: 0.09548, loss: 0.09548, batch_cost: 0.62602s, reader_cost: 0.01092, ips: 102.23356 samples/s, eta: 1:39:04
[2022/06/19 04:54:02] ppcls INFO: [Train][Epoch 245/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00737884, top1: 0.96617, CELoss: 0.10047, loss: 0.10047, batch_cost: 0.61981s, reader_cost: 0.01108, ips: 103.25666 samples/s, eta: 1:37:59
[2022/06/19 04:54:08] ppcls INFO: [Train][Epoch 245/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00736372, top1: 0.96658, CELoss: 0.10139, loss: 0.10139, batch_cost: 0.62481s, reader_cost: 0.01237, ips: 102.43169 samples/s, eta: 1:38:40
[2022/06/19 04:54:14] ppcls INFO: [Train][Epoch 245/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00734862, top1: 0.96537, CELoss: 0.10149, loss: 0.10149, batch_cost: 0.61584s, reader_cost: 0.01436, ips: 103.92313 samples/s, eta: 1:37:09
[2022/06/19 04:54:19] ppcls INFO: [Train][Epoch 245/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00733354, top1: 0.96488, CELoss: 0.10122, loss: 0.10122, batch_cost: 0.61185s, reader_cost: 0.01419, ips: 104.60110 samples/s, eta: 1:36:25
[2022/06/19 04:54:27] ppcls INFO: [Train][Epoch 245/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00731847, top1: 0.96505, CELoss: 0.10061, loss: 0.10061, batch_cost: 0.62634s, reader_cost: 0.01407, ips: 102.18023 samples/s, eta: 1:38:36
[2022/06/19 04:54:32] ppcls INFO: [Train][Epoch 245/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00730341, top1: 0.96410, CELoss: 0.10320, loss: 0.10320, batch_cost: 0.61759s, reader_cost: 0.01375, ips: 103.62855 samples/s, eta: 1:37:07
[2022/06/19 04:54:38] ppcls INFO: [Train][Epoch 245/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00728837, top1: 0.96492, CELoss: 0.10278, loss: 0.10278, batch_cost: 0.61560s, reader_cost: 0.01325, ips: 103.96350 samples/s, eta: 1:36:42
[2022/06/19 04:54:43] ppcls INFO: [Train][Epoch 245/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00727334, top1: 0.96467, CELoss: 0.10382, loss: 0.10382, batch_cost: 0.60842s, reader_cost: 0.01312, ips: 105.19016 samples/s, eta: 1:35:28
[2022/06/19 04:54:46] ppcls INFO: [Train][Epoch 245/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00725832, top1: 0.96477, CELoss: 0.10357, loss: 0.10357, batch_cost: 0.58465s, reader_cost: 0.01240, ips: 83.81131 samples/s, eta: 1:31:39
[2022/06/19 04:54:46] ppcls INFO: [Train][Epoch 245/300][Avg]top1: 0.96477, CELoss: 0.10357, loss: 0.10357
[2022/06/19 04:54:53] ppcls INFO: [Eval][Epoch 245][Iter: 0/16]CELoss: 1.01267, loss: 1.01267, top1: 0.81836, batch_cost: 6.99507s, reader_cost: 3.65518, ips: 9.14930 images/sec
[2022/06/19 04:55:01] ppcls INFO: [Eval][Epoch 245][Iter: 10/16]CELoss: 1.01332, loss: 1.01332, top1: 0.82404, batch_cost: 0.60664s, reader_cost: 0.00206, ips: 105.49936 images/sec
[2022/06/19 04:55:03] ppcls INFO: [Eval][Epoch 245][Avg]CELoss: 0.81341, loss: 0.81341, top1: 0.82770
[2022/06/19 04:55:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 04:55:03] ppcls INFO: [Eval][Epoch 245][best metric: 0.8276961445808411]
[2022/06/19 04:55:03] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:55:10] ppcls INFO: [Train][Epoch 246/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00725682, top1: 0.96875, CELoss: 0.05542, loss: 0.05542, batch_cost: 0.62295s, reader_cost: 0.04636, ips: 102.73681 samples/s, eta: 1:37:38
[2022/06/19 04:55:17] ppcls INFO: [Train][Epoch 246/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00724182, top1: 0.96449, CELoss: 0.10645, loss: 0.10645, batch_cost: 0.69968s, reader_cost: 0.01859, ips: 91.47076 samples/s, eta: 1:49:33
[2022/06/19 04:55:23] ppcls INFO: [Train][Epoch 246/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00722684, top1: 0.97024, CELoss: 0.09284, loss: 0.09284, batch_cost: 0.67340s, reader_cost: 0.01677, ips: 95.03978 samples/s, eta: 1:45:19
[2022/06/19 04:55:29] ppcls INFO: [Train][Epoch 246/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00721187, top1: 0.96875, CELoss: 0.09901, loss: 0.09901, batch_cost: 0.64191s, reader_cost: 0.01290, ips: 99.70225 samples/s, eta: 1:40:17
[2022/06/19 04:55:35] ppcls INFO: [Train][Epoch 246/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00719691, top1: 0.96913, CELoss: 0.09884, loss: 0.09884, batch_cost: 0.63326s, reader_cost: 0.01293, ips: 101.06491 samples/s, eta: 1:38:50
[2022/06/19 04:55:41] ppcls INFO: [Train][Epoch 246/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00718197, top1: 0.96691, CELoss: 0.10226, loss: 0.10226, batch_cost: 0.62368s, reader_cost: 0.01163, ips: 102.61602 samples/s, eta: 1:37:14
[2022/06/19 04:55:47] ppcls INFO: [Train][Epoch 246/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00716704, top1: 0.96773, CELoss: 0.09849, loss: 0.09849, batch_cost: 0.62473s, reader_cost: 0.02266, ips: 102.44474 samples/s, eta: 1:37:18
[2022/06/19 04:55:53] ppcls INFO: [Train][Epoch 246/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00715213, top1: 0.96919, CELoss: 0.09735, loss: 0.09735, batch_cost: 0.61483s, reader_cost: 0.02581, ips: 104.09458 samples/s, eta: 1:35:39
[2022/06/19 04:56:00] ppcls INFO: [Train][Epoch 246/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00713723, top1: 0.96817, CELoss: 0.09778, loss: 0.09778, batch_cost: 0.62221s, reader_cost: 0.03820, ips: 102.85875 samples/s, eta: 1:36:42
[2022/06/19 04:56:05] ppcls INFO: [Train][Epoch 246/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00712234, top1: 0.96892, CELoss: 0.09614, loss: 0.09614, batch_cost: 0.61595s, reader_cost: 0.03434, ips: 103.90538 samples/s, eta: 1:35:37
[2022/06/19 04:56:11] ppcls INFO: [Train][Epoch 246/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00710747, top1: 0.96844, CELoss: 0.09739, loss: 0.09739, batch_cost: 0.61437s, reader_cost: 0.03715, ips: 104.17209 samples/s, eta: 1:35:16
[2022/06/19 04:56:18] ppcls INFO: [Train][Epoch 246/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00709261, top1: 0.96819, CELoss: 0.09679, loss: 0.09679, batch_cost: 0.61321s, reader_cost: 0.03413, ips: 104.36845 samples/s, eta: 1:34:59
[2022/06/19 04:56:23] ppcls INFO: [Train][Epoch 246/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00707777, top1: 0.96823, CELoss: 0.09706, loss: 0.09706, batch_cost: 0.61097s, reader_cost: 0.03146, ips: 104.75156 samples/s, eta: 1:34:32
[2022/06/19 04:56:31] ppcls INFO: [Train][Epoch 246/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00706294, top1: 0.96887, CELoss: 0.09569, loss: 0.09569, batch_cost: 0.62034s, reader_cost: 0.02968, ips: 103.16927 samples/s, eta: 1:35:53
[2022/06/19 04:56:36] ppcls INFO: [Train][Epoch 246/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00704813, top1: 0.96897, CELoss: 0.09565, loss: 0.09565, batch_cost: 0.61751s, reader_cost: 0.02867, ips: 103.64187 samples/s, eta: 1:35:21
[2022/06/19 04:56:43] ppcls INFO: [Train][Epoch 246/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00703333, top1: 0.96823, CELoss: 0.09790, loss: 0.09790, batch_cost: 0.61692s, reader_cost: 0.02808, ips: 103.74176 samples/s, eta: 1:35:09
[2022/06/19 04:56:48] ppcls INFO: [Train][Epoch 246/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00701854, top1: 0.96729, CELoss: 0.10027, loss: 0.10027, batch_cost: 0.61050s, reader_cost: 0.02645, ips: 104.83244 samples/s, eta: 1:34:04
[2022/06/19 04:56:50] ppcls INFO: [Train][Epoch 246/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00700377, top1: 0.96715, CELoss: 0.09955, loss: 0.09955, batch_cost: 0.58636s, reader_cost: 0.02486, ips: 83.56573 samples/s, eta: 1:30:15
[2022/06/19 04:56:51] ppcls INFO: [Train][Epoch 246/300][Avg]top1: 0.96715, CELoss: 0.09955, loss: 0.09955
[2022/06/19 04:56:51] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:56:58] ppcls INFO: [Train][Epoch 247/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00700229, top1: 0.98438, CELoss: 0.04544, loss: 0.04544, batch_cost: 0.62911s, reader_cost: 0.06315, ips: 101.73029 samples/s, eta: 1:36:49
[2022/06/19 04:57:05] ppcls INFO: [Train][Epoch 247/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00698753, top1: 0.97017, CELoss: 0.08900, loss: 0.08900, batch_cost: 0.71400s, reader_cost: 0.18673, ips: 89.63566 samples/s, eta: 1:49:45
[2022/06/19 04:57:11] ppcls INFO: [Train][Epoch 247/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00697279, top1: 0.95982, CELoss: 0.11768, loss: 0.11768, batch_cost: 0.63117s, reader_cost: 0.07956, ips: 101.39921 samples/s, eta: 1:36:55
[2022/06/19 04:57:17] ppcls INFO: [Train][Epoch 247/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00695806, top1: 0.95766, CELoss: 0.12072, loss: 0.12072, batch_cost: 0.61909s, reader_cost: 0.05883, ips: 103.37677 samples/s, eta: 1:34:58
[2022/06/19 04:57:23] ppcls INFO: [Train][Epoch 247/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00694335, top1: 0.96151, CELoss: 0.11360, loss: 0.11360, batch_cost: 0.61335s, reader_cost: 0.05036, ips: 104.34519 samples/s, eta: 1:33:59
[2022/06/19 04:57:29] ppcls INFO: [Train][Epoch 247/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00692865, top1: 0.96293, CELoss: 0.11533, loss: 0.11533, batch_cost: 0.61480s, reader_cost: 0.04150, ips: 104.09852 samples/s, eta: 1:34:06
[2022/06/19 04:57:36] ppcls INFO: [Train][Epoch 247/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00691397, top1: 0.96209, CELoss: 0.11594, loss: 0.11594, batch_cost: 0.62798s, reader_cost: 0.03652, ips: 101.91370 samples/s, eta: 1:36:01
[2022/06/19 04:57:41] ppcls INFO: [Train][Epoch 247/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00689930, top1: 0.96369, CELoss: 0.11383, loss: 0.11383, batch_cost: 0.61815s, reader_cost: 0.03526, ips: 103.53463 samples/s, eta: 1:34:24
[2022/06/19 04:57:47] ppcls INFO: [Train][Epoch 247/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00688464, top1: 0.96489, CELoss: 0.11233, loss: 0.11233, batch_cost: 0.60909s, reader_cost: 0.03213, ips: 105.07397 samples/s, eta: 1:32:55
[2022/06/19 04:57:53] ppcls INFO: [Train][Epoch 247/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00687000, top1: 0.96549, CELoss: 0.11189, loss: 0.11189, batch_cost: 0.60798s, reader_cost: 0.02912, ips: 105.26626 samples/s, eta: 1:32:39
[2022/06/19 04:57:59] ppcls INFO: [Train][Epoch 247/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00685537, top1: 0.96519, CELoss: 0.11107, loss: 0.11107, batch_cost: 0.60706s, reader_cost: 0.02702, ips: 105.42608 samples/s, eta: 1:32:24
[2022/06/19 04:58:06] ppcls INFO: [Train][Epoch 247/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00684076, top1: 0.96495, CELoss: 0.11057, loss: 0.11057, batch_cost: 0.61404s, reader_cost: 0.02511, ips: 104.22797 samples/s, eta: 1:33:22
[2022/06/19 04:58:11] ppcls INFO: [Train][Epoch 247/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00682616, top1: 0.96462, CELoss: 0.11049, loss: 0.11049, batch_cost: 0.60841s, reader_cost: 0.02445, ips: 105.19248 samples/s, eta: 1:32:25
[2022/06/19 04:58:18] ppcls INFO: [Train][Epoch 247/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00681157, top1: 0.96458, CELoss: 0.11058, loss: 0.11058, batch_cost: 0.61178s, reader_cost: 0.02306, ips: 104.61210 samples/s, eta: 1:32:49
[2022/06/19 04:58:24] ppcls INFO: [Train][Epoch 247/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00679700, top1: 0.96554, CELoss: 0.10754, loss: 0.10754, batch_cost: 0.61296s, reader_cost: 0.02250, ips: 104.41075 samples/s, eta: 1:32:54
[2022/06/19 04:58:30] ppcls INFO: [Train][Epoch 247/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00678245, top1: 0.96513, CELoss: 0.10743, loss: 0.10743, batch_cost: 0.61150s, reader_cost: 0.02197, ips: 104.66006 samples/s, eta: 1:32:34
[2022/06/19 04:58:35] ppcls INFO: [Train][Epoch 247/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00676790, top1: 0.96516, CELoss: 0.10724, loss: 0.10724, batch_cost: 0.60429s, reader_cost: 0.02091, ips: 105.90907 samples/s, eta: 1:31:23
[2022/06/19 04:58:37] ppcls INFO: [Train][Epoch 247/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00675338, top1: 0.96560, CELoss: 0.10558, loss: 0.10558, batch_cost: 0.58083s, reader_cost: 0.01974, ips: 84.36242 samples/s, eta: 1:27:44
[2022/06/19 04:58:38] ppcls INFO: [Train][Epoch 247/300][Avg]top1: 0.96560, CELoss: 0.10558, loss: 0.10558
[2022/06/19 04:58:38] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 04:58:43] ppcls INFO: [Train][Epoch 248/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00675192, top1: 1.00000, CELoss: 0.01600, loss: 0.01600, batch_cost: 0.61025s, reader_cost: 0.04885, ips: 104.87435 samples/s, eta: 1:32:10
[2022/06/19 04:58:51] ppcls INFO: [Train][Epoch 248/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00673741, top1: 0.96733, CELoss: 0.09526, loss: 0.09526, batch_cost: 0.76323s, reader_cost: 0.01814, ips: 83.85382 samples/s, eta: 1:55:09
[2022/06/19 04:58:57] ppcls INFO: [Train][Epoch 248/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00672292, top1: 0.96354, CELoss: 0.10242, loss: 0.10242, batch_cost: 0.65610s, reader_cost: 0.02436, ips: 97.54655 samples/s, eta: 1:38:53
[2022/06/19 04:59:04] ppcls INFO: [Train][Epoch 248/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00670843, top1: 0.96825, CELoss: 0.09703, loss: 0.09703, batch_cost: 0.66478s, reader_cost: 0.02330, ips: 96.27190 samples/s, eta: 1:40:04
[2022/06/19 04:59:10] ppcls INFO: [Train][Epoch 248/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00669396, top1: 0.97027, CELoss: 0.09528, loss: 0.09528, batch_cost: 0.64380s, reader_cost: 0.01884, ips: 99.40981 samples/s, eta: 1:36:49
[2022/06/19 04:59:18] ppcls INFO: [Train][Epoch 248/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00667951, top1: 0.97120, CELoss: 0.09148, loss: 0.09148, batch_cost: 0.68094s, reader_cost: 0.01967, ips: 93.98742 samples/s, eta: 1:42:17
[2022/06/19 04:59:23] ppcls INFO: [Train][Epoch 248/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00666507, top1: 0.96926, CELoss: 0.09494, loss: 0.09494, batch_cost: 0.64388s, reader_cost: 0.01777, ips: 99.39687 samples/s, eta: 1:36:36
[2022/06/19 04:59:29] ppcls INFO: [Train][Epoch 248/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00665064, top1: 0.96743, CELoss: 0.09866, loss: 0.09866, batch_cost: 0.63754s, reader_cost: 0.01768, ips: 100.38572 samples/s, eta: 1:35:33
[2022/06/19 04:59:34] ppcls INFO: [Train][Epoch 248/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00663623, top1: 0.96779, CELoss: 0.09827, loss: 0.09827, batch_cost: 0.62982s, reader_cost: 0.01800, ips: 101.61621 samples/s, eta: 1:34:17
[2022/06/19 04:59:41] ppcls INFO: [Train][Epoch 248/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00662184, top1: 0.96789, CELoss: 0.09788, loss: 0.09788, batch_cost: 0.62867s, reader_cost: 0.02089, ips: 101.80230 samples/s, eta: 1:34:01
[2022/06/19 04:59:47] ppcls INFO: [Train][Epoch 248/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00660745, top1: 0.96767, CELoss: 0.09862, loss: 0.09862, batch_cost: 0.63309s, reader_cost: 0.02062, ips: 101.09159 samples/s, eta: 1:34:34
[2022/06/19 04:59:53] ppcls INFO: [Train][Epoch 248/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00659309, top1: 0.96805, CELoss: 0.09893, loss: 0.09893, batch_cost: 0.62619s, reader_cost: 0.02065, ips: 102.20551 samples/s, eta: 1:33:26
[2022/06/19 04:59:59] ppcls INFO: [Train][Epoch 248/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00657873, top1: 0.96849, CELoss: 0.09932, loss: 0.09932, batch_cost: 0.62214s, reader_cost: 0.02087, ips: 102.87109 samples/s, eta: 1:32:43
[2022/06/19 05:00:06] ppcls INFO: [Train][Epoch 248/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00656439, top1: 0.96732, CELoss: 0.10063, loss: 0.10063, batch_cost: 0.62686s, reader_cost: 0.02029, ips: 102.09600 samples/s, eta: 1:33:19
[2022/06/19 05:00:12] ppcls INFO: [Train][Epoch 248/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00655007, top1: 0.96709, CELoss: 0.10032, loss: 0.10032, batch_cost: 0.63123s, reader_cost: 0.01970, ips: 101.38913 samples/s, eta: 1:33:52
[2022/06/19 05:00:17] ppcls INFO: [Train][Epoch 248/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00653576, top1: 0.96637, CELoss: 0.10140, loss: 0.10140, batch_cost: 0.61896s, reader_cost: 0.01921, ips: 103.39987 samples/s, eta: 1:31:56
[2022/06/19 05:00:23] ppcls INFO: [Train][Epoch 248/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00652146, top1: 0.96603, CELoss: 0.10231, loss: 0.10231, batch_cost: 0.61553s, reader_cost: 0.01807, ips: 103.97603 samples/s, eta: 1:31:20
[2022/06/19 05:00:25] ppcls INFO: [Train][Epoch 248/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00650718, top1: 0.96624, CELoss: 0.10187, loss: 0.10187, batch_cost: 0.59140s, reader_cost: 0.01703, ips: 82.85422 samples/s, eta: 1:27:39
[2022/06/19 05:00:25] ppcls INFO: [Train][Epoch 248/300][Avg]top1: 0.96624, CELoss: 0.10187, loss: 0.10187
[2022/06/19 05:00:26] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:00:32] ppcls INFO: [Train][Epoch 249/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00650575, top1: 0.98438, CELoss: 0.03833, loss: 0.03833, batch_cost: 0.62429s, reader_cost: 0.04737, ips: 102.51673 samples/s, eta: 1:32:31
[2022/06/19 05:00:39] ppcls INFO: [Train][Epoch 249/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00649149, top1: 0.97159, CELoss: 0.07940, loss: 0.07940, batch_cost: 0.68157s, reader_cost: 0.01372, ips: 93.90146 samples/s, eta: 1:40:53
[2022/06/19 05:00:45] ppcls INFO: [Train][Epoch 249/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00647724, top1: 0.96875, CELoss: 0.08549, loss: 0.08549, batch_cost: 0.61763s, reader_cost: 0.01347, ips: 103.62183 samples/s, eta: 1:31:19
[2022/06/19 05:00:51] ppcls INFO: [Train][Epoch 249/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00646300, top1: 0.96573, CELoss: 0.09803, loss: 0.09803, batch_cost: 0.60712s, reader_cost: 0.02094, ips: 105.41513 samples/s, eta: 1:29:40
[2022/06/19 05:00:57] ppcls INFO: [Train][Epoch 249/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00644878, top1: 0.96532, CELoss: 0.10352, loss: 0.10352, batch_cost: 0.60223s, reader_cost: 0.02154, ips: 106.27104 samples/s, eta: 1:28:50
[2022/06/19 05:01:03] ppcls INFO: [Train][Epoch 249/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00643457, top1: 0.96722, CELoss: 0.10014, loss: 0.10014, batch_cost: 0.60833s, reader_cost: 0.01817, ips: 105.20668 samples/s, eta: 1:29:38
[2022/06/19 05:01:08] ppcls INFO: [Train][Epoch 249/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00642038, top1: 0.96824, CELoss: 0.09634, loss: 0.09634, batch_cost: 0.59644s, reader_cost: 0.01867, ips: 107.30261 samples/s, eta: 1:27:47
[2022/06/19 05:01:14] ppcls INFO: [Train][Epoch 249/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00640620, top1: 0.96633, CELoss: 0.10134, loss: 0.10134, batch_cost: 0.59818s, reader_cost: 0.01653, ips: 106.99101 samples/s, eta: 1:27:57
[2022/06/19 05:01:21] ppcls INFO: [Train][Epoch 249/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00639203, top1: 0.96605, CELoss: 0.10290, loss: 0.10290, batch_cost: 0.60881s, reader_cost: 0.03490, ips: 105.12370 samples/s, eta: 1:29:24
[2022/06/19 05:01:27] ppcls INFO: [Train][Epoch 249/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00637788, top1: 0.96549, CELoss: 0.10502, loss: 0.10502, batch_cost: 0.60193s, reader_cost: 0.03662, ips: 106.32443 samples/s, eta: 1:28:18
[2022/06/19 05:01:33] ppcls INFO: [Train][Epoch 249/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00636375, top1: 0.96442, CELoss: 0.10461, loss: 0.10461, batch_cost: 0.60057s, reader_cost: 0.03513, ips: 106.56494 samples/s, eta: 1:28:00
[2022/06/19 05:01:39] ppcls INFO: [Train][Epoch 249/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00634963, top1: 0.96467, CELoss: 0.10324, loss: 0.10324, batch_cost: 0.60259s, reader_cost: 0.03698, ips: 106.20805 samples/s, eta: 1:28:11
[2022/06/19 05:01:45] ppcls INFO: [Train][Epoch 249/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00633552, top1: 0.96423, CELoss: 0.10331, loss: 0.10331, batch_cost: 0.60599s, reader_cost: 0.04437, ips: 105.61197 samples/s, eta: 1:28:35
[2022/06/19 05:01:51] ppcls INFO: [Train][Epoch 249/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00632143, top1: 0.96398, CELoss: 0.10625, loss: 0.10625, batch_cost: 0.60046s, reader_cost: 0.04270, ips: 106.58579 samples/s, eta: 1:27:41
[2022/06/19 05:01:57] ppcls INFO: [Train][Epoch 249/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00630735, top1: 0.96376, CELoss: 0.10664, loss: 0.10664, batch_cost: 0.60124s, reader_cost: 0.05012, ips: 106.44750 samples/s, eta: 1:27:42
[2022/06/19 05:02:03] ppcls INFO: [Train][Epoch 249/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00629329, top1: 0.96409, CELoss: 0.10736, loss: 0.10736, batch_cost: 0.60191s, reader_cost: 0.04698, ips: 106.32905 samples/s, eta: 1:27:41
[2022/06/19 05:02:08] ppcls INFO: [Train][Epoch 249/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00627924, top1: 0.96438, CELoss: 0.10579, loss: 0.10579, batch_cost: 0.59318s, reader_cost: 0.04533, ips: 107.89258 samples/s, eta: 1:26:19
[2022/06/19 05:02:10] ppcls INFO: [Train][Epoch 249/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00626521, top1: 0.96432, CELoss: 0.10602, loss: 0.10602, batch_cost: 0.57036s, reader_cost: 0.04263, ips: 85.91084 samples/s, eta: 1:22:54
[2022/06/19 05:02:10] ppcls INFO: [Train][Epoch 249/300][Avg]top1: 0.96432, CELoss: 0.10602, loss: 0.10602
[2022/06/19 05:02:10] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:02:19] ppcls INFO: [Train][Epoch 250/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00626380, top1: 0.96875, CELoss: 0.06885, loss: 0.06885, batch_cost: 0.61667s, reader_cost: 0.06743, ips: 103.78322 samples/s, eta: 1:29:37
[2022/06/19 05:02:24] ppcls INFO: [Train][Epoch 250/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00624979, top1: 0.96733, CELoss: 0.09317, loss: 0.09317, batch_cost: 0.64804s, reader_cost: 0.00958, ips: 98.75933 samples/s, eta: 1:34:05
[2022/06/19 05:02:30] ppcls INFO: [Train][Epoch 250/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00623578, top1: 0.96801, CELoss: 0.08624, loss: 0.08624, batch_cost: 0.59977s, reader_cost: 0.01689, ips: 106.70682 samples/s, eta: 1:26:58
[2022/06/19 05:02:37] ppcls INFO: [Train][Epoch 250/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00622179, top1: 0.96522, CELoss: 0.09155, loss: 0.09155, batch_cost: 0.61451s, reader_cost: 0.01505, ips: 104.14861 samples/s, eta: 1:29:00
[2022/06/19 05:02:43] ppcls INFO: [Train][Epoch 250/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00620782, top1: 0.96646, CELoss: 0.08842, loss: 0.08842, batch_cost: 0.61889s, reader_cost: 0.01791, ips: 103.41142 samples/s, eta: 1:29:32
[2022/06/19 05:02:49] ppcls INFO: [Train][Epoch 250/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00619386, top1: 0.96844, CELoss: 0.08931, loss: 0.08931, batch_cost: 0.61915s, reader_cost: 0.01708, ips: 103.36737 samples/s, eta: 1:29:28
[2022/06/19 05:02:54] ppcls INFO: [Train][Epoch 250/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00617991, top1: 0.96644, CELoss: 0.09754, loss: 0.09754, batch_cost: 0.60322s, reader_cost: 0.01964, ips: 106.09644 samples/s, eta: 1:27:04
[2022/06/19 05:03:00] ppcls INFO: [Train][Epoch 250/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00616598, top1: 0.96853, CELoss: 0.09308, loss: 0.09308, batch_cost: 0.59660s, reader_cost: 0.02005, ips: 107.27437 samples/s, eta: 1:26:01
[2022/06/19 05:03:06] ppcls INFO: [Train][Epoch 250/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00615207, top1: 0.96856, CELoss: 0.09709, loss: 0.09709, batch_cost: 0.59159s, reader_cost: 0.01901, ips: 108.18353 samples/s, eta: 1:25:11
[2022/06/19 05:03:12] ppcls INFO: [Train][Epoch 250/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00613817, top1: 0.96841, CELoss: 0.09669, loss: 0.09669, batch_cost: 0.59967s, reader_cost: 0.03019, ips: 106.72524 samples/s, eta: 1:26:15
[2022/06/19 05:03:19] ppcls INFO: [Train][Epoch 250/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00612428, top1: 0.96860, CELoss: 0.09736, loss: 0.09736, batch_cost: 0.60693s, reader_cost: 0.04311, ips: 105.44928 samples/s, eta: 1:27:12
[2022/06/19 05:03:25] ppcls INFO: [Train][Epoch 250/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00611041, top1: 0.96917, CELoss: 0.09653, loss: 0.09653, batch_cost: 0.60431s, reader_cost: 0.03964, ips: 105.90564 samples/s, eta: 1:26:43
[2022/06/19 05:03:31] ppcls INFO: [Train][Epoch 250/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00609655, top1: 0.96940, CELoss: 0.09563, loss: 0.09563, batch_cost: 0.60909s, reader_cost: 0.03793, ips: 105.07537 samples/s, eta: 1:27:18
[2022/06/19 05:03:37] ppcls INFO: [Train][Epoch 250/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00608271, top1: 0.96947, CELoss: 0.09530, loss: 0.09530, batch_cost: 0.60681s, reader_cost: 0.03591, ips: 105.47006 samples/s, eta: 1:26:53
[2022/06/19 05:03:44] ppcls INFO: [Train][Epoch 250/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00606888, top1: 0.96908, CELoss: 0.09670, loss: 0.09670, batch_cost: 0.61003s, reader_cost: 0.04350, ips: 104.91213 samples/s, eta: 1:27:14
[2022/06/19 05:03:49] ppcls INFO: [Train][Epoch 250/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00605506, top1: 0.96916, CELoss: 0.09622, loss: 0.09622, batch_cost: 0.60664s, reader_cost: 0.04534, ips: 105.49981 samples/s, eta: 1:26:39
[2022/06/19 05:03:55] ppcls INFO: [Train][Epoch 250/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00604126, top1: 0.96924, CELoss: 0.09528, loss: 0.09528, batch_cost: 0.60206s, reader_cost: 0.04921, ips: 106.30187 samples/s, eta: 1:25:54
[2022/06/19 05:03:57] ppcls INFO: [Train][Epoch 250/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00602748, top1: 0.96944, CELoss: 0.09487, loss: 0.09487, batch_cost: 0.57861s, reader_cost: 0.04625, ips: 84.68583 samples/s, eta: 1:22:27
[2022/06/19 05:03:57] ppcls INFO: [Train][Epoch 250/300][Avg]top1: 0.96944, CELoss: 0.09487, loss: 0.09487
[2022/06/19 05:04:04] ppcls INFO: [Eval][Epoch 250][Iter: 0/16]CELoss: 1.09677, loss: 1.09677, top1: 0.80469, batch_cost: 7.03989s, reader_cost: 3.50078, ips: 9.09105 images/sec
[2022/06/19 05:04:12] ppcls INFO: [Eval][Epoch 250][Iter: 10/16]CELoss: 1.10339, loss: 1.10339, top1: 0.81765, batch_cost: 0.57175s, reader_cost: 0.00345, ips: 111.93777 images/sec
[2022/06/19 05:04:14] ppcls INFO: [Eval][Epoch 250][Avg]CELoss: 0.84671, loss: 0.84671, top1: 0.82586
[2022/06/19 05:04:14] ppcls INFO: [Eval][Epoch 250][best metric: 0.8276961445808411]
[2022/06/19 05:04:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_250
[2022/06/19 05:04:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:04:20] ppcls INFO: [Train][Epoch 251/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00602610, top1: 0.95312, CELoss: 0.13806, loss: 0.13806, batch_cost: 0.61071s, reader_cost: 0.07378, ips: 104.79537 samples/s, eta: 1:27:01
[2022/06/19 05:04:28] ppcls INFO: [Train][Epoch 251/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00601233, top1: 0.96449, CELoss: 0.10866, loss: 0.10866, batch_cost: 0.83623s, reader_cost: 0.00804, ips: 76.53413 samples/s, eta: 1:59:01
[2022/06/19 05:04:34] ppcls INFO: [Train][Epoch 251/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00599858, top1: 0.96429, CELoss: 0.11025, loss: 0.11025, batch_cost: 0.72401s, reader_cost: 0.01359, ips: 88.39705 samples/s, eta: 1:42:55
[2022/06/19 05:04:40] ppcls INFO: [Train][Epoch 251/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00598484, top1: 0.96673, CELoss: 0.09976, loss: 0.09976, batch_cost: 0.66949s, reader_cost: 0.01392, ips: 95.59479 samples/s, eta: 1:35:04
[2022/06/19 05:04:46] ppcls INFO: [Train][Epoch 251/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00597111, top1: 0.96799, CELoss: 0.09822, loss: 0.09822, batch_cost: 0.64412s, reader_cost: 0.01643, ips: 99.36028 samples/s, eta: 1:31:21
[2022/06/19 05:04:53] ppcls INFO: [Train][Epoch 251/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00595740, top1: 0.96722, CELoss: 0.09929, loss: 0.09929, batch_cost: 0.65904s, reader_cost: 0.01571, ips: 97.11153 samples/s, eta: 1:33:21
[2022/06/19 05:04:58] ppcls INFO: [Train][Epoch 251/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00594371, top1: 0.96747, CELoss: 0.09834, loss: 0.09834, batch_cost: 0.63391s, reader_cost: 0.01748, ips: 100.96015 samples/s, eta: 1:29:41
[2022/06/19 05:05:04] ppcls INFO: [Train][Epoch 251/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00593003, top1: 0.96765, CELoss: 0.09977, loss: 0.09977, batch_cost: 0.62401s, reader_cost: 0.01785, ips: 102.56200 samples/s, eta: 1:28:11
[2022/06/19 05:05:10] ppcls INFO: [Train][Epoch 251/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00591636, top1: 0.96798, CELoss: 0.10089, loss: 0.10089, batch_cost: 0.61963s, reader_cost: 0.01952, ips: 103.28783 samples/s, eta: 1:27:28
[2022/06/19 05:05:16] ppcls INFO: [Train][Epoch 251/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00590271, top1: 0.96789, CELoss: 0.10084, loss: 0.10084, batch_cost: 0.62211s, reader_cost: 0.01822, ips: 102.87588 samples/s, eta: 1:27:43
[2022/06/19 05:05:23] ppcls INFO: [Train][Epoch 251/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00588907, top1: 0.96860, CELoss: 0.09846, loss: 0.09846, batch_cost: 0.62812s, reader_cost: 0.01818, ips: 101.89090 samples/s, eta: 1:28:27
[2022/06/19 05:05:31] ppcls INFO: [Train][Epoch 251/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00587545, top1: 0.96889, CELoss: 0.09693, loss: 0.09693, batch_cost: 0.64669s, reader_cost: 0.01675, ips: 98.96494 samples/s, eta: 1:30:58
[2022/06/19 05:05:36] ppcls INFO: [Train][Epoch 251/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00586184, top1: 0.96836, CELoss: 0.10012, loss: 0.10012, batch_cost: 0.63690s, reader_cost: 0.01587, ips: 100.48743 samples/s, eta: 1:29:29
[2022/06/19 05:05:42] ppcls INFO: [Train][Epoch 251/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00584825, top1: 0.96792, CELoss: 0.10000, loss: 0.10000, batch_cost: 0.63409s, reader_cost: 0.01575, ips: 100.93271 samples/s, eta: 1:28:59
[2022/06/19 05:05:48] ppcls INFO: [Train][Epoch 251/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00583467, top1: 0.96775, CELoss: 0.10036, loss: 0.10036, batch_cost: 0.63066s, reader_cost: 0.01581, ips: 101.48121 samples/s, eta: 1:28:23
[2022/06/19 05:05:54] ppcls INFO: [Train][Epoch 251/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00582111, top1: 0.96782, CELoss: 0.09955, loss: 0.09955, batch_cost: 0.63008s, reader_cost: 0.01540, ips: 101.57394 samples/s, eta: 1:28:12
[2022/06/19 05:05:59] ppcls INFO: [Train][Epoch 251/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00580756, top1: 0.96836, CELoss: 0.09911, loss: 0.09911, batch_cost: 0.61950s, reader_cost: 0.01467, ips: 103.30831 samples/s, eta: 1:26:37
[2022/06/19 05:06:01] ppcls INFO: [Train][Epoch 251/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00579403, top1: 0.96889, CELoss: 0.09831, loss: 0.09831, batch_cost: 0.59501s, reader_cost: 0.01379, ips: 82.35133 samples/s, eta: 1:23:06
[2022/06/19 05:06:02] ppcls INFO: [Train][Epoch 251/300][Avg]top1: 0.96889, CELoss: 0.09831, loss: 0.09831
[2022/06/19 05:06:02] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:06:09] ppcls INFO: [Train][Epoch 252/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00579267, top1: 0.96875, CELoss: 0.11930, loss: 0.11930, batch_cost: 0.63106s, reader_cost: 0.04546, ips: 101.41613 samples/s, eta: 1:28:07
[2022/06/19 05:06:16] ppcls INFO: [Train][Epoch 252/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00577916, top1: 0.97017, CELoss: 0.09149, loss: 0.09149, batch_cost: 0.71662s, reader_cost: 0.14457, ips: 89.30796 samples/s, eta: 1:39:57
[2022/06/19 05:06:22] ppcls INFO: [Train][Epoch 252/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00576565, top1: 0.96429, CELoss: 0.09623, loss: 0.09623, batch_cost: 0.65596s, reader_cost: 0.06812, ips: 97.56719 samples/s, eta: 1:31:23
[2022/06/19 05:06:28] ppcls INFO: [Train][Epoch 252/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00575216, top1: 0.96169, CELoss: 0.10380, loss: 0.10380, batch_cost: 0.64602s, reader_cost: 0.05981, ips: 99.06754 samples/s, eta: 1:29:53
[2022/06/19 05:06:34] ppcls INFO: [Train][Epoch 252/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00573869, top1: 0.96418, CELoss: 0.10003, loss: 0.10003, batch_cost: 0.63289s, reader_cost: 0.04608, ips: 101.12285 samples/s, eta: 1:27:57
[2022/06/19 05:06:41] ppcls INFO: [Train][Epoch 252/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00572523, top1: 0.96262, CELoss: 0.10711, loss: 0.10711, batch_cost: 0.64125s, reader_cost: 0.06438, ips: 99.80570 samples/s, eta: 1:29:00
[2022/06/19 05:06:47] ppcls INFO: [Train][Epoch 252/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00571179, top1: 0.96183, CELoss: 0.10838, loss: 0.10838, batch_cost: 0.63520s, reader_cost: 0.05527, ips: 100.75522 samples/s, eta: 1:28:04
[2022/06/19 05:06:54] ppcls INFO: [Train][Epoch 252/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00569836, top1: 0.96281, CELoss: 0.10696, loss: 0.10696, batch_cost: 0.64255s, reader_cost: 0.04920, ips: 99.60324 samples/s, eta: 1:28:58
[2022/06/19 05:06:59] ppcls INFO: [Train][Epoch 252/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00568494, top1: 0.96335, CELoss: 0.10681, loss: 0.10681, batch_cost: 0.62360s, reader_cost: 0.04656, ips: 102.62938 samples/s, eta: 1:26:15
[2022/06/19 05:07:04] ppcls INFO: [Train][Epoch 252/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00567154, top1: 0.96326, CELoss: 0.10698, loss: 0.10698, batch_cost: 0.61475s, reader_cost: 0.04451, ips: 104.10778 samples/s, eta: 1:24:55
[2022/06/19 05:07:10] ppcls INFO: [Train][Epoch 252/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00565816, top1: 0.96411, CELoss: 0.10441, loss: 0.10441, batch_cost: 0.61223s, reader_cost: 0.04140, ips: 104.53527 samples/s, eta: 1:24:28
[2022/06/19 05:07:16] ppcls INFO: [Train][Epoch 252/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00564479, top1: 0.96410, CELoss: 0.10628, loss: 0.10628, batch_cost: 0.60829s, reader_cost: 0.03947, ips: 105.21274 samples/s, eta: 1:23:49
[2022/06/19 05:07:23] ppcls INFO: [Train][Epoch 252/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00563143, top1: 0.96488, CELoss: 0.10485, loss: 0.10485, batch_cost: 0.61795s, reader_cost: 0.03646, ips: 103.56849 samples/s, eta: 1:25:03
[2022/06/19 05:07:30] ppcls INFO: [Train][Epoch 252/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00561809, top1: 0.96469, CELoss: 0.10533, loss: 0.10533, batch_cost: 0.62346s, reader_cost: 0.03522, ips: 102.65214 samples/s, eta: 1:25:42
[2022/06/19 05:07:36] ppcls INFO: [Train][Epoch 252/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00560476, top1: 0.96487, CELoss: 0.10383, loss: 0.10383, batch_cost: 0.62118s, reader_cost: 0.03361, ips: 103.02941 samples/s, eta: 1:25:17
[2022/06/19 05:07:43] ppcls INFO: [Train][Epoch 252/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00559145, top1: 0.96492, CELoss: 0.10509, loss: 0.10509, batch_cost: 0.62578s, reader_cost: 0.03261, ips: 102.27185 samples/s, eta: 1:25:49
[2022/06/19 05:07:46] ppcls INFO: [Train][Epoch 252/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00557815, top1: 0.96497, CELoss: 0.10591, loss: 0.10591, batch_cost: 0.60948s, reader_cost: 0.03066, ips: 105.00778 samples/s, eta: 1:23:29
[2022/06/19 05:07:49] ppcls INFO: [Train][Epoch 252/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00556487, top1: 0.96569, CELoss: 0.10360, loss: 0.10360, batch_cost: 0.58562s, reader_cost: 0.02882, ips: 83.67154 samples/s, eta: 1:20:07
[2022/06/19 05:07:49] ppcls INFO: [Train][Epoch 252/300][Avg]top1: 0.96569, CELoss: 0.10360, loss: 0.10360
[2022/06/19 05:07:49] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:07:55] ppcls INFO: [Train][Epoch 253/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00556354, top1: 0.95312, CELoss: 0.15034, loss: 0.15034, batch_cost: 0.61708s, reader_cost: 0.05876, ips: 103.71413 samples/s, eta: 1:24:24
[2022/06/19 05:08:02] ppcls INFO: [Train][Epoch 253/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00555028, top1: 0.97017, CELoss: 0.09180, loss: 0.09180, batch_cost: 0.68436s, reader_cost: 0.01769, ips: 93.51836 samples/s, eta: 1:33:30
[2022/06/19 05:08:09] ppcls INFO: [Train][Epoch 253/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00553703, top1: 0.97470, CELoss: 0.08448, loss: 0.08448, batch_cost: 0.71166s, reader_cost: 0.01844, ips: 89.93087 samples/s, eta: 1:37:07
[2022/06/19 05:08:16] ppcls INFO: [Train][Epoch 253/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00552379, top1: 0.97228, CELoss: 0.08364, loss: 0.08364, batch_cost: 0.69508s, reader_cost: 0.01732, ips: 92.07608 samples/s, eta: 1:34:44
[2022/06/19 05:08:22] ppcls INFO: [Train][Epoch 253/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00551057, top1: 0.97104, CELoss: 0.08326, loss: 0.08326, batch_cost: 0.66125s, reader_cost: 0.01583, ips: 96.78632 samples/s, eta: 1:30:01
[2022/06/19 05:08:28] ppcls INFO: [Train][Epoch 253/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00549736, top1: 0.97151, CELoss: 0.08270, loss: 0.08270, batch_cost: 0.65161s, reader_cost: 0.02114, ips: 98.21794 samples/s, eta: 1:28:35
[2022/06/19 05:08:34] ppcls INFO: [Train][Epoch 253/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00548417, top1: 0.97234, CELoss: 0.08195, loss: 0.08195, batch_cost: 0.64469s, reader_cost: 0.02075, ips: 99.27324 samples/s, eta: 1:27:32
[2022/06/19 05:08:40] ppcls INFO: [Train][Epoch 253/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00547100, top1: 0.97183, CELoss: 0.08285, loss: 0.08285, batch_cost: 0.64224s, reader_cost: 0.01842, ips: 99.65102 samples/s, eta: 1:27:06
[2022/06/19 05:08:46] ppcls INFO: [Train][Epoch 253/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00545783, top1: 0.97203, CELoss: 0.08327, loss: 0.08327, batch_cost: 0.63129s, reader_cost: 0.01857, ips: 101.37935 samples/s, eta: 1:25:31
[2022/06/19 05:08:52] ppcls INFO: [Train][Epoch 253/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00544469, top1: 0.97201, CELoss: 0.08456, loss: 0.08456, batch_cost: 0.62768s, reader_cost: 0.01906, ips: 101.96270 samples/s, eta: 1:24:55
[2022/06/19 05:08:58] ppcls INFO: [Train][Epoch 253/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00543155, top1: 0.97184, CELoss: 0.08551, loss: 0.08551, batch_cost: 0.62996s, reader_cost: 0.01977, ips: 101.59449 samples/s, eta: 1:25:07
[2022/06/19 05:09:04] ppcls INFO: [Train][Epoch 253/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00541844, top1: 0.97128, CELoss: 0.08774, loss: 0.08774, batch_cost: 0.62431s, reader_cost: 0.02057, ips: 102.51281 samples/s, eta: 1:24:15
[2022/06/19 05:09:10] ppcls INFO: [Train][Epoch 253/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00540533, top1: 0.97107, CELoss: 0.08800, loss: 0.08800, batch_cost: 0.62462s, reader_cost: 0.02043, ips: 102.46247 samples/s, eta: 1:24:11
[2022/06/19 05:09:17] ppcls INFO: [Train][Epoch 253/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00539225, top1: 0.97102, CELoss: 0.08962, loss: 0.08962, batch_cost: 0.62970s, reader_cost: 0.02039, ips: 101.63583 samples/s, eta: 1:24:46
[2022/06/19 05:09:23] ppcls INFO: [Train][Epoch 253/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00537917, top1: 0.97130, CELoss: 0.08991, loss: 0.08991, batch_cost: 0.62382s, reader_cost: 0.01923, ips: 102.59378 samples/s, eta: 1:23:52
[2022/06/19 05:09:29] ppcls INFO: [Train][Epoch 253/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00536611, top1: 0.97175, CELoss: 0.08820, loss: 0.08820, batch_cost: 0.62697s, reader_cost: 0.01885, ips: 102.07883 samples/s, eta: 1:24:12
[2022/06/19 05:09:34] ppcls INFO: [Train][Epoch 253/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00535307, top1: 0.97156, CELoss: 0.08955, loss: 0.08955, batch_cost: 0.61550s, reader_cost: 0.01955, ips: 103.98077 samples/s, eta: 1:22:33
[2022/06/19 05:09:36] ppcls INFO: [Train][Epoch 253/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00534004, top1: 0.97118, CELoss: 0.08985, loss: 0.08985, batch_cost: 0.59145s, reader_cost: 0.01840, ips: 82.84764 samples/s, eta: 1:19:14
[2022/06/19 05:09:37] ppcls INFO: [Train][Epoch 253/300][Avg]top1: 0.97118, CELoss: 0.08985, loss: 0.08985
[2022/06/19 05:09:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:09:43] ppcls INFO: [Train][Epoch 254/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00533874, top1: 0.98438, CELoss: 0.04985, loss: 0.04985, batch_cost: 0.62633s, reader_cost: 0.04220, ips: 102.18177 samples/s, eta: 1:23:53
[2022/06/19 05:09:50] ppcls INFO: [Train][Epoch 254/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00532573, top1: 0.98153, CELoss: 0.06827, loss: 0.06827, batch_cost: 0.71785s, reader_cost: 0.01473, ips: 89.15506 samples/s, eta: 1:36:02
[2022/06/19 05:09:56] ppcls INFO: [Train][Epoch 254/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00531273, top1: 0.97619, CELoss: 0.07922, loss: 0.07922, batch_cost: 0.65003s, reader_cost: 0.01682, ips: 98.45751 samples/s, eta: 1:26:51
[2022/06/19 05:10:03] ppcls INFO: [Train][Epoch 254/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00529975, top1: 0.97530, CELoss: 0.07813, loss: 0.07813, batch_cost: 0.65369s, reader_cost: 0.01203, ips: 97.90544 samples/s, eta: 1:27:14
[2022/06/19 05:10:09] ppcls INFO: [Train][Epoch 254/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00528678, top1: 0.97447, CELoss: 0.08338, loss: 0.08338, batch_cost: 0.63352s, reader_cost: 0.01576, ips: 101.02350 samples/s, eta: 1:24:26
[2022/06/19 05:10:14] ppcls INFO: [Train][Epoch 254/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00527383, top1: 0.97151, CELoss: 0.09057, loss: 0.09057, batch_cost: 0.61548s, reader_cost: 0.01678, ips: 103.98447 samples/s, eta: 1:21:55
[2022/06/19 05:10:20] ppcls INFO: [Train][Epoch 254/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00526089, top1: 0.97080, CELoss: 0.09246, loss: 0.09246, batch_cost: 0.60561s, reader_cost: 0.01722, ips: 105.67893 samples/s, eta: 1:20:30
[2022/06/19 05:10:26] ppcls INFO: [Train][Epoch 254/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00524797, top1: 0.97007, CELoss: 0.09412, loss: 0.09412, batch_cost: 0.61092s, reader_cost: 0.01966, ips: 104.76052 samples/s, eta: 1:21:07
[2022/06/19 05:10:32] ppcls INFO: [Train][Epoch 254/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00523506, top1: 0.97029, CELoss: 0.09260, loss: 0.09260, batch_cost: 0.61052s, reader_cost: 0.01802, ips: 104.82844 samples/s, eta: 1:20:57
[2022/06/19 05:10:40] ppcls INFO: [Train][Epoch 254/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00522217, top1: 0.97012, CELoss: 0.09146, loss: 0.09146, batch_cost: 0.62540s, reader_cost: 0.04083, ips: 102.33418 samples/s, eta: 1:22:50
[2022/06/19 05:10:46] ppcls INFO: [Train][Epoch 254/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00520929, top1: 0.96968, CELoss: 0.09224, loss: 0.09224, batch_cost: 0.62710s, reader_cost: 0.06164, ips: 102.05672 samples/s, eta: 1:22:57
[2022/06/19 05:10:51] ppcls INFO: [Train][Epoch 254/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00519643, top1: 0.96917, CELoss: 0.09164, loss: 0.09164, batch_cost: 0.61518s, reader_cost: 0.05643, ips: 104.03433 samples/s, eta: 1:21:16
[2022/06/19 05:10:57] ppcls INFO: [Train][Epoch 254/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00518358, top1: 0.96849, CELoss: 0.09308, loss: 0.09308, batch_cost: 0.60971s, reader_cost: 0.05303, ips: 104.96810 samples/s, eta: 1:20:27
[2022/06/19 05:11:03] ppcls INFO: [Train][Epoch 254/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00517075, top1: 0.96815, CELoss: 0.09429, loss: 0.09429, batch_cost: 0.60734s, reader_cost: 0.04975, ips: 105.37769 samples/s, eta: 1:20:02
[2022/06/19 05:11:08] ppcls INFO: [Train][Epoch 254/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00515793, top1: 0.96764, CELoss: 0.09426, loss: 0.09426, batch_cost: 0.60470s, reader_cost: 0.04664, ips: 105.83710 samples/s, eta: 1:19:35
[2022/06/19 05:11:15] ppcls INFO: [Train][Epoch 254/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00514512, top1: 0.96751, CELoss: 0.09532, loss: 0.09532, batch_cost: 0.60690s, reader_cost: 0.04968, ips: 105.45437 samples/s, eta: 1:19:46
[2022/06/19 05:11:21] ppcls INFO: [Train][Epoch 254/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00513234, top1: 0.96759, CELoss: 0.09474, loss: 0.09474, batch_cost: 0.60755s, reader_cost: 0.05823, ips: 105.34095 samples/s, eta: 1:19:45
[2022/06/19 05:11:23] ppcls INFO: [Train][Epoch 254/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00511956, top1: 0.96807, CELoss: 0.09433, loss: 0.09433, batch_cost: 0.58389s, reader_cost: 0.05475, ips: 83.91992 samples/s, eta: 1:16:33
[2022/06/19 05:11:24] ppcls INFO: [Train][Epoch 254/300][Avg]top1: 0.96807, CELoss: 0.09433, loss: 0.09433
[2022/06/19 05:11:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:11:31] ppcls INFO: [Train][Epoch 255/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00511829, top1: 0.96875, CELoss: 0.23588, loss: 0.23588, batch_cost: 0.62161s, reader_cost: 0.08915, ips: 102.95839 samples/s, eta: 1:21:29
[2022/06/19 05:11:38] ppcls INFO: [Train][Epoch 255/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00510553, top1: 0.97159, CELoss: 0.10426, loss: 0.10426, batch_cost: 0.75059s, reader_cost: 0.01554, ips: 85.26658 samples/s, eta: 1:38:16
[2022/06/19 05:11:44] ppcls INFO: [Train][Epoch 255/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00509279, top1: 0.97470, CELoss: 0.09055, loss: 0.09055, batch_cost: 0.65615s, reader_cost: 0.01947, ips: 97.53806 samples/s, eta: 1:25:48
[2022/06/19 05:11:50] ppcls INFO: [Train][Epoch 255/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00508006, top1: 0.97429, CELoss: 0.08306, loss: 0.08306, batch_cost: 0.63849s, reader_cost: 0.02047, ips: 100.23710 samples/s, eta: 1:23:23
[2022/06/19 05:11:56] ppcls INFO: [Train][Epoch 255/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00506735, top1: 0.97332, CELoss: 0.08427, loss: 0.08427, batch_cost: 0.63035s, reader_cost: 0.01954, ips: 101.53142 samples/s, eta: 1:22:13
[2022/06/19 05:12:02] ppcls INFO: [Train][Epoch 255/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00505465, top1: 0.96967, CELoss: 0.09181, loss: 0.09181, batch_cost: 0.61721s, reader_cost: 0.02014, ips: 103.69304 samples/s, eta: 1:20:24
[2022/06/19 05:12:08] ppcls INFO: [Train][Epoch 255/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00504197, top1: 0.97029, CELoss: 0.09108, loss: 0.09108, batch_cost: 0.61065s, reader_cost: 0.01992, ips: 104.80661 samples/s, eta: 1:19:26
[2022/06/19 05:12:14] ppcls INFO: [Train][Epoch 255/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00502930, top1: 0.97073, CELoss: 0.08786, loss: 0.08786, batch_cost: 0.61042s, reader_cost: 0.01919, ips: 104.84544 samples/s, eta: 1:19:18
[2022/06/19 05:12:19] ppcls INFO: [Train][Epoch 255/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00501665, top1: 0.96856, CELoss: 0.09061, loss: 0.09061, batch_cost: 0.60135s, reader_cost: 0.01860, ips: 106.42771 samples/s, eta: 1:18:02
[2022/06/19 05:12:25] ppcls INFO: [Train][Epoch 255/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00500401, top1: 0.96738, CELoss: 0.09258, loss: 0.09258, batch_cost: 0.60578s, reader_cost: 0.01793, ips: 105.64933 samples/s, eta: 1:18:30
[2022/06/19 05:12:32] ppcls INFO: [Train][Epoch 255/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00499139, top1: 0.96751, CELoss: 0.09342, loss: 0.09342, batch_cost: 0.61025s, reader_cost: 0.01781, ips: 104.87554 samples/s, eta: 1:18:59
[2022/06/19 05:12:38] ppcls INFO: [Train][Epoch 255/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00497878, top1: 0.96776, CELoss: 0.09316, loss: 0.09316, batch_cost: 0.60815s, reader_cost: 0.01662, ips: 105.23730 samples/s, eta: 1:18:36
[2022/06/19 05:12:43] ppcls INFO: [Train][Epoch 255/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00496619, top1: 0.96707, CELoss: 0.09436, loss: 0.09436, batch_cost: 0.60498s, reader_cost: 0.01708, ips: 105.78862 samples/s, eta: 1:18:06
[2022/06/19 05:12:50] ppcls INFO: [Train][Epoch 255/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00495361, top1: 0.96744, CELoss: 0.09342, loss: 0.09342, batch_cost: 0.61094s, reader_cost: 0.01734, ips: 104.75652 samples/s, eta: 1:18:46
[2022/06/19 05:12:56] ppcls INFO: [Train][Epoch 255/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00494105, top1: 0.96786, CELoss: 0.09360, loss: 0.09360, batch_cost: 0.61010s, reader_cost: 0.02393, ips: 104.90080 samples/s, eta: 1:18:33
[2022/06/19 05:13:03] ppcls INFO: [Train][Epoch 255/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00492850, top1: 0.96772, CELoss: 0.09498, loss: 0.09498, batch_cost: 0.61207s, reader_cost: 0.02882, ips: 104.56339 samples/s, eta: 1:18:42
[2022/06/19 05:13:07] ppcls INFO: [Train][Epoch 255/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00491597, top1: 0.96759, CELoss: 0.09618, loss: 0.09618, batch_cost: 0.60075s, reader_cost: 0.02726, ips: 106.53273 samples/s, eta: 1:17:09
[2022/06/19 05:13:09] ppcls INFO: [Train][Epoch 255/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00490346, top1: 0.96733, CELoss: 0.09687, loss: 0.09687, batch_cost: 0.57741s, reader_cost: 0.02563, ips: 84.86115 samples/s, eta: 1:14:03
[2022/06/19 05:13:10] ppcls INFO: [Train][Epoch 255/300][Avg]top1: 0.96733, CELoss: 0.09687, loss: 0.09687
[2022/06/19 05:13:17] ppcls INFO: [Eval][Epoch 255][Iter: 0/16]CELoss: 1.05739, loss: 1.05739, top1: 0.79883, batch_cost: 7.21911s, reader_cost: 3.66972, ips: 8.86536 images/sec
[2022/06/19 05:13:25] ppcls INFO: [Eval][Epoch 255][Iter: 10/16]CELoss: 1.02923, loss: 1.02923, top1: 0.81925, batch_cost: 0.59030s, reader_cost: 0.00488, ips: 108.41975 images/sec
[2022/06/19 05:13:27] ppcls INFO: [Eval][Epoch 255][Avg]CELoss: 0.83190, loss: 0.83190, top1: 0.82549
[2022/06/19 05:13:27] ppcls INFO: [Eval][Epoch 255][best metric: 0.8276961445808411]
[2022/06/19 05:13:27] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:13:33] ppcls INFO: [Train][Epoch 256/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00490220, top1: 0.93750, CELoss: 0.10842, loss: 0.10842, batch_cost: 0.61411s, reader_cost: 0.06214, ips: 104.21560 samples/s, eta: 1:18:45
[2022/06/19 05:13:40] ppcls INFO: [Train][Epoch 256/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00488970, top1: 0.96591, CELoss: 0.07766, loss: 0.07766, batch_cost: 0.63219s, reader_cost: 0.01662, ips: 101.23574 samples/s, eta: 1:20:58
[2022/06/19 05:13:46] ppcls INFO: [Train][Epoch 256/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00487722, top1: 0.96577, CELoss: 0.09537, loss: 0.09537, batch_cost: 0.65532s, reader_cost: 0.01975, ips: 97.66291 samples/s, eta: 1:23:49
[2022/06/19 05:13:54] ppcls INFO: [Train][Epoch 256/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00486475, top1: 0.96724, CELoss: 0.09104, loss: 0.09104, batch_cost: 0.68501s, reader_cost: 0.02134, ips: 93.42958 samples/s, eta: 1:27:30
[2022/06/19 05:14:00] ppcls INFO: [Train][Epoch 256/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00485229, top1: 0.96875, CELoss: 0.08951, loss: 0.08951, batch_cost: 0.66076s, reader_cost: 0.02214, ips: 96.85881 samples/s, eta: 1:24:18
[2022/06/19 05:14:06] ppcls INFO: [Train][Epoch 256/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00483985, top1: 0.96814, CELoss: 0.09057, loss: 0.09057, batch_cost: 0.65627s, reader_cost: 0.02118, ips: 97.52055 samples/s, eta: 1:23:37
[2022/06/19 05:14:12] ppcls INFO: [Train][Epoch 256/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00482743, top1: 0.96849, CELoss: 0.09065, loss: 0.09065, batch_cost: 0.64996s, reader_cost: 0.02259, ips: 98.46777 samples/s, eta: 1:22:42
[2022/06/19 05:14:19] ppcls INFO: [Train][Epoch 256/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00481502, top1: 0.96831, CELoss: 0.09611, loss: 0.09611, batch_cost: 0.64658s, reader_cost: 0.02013, ips: 98.98310 samples/s, eta: 1:22:10
[2022/06/19 05:14:25] ppcls INFO: [Train][Epoch 256/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00480262, top1: 0.96682, CELoss: 0.09959, loss: 0.09959, batch_cost: 0.64060s, reader_cost: 0.01856, ips: 99.90585 samples/s, eta: 1:21:18
[2022/06/19 05:14:30] ppcls INFO: [Train][Epoch 256/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00479024, top1: 0.96600, CELoss: 0.10289, loss: 0.10289, batch_cost: 0.63137s, reader_cost: 0.01866, ips: 101.36696 samples/s, eta: 1:20:01
[2022/06/19 05:14:36] ppcls INFO: [Train][Epoch 256/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00477788, top1: 0.96566, CELoss: 0.10405, loss: 0.10405, batch_cost: 0.62265s, reader_cost: 0.01708, ips: 102.78614 samples/s, eta: 1:18:49
[2022/06/19 05:14:42] ppcls INFO: [Train][Epoch 256/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00476553, top1: 0.96678, CELoss: 0.10081, loss: 0.10081, batch_cost: 0.62512s, reader_cost: 0.01597, ips: 102.38035 samples/s, eta: 1:19:01
[2022/06/19 05:14:49] ppcls INFO: [Train][Epoch 256/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00475319, top1: 0.96694, CELoss: 0.10206, loss: 0.10206, batch_cost: 0.62663s, reader_cost: 0.01628, ips: 102.13402 samples/s, eta: 1:19:06
[2022/06/19 05:14:54] ppcls INFO: [Train][Epoch 256/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00474087, top1: 0.96708, CELoss: 0.10107, loss: 0.10107, batch_cost: 0.62271s, reader_cost: 0.01657, ips: 102.77675 samples/s, eta: 1:18:30
[2022/06/19 05:15:00] ppcls INFO: [Train][Epoch 256/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00472857, top1: 0.96698, CELoss: 0.10031, loss: 0.10031, batch_cost: 0.62035s, reader_cost: 0.01569, ips: 103.16779 samples/s, eta: 1:18:06
[2022/06/19 05:15:07] ppcls INFO: [Train][Epoch 256/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00471628, top1: 0.96678, CELoss: 0.09994, loss: 0.09994, batch_cost: 0.62160s, reader_cost: 0.01564, ips: 102.96014 samples/s, eta: 1:18:09
[2022/06/19 05:15:12] ppcls INFO: [Train][Epoch 256/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00470400, top1: 0.96642, CELoss: 0.10008, loss: 0.10008, batch_cost: 0.61460s, reader_cost: 0.01725, ips: 104.13347 samples/s, eta: 1:17:10
[2022/06/19 05:15:14] ppcls INFO: [Train][Epoch 256/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00469175, top1: 0.96587, CELoss: 0.10179, loss: 0.10179, batch_cost: 0.59022s, reader_cost: 0.01622, ips: 83.02015 samples/s, eta: 1:14:01
[2022/06/19 05:15:15] ppcls INFO: [Train][Epoch 256/300][Avg]top1: 0.96587, CELoss: 0.10179, loss: 0.10179
[2022/06/19 05:15:15] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:15:22] ppcls INFO: [Train][Epoch 257/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00469052, top1: 0.96875, CELoss: 0.11927, loss: 0.11927, batch_cost: 0.62852s, reader_cost: 0.05187, ips: 101.82672 samples/s, eta: 1:18:48
[2022/06/19 05:15:28] ppcls INFO: [Train][Epoch 257/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00467828, top1: 0.97159, CELoss: 0.08275, loss: 0.08275, batch_cost: 0.72124s, reader_cost: 0.02793, ips: 88.73629 samples/s, eta: 1:30:19
[2022/06/19 05:15:35] ppcls INFO: [Train][Epoch 257/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00466605, top1: 0.96577, CELoss: 0.10044, loss: 0.10044, batch_cost: 0.66389s, reader_cost: 0.03001, ips: 96.40170 samples/s, eta: 1:23:01
[2022/06/19 05:15:41] ppcls INFO: [Train][Epoch 257/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00465384, top1: 0.96875, CELoss: 0.09443, loss: 0.09443, batch_cost: 0.63145s, reader_cost: 0.02366, ips: 101.35413 samples/s, eta: 1:18:52
[2022/06/19 05:15:47] ppcls INFO: [Train][Epoch 257/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00464164, top1: 0.97027, CELoss: 0.09656, loss: 0.09656, batch_cost: 0.64170s, reader_cost: 0.02698, ips: 99.73540 samples/s, eta: 1:20:02
[2022/06/19 05:15:53] ppcls INFO: [Train][Epoch 257/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00462946, top1: 0.96814, CELoss: 0.09877, loss: 0.09877, batch_cost: 0.63256s, reader_cost: 0.03331, ips: 101.17560 samples/s, eta: 1:18:47
[2022/06/19 05:15:59] ppcls INFO: [Train][Epoch 257/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00461729, top1: 0.96798, CELoss: 0.09742, loss: 0.09742, batch_cost: 0.62334s, reader_cost: 0.02829, ips: 102.67307 samples/s, eta: 1:17:32
[2022/06/19 05:16:05] ppcls INFO: [Train][Epoch 257/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00460514, top1: 0.96743, CELoss: 0.09965, loss: 0.09965, batch_cost: 0.62547s, reader_cost: 0.02891, ips: 102.32244 samples/s, eta: 1:17:42
[2022/06/19 05:16:11] ppcls INFO: [Train][Epoch 257/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00459300, top1: 0.96721, CELoss: 0.10201, loss: 0.10201, batch_cost: 0.61743s, reader_cost: 0.03717, ips: 103.65488 samples/s, eta: 1:16:36
[2022/06/19 05:16:17] ppcls INFO: [Train][Epoch 257/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00458088, top1: 0.96841, CELoss: 0.09896, loss: 0.09896, batch_cost: 0.61285s, reader_cost: 0.04220, ips: 104.43047 samples/s, eta: 1:15:55
[2022/06/19 05:16:23] ppcls INFO: [Train][Epoch 257/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00456878, top1: 0.96767, CELoss: 0.09763, loss: 0.09763, batch_cost: 0.61477s, reader_cost: 0.05244, ips: 104.10385 samples/s, eta: 1:16:04
[2022/06/19 05:16:29] ppcls INFO: [Train][Epoch 257/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00455668, top1: 0.96791, CELoss: 0.09578, loss: 0.09578, batch_cost: 0.61609s, reader_cost: 0.06687, ips: 103.88028 samples/s, eta: 1:16:07
[2022/06/19 05:16:35] ppcls INFO: [Train][Epoch 257/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00454461, top1: 0.96798, CELoss: 0.09513, loss: 0.09513, batch_cost: 0.61126s, reader_cost: 0.06226, ips: 104.70226 samples/s, eta: 1:15:25
[2022/06/19 05:16:41] ppcls INFO: [Train][Epoch 257/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00453255, top1: 0.96780, CELoss: 0.09510, loss: 0.09510, batch_cost: 0.61036s, reader_cost: 0.06370, ips: 104.85590 samples/s, eta: 1:15:13
[2022/06/19 05:16:47] ppcls INFO: [Train][Epoch 257/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00452050, top1: 0.96809, CELoss: 0.09518, loss: 0.09518, batch_cost: 0.60751s, reader_cost: 0.06018, ips: 105.34878 samples/s, eta: 1:14:45
[2022/06/19 05:16:54] ppcls INFO: [Train][Epoch 257/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00450847, top1: 0.96865, CELoss: 0.09348, loss: 0.09348, batch_cost: 0.61650s, reader_cost: 0.07726, ips: 103.81148 samples/s, eta: 1:15:46
[2022/06/19 05:16:59] ppcls INFO: [Train][Epoch 257/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00449646, top1: 0.96817, CELoss: 0.09381, loss: 0.09381, batch_cost: 0.60921s, reader_cost: 0.07571, ips: 105.05404 samples/s, eta: 1:14:46
[2022/06/19 05:17:01] ppcls INFO: [Train][Epoch 257/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00448446, top1: 0.96733, CELoss: 0.09576, loss: 0.09576, batch_cost: 0.58548s, reader_cost: 0.07116, ips: 83.69171 samples/s, eta: 1:11:45
[2022/06/19 05:17:02] ppcls INFO: [Train][Epoch 257/300][Avg]top1: 0.96733, CELoss: 0.09576, loss: 0.09576
[2022/06/19 05:17:02] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:17:08] ppcls INFO: [Train][Epoch 258/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00448326, top1: 0.95312, CELoss: 0.12614, loss: 0.12614, batch_cost: 0.61923s, reader_cost: 0.09717, ips: 103.35435 samples/s, eta: 1:15:53
[2022/06/19 05:17:15] ppcls INFO: [Train][Epoch 258/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00447127, top1: 0.97017, CELoss: 0.07936, loss: 0.07936, batch_cost: 0.71745s, reader_cost: 0.06586, ips: 89.20432 samples/s, eta: 1:27:48
[2022/06/19 05:17:22] ppcls INFO: [Train][Epoch 258/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00445931, top1: 0.96875, CELoss: 0.09095, loss: 0.09095, batch_cost: 0.65695s, reader_cost: 0.03226, ips: 97.41929 samples/s, eta: 1:20:17
[2022/06/19 05:17:28] ppcls INFO: [Train][Epoch 258/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00444735, top1: 0.96925, CELoss: 0.09037, loss: 0.09037, batch_cost: 0.64303s, reader_cost: 0.02656, ips: 99.52948 samples/s, eta: 1:18:28
[2022/06/19 05:17:34] ppcls INFO: [Train][Epoch 258/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00443541, top1: 0.97066, CELoss: 0.08822, loss: 0.08822, batch_cost: 0.62810s, reader_cost: 0.02953, ips: 101.89482 samples/s, eta: 1:16:33
[2022/06/19 05:17:40] ppcls INFO: [Train][Epoch 258/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00442349, top1: 0.96875, CELoss: 0.09161, loss: 0.09161, batch_cost: 0.63084s, reader_cost: 0.02447, ips: 101.45174 samples/s, eta: 1:16:47
[2022/06/19 05:17:46] ppcls INFO: [Train][Epoch 258/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00441158, top1: 0.96773, CELoss: 0.09267, loss: 0.09267, batch_cost: 0.62480s, reader_cost: 0.02202, ips: 102.43345 samples/s, eta: 1:15:56
[2022/06/19 05:17:52] ppcls INFO: [Train][Epoch 258/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00439969, top1: 0.96853, CELoss: 0.09028, loss: 0.09028, batch_cost: 0.62595s, reader_cost: 0.02222, ips: 102.24383 samples/s, eta: 1:15:58
[2022/06/19 05:17:59] ppcls INFO: [Train][Epoch 258/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00438782, top1: 0.96836, CELoss: 0.09242, loss: 0.09242, batch_cost: 0.63049s, reader_cost: 0.03659, ips: 101.50836 samples/s, eta: 1:16:25
[2022/06/19 05:18:07] ppcls INFO: [Train][Epoch 258/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00437595, top1: 0.96686, CELoss: 0.09753, loss: 0.09753, batch_cost: 0.64607s, reader_cost: 0.06317, ips: 99.06014 samples/s, eta: 1:18:12
[2022/06/19 05:18:11] ppcls INFO: [Train][Epoch 258/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00436411, top1: 0.96674, CELoss: 0.09769, loss: 0.09769, batch_cost: 0.62517s, reader_cost: 0.05703, ips: 102.37293 samples/s, eta: 1:15:34
[2022/06/19 05:18:17] ppcls INFO: [Train][Epoch 258/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00435228, top1: 0.96748, CELoss: 0.09634, loss: 0.09634, batch_cost: 0.61871s, reader_cost: 0.05319, ips: 103.44042 samples/s, eta: 1:14:41
[2022/06/19 05:18:22] ppcls INFO: [Train][Epoch 258/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00434046, top1: 0.96772, CELoss: 0.09523, loss: 0.09523, batch_cost: 0.61209s, reader_cost: 0.05496, ips: 104.55923 samples/s, eta: 1:13:47
[2022/06/19 05:18:29] ppcls INFO: [Train][Epoch 258/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00432866, top1: 0.96839, CELoss: 0.09412, loss: 0.09412, batch_cost: 0.62050s, reader_cost: 0.06124, ips: 103.14284 samples/s, eta: 1:14:41
[2022/06/19 05:18:36] ppcls INFO: [Train][Epoch 258/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00431687, top1: 0.96886, CELoss: 0.09246, loss: 0.09246, batch_cost: 0.62616s, reader_cost: 0.06667, ips: 102.21027 samples/s, eta: 1:15:16
[2022/06/19 05:18:41] ppcls INFO: [Train][Epoch 258/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00430510, top1: 0.96958, CELoss: 0.09248, loss: 0.09248, batch_cost: 0.61421s, reader_cost: 0.06347, ips: 104.19925 samples/s, eta: 1:13:44
[2022/06/19 05:18:47] ppcls INFO: [Train][Epoch 258/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00429335, top1: 0.97001, CELoss: 0.09093, loss: 0.09093, batch_cost: 0.61331s, reader_cost: 0.06015, ips: 104.35152 samples/s, eta: 1:13:31
[2022/06/19 05:18:49] ppcls INFO: [Train][Epoch 258/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00428161, top1: 0.96944, CELoss: 0.09171, loss: 0.09171, batch_cost: 0.58903s, reader_cost: 0.05654, ips: 83.18796 samples/s, eta: 1:10:30
[2022/06/19 05:18:50] ppcls INFO: [Train][Epoch 258/300][Avg]top1: 0.96944, CELoss: 0.09171, loss: 0.09171
[2022/06/19 05:18:50] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:18:56] ppcls INFO: [Train][Epoch 259/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00428044, top1: 0.96875, CELoss: 0.07919, loss: 0.07919, batch_cost: 0.62534s, reader_cost: 0.08394, ips: 102.34468 samples/s, eta: 1:14:51
[2022/06/19 05:19:03] ppcls INFO: [Train][Epoch 259/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00426871, top1: 0.96449, CELoss: 0.11791, loss: 0.11791, batch_cost: 0.65283s, reader_cost: 0.01446, ips: 98.03438 samples/s, eta: 1:18:02
[2022/06/19 05:19:09] ppcls INFO: [Train][Epoch 259/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00425701, top1: 0.96801, CELoss: 0.10677, loss: 0.10677, batch_cost: 0.62491s, reader_cost: 0.01406, ips: 102.41406 samples/s, eta: 1:14:35
[2022/06/19 05:19:15] ppcls INFO: [Train][Epoch 259/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00424531, top1: 0.97026, CELoss: 0.09523, loss: 0.09523, batch_cost: 0.59616s, reader_cost: 0.01166, ips: 107.35308 samples/s, eta: 1:11:03
[2022/06/19 05:19:21] ppcls INFO: [Train][Epoch 259/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00423364, top1: 0.96913, CELoss: 0.10199, loss: 0.10199, batch_cost: 0.60259s, reader_cost: 0.01072, ips: 106.20797 samples/s, eta: 1:11:43
[2022/06/19 05:19:28] ppcls INFO: [Train][Epoch 259/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00422197, top1: 0.97120, CELoss: 0.09595, loss: 0.09595, batch_cost: 0.61096s, reader_cost: 0.01257, ips: 104.75365 samples/s, eta: 1:12:37
[2022/06/19 05:19:34] ppcls INFO: [Train][Epoch 259/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00421033, top1: 0.97106, CELoss: 0.09570, loss: 0.09570, batch_cost: 0.61260s, reader_cost: 0.01262, ips: 104.47263 samples/s, eta: 1:12:42
[2022/06/19 05:19:41] ppcls INFO: [Train][Epoch 259/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00419870, top1: 0.97139, CELoss: 0.09288, loss: 0.09288, batch_cost: 0.62312s, reader_cost: 0.01516, ips: 102.70881 samples/s, eta: 1:13:51
[2022/06/19 05:19:47] ppcls INFO: [Train][Epoch 259/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00418708, top1: 0.97106, CELoss: 0.09322, loss: 0.09322, batch_cost: 0.61863s, reader_cost: 0.01568, ips: 103.45369 samples/s, eta: 1:13:13
[2022/06/19 05:19:54] ppcls INFO: [Train][Epoch 259/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00417548, top1: 0.97115, CELoss: 0.09103, loss: 0.09103, batch_cost: 0.63240s, reader_cost: 0.01500, ips: 101.20221 samples/s, eta: 1:14:44
[2022/06/19 05:19:59] ppcls INFO: [Train][Epoch 259/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00416390, top1: 0.97092, CELoss: 0.09024, loss: 0.09024, batch_cost: 0.62273s, reader_cost: 0.01398, ips: 102.77283 samples/s, eta: 1:13:30
[2022/06/19 05:20:05] ppcls INFO: [Train][Epoch 259/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00415233, top1: 0.96931, CELoss: 0.09201, loss: 0.09201, batch_cost: 0.61975s, reader_cost: 0.01325, ips: 103.26758 samples/s, eta: 1:13:02
[2022/06/19 05:20:11] ppcls INFO: [Train][Epoch 259/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00414077, top1: 0.96888, CELoss: 0.09326, loss: 0.09326, batch_cost: 0.61381s, reader_cost: 0.01302, ips: 104.26688 samples/s, eta: 1:12:14
[2022/06/19 05:20:17] ppcls INFO: [Train][Epoch 259/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00412923, top1: 0.96911, CELoss: 0.09276, loss: 0.09276, batch_cost: 0.61657s, reader_cost: 0.01261, ips: 103.79958 samples/s, eta: 1:12:28
[2022/06/19 05:20:23] ppcls INFO: [Train][Epoch 259/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00411771, top1: 0.96941, CELoss: 0.09191, loss: 0.09191, batch_cost: 0.61319s, reader_cost: 0.01237, ips: 104.37235 samples/s, eta: 1:11:58
[2022/06/19 05:20:30] ppcls INFO: [Train][Epoch 259/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00410620, top1: 0.96927, CELoss: 0.09153, loss: 0.09153, batch_cost: 0.61772s, reader_cost: 0.01283, ips: 103.60630 samples/s, eta: 1:12:23
[2022/06/19 05:20:34] ppcls INFO: [Train][Epoch 259/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00409471, top1: 0.96972, CELoss: 0.08972, loss: 0.08972, batch_cost: 0.60785s, reader_cost: 0.01238, ips: 105.28890 samples/s, eta: 1:11:08
[2022/06/19 05:20:36] ppcls INFO: [Train][Epoch 259/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00408323, top1: 0.96944, CELoss: 0.09027, loss: 0.09027, batch_cost: 0.58412s, reader_cost: 0.01166, ips: 83.88672 samples/s, eta: 1:08:15
[2022/06/19 05:20:37] ppcls INFO: [Train][Epoch 259/300][Avg]top1: 0.96944, CELoss: 0.09027, loss: 0.09027
[2022/06/19 05:20:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:20:45] ppcls INFO: [Train][Epoch 260/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00408208, top1: 0.96875, CELoss: 0.08027, loss: 0.08027, batch_cost: 0.62641s, reader_cost: 0.04009, ips: 102.17000 samples/s, eta: 1:13:11
[2022/06/19 05:20:51] ppcls INFO: [Train][Epoch 260/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00407062, top1: 0.97159, CELoss: 0.07328, loss: 0.07328, batch_cost: 0.65461s, reader_cost: 0.00967, ips: 97.76883 samples/s, eta: 1:16:22
[2022/06/19 05:20:57] ppcls INFO: [Train][Epoch 260/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00405917, top1: 0.97173, CELoss: 0.07687, loss: 0.07687, batch_cost: 0.62507s, reader_cost: 0.01534, ips: 102.38887 samples/s, eta: 1:12:49
[2022/06/19 05:21:03] ppcls INFO: [Train][Epoch 260/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00404774, top1: 0.97278, CELoss: 0.07794, loss: 0.07794, batch_cost: 0.61446s, reader_cost: 0.01888, ips: 104.15669 samples/s, eta: 1:11:29
[2022/06/19 05:21:09] ppcls INFO: [Train][Epoch 260/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00403633, top1: 0.97104, CELoss: 0.08695, loss: 0.08695, batch_cost: 0.61113s, reader_cost: 0.01824, ips: 104.72329 samples/s, eta: 1:11:00
[2022/06/19 05:21:16] ppcls INFO: [Train][Epoch 260/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00402493, top1: 0.97120, CELoss: 0.09022, loss: 0.09022, batch_cost: 0.61093s, reader_cost: 0.01549, ips: 104.75845 samples/s, eta: 1:10:52
[2022/06/19 05:21:21] ppcls INFO: [Train][Epoch 260/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00401355, top1: 0.97029, CELoss: 0.09027, loss: 0.09027, batch_cost: 0.60701s, reader_cost: 0.01547, ips: 105.43484 samples/s, eta: 1:10:19
[2022/06/19 05:21:27] ppcls INFO: [Train][Epoch 260/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00400218, top1: 0.97139, CELoss: 0.08738, loss: 0.08738, batch_cost: 0.60124s, reader_cost: 0.01393, ips: 106.44726 samples/s, eta: 1:09:33
[2022/06/19 05:21:33] ppcls INFO: [Train][Epoch 260/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00399082, top1: 0.97164, CELoss: 0.08778, loss: 0.08778, batch_cost: 0.59966s, reader_cost: 0.01311, ips: 106.72667 samples/s, eta: 1:09:16
[2022/06/19 05:21:40] ppcls INFO: [Train][Epoch 260/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00397948, top1: 0.97064, CELoss: 0.09378, loss: 0.09378, batch_cost: 0.60768s, reader_cost: 0.01254, ips: 105.31801 samples/s, eta: 1:10:05
[2022/06/19 05:21:45] ppcls INFO: [Train][Epoch 260/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00396816, top1: 0.97014, CELoss: 0.09569, loss: 0.09569, batch_cost: 0.60181s, reader_cost: 0.01237, ips: 106.34498 samples/s, eta: 1:09:19
[2022/06/19 05:21:51] ppcls INFO: [Train][Epoch 260/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00395685, top1: 0.96959, CELoss: 0.09522, loss: 0.09522, batch_cost: 0.60265s, reader_cost: 0.01983, ips: 106.19792 samples/s, eta: 1:09:18
[2022/06/19 05:21:58] ppcls INFO: [Train][Epoch 260/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00394556, top1: 0.96927, CELoss: 0.09462, loss: 0.09462, batch_cost: 0.60833s, reader_cost: 0.02098, ips: 105.20681 samples/s, eta: 1:09:51
[2022/06/19 05:22:04] ppcls INFO: [Train][Epoch 260/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00393429, top1: 0.96899, CELoss: 0.09546, loss: 0.09546, batch_cost: 0.60842s, reader_cost: 0.02051, ips: 105.19079 samples/s, eta: 1:09:46
[2022/06/19 05:22:10] ppcls INFO: [Train][Epoch 260/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00392302, top1: 0.96820, CELoss: 0.09717, loss: 0.09717, batch_cost: 0.60861s, reader_cost: 0.01968, ips: 105.15739 samples/s, eta: 1:09:41
[2022/06/19 05:22:16] ppcls INFO: [Train][Epoch 260/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00391178, top1: 0.96865, CELoss: 0.09588, loss: 0.09588, batch_cost: 0.60733s, reader_cost: 0.01888, ips: 105.37899 samples/s, eta: 1:09:26
[2022/06/19 05:22:21] ppcls INFO: [Train][Epoch 260/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00390055, top1: 0.96807, CELoss: 0.09706, loss: 0.09706, batch_cost: 0.59981s, reader_cost: 0.01794, ips: 106.70039 samples/s, eta: 1:08:29
[2022/06/19 05:22:23] ppcls INFO: [Train][Epoch 260/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00388933, top1: 0.96816, CELoss: 0.09550, loss: 0.09550, batch_cost: 0.57657s, reader_cost: 0.01686, ips: 84.98551 samples/s, eta: 1:05:44
[2022/06/19 05:22:24] ppcls INFO: [Train][Epoch 260/300][Avg]top1: 0.96816, CELoss: 0.09550, loss: 0.09550
[2022/06/19 05:22:30] ppcls INFO: [Eval][Epoch 260][Iter: 0/16]CELoss: 1.13401, loss: 1.13401, top1: 0.79297, batch_cost: 6.41483s, reader_cost: 3.87978, ips: 9.97688 images/sec
[2022/06/19 05:22:38] ppcls INFO: [Eval][Epoch 260][Iter: 10/16]CELoss: 1.00472, loss: 1.00472, top1: 0.82031, batch_cost: 0.61778s, reader_cost: 0.00845, ips: 103.59739 images/sec
[2022/06/19 05:22:40] ppcls INFO: [Eval][Epoch 260][Avg]CELoss: 0.84622, loss: 0.84622, top1: 0.82794
[2022/06/19 05:22:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 05:22:40] ppcls INFO: [Eval][Epoch 260][best metric: 0.8279412388801575]
[2022/06/19 05:22:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_260
[2022/06/19 05:22:40] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:22:47] ppcls INFO: [Train][Epoch 261/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00388821, top1: 0.98438, CELoss: 0.04575, loss: 0.04575, batch_cost: 0.61530s, reader_cost: 0.04707, ips: 104.01463 samples/s, eta: 1:10:08
[2022/06/19 05:22:54] ppcls INFO: [Train][Epoch 261/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00387702, top1: 0.97585, CELoss: 0.07837, loss: 0.07837, batch_cost: 0.61653s, reader_cost: 0.09015, ips: 103.80718 samples/s, eta: 1:10:10
[2022/06/19 05:23:00] ppcls INFO: [Train][Epoch 261/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00386583, top1: 0.97470, CELoss: 0.09206, loss: 0.09206, batch_cost: 0.61775s, reader_cost: 0.09871, ips: 103.60240 samples/s, eta: 1:10:13
[2022/06/19 05:23:06] ppcls INFO: [Train][Epoch 261/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00385467, top1: 0.97278, CELoss: 0.08776, loss: 0.08776, batch_cost: 0.61847s, reader_cost: 0.06426, ips: 103.48039 samples/s, eta: 1:10:11
[2022/06/19 05:23:12] ppcls INFO: [Train][Epoch 261/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00384351, top1: 0.97675, CELoss: 0.08103, loss: 0.08103, batch_cost: 0.61086s, reader_cost: 0.04888, ips: 104.76990 samples/s, eta: 1:09:13
[2022/06/19 05:23:18] ppcls INFO: [Train][Epoch 261/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00383238, top1: 0.97488, CELoss: 0.08437, loss: 0.08437, batch_cost: 0.59710s, reader_cost: 0.04178, ips: 107.18422 samples/s, eta: 1:07:34
[2022/06/19 05:23:23] ppcls INFO: [Train][Epoch 261/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00382126, top1: 0.97464, CELoss: 0.08369, loss: 0.08369, batch_cost: 0.59592s, reader_cost: 0.03540, ips: 107.39786 samples/s, eta: 1:07:20
[2022/06/19 05:23:30] ppcls INFO: [Train][Epoch 261/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00381015, top1: 0.97271, CELoss: 0.08555, loss: 0.08555, batch_cost: 0.60097s, reader_cost: 0.03201, ips: 106.49433 samples/s, eta: 1:07:48
[2022/06/19 05:23:36] ppcls INFO: [Train][Epoch 261/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00379906, top1: 0.97338, CELoss: 0.08611, loss: 0.08611, batch_cost: 0.60224s, reader_cost: 0.02846, ips: 106.27039 samples/s, eta: 1:07:51
[2022/06/19 05:23:42] ppcls INFO: [Train][Epoch 261/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00378799, top1: 0.97201, CELoss: 0.09107, loss: 0.09107, batch_cost: 0.60546s, reader_cost: 0.02748, ips: 105.70400 samples/s, eta: 1:08:06
[2022/06/19 05:23:50] ppcls INFO: [Train][Epoch 261/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00377693, top1: 0.97200, CELoss: 0.09153, loss: 0.09153, batch_cost: 0.62030s, reader_cost: 0.02576, ips: 103.17534 samples/s, eta: 1:09:40
[2022/06/19 05:23:54] ppcls INFO: [Train][Epoch 261/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00376588, top1: 0.97030, CELoss: 0.09500, loss: 0.09500, batch_cost: 0.60634s, reader_cost: 0.02457, ips: 105.55180 samples/s, eta: 1:08:00
[2022/06/19 05:24:00] ppcls INFO: [Train][Epoch 261/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00375486, top1: 0.97043, CELoss: 0.09495, loss: 0.09495, batch_cost: 0.60220s, reader_cost: 0.02308, ips: 106.27727 samples/s, eta: 1:07:26
[2022/06/19 05:24:06] ppcls INFO: [Train][Epoch 261/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00374384, top1: 0.96970, CELoss: 0.09663, loss: 0.09663, batch_cost: 0.60292s, reader_cost: 0.02266, ips: 106.15073 samples/s, eta: 1:07:25
[2022/06/19 05:24:12] ppcls INFO: [Train][Epoch 261/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00373285, top1: 0.96941, CELoss: 0.09749, loss: 0.09749, batch_cost: 0.60553s, reader_cost: 0.02140, ips: 105.69293 samples/s, eta: 1:07:37
[2022/06/19 05:24:18] ppcls INFO: [Train][Epoch 261/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00372186, top1: 0.96947, CELoss: 0.09708, loss: 0.09708, batch_cost: 0.60368s, reader_cost: 0.02085, ips: 106.01717 samples/s, eta: 1:07:18
[2022/06/19 05:24:23] ppcls INFO: [Train][Epoch 261/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00371090, top1: 0.96894, CELoss: 0.09763, loss: 0.09763, batch_cost: 0.59610s, reader_cost: 0.02040, ips: 107.36413 samples/s, eta: 1:06:21
[2022/06/19 05:24:25] ppcls INFO: [Train][Epoch 261/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00369995, top1: 0.96953, CELoss: 0.09652, loss: 0.09652, batch_cost: 0.57317s, reader_cost: 0.01924, ips: 85.48974 samples/s, eta: 1:03:43
[2022/06/19 05:24:26] ppcls INFO: [Train][Epoch 261/300][Avg]top1: 0.96953, CELoss: 0.09652, loss: 0.09652
[2022/06/19 05:24:26] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:24:32] ppcls INFO: [Train][Epoch 262/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00369885, top1: 0.96875, CELoss: 0.08490, loss: 0.08490, batch_cost: 0.60589s, reader_cost: 0.04702, ips: 105.62925 samples/s, eta: 1:07:20
[2022/06/19 05:24:39] ppcls INFO: [Train][Epoch 262/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00368792, top1: 0.97869, CELoss: 0.07751, loss: 0.07751, batch_cost: 0.76657s, reader_cost: 0.01649, ips: 83.48873 samples/s, eta: 1:25:04
[2022/06/19 05:24:45] ppcls INFO: [Train][Epoch 262/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00367700, top1: 0.97470, CELoss: 0.08212, loss: 0.08212, batch_cost: 0.65616s, reader_cost: 0.00664, ips: 97.53730 samples/s, eta: 1:12:42
[2022/06/19 05:24:52] ppcls INFO: [Train][Epoch 262/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00366610, top1: 0.96875, CELoss: 0.09251, loss: 0.09251, batch_cost: 0.66813s, reader_cost: 0.04357, ips: 95.79038 samples/s, eta: 1:13:55
[2022/06/19 05:24:59] ppcls INFO: [Train][Epoch 262/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00365521, top1: 0.97066, CELoss: 0.08654, loss: 0.08654, batch_cost: 0.66870s, reader_cost: 0.03362, ips: 95.70833 samples/s, eta: 1:13:52
[2022/06/19 05:25:05] ppcls INFO: [Train][Epoch 262/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00364434, top1: 0.96936, CELoss: 0.09095, loss: 0.09095, batch_cost: 0.67104s, reader_cost: 0.03200, ips: 95.37406 samples/s, eta: 1:14:01
[2022/06/19 05:25:11] ppcls INFO: [Train][Epoch 262/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00363348, top1: 0.96619, CELoss: 0.09703, loss: 0.09703, batch_cost: 0.65179s, reader_cost: 0.02827, ips: 98.19156 samples/s, eta: 1:11:47
[2022/06/19 05:25:17] ppcls INFO: [Train][Epoch 262/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00362264, top1: 0.96501, CELoss: 0.10444, loss: 0.10444, batch_cost: 0.64092s, reader_cost: 0.02485, ips: 99.85592 samples/s, eta: 1:10:29
[2022/06/19 05:25:23] ppcls INFO: [Train][Epoch 262/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00361182, top1: 0.96663, CELoss: 0.10076, loss: 0.10076, batch_cost: 0.63700s, reader_cost: 0.02331, ips: 100.47020 samples/s, eta: 1:09:57
[2022/06/19 05:25:29] ppcls INFO: [Train][Epoch 262/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00360101, top1: 0.96686, CELoss: 0.10114, loss: 0.10114, batch_cost: 0.63297s, reader_cost: 0.02142, ips: 101.11069 samples/s, eta: 1:09:24
[2022/06/19 05:25:35] ppcls INFO: [Train][Epoch 262/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00359021, top1: 0.96674, CELoss: 0.10125, loss: 0.10125, batch_cost: 0.62840s, reader_cost: 0.02068, ips: 101.84565 samples/s, eta: 1:08:47
[2022/06/19 05:25:41] ppcls INFO: [Train][Epoch 262/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00357944, top1: 0.96678, CELoss: 0.09929, loss: 0.09929, batch_cost: 0.62383s, reader_cost: 0.02011, ips: 102.59155 samples/s, eta: 1:08:11
[2022/06/19 05:25:46] ppcls INFO: [Train][Epoch 262/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00356867, top1: 0.96746, CELoss: 0.09666, loss: 0.09666, batch_cost: 0.61649s, reader_cost: 0.01990, ips: 103.81397 samples/s, eta: 1:07:17
[2022/06/19 05:25:52] ppcls INFO: [Train][Epoch 262/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00355793, top1: 0.96720, CELoss: 0.09752, loss: 0.09752, batch_cost: 0.61758s, reader_cost: 0.01997, ips: 103.63034 samples/s, eta: 1:07:18
[2022/06/19 05:25:58] ppcls INFO: [Train][Epoch 262/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00354719, top1: 0.96753, CELoss: 0.09783, loss: 0.09783, batch_cost: 0.61479s, reader_cost: 0.02056, ips: 104.10091 samples/s, eta: 1:06:53
[2022/06/19 05:26:04] ppcls INFO: [Train][Epoch 262/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00353648, top1: 0.96761, CELoss: 0.09574, loss: 0.09574, batch_cost: 0.61251s, reader_cost: 0.02045, ips: 104.48864 samples/s, eta: 1:06:32
[2022/06/19 05:26:10] ppcls INFO: [Train][Epoch 262/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00352578, top1: 0.96788, CELoss: 0.09656, loss: 0.09656, batch_cost: 0.61147s, reader_cost: 0.01968, ips: 104.66500 samples/s, eta: 1:06:20
[2022/06/19 05:26:12] ppcls INFO: [Train][Epoch 262/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00351509, top1: 0.96770, CELoss: 0.09776, loss: 0.09776, batch_cost: 0.58758s, reader_cost: 0.01852, ips: 83.39314 samples/s, eta: 1:03:38
[2022/06/19 05:26:13] ppcls INFO: [Train][Epoch 262/300][Avg]top1: 0.96770, CELoss: 0.09776, loss: 0.09776
[2022/06/19 05:26:13] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:26:19] ppcls INFO: [Train][Epoch 263/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00351402, top1: 1.00000, CELoss: 0.05232, loss: 0.05232, batch_cost: 0.62202s, reader_cost: 0.04437, ips: 102.89021 samples/s, eta: 1:07:21
[2022/06/19 05:26:27] ppcls INFO: [Train][Epoch 263/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00350335, top1: 0.97869, CELoss: 0.06473, loss: 0.06473, batch_cost: 0.69941s, reader_cost: 0.03103, ips: 91.50540 samples/s, eta: 1:15:37
[2022/06/19 05:26:33] ppcls INFO: [Train][Epoch 263/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00349270, top1: 0.97173, CELoss: 0.07685, loss: 0.07685, batch_cost: 0.60791s, reader_cost: 0.02011, ips: 105.27818 samples/s, eta: 1:05:38
[2022/06/19 05:26:38] ppcls INFO: [Train][Epoch 263/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00348206, top1: 0.96925, CELoss: 0.08011, loss: 0.08011, batch_cost: 0.59638s, reader_cost: 0.01797, ips: 107.31482 samples/s, eta: 1:04:17
[2022/06/19 05:26:44] ppcls INFO: [Train][Epoch 263/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00347144, top1: 0.96646, CELoss: 0.09154, loss: 0.09154, batch_cost: 0.59438s, reader_cost: 0.02119, ips: 107.67504 samples/s, eta: 1:03:58
[2022/06/19 05:26:50] ppcls INFO: [Train][Epoch 263/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00346084, top1: 0.96752, CELoss: 0.09096, loss: 0.09096, batch_cost: 0.59114s, reader_cost: 0.01933, ips: 108.26502 samples/s, eta: 1:03:31
[2022/06/19 05:26:56] ppcls INFO: [Train][Epoch 263/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00345025, top1: 0.96619, CELoss: 0.09470, loss: 0.09470, batch_cost: 0.59489s, reader_cost: 0.02033, ips: 107.58346 samples/s, eta: 1:03:49
[2022/06/19 05:27:02] ppcls INFO: [Train][Epoch 263/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00343967, top1: 0.96611, CELoss: 0.09372, loss: 0.09372, batch_cost: 0.59239s, reader_cost: 0.02049, ips: 108.03688 samples/s, eta: 1:03:27
[2022/06/19 05:27:08] ppcls INFO: [Train][Epoch 263/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00342911, top1: 0.96836, CELoss: 0.08974, loss: 0.08974, batch_cost: 0.59063s, reader_cost: 0.02049, ips: 108.35907 samples/s, eta: 1:03:10
[2022/06/19 05:27:14] ppcls INFO: [Train][Epoch 263/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00341857, top1: 0.96927, CELoss: 0.08896, loss: 0.08896, batch_cost: 0.59632s, reader_cost: 0.01919, ips: 107.32455 samples/s, eta: 1:03:41
[2022/06/19 05:27:20] ppcls INFO: [Train][Epoch 263/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00340804, top1: 0.96906, CELoss: 0.08892, loss: 0.08892, batch_cost: 0.59878s, reader_cost: 0.01991, ips: 106.88411 samples/s, eta: 1:03:50
[2022/06/19 05:27:26] ppcls INFO: [Train][Epoch 263/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00339753, top1: 0.96959, CELoss: 0.08878, loss: 0.08878, batch_cost: 0.59326s, reader_cost: 0.02061, ips: 107.87818 samples/s, eta: 1:03:09
[2022/06/19 05:27:31] ppcls INFO: [Train][Epoch 263/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00338703, top1: 0.97017, CELoss: 0.08832, loss: 0.08832, batch_cost: 0.59043s, reader_cost: 0.01984, ips: 108.39588 samples/s, eta: 1:02:45
[2022/06/19 05:27:40] ppcls INFO: [Train][Epoch 263/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00337655, top1: 0.96970, CELoss: 0.08913, loss: 0.08913, batch_cost: 0.61367s, reader_cost: 0.01970, ips: 104.29078 samples/s, eta: 1:05:07
[2022/06/19 05:27:45] ppcls INFO: [Train][Epoch 263/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00336609, top1: 0.96975, CELoss: 0.08930, loss: 0.08930, batch_cost: 0.60534s, reader_cost: 0.01856, ips: 105.72532 samples/s, eta: 1:04:08
[2022/06/19 05:27:50] ppcls INFO: [Train][Epoch 263/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00335564, top1: 0.96896, CELoss: 0.09215, loss: 0.09215, batch_cost: 0.59929s, reader_cost: 0.01741, ips: 106.79279 samples/s, eta: 1:03:24
[2022/06/19 05:27:56] ppcls INFO: [Train][Epoch 263/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00334520, top1: 0.96836, CELoss: 0.09230, loss: 0.09230, batch_cost: 0.59516s, reader_cost: 0.01647, ips: 107.53323 samples/s, eta: 1:02:52
[2022/06/19 05:27:58] ppcls INFO: [Train][Epoch 263/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00333478, top1: 0.96898, CELoss: 0.09106, loss: 0.09106, batch_cost: 0.57219s, reader_cost: 0.01550, ips: 85.63527 samples/s, eta: 1:00:20
[2022/06/19 05:27:59] ppcls INFO: [Train][Epoch 263/300][Avg]top1: 0.96898, CELoss: 0.09106, loss: 0.09106
[2022/06/19 05:27:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:28:05] ppcls INFO: [Train][Epoch 264/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00333374, top1: 1.00000, CELoss: 0.04618, loss: 0.04618, batch_cost: 0.60502s, reader_cost: 0.04136, ips: 105.78099 samples/s, eta: 1:03:47
[2022/06/19 05:28:12] ppcls INFO: [Train][Epoch 264/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00332334, top1: 0.97017, CELoss: 0.10256, loss: 0.10256, batch_cost: 0.78182s, reader_cost: 0.01786, ips: 81.86022 samples/s, eta: 1:22:18
[2022/06/19 05:28:19] ppcls INFO: [Train][Epoch 264/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00331295, top1: 0.96875, CELoss: 0.09739, loss: 0.09739, batch_cost: 0.70016s, reader_cost: 0.01497, ips: 91.40773 samples/s, eta: 1:13:35
[2022/06/19 05:28:25] ppcls INFO: [Train][Epoch 264/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00330258, top1: 0.96673, CELoss: 0.10493, loss: 0.10493, batch_cost: 0.66899s, reader_cost: 0.01649, ips: 95.66716 samples/s, eta: 1:10:12
[2022/06/19 05:28:30] ppcls INFO: [Train][Epoch 264/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00329223, top1: 0.97180, CELoss: 0.09268, loss: 0.09268, batch_cost: 0.63110s, reader_cost: 0.01400, ips: 101.41087 samples/s, eta: 1:06:07
[2022/06/19 05:28:37] ppcls INFO: [Train][Epoch 264/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00328189, top1: 0.97243, CELoss: 0.09135, loss: 0.09135, batch_cost: 0.64972s, reader_cost: 0.01997, ips: 98.50405 samples/s, eta: 1:07:58
[2022/06/19 05:28:43] ppcls INFO: [Train][Epoch 264/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00327157, top1: 0.96901, CELoss: 0.09717, loss: 0.09717, batch_cost: 0.62709s, reader_cost: 0.02370, ips: 102.05796 samples/s, eta: 1:05:30
[2022/06/19 05:28:49] ppcls INFO: [Train][Epoch 264/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00326126, top1: 0.96941, CELoss: 0.09569, loss: 0.09569, batch_cost: 0.62101s, reader_cost: 0.02401, ips: 103.05867 samples/s, eta: 1:04:45
[2022/06/19 05:28:55] ppcls INFO: [Train][Epoch 264/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00325097, top1: 0.96952, CELoss: 0.09593, loss: 0.09593, batch_cost: 0.62610s, reader_cost: 0.02196, ips: 102.22006 samples/s, eta: 1:05:11
[2022/06/19 05:29:01] ppcls INFO: [Train][Epoch 264/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00324069, top1: 0.96892, CELoss: 0.09502, loss: 0.09502, batch_cost: 0.61829s, reader_cost: 0.02136, ips: 103.51058 samples/s, eta: 1:04:16
[2022/06/19 05:29:06] ppcls INFO: [Train][Epoch 264/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00323043, top1: 0.96999, CELoss: 0.09167, loss: 0.09167, batch_cost: 0.61031s, reader_cost: 0.02061, ips: 104.86447 samples/s, eta: 1:03:20
[2022/06/19 05:29:13] ppcls INFO: [Train][Epoch 264/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00322019, top1: 0.96974, CELoss: 0.09127, loss: 0.09127, batch_cost: 0.61386s, reader_cost: 0.02002, ips: 104.25897 samples/s, eta: 1:03:36
[2022/06/19 05:29:19] ppcls INFO: [Train][Epoch 264/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00320996, top1: 0.97004, CELoss: 0.08929, loss: 0.08929, batch_cost: 0.61370s, reader_cost: 0.01993, ips: 104.28484 samples/s, eta: 1:03:29
[2022/06/19 05:29:25] ppcls INFO: [Train][Epoch 264/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00319974, top1: 0.96982, CELoss: 0.09146, loss: 0.09146, batch_cost: 0.61478s, reader_cost: 0.01879, ips: 104.10285 samples/s, eta: 1:03:29
[2022/06/19 05:29:31] ppcls INFO: [Train][Epoch 264/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00318954, top1: 0.96930, CELoss: 0.09482, loss: 0.09482, batch_cost: 0.61462s, reader_cost: 0.01770, ips: 104.12933 samples/s, eta: 1:03:22
[2022/06/19 05:29:36] ppcls INFO: [Train][Epoch 264/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00317936, top1: 0.96896, CELoss: 0.09445, loss: 0.09445, batch_cost: 0.60802s, reader_cost: 0.01694, ips: 105.25897 samples/s, eta: 1:02:35
[2022/06/19 05:29:42] ppcls INFO: [Train][Epoch 264/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00316919, top1: 0.96807, CELoss: 0.09634, loss: 0.09634, batch_cost: 0.60417s, reader_cost: 0.01876, ips: 105.93080 samples/s, eta: 1:02:05
[2022/06/19 05:29:44] ppcls INFO: [Train][Epoch 264/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00315904, top1: 0.96852, CELoss: 0.09524, loss: 0.09524, batch_cost: 0.58060s, reader_cost: 0.01767, ips: 84.39523 samples/s, eta: 0:59:34
[2022/06/19 05:29:45] ppcls INFO: [Train][Epoch 264/300][Avg]top1: 0.96852, CELoss: 0.09524, loss: 0.09524
[2022/06/19 05:29:45] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:29:51] ppcls INFO: [Train][Epoch 265/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00315803, top1: 0.96875, CELoss: 0.08401, loss: 0.08401, batch_cost: 0.61238s, reader_cost: 0.04564, ips: 104.51067 samples/s, eta: 1:02:49
[2022/06/19 05:29:58] ppcls INFO: [Train][Epoch 265/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00314790, top1: 0.96875, CELoss: 0.09411, loss: 0.09411, batch_cost: 0.66117s, reader_cost: 0.03297, ips: 96.79811 samples/s, eta: 1:07:43
[2022/06/19 05:30:04] ppcls INFO: [Train][Epoch 265/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00313778, top1: 0.96503, CELoss: 0.10840, loss: 0.10840, batch_cost: 0.66898s, reader_cost: 0.02587, ips: 95.66810 samples/s, eta: 1:08:24
[2022/06/19 05:30:10] ppcls INFO: [Train][Epoch 265/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00312768, top1: 0.96724, CELoss: 0.10501, loss: 0.10501, batch_cost: 0.64630s, reader_cost: 0.02861, ips: 99.02550 samples/s, eta: 1:05:59
[2022/06/19 05:30:16] ppcls INFO: [Train][Epoch 265/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00311759, top1: 0.96799, CELoss: 0.10546, loss: 0.10546, batch_cost: 0.63128s, reader_cost: 0.02403, ips: 101.38184 samples/s, eta: 1:04:20
[2022/06/19 05:30:23] ppcls INFO: [Train][Epoch 265/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00310752, top1: 0.96936, CELoss: 0.10400, loss: 0.10400, batch_cost: 0.62824s, reader_cost: 0.02387, ips: 101.87231 samples/s, eta: 1:03:56
[2022/06/19 05:30:28] ppcls INFO: [Train][Epoch 265/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00309746, top1: 0.96926, CELoss: 0.10177, loss: 0.10177, batch_cost: 0.62165s, reader_cost: 0.02052, ips: 102.95229 samples/s, eta: 1:03:09
[2022/06/19 05:30:34] ppcls INFO: [Train][Epoch 265/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00308742, top1: 0.97007, CELoss: 0.09734, loss: 0.09734, batch_cost: 0.61532s, reader_cost: 0.01891, ips: 104.01037 samples/s, eta: 1:02:24
[2022/06/19 05:30:40] ppcls INFO: [Train][Epoch 265/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00307740, top1: 0.96991, CELoss: 0.09608, loss: 0.09608, batch_cost: 0.60807s, reader_cost: 0.01720, ips: 105.25131 samples/s, eta: 1:01:34
[2022/06/19 05:30:46] ppcls INFO: [Train][Epoch 265/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00306739, top1: 0.96944, CELoss: 0.09640, loss: 0.09640, batch_cost: 0.60580s, reader_cost: 0.01695, ips: 105.64591 samples/s, eta: 1:01:14
[2022/06/19 05:30:51] ppcls INFO: [Train][Epoch 265/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00305740, top1: 0.96937, CELoss: 0.09727, loss: 0.09727, batch_cost: 0.60131s, reader_cost: 0.01578, ips: 106.43448 samples/s, eta: 1:00:41
[2022/06/19 05:30:58] ppcls INFO: [Train][Epoch 265/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00304742, top1: 0.96861, CELoss: 0.09809, loss: 0.09809, batch_cost: 0.60890s, reader_cost: 0.01539, ips: 105.10735 samples/s, eta: 1:01:21
[2022/06/19 05:31:04] ppcls INFO: [Train][Epoch 265/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00303746, top1: 0.96875, CELoss: 0.09611, loss: 0.09611, batch_cost: 0.60212s, reader_cost: 0.01595, ips: 106.29112 samples/s, eta: 1:00:34
[2022/06/19 05:31:10] ppcls INFO: [Train][Epoch 265/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00302752, top1: 0.96863, CELoss: 0.09487, loss: 0.09487, batch_cost: 0.60660s, reader_cost: 0.01548, ips: 105.50653 samples/s, eta: 1:00:55
[2022/06/19 05:31:16] ppcls INFO: [Train][Epoch 265/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00301759, top1: 0.96797, CELoss: 0.09536, loss: 0.09536, batch_cost: 0.60386s, reader_cost: 0.01634, ips: 105.98568 samples/s, eta: 1:00:32
[2022/06/19 05:31:22] ppcls INFO: [Train][Epoch 265/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00300767, top1: 0.96740, CELoss: 0.09701, loss: 0.09701, batch_cost: 0.60508s, reader_cost: 0.01543, ips: 105.77153 samples/s, eta: 1:00:34
[2022/06/19 05:31:27] ppcls INFO: [Train][Epoch 265/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00299778, top1: 0.96797, CELoss: 0.09534, loss: 0.09534, batch_cost: 0.59549s, reader_cost: 0.01484, ips: 107.47497 samples/s, eta: 0:59:30
[2022/06/19 05:31:29] ppcls INFO: [Train][Epoch 265/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00298789, top1: 0.96807, CELoss: 0.09504, loss: 0.09504, batch_cost: 0.57221s, reader_cost: 0.01398, ips: 85.63297 samples/s, eta: 0:57:05
[2022/06/19 05:31:29] ppcls INFO: [Train][Epoch 265/300][Avg]top1: 0.96807, CELoss: 0.09504, loss: 0.09504
[2022/06/19 05:31:36] ppcls INFO: [Eval][Epoch 265][Iter: 0/16]CELoss: 1.06792, loss: 1.06792, top1: 0.82031, batch_cost: 6.97503s, reader_cost: 3.57571, ips: 9.17559 images/sec
[2022/06/19 05:31:45] ppcls INFO: [Eval][Epoch 265][Iter: 10/16]CELoss: 1.07253, loss: 1.07253, top1: 0.82085, batch_cost: 0.59034s, reader_cost: 0.00177, ips: 108.41176 images/sec
[2022/06/19 05:31:46] ppcls INFO: [Eval][Epoch 265][Avg]CELoss: 0.85832, loss: 0.85832, top1: 0.82794
[2022/06/19 05:31:46] ppcls INFO: [Eval][Epoch 265][best metric: 0.8279412388801575]
[2022/06/19 05:31:46] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:31:53] ppcls INFO: [Train][Epoch 266/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00298691, top1: 0.96875, CELoss: 0.10024, loss: 0.10024, batch_cost: 0.60968s, reader_cost: 0.04761, ips: 104.97270 samples/s, eta: 1:00:48
[2022/06/19 05:31:59] ppcls INFO: [Train][Epoch 266/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00297704, top1: 0.97585, CELoss: 0.07047, loss: 0.07047, batch_cost: 0.60089s, reader_cost: 0.00622, ips: 106.50848 samples/s, eta: 0:59:50
[2022/06/19 05:32:06] ppcls INFO: [Train][Epoch 266/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00296719, top1: 0.97247, CELoss: 0.07849, loss: 0.07849, batch_cost: 0.61870s, reader_cost: 0.01088, ips: 103.44218 samples/s, eta: 1:01:30
[2022/06/19 05:32:12] ppcls INFO: [Train][Epoch 266/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00295736, top1: 0.97127, CELoss: 0.07872, loss: 0.07872, batch_cost: 0.64199s, reader_cost: 0.01158, ips: 99.69033 samples/s, eta: 1:03:43
[2022/06/19 05:32:18] ppcls INFO: [Train][Epoch 266/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00294754, top1: 0.96799, CELoss: 0.08302, loss: 0.08302, batch_cost: 0.62518s, reader_cost: 0.01289, ips: 102.37074 samples/s, eta: 1:01:56
[2022/06/19 05:32:24] ppcls INFO: [Train][Epoch 266/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00293774, top1: 0.96814, CELoss: 0.08477, loss: 0.08477, batch_cost: 0.62361s, reader_cost: 0.01125, ips: 102.62880 samples/s, eta: 1:01:41
[2022/06/19 05:32:33] ppcls INFO: [Train][Epoch 266/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00292795, top1: 0.96798, CELoss: 0.08607, loss: 0.08607, batch_cost: 0.65772s, reader_cost: 0.01151, ips: 97.30633 samples/s, eta: 1:04:56
[2022/06/19 05:32:38] ppcls INFO: [Train][Epoch 266/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00291818, top1: 0.96809, CELoss: 0.08936, loss: 0.08936, batch_cost: 0.63330s, reader_cost: 0.01067, ips: 101.05835 samples/s, eta: 1:02:25
[2022/06/19 05:32:44] ppcls INFO: [Train][Epoch 266/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00290843, top1: 0.96914, CELoss: 0.08680, loss: 0.08680, batch_cost: 0.63262s, reader_cost: 0.01206, ips: 101.16585 samples/s, eta: 1:02:15
[2022/06/19 05:32:49] ppcls INFO: [Train][Epoch 266/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00289869, top1: 0.96806, CELoss: 0.08995, loss: 0.08995, batch_cost: 0.62173s, reader_cost: 0.01290, ips: 102.93905 samples/s, eta: 1:01:05
[2022/06/19 05:32:55] ppcls INFO: [Train][Epoch 266/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00288897, top1: 0.96952, CELoss: 0.08692, loss: 0.08692, batch_cost: 0.62065s, reader_cost: 0.01258, ips: 103.11820 samples/s, eta: 1:00:52
[2022/06/19 05:33:01] ppcls INFO: [Train][Epoch 266/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00287926, top1: 0.96917, CELoss: 0.08877, loss: 0.08877, batch_cost: 0.61784s, reader_cost: 0.01184, ips: 103.58627 samples/s, eta: 1:00:29
[2022/06/19 05:33:07] ppcls INFO: [Train][Epoch 266/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00286957, top1: 0.96952, CELoss: 0.08922, loss: 0.08922, batch_cost: 0.61880s, reader_cost: 0.01193, ips: 103.42522 samples/s, eta: 1:00:29
[2022/06/19 05:33:14] ppcls INFO: [Train][Epoch 266/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00285989, top1: 0.96994, CELoss: 0.08878, loss: 0.08878, batch_cost: 0.61976s, reader_cost: 0.01204, ips: 103.26517 samples/s, eta: 1:00:28
[2022/06/19 05:33:21] ppcls INFO: [Train][Epoch 266/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00285023, top1: 0.97019, CELoss: 0.08864, loss: 0.08864, batch_cost: 0.62351s, reader_cost: 0.01196, ips: 102.64517 samples/s, eta: 1:00:44
[2022/06/19 05:33:27] ppcls INFO: [Train][Epoch 266/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00284059, top1: 0.97092, CELoss: 0.08775, loss: 0.08775, batch_cost: 0.62721s, reader_cost: 0.01180, ips: 102.03981 samples/s, eta: 1:00:59
[2022/06/19 05:33:32] ppcls INFO: [Train][Epoch 266/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00283096, top1: 0.97050, CELoss: 0.08831, loss: 0.08831, batch_cost: 0.61917s, reader_cost: 0.01143, ips: 103.36468 samples/s, eta: 1:00:06
[2022/06/19 05:33:34] ppcls INFO: [Train][Epoch 266/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00282135, top1: 0.97045, CELoss: 0.08845, loss: 0.08845, batch_cost: 0.59468s, reader_cost: 0.01076, ips: 82.39690 samples/s, eta: 0:57:38
[2022/06/19 05:33:35] ppcls INFO: [Train][Epoch 266/300][Avg]top1: 0.97045, CELoss: 0.08845, loss: 0.08845
[2022/06/19 05:33:35] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:33:42] ppcls INFO: [Train][Epoch 267/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00282039, top1: 0.98438, CELoss: 0.07387, loss: 0.07387, batch_cost: 0.62993s, reader_cost: 0.03709, ips: 101.59889 samples/s, eta: 1:01:02
[2022/06/19 05:33:48] ppcls INFO: [Train][Epoch 267/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00281079, top1: 0.97301, CELoss: 0.10626, loss: 0.10626, batch_cost: 0.63399s, reader_cost: 0.01492, ips: 100.94839 samples/s, eta: 1:01:19
[2022/06/19 05:33:54] ppcls INFO: [Train][Epoch 267/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00280122, top1: 0.96875, CELoss: 0.10136, loss: 0.10136, batch_cost: 0.63652s, reader_cost: 0.00928, ips: 100.54718 samples/s, eta: 1:01:27
[2022/06/19 05:34:01] ppcls INFO: [Train][Epoch 267/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00279165, top1: 0.96673, CELoss: 0.10071, loss: 0.10071, batch_cost: 0.64574s, reader_cost: 0.01130, ips: 99.11062 samples/s, eta: 1:02:14
[2022/06/19 05:34:08] ppcls INFO: [Train][Epoch 267/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00278211, top1: 0.96646, CELoss: 0.09801, loss: 0.09801, batch_cost: 0.65572s, reader_cost: 0.01203, ips: 97.60264 samples/s, eta: 1:03:06
[2022/06/19 05:34:15] ppcls INFO: [Train][Epoch 267/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00277257, top1: 0.96477, CELoss: 0.10027, loss: 0.10027, batch_cost: 0.66698s, reader_cost: 0.01443, ips: 95.95492 samples/s, eta: 1:04:04
[2022/06/19 05:34:20] ppcls INFO: [Train][Epoch 267/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00276306, top1: 0.96491, CELoss: 0.10006, loss: 0.10006, batch_cost: 0.63757s, reader_cost: 0.01342, ips: 100.38192 samples/s, eta: 1:01:08
[2022/06/19 05:34:26] ppcls INFO: [Train][Epoch 267/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00275356, top1: 0.96567, CELoss: 0.09721, loss: 0.09721, batch_cost: 0.63162s, reader_cost: 0.01248, ips: 101.32741 samples/s, eta: 1:00:28
[2022/06/19 05:34:33] ppcls INFO: [Train][Epoch 267/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00274407, top1: 0.96644, CELoss: 0.09719, loss: 0.09719, batch_cost: 0.63574s, reader_cost: 0.01234, ips: 100.67012 samples/s, eta: 1:00:45
[2022/06/19 05:34:39] ppcls INFO: [Train][Epoch 267/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00273461, top1: 0.96686, CELoss: 0.09634, loss: 0.09634, batch_cost: 0.63388s, reader_cost: 0.01222, ips: 100.96588 samples/s, eta: 1:00:28
[2022/06/19 05:34:44] ppcls INFO: [Train][Epoch 267/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00272515, top1: 0.96813, CELoss: 0.09480, loss: 0.09480, batch_cost: 0.62206s, reader_cost: 0.01255, ips: 102.88407 samples/s, eta: 0:59:14
[2022/06/19 05:34:49] ppcls INFO: [Train][Epoch 267/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00271572, top1: 0.96819, CELoss: 0.09513, loss: 0.09513, batch_cost: 0.61323s, reader_cost: 0.01253, ips: 104.36565 samples/s, eta: 0:58:17
[2022/06/19 05:34:58] ppcls INFO: [Train][Epoch 267/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00270630, top1: 0.96759, CELoss: 0.09695, loss: 0.09695, batch_cost: 0.63456s, reader_cost: 0.01217, ips: 100.85747 samples/s, eta: 1:00:13
[2022/06/19 05:35:05] ppcls INFO: [Train][Epoch 267/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00269689, top1: 0.96839, CELoss: 0.09458, loss: 0.09458, batch_cost: 0.63682s, reader_cost: 0.01230, ips: 100.49888 samples/s, eta: 1:00:19
[2022/06/19 05:35:09] ppcls INFO: [Train][Epoch 267/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00268750, top1: 0.96886, CELoss: 0.09430, loss: 0.09430, batch_cost: 0.62504s, reader_cost: 0.01239, ips: 102.39326 samples/s, eta: 0:59:06
[2022/06/19 05:35:16] ppcls INFO: [Train][Epoch 267/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00267813, top1: 0.96906, CELoss: 0.09254, loss: 0.09254, batch_cost: 0.62407s, reader_cost: 0.01220, ips: 102.55279 samples/s, eta: 0:58:54
[2022/06/19 05:35:20] ppcls INFO: [Train][Epoch 267/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00266877, top1: 0.96865, CELoss: 0.09467, loss: 0.09467, batch_cost: 0.61520s, reader_cost: 0.01174, ips: 104.03060 samples/s, eta: 0:57:58
[2022/06/19 05:35:23] ppcls INFO: [Train][Epoch 267/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00265943, top1: 0.96862, CELoss: 0.09540, loss: 0.09540, batch_cost: 0.59079s, reader_cost: 0.01105, ips: 82.94031 samples/s, eta: 0:55:34
[2022/06/19 05:35:23] ppcls INFO: [Train][Epoch 267/300][Avg]top1: 0.96862, CELoss: 0.09540, loss: 0.09540
[2022/06/19 05:35:23] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:35:29] ppcls INFO: [Train][Epoch 268/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00265850, top1: 0.98438, CELoss: 0.03819, loss: 0.03819, batch_cost: 0.62313s, reader_cost: 0.04159, ips: 102.70770 samples/s, eta: 0:58:36
[2022/06/19 05:35:38] ppcls INFO: [Train][Epoch 268/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00264918, top1: 0.96307, CELoss: 0.10097, loss: 0.10097, batch_cost: 0.81427s, reader_cost: 0.34549, ips: 78.59764 samples/s, eta: 1:16:26
[2022/06/19 05:35:44] ppcls INFO: [Train][Epoch 268/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00263987, top1: 0.96949, CELoss: 0.09941, loss: 0.09941, batch_cost: 0.65526s, reader_cost: 0.18729, ips: 97.67059 samples/s, eta: 1:01:24
[2022/06/19 05:35:50] ppcls INFO: [Train][Epoch 268/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00263058, top1: 0.97077, CELoss: 0.09609, loss: 0.09609, batch_cost: 0.63131s, reader_cost: 0.14471, ips: 101.37702 samples/s, eta: 0:59:03
[2022/06/19 05:35:56] ppcls INFO: [Train][Epoch 268/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00262130, top1: 0.96875, CELoss: 0.09777, loss: 0.09777, batch_cost: 0.61968s, reader_cost: 0.10636, ips: 103.27944 samples/s, eta: 0:57:52
[2022/06/19 05:36:02] ppcls INFO: [Train][Epoch 268/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00261204, top1: 0.96630, CELoss: 0.10127, loss: 0.10127, batch_cost: 0.61544s, reader_cost: 0.08774, ips: 103.99126 samples/s, eta: 0:57:22
[2022/06/19 05:36:08] ppcls INFO: [Train][Epoch 268/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00260279, top1: 0.96644, CELoss: 0.09966, loss: 0.09966, batch_cost: 0.61745s, reader_cost: 0.08927, ips: 103.65133 samples/s, eta: 0:57:27
[2022/06/19 05:36:14] ppcls INFO: [Train][Epoch 268/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00259357, top1: 0.96633, CELoss: 0.09884, loss: 0.09884, batch_cost: 0.61323s, reader_cost: 0.08393, ips: 104.36538 samples/s, eta: 0:56:57
[2022/06/19 05:36:20] ppcls INFO: [Train][Epoch 268/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00258435, top1: 0.96624, CELoss: 0.10004, loss: 0.10004, batch_cost: 0.61033s, reader_cost: 0.07770, ips: 104.86149 samples/s, eta: 0:56:35
[2022/06/19 05:36:27] ppcls INFO: [Train][Epoch 268/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00257516, top1: 0.96686, CELoss: 0.09992, loss: 0.09992, batch_cost: 0.61707s, reader_cost: 0.07032, ips: 103.71657 samples/s, eta: 0:57:06
[2022/06/19 05:36:32] ppcls INFO: [Train][Epoch 268/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00256598, top1: 0.96689, CELoss: 0.09778, loss: 0.09778, batch_cost: 0.61352s, reader_cost: 0.06450, ips: 104.31567 samples/s, eta: 0:56:40
[2022/06/19 05:36:38] ppcls INFO: [Train][Epoch 268/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00255681, top1: 0.96720, CELoss: 0.09955, loss: 0.09955, batch_cost: 0.60926s, reader_cost: 0.05956, ips: 105.04584 samples/s, eta: 0:56:11
[2022/06/19 05:36:44] ppcls INFO: [Train][Epoch 268/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00254766, top1: 0.96810, CELoss: 0.09714, loss: 0.09714, batch_cost: 0.60400s, reader_cost: 0.05671, ips: 105.95957 samples/s, eta: 0:55:35
[2022/06/19 05:36:50] ppcls INFO: [Train][Epoch 268/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00253853, top1: 0.96803, CELoss: 0.09748, loss: 0.09748, batch_cost: 0.60944s, reader_cost: 0.06567, ips: 105.01400 samples/s, eta: 0:55:59
[2022/06/19 05:36:57] ppcls INFO: [Train][Epoch 268/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00252941, top1: 0.96764, CELoss: 0.09873, loss: 0.09873, batch_cost: 0.61321s, reader_cost: 0.06973, ips: 104.36932 samples/s, eta: 0:56:14
[2022/06/19 05:37:02] ppcls INFO: [Train][Epoch 268/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00252031, top1: 0.96720, CELoss: 0.09972, loss: 0.09972, batch_cost: 0.60942s, reader_cost: 0.06545, ips: 105.01753 samples/s, eta: 0:55:47
[2022/06/19 05:37:07] ppcls INFO: [Train][Epoch 268/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00251123, top1: 0.96788, CELoss: 0.09712, loss: 0.09712, batch_cost: 0.60198s, reader_cost: 0.06192, ips: 106.31499 samples/s, eta: 0:55:00
[2022/06/19 05:37:10] ppcls INFO: [Train][Epoch 268/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00250216, top1: 0.96825, CELoss: 0.09621, loss: 0.09621, batch_cost: 0.57874s, reader_cost: 0.05822, ips: 84.66694 samples/s, eta: 0:52:47
[2022/06/19 05:37:10] ppcls INFO: [Train][Epoch 268/300][Avg]top1: 0.96825, CELoss: 0.09621, loss: 0.09621
[2022/06/19 05:37:10] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:37:18] ppcls INFO: [Train][Epoch 269/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00250125, top1: 0.98438, CELoss: 0.07630, loss: 0.07630, batch_cost: 0.61907s, reader_cost: 0.09792, ips: 103.38047 samples/s, eta: 0:56:27
[2022/06/19 05:37:24] ppcls INFO: [Train][Epoch 269/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00249220, top1: 0.97443, CELoss: 0.08900, loss: 0.08900, batch_cost: 0.65552s, reader_cost: 0.00866, ips: 97.63280 samples/s, eta: 0:59:40
[2022/06/19 05:37:30] ppcls INFO: [Train][Epoch 269/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00248316, top1: 0.97321, CELoss: 0.08625, loss: 0.08625, batch_cost: 0.62706s, reader_cost: 0.01467, ips: 102.06295 samples/s, eta: 0:56:58
[2022/06/19 05:37:37] ppcls INFO: [Train][Epoch 269/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00247414, top1: 0.97379, CELoss: 0.08080, loss: 0.08080, batch_cost: 0.63177s, reader_cost: 0.01979, ips: 101.30283 samples/s, eta: 0:57:18
[2022/06/19 05:37:42] ppcls INFO: [Train][Epoch 269/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00246514, top1: 0.97294, CELoss: 0.08321, loss: 0.08321, batch_cost: 0.61974s, reader_cost: 0.01780, ips: 103.26937 samples/s, eta: 0:56:06
[2022/06/19 05:37:48] ppcls INFO: [Train][Epoch 269/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00245615, top1: 0.97028, CELoss: 0.08770, loss: 0.08770, batch_cost: 0.61333s, reader_cost: 0.01877, ips: 104.34840 samples/s, eta: 0:55:25
[2022/06/19 05:37:54] ppcls INFO: [Train][Epoch 269/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00244718, top1: 0.97106, CELoss: 0.08707, loss: 0.08707, batch_cost: 0.61079s, reader_cost: 0.02070, ips: 104.78312 samples/s, eta: 0:55:05
[2022/06/19 05:38:01] ppcls INFO: [Train][Epoch 269/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00243822, top1: 0.97205, CELoss: 0.08521, loss: 0.08521, batch_cost: 0.61656s, reader_cost: 0.03552, ips: 103.80151 samples/s, eta: 0:55:30
[2022/06/19 05:38:07] ppcls INFO: [Train][Epoch 269/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00242928, top1: 0.97203, CELoss: 0.08490, loss: 0.08490, batch_cost: 0.61328s, reader_cost: 0.04091, ips: 104.35762 samples/s, eta: 0:55:06
[2022/06/19 05:38:13] ppcls INFO: [Train][Epoch 269/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00242036, top1: 0.97218, CELoss: 0.08574, loss: 0.08574, batch_cost: 0.61292s, reader_cost: 0.04604, ips: 104.41872 samples/s, eta: 0:54:58
[2022/06/19 05:38:19] ppcls INFO: [Train][Epoch 269/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00241145, top1: 0.97184, CELoss: 0.08621, loss: 0.08621, batch_cost: 0.61567s, reader_cost: 0.04902, ips: 103.95223 samples/s, eta: 0:55:07
[2022/06/19 05:38:25] ppcls INFO: [Train][Epoch 269/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00240256, top1: 0.97142, CELoss: 0.08673, loss: 0.08673, batch_cost: 0.61434s, reader_cost: 0.04786, ips: 104.17731 samples/s, eta: 0:54:54
[2022/06/19 05:38:31] ppcls INFO: [Train][Epoch 269/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00239368, top1: 0.97198, CELoss: 0.08697, loss: 0.08697, batch_cost: 0.61217s, reader_cost: 0.05222, ips: 104.54603 samples/s, eta: 0:54:36
[2022/06/19 05:38:37] ppcls INFO: [Train][Epoch 269/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00238482, top1: 0.97173, CELoss: 0.08710, loss: 0.08710, batch_cost: 0.60718s, reader_cost: 0.04901, ips: 105.40478 samples/s, eta: 0:54:03
[2022/06/19 05:38:43] ppcls INFO: [Train][Epoch 269/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00237598, top1: 0.97130, CELoss: 0.08654, loss: 0.08654, batch_cost: 0.61162s, reader_cost: 0.06090, ips: 104.63972 samples/s, eta: 0:54:21
[2022/06/19 05:38:49] ppcls INFO: [Train][Epoch 269/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00236715, top1: 0.97092, CELoss: 0.08739, loss: 0.08739, batch_cost: 0.60680s, reader_cost: 0.05753, ips: 105.47168 samples/s, eta: 0:53:49
[2022/06/19 05:38:55] ppcls INFO: [Train][Epoch 269/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00235834, top1: 0.97011, CELoss: 0.08873, loss: 0.08873, batch_cost: 0.60525s, reader_cost: 0.05843, ips: 105.74112 samples/s, eta: 0:53:35
[2022/06/19 05:38:57] ppcls INFO: [Train][Epoch 269/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00234954, top1: 0.97026, CELoss: 0.08885, loss: 0.08885, batch_cost: 0.58161s, reader_cost: 0.05500, ips: 84.24903 samples/s, eta: 0:51:23
[2022/06/19 05:38:57] ppcls INFO: [Train][Epoch 269/300][Avg]top1: 0.97026, CELoss: 0.08885, loss: 0.08885
[2022/06/19 05:38:57] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:39:04] ppcls INFO: [Train][Epoch 270/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00234866, top1: 0.95312, CELoss: 0.16606, loss: 0.16606, batch_cost: 0.61770s, reader_cost: 0.08755, ips: 103.61019 samples/s, eta: 0:54:34
[2022/06/19 05:39:11] ppcls INFO: [Train][Epoch 270/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00233989, top1: 0.96165, CELoss: 0.10176, loss: 0.10176, batch_cost: 0.65186s, reader_cost: 0.01631, ips: 98.17987 samples/s, eta: 0:57:29
[2022/06/19 05:39:17] ppcls INFO: [Train][Epoch 270/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00233112, top1: 0.96726, CELoss: 0.09157, loss: 0.09157, batch_cost: 0.61911s, reader_cost: 0.01727, ips: 103.37391 samples/s, eta: 0:54:29
[2022/06/19 05:39:23] ppcls INFO: [Train][Epoch 270/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00232238, top1: 0.96925, CELoss: 0.09088, loss: 0.09088, batch_cost: 0.61483s, reader_cost: 0.01560, ips: 104.09349 samples/s, eta: 0:54:00
[2022/06/19 05:39:29] ppcls INFO: [Train][Epoch 270/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00231365, top1: 0.96989, CELoss: 0.09041, loss: 0.09041, batch_cost: 0.61674s, reader_cost: 0.01651, ips: 103.77106 samples/s, eta: 0:54:04
[2022/06/19 05:39:35] ppcls INFO: [Train][Epoch 270/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00230493, top1: 0.96875, CELoss: 0.09132, loss: 0.09132, batch_cost: 0.61771s, reader_cost: 0.01629, ips: 103.60865 samples/s, eta: 0:54:03
[2022/06/19 05:39:42] ppcls INFO: [Train][Epoch 270/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00229623, top1: 0.96824, CELoss: 0.09637, loss: 0.09637, batch_cost: 0.62332s, reader_cost: 0.01684, ips: 102.67555 samples/s, eta: 0:54:26
[2022/06/19 05:39:47] ppcls INFO: [Train][Epoch 270/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00228755, top1: 0.96743, CELoss: 0.09746, loss: 0.09746, batch_cost: 0.61672s, reader_cost: 0.01531, ips: 103.77398 samples/s, eta: 0:53:46
[2022/06/19 05:39:53] ppcls INFO: [Train][Epoch 270/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00227888, top1: 0.96875, CELoss: 0.09417, loss: 0.09417, batch_cost: 0.60641s, reader_cost: 0.01506, ips: 105.53950 samples/s, eta: 0:52:46
[2022/06/19 05:39:58] ppcls INFO: [Train][Epoch 270/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00227023, top1: 0.96738, CELoss: 0.09762, loss: 0.09762, batch_cost: 0.59766s, reader_cost: 0.01441, ips: 107.08350 samples/s, eta: 0:51:54
[2022/06/19 05:40:04] ppcls INFO: [Train][Epoch 270/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00226160, top1: 0.96674, CELoss: 0.09737, loss: 0.09737, batch_cost: 0.59563s, reader_cost: 0.01431, ips: 107.45005 samples/s, eta: 0:51:37
[2022/06/19 05:40:10] ppcls INFO: [Train][Epoch 270/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00225298, top1: 0.96706, CELoss: 0.09597, loss: 0.09597, batch_cost: 0.59703s, reader_cost: 0.01882, ips: 107.19650 samples/s, eta: 0:51:39
[2022/06/19 05:40:16] ppcls INFO: [Train][Epoch 270/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00224438, top1: 0.96720, CELoss: 0.09545, loss: 0.09545, batch_cost: 0.59580s, reader_cost: 0.01909, ips: 107.41866 samples/s, eta: 0:51:26
[2022/06/19 05:40:22] ppcls INFO: [Train][Epoch 270/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00223579, top1: 0.96780, CELoss: 0.09436, loss: 0.09436, batch_cost: 0.59537s, reader_cost: 0.01915, ips: 107.49605 samples/s, eta: 0:51:18
[2022/06/19 05:40:28] ppcls INFO: [Train][Epoch 270/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00222722, top1: 0.96831, CELoss: 0.09187, loss: 0.09187, batch_cost: 0.59729s, reader_cost: 0.01912, ips: 107.15060 samples/s, eta: 0:51:22
[2022/06/19 05:40:34] ppcls INFO: [Train][Epoch 270/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00221867, top1: 0.96834, CELoss: 0.09166, loss: 0.09166, batch_cost: 0.59945s, reader_cost: 0.01796, ips: 106.76401 samples/s, eta: 0:51:27
[2022/06/19 05:40:39] ppcls INFO: [Train][Epoch 270/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00221013, top1: 0.96865, CELoss: 0.09129, loss: 0.09129, batch_cost: 0.59365s, reader_cost: 0.01693, ips: 107.80684 samples/s, eta: 0:50:51
[2022/06/19 05:40:41] ppcls INFO: [Train][Epoch 270/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00220161, top1: 0.96889, CELoss: 0.09076, loss: 0.09076, batch_cost: 0.57058s, reader_cost: 0.01596, ips: 85.87715 samples/s, eta: 0:48:47
[2022/06/19 05:40:42] ppcls INFO: [Train][Epoch 270/300][Avg]top1: 0.96889, CELoss: 0.09076, loss: 0.09076
[2022/06/19 05:40:49] ppcls INFO: [Eval][Epoch 270][Iter: 0/16]CELoss: 1.14947, loss: 1.14947, top1: 0.80273, batch_cost: 6.76167s, reader_cost: 3.85082, ips: 9.46511 images/sec
[2022/06/19 05:40:57] ppcls INFO: [Eval][Epoch 270][Iter: 10/16]CELoss: 1.03606, loss: 1.03606, top1: 0.82298, batch_cost: 0.59979s, reader_cost: 0.00584, ips: 106.70460 images/sec
[2022/06/19 05:40:59] ppcls INFO: [Eval][Epoch 270][Avg]CELoss: 0.85773, loss: 0.85773, top1: 0.82966
[2022/06/19 05:40:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 05:40:59] ppcls INFO: [Eval][Epoch 270][best metric: 0.8296568989753723]
[2022/06/19 05:40:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_270
[2022/06/19 05:40:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:41:06] ppcls INFO: [Train][Epoch 271/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00220075, top1: 0.98438, CELoss: 0.07954, loss: 0.07954, batch_cost: 0.60741s, reader_cost: 0.05187, ips: 105.36569 samples/s, eta: 0:51:56
[2022/06/19 05:41:12] ppcls INFO: [Train][Epoch 271/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00219225, top1: 0.97443, CELoss: 0.09925, loss: 0.09925, batch_cost: 0.71069s, reader_cost: 0.00374, ips: 90.05304 samples/s, eta: 1:00:38
[2022/06/19 05:41:18] ppcls INFO: [Train][Epoch 271/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00218376, top1: 0.97396, CELoss: 0.09194, loss: 0.09194, batch_cost: 0.62326s, reader_cost: 0.00576, ips: 102.68529 samples/s, eta: 0:53:04
[2022/06/19 05:41:24] ppcls INFO: [Train][Epoch 271/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00217529, top1: 0.96976, CELoss: 0.09743, loss: 0.09743, batch_cost: 0.62626s, reader_cost: 0.01168, ips: 102.19445 samples/s, eta: 0:53:13
[2022/06/19 05:41:31] ppcls INFO: [Train][Epoch 271/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00216683, top1: 0.96989, CELoss: 0.09813, loss: 0.09813, batch_cost: 0.62437s, reader_cost: 0.01395, ips: 102.50320 samples/s, eta: 0:52:58
[2022/06/19 05:41:37] ppcls INFO: [Train][Epoch 271/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00215839, top1: 0.97120, CELoss: 0.09029, loss: 0.09029, batch_cost: 0.62787s, reader_cost: 0.01285, ips: 101.93196 samples/s, eta: 0:53:09
[2022/06/19 05:41:43] ppcls INFO: [Train][Epoch 271/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00214997, top1: 0.97054, CELoss: 0.08923, loss: 0.08923, batch_cost: 0.62953s, reader_cost: 0.01398, ips: 101.66256 samples/s, eta: 0:53:11
[2022/06/19 05:41:49] ppcls INFO: [Train][Epoch 271/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00214156, top1: 0.97051, CELoss: 0.08893, loss: 0.08893, batch_cost: 0.61804s, reader_cost: 0.01448, ips: 103.55302 samples/s, eta: 0:52:07
[2022/06/19 05:41:56] ppcls INFO: [Train][Epoch 271/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00213317, top1: 0.97106, CELoss: 0.08766, loss: 0.08766, batch_cost: 0.62572s, reader_cost: 0.02498, ips: 102.28242 samples/s, eta: 0:52:39
[2022/06/19 05:42:02] ppcls INFO: [Train][Epoch 271/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00212479, top1: 0.96995, CELoss: 0.08927, loss: 0.08927, batch_cost: 0.62298s, reader_cost: 0.02340, ips: 102.73273 samples/s, eta: 0:52:19
[2022/06/19 05:42:08] ppcls INFO: [Train][Epoch 271/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00211643, top1: 0.96890, CELoss: 0.09272, loss: 0.09272, batch_cost: 0.61926s, reader_cost: 0.02342, ips: 103.34875 samples/s, eta: 0:51:54
[2022/06/19 05:42:14] ppcls INFO: [Train][Epoch 271/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00210809, top1: 0.96819, CELoss: 0.09459, loss: 0.09459, batch_cost: 0.62227s, reader_cost: 0.02821, ips: 102.84918 samples/s, eta: 0:52:03
[2022/06/19 05:42:21] ppcls INFO: [Train][Epoch 271/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00209976, top1: 0.96836, CELoss: 0.09628, loss: 0.09628, batch_cost: 0.62539s, reader_cost: 0.02627, ips: 102.33595 samples/s, eta: 0:52:13
[2022/06/19 05:42:28] ppcls INFO: [Train][Epoch 271/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00209145, top1: 0.96768, CELoss: 0.09662, loss: 0.09662, batch_cost: 0.63655s, reader_cost: 0.02612, ips: 100.54179 samples/s, eta: 0:53:02
[2022/06/19 05:42:32] ppcls INFO: [Train][Epoch 271/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00208315, top1: 0.96797, CELoss: 0.09531, loss: 0.09531, batch_cost: 0.61732s, reader_cost: 0.02465, ips: 103.67395 samples/s, eta: 0:51:20
[2022/06/19 05:42:37] ppcls INFO: [Train][Epoch 271/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00207487, top1: 0.96823, CELoss: 0.09484, loss: 0.09484, batch_cost: 0.60694s, reader_cost: 0.02311, ips: 105.44659 samples/s, eta: 0:50:22
[2022/06/19 05:42:46] ppcls INFO: [Train][Epoch 271/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00206661, top1: 0.96807, CELoss: 0.09430, loss: 0.09430, batch_cost: 0.62621s, reader_cost: 0.02437, ips: 102.20255 samples/s, eta: 0:51:52
[2022/06/19 05:42:48] ppcls INFO: [Train][Epoch 271/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00205836, top1: 0.96862, CELoss: 0.09252, loss: 0.09252, batch_cost: 0.60173s, reader_cost: 0.02293, ips: 81.43126 samples/s, eta: 0:49:44
[2022/06/19 05:42:49] ppcls INFO: [Train][Epoch 271/300][Avg]top1: 0.96862, CELoss: 0.09252, loss: 0.09252
[2022/06/19 05:42:49] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:42:56] ppcls INFO: [Train][Epoch 272/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00205754, top1: 0.89062, CELoss: 0.22705, loss: 0.22705, batch_cost: 0.64201s, reader_cost: 0.05570, ips: 99.68685 samples/s, eta: 0:53:03
[2022/06/19 05:43:02] ppcls INFO: [Train][Epoch 272/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00204931, top1: 0.96591, CELoss: 0.09201, loss: 0.09201, batch_cost: 0.58203s, reader_cost: 0.02837, ips: 109.96066 samples/s, eta: 0:48:00
[2022/06/19 05:43:09] ppcls INFO: [Train][Epoch 272/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00204109, top1: 0.96801, CELoss: 0.08186, loss: 0.08186, batch_cost: 0.62474s, reader_cost: 0.02586, ips: 102.44213 samples/s, eta: 0:51:25
[2022/06/19 05:43:15] ppcls INFO: [Train][Epoch 272/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00203290, top1: 0.97177, CELoss: 0.07887, loss: 0.07887, batch_cost: 0.62039s, reader_cost: 0.02402, ips: 103.16066 samples/s, eta: 0:50:57
[2022/06/19 05:43:21] ppcls INFO: [Train][Epoch 272/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00202472, top1: 0.97142, CELoss: 0.08020, loss: 0.08020, batch_cost: 0.61426s, reader_cost: 0.02229, ips: 104.19075 samples/s, eta: 0:50:21
[2022/06/19 05:43:27] ppcls INFO: [Train][Epoch 272/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00201655, top1: 0.97181, CELoss: 0.08137, loss: 0.08137, batch_cost: 0.61112s, reader_cost: 0.02341, ips: 104.72598 samples/s, eta: 0:49:59
[2022/06/19 05:43:33] ppcls INFO: [Train][Epoch 272/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00200840, top1: 0.97208, CELoss: 0.08383, loss: 0.08383, batch_cost: 0.60901s, reader_cost: 0.02418, ips: 105.08914 samples/s, eta: 0:49:43
[2022/06/19 05:43:38] ppcls INFO: [Train][Epoch 272/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00200027, top1: 0.97227, CELoss: 0.08266, loss: 0.08266, batch_cost: 0.60467s, reader_cost: 0.02401, ips: 105.84304 samples/s, eta: 0:49:16
[2022/06/19 05:43:45] ppcls INFO: [Train][Epoch 272/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00199215, top1: 0.97126, CELoss: 0.08555, loss: 0.08555, batch_cost: 0.60561s, reader_cost: 0.02340, ips: 105.67813 samples/s, eta: 0:49:14
[2022/06/19 05:43:50] ppcls INFO: [Train][Epoch 272/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00198405, top1: 0.97030, CELoss: 0.08958, loss: 0.08958, batch_cost: 0.60251s, reader_cost: 0.02185, ips: 106.22299 samples/s, eta: 0:48:53
[2022/06/19 05:43:57] ppcls INFO: [Train][Epoch 272/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00197597, top1: 0.97107, CELoss: 0.08824, loss: 0.08824, batch_cost: 0.60425s, reader_cost: 0.02100, ips: 105.91726 samples/s, eta: 0:48:56
[2022/06/19 05:44:03] ppcls INFO: [Train][Epoch 272/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00196790, top1: 0.97086, CELoss: 0.08996, loss: 0.08996, batch_cost: 0.60671s, reader_cost: 0.02013, ips: 105.48731 samples/s, eta: 0:49:01
[2022/06/19 05:44:08] ppcls INFO: [Train][Epoch 272/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00195985, top1: 0.97120, CELoss: 0.08925, loss: 0.08925, batch_cost: 0.60181s, reader_cost: 0.01973, ips: 106.34661 samples/s, eta: 0:48:32
[2022/06/19 05:44:15] ppcls INFO: [Train][Epoch 272/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00195181, top1: 0.97114, CELoss: 0.08764, loss: 0.08764, batch_cost: 0.60469s, reader_cost: 0.02834, ips: 105.83990 samples/s, eta: 0:48:40
[2022/06/19 05:44:21] ppcls INFO: [Train][Epoch 272/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00194379, top1: 0.97086, CELoss: 0.08893, loss: 0.08893, batch_cost: 0.60674s, reader_cost: 0.04444, ips: 105.48204 samples/s, eta: 0:48:43
[2022/06/19 05:44:26] ppcls INFO: [Train][Epoch 272/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00193579, top1: 0.97072, CELoss: 0.08980, loss: 0.08980, batch_cost: 0.59875s, reader_cost: 0.04218, ips: 106.88975 samples/s, eta: 0:47:59
[2022/06/19 05:44:31] ppcls INFO: [Train][Epoch 272/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00192780, top1: 0.97098, CELoss: 0.08817, loss: 0.08817, batch_cost: 0.59235s, reader_cost: 0.03994, ips: 108.04336 samples/s, eta: 0:47:22
[2022/06/19 05:44:33] ppcls INFO: [Train][Epoch 272/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00191983, top1: 0.97054, CELoss: 0.08801, loss: 0.08801, batch_cost: 0.57091s, reader_cost: 0.03757, ips: 85.82776 samples/s, eta: 0:45:34
[2022/06/19 05:44:34] ppcls INFO: [Train][Epoch 272/300][Avg]top1: 0.97054, CELoss: 0.08801, loss: 0.08801
[2022/06/19 05:44:34] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:44:41] ppcls INFO: [Train][Epoch 273/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00191903, top1: 1.00000, CELoss: 0.01652, loss: 0.01652, batch_cost: 0.60671s, reader_cost: 0.07013, ips: 105.48619 samples/s, eta: 0:48:24
[2022/06/19 05:44:47] ppcls INFO: [Train][Epoch 273/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00191108, top1: 0.97869, CELoss: 0.07770, loss: 0.07770, batch_cost: 0.60381s, reader_cost: 0.00587, ips: 105.99334 samples/s, eta: 0:48:05
[2022/06/19 05:44:54] ppcls INFO: [Train][Epoch 273/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00190314, top1: 0.97396, CELoss: 0.07648, loss: 0.07648, batch_cost: 0.65034s, reader_cost: 0.10367, ips: 98.40998 samples/s, eta: 0:51:40
[2022/06/19 05:45:01] ppcls INFO: [Train][Epoch 273/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00189522, top1: 0.97278, CELoss: 0.07823, loss: 0.07823, batch_cost: 0.65419s, reader_cost: 0.14806, ips: 97.83095 samples/s, eta: 0:51:52
[2022/06/19 05:45:06] ppcls INFO: [Train][Epoch 273/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00188731, top1: 0.97370, CELoss: 0.07921, loss: 0.07921, batch_cost: 0.62807s, reader_cost: 0.11263, ips: 101.89906 samples/s, eta: 0:49:42
[2022/06/19 05:45:12] ppcls INFO: [Train][Epoch 273/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00187942, top1: 0.97059, CELoss: 0.09028, loss: 0.09028, batch_cost: 0.62420s, reader_cost: 0.09772, ips: 102.53081 samples/s, eta: 0:49:17
[2022/06/19 05:45:19] ppcls INFO: [Train][Epoch 273/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00187155, top1: 0.96952, CELoss: 0.09355, loss: 0.09355, batch_cost: 0.63042s, reader_cost: 0.09548, ips: 101.52023 samples/s, eta: 0:49:40
[2022/06/19 05:45:25] ppcls INFO: [Train][Epoch 273/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00186369, top1: 0.97029, CELoss: 0.09160, loss: 0.09160, batch_cost: 0.63036s, reader_cost: 0.10609, ips: 101.52982 samples/s, eta: 0:49:34
[2022/06/19 05:45:31] ppcls INFO: [Train][Epoch 273/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00185585, top1: 0.96952, CELoss: 0.09220, loss: 0.09220, batch_cost: 0.62267s, reader_cost: 0.09428, ips: 102.78272 samples/s, eta: 0:48:51
[2022/06/19 05:45:37] ppcls INFO: [Train][Epoch 273/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00184803, top1: 0.96927, CELoss: 0.09454, loss: 0.09454, batch_cost: 0.62326s, reader_cost: 0.08453, ips: 102.68650 samples/s, eta: 0:48:48
[2022/06/19 05:45:43] ppcls INFO: [Train][Epoch 273/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00184022, top1: 0.96999, CELoss: 0.09263, loss: 0.09263, batch_cost: 0.62073s, reader_cost: 0.08354, ips: 103.10366 samples/s, eta: 0:48:30
[2022/06/19 05:45:49] ppcls INFO: [Train][Epoch 273/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00183243, top1: 0.96889, CELoss: 0.09415, loss: 0.09415, batch_cost: 0.61522s, reader_cost: 0.07722, ips: 104.02859 samples/s, eta: 0:47:57
[2022/06/19 05:45:55] ppcls INFO: [Train][Epoch 273/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00182465, top1: 0.96927, CELoss: 0.09192, loss: 0.09192, batch_cost: 0.61910s, reader_cost: 0.07296, ips: 103.37653 samples/s, eta: 0:48:09
[2022/06/19 05:46:02] ppcls INFO: [Train][Epoch 273/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00181689, top1: 0.96851, CELoss: 0.09328, loss: 0.09328, batch_cost: 0.62218s, reader_cost: 0.06766, ips: 102.86339 samples/s, eta: 0:48:18
[2022/06/19 05:46:08] ppcls INFO: [Train][Epoch 273/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00180915, top1: 0.96919, CELoss: 0.09231, loss: 0.09231, batch_cost: 0.62057s, reader_cost: 0.06402, ips: 103.13079 samples/s, eta: 0:48:04
[2022/06/19 05:46:14] ppcls INFO: [Train][Epoch 273/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00180142, top1: 0.96865, CELoss: 0.09372, loss: 0.09372, batch_cost: 0.61924s, reader_cost: 0.06127, ips: 103.35291 samples/s, eta: 0:47:52
[2022/06/19 05:46:20] ppcls INFO: [Train][Epoch 273/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00179371, top1: 0.96846, CELoss: 0.09328, loss: 0.09328, batch_cost: 0.61852s, reader_cost: 0.05750, ips: 103.47337 samples/s, eta: 0:47:42
[2022/06/19 05:46:22] ppcls INFO: [Train][Epoch 273/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00178602, top1: 0.96843, CELoss: 0.09446, loss: 0.09446, batch_cost: 0.59384s, reader_cost: 0.05408, ips: 82.51397 samples/s, eta: 0:45:42
[2022/06/19 05:46:23] ppcls INFO: [Train][Epoch 273/300][Avg]top1: 0.96843, CELoss: 0.09446, loss: 0.09446
[2022/06/19 05:46:23] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:46:30] ppcls INFO: [Train][Epoch 274/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00178525, top1: 0.98438, CELoss: 0.08908, loss: 0.08908, batch_cost: 0.62934s, reader_cost: 0.08566, ips: 101.69450 samples/s, eta: 0:48:25
[2022/06/19 05:46:37] ppcls INFO: [Train][Epoch 274/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00177757, top1: 0.97017, CELoss: 0.09458, loss: 0.09458, batch_cost: 0.68350s, reader_cost: 0.01945, ips: 93.63638 samples/s, eta: 0:52:28
[2022/06/19 05:46:43] ppcls INFO: [Train][Epoch 274/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00176991, top1: 0.97024, CELoss: 0.08789, loss: 0.08789, batch_cost: 0.65552s, reader_cost: 0.01507, ips: 97.63194 samples/s, eta: 0:50:13
[2022/06/19 05:46:49] ppcls INFO: [Train][Epoch 274/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00176226, top1: 0.96774, CELoss: 0.09363, loss: 0.09363, batch_cost: 0.63087s, reader_cost: 0.01422, ips: 101.44685 samples/s, eta: 0:48:13
[2022/06/19 05:46:55] ppcls INFO: [Train][Epoch 274/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00175464, top1: 0.97066, CELoss: 0.08839, loss: 0.08839, batch_cost: 0.61406s, reader_cost: 0.01442, ips: 104.22514 samples/s, eta: 0:46:50
[2022/06/19 05:47:01] ppcls INFO: [Train][Epoch 274/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00174702, top1: 0.96936, CELoss: 0.08831, loss: 0.08831, batch_cost: 0.61295s, reader_cost: 0.01435, ips: 104.41370 samples/s, eta: 0:46:39
[2022/06/19 05:47:07] ppcls INFO: [Train][Epoch 274/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00173943, top1: 0.96977, CELoss: 0.08955, loss: 0.08955, batch_cost: 0.61628s, reader_cost: 0.01392, ips: 103.84866 samples/s, eta: 0:46:48
[2022/06/19 05:47:13] ppcls INFO: [Train][Epoch 274/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00173185, top1: 0.97051, CELoss: 0.08763, loss: 0.08763, batch_cost: 0.60759s, reader_cost: 0.01371, ips: 105.33368 samples/s, eta: 0:46:02
[2022/06/19 05:47:20] ppcls INFO: [Train][Epoch 274/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00172428, top1: 0.96971, CELoss: 0.08908, loss: 0.08908, batch_cost: 0.62342s, reader_cost: 0.01389, ips: 102.65893 samples/s, eta: 0:47:08
[2022/06/19 05:47:25] ppcls INFO: [Train][Epoch 274/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00171674, top1: 0.97098, CELoss: 0.08701, loss: 0.08701, batch_cost: 0.61620s, reader_cost: 0.01395, ips: 103.86295 samples/s, eta: 0:46:29
[2022/06/19 05:47:31] ppcls INFO: [Train][Epoch 274/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00170921, top1: 0.97138, CELoss: 0.08595, loss: 0.08595, batch_cost: 0.60934s, reader_cost: 0.01469, ips: 105.03192 samples/s, eta: 0:45:52
[2022/06/19 05:47:38] ppcls INFO: [Train][Epoch 274/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00170169, top1: 0.97030, CELoss: 0.08948, loss: 0.08948, batch_cost: 0.61681s, reader_cost: 0.01498, ips: 103.75929 samples/s, eta: 0:46:19
[2022/06/19 05:47:44] ppcls INFO: [Train][Epoch 274/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00169419, top1: 0.96927, CELoss: 0.09186, loss: 0.09186, batch_cost: 0.61710s, reader_cost: 0.01427, ips: 103.71148 samples/s, eta: 0:46:15
[2022/06/19 05:47:50] ppcls INFO: [Train][Epoch 274/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00168671, top1: 0.96899, CELoss: 0.09212, loss: 0.09212, batch_cost: 0.61579s, reader_cost: 0.01353, ips: 103.93072 samples/s, eta: 0:46:03
[2022/06/19 05:47:56] ppcls INFO: [Train][Epoch 274/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00167924, top1: 0.96941, CELoss: 0.09151, loss: 0.09151, batch_cost: 0.61087s, reader_cost: 0.01325, ips: 104.76804 samples/s, eta: 0:45:34
[2022/06/19 05:48:01] ppcls INFO: [Train][Epoch 274/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00167179, top1: 0.96947, CELoss: 0.09116, loss: 0.09116, batch_cost: 0.60538s, reader_cost: 0.01256, ips: 105.71875 samples/s, eta: 0:45:04
[2022/06/19 05:48:07] ppcls INFO: [Train][Epoch 274/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00166436, top1: 0.97001, CELoss: 0.09002, loss: 0.09002, batch_cost: 0.60425s, reader_cost: 0.01253, ips: 105.91661 samples/s, eta: 0:44:53
[2022/06/19 05:48:09] ppcls INFO: [Train][Epoch 274/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00165694, top1: 0.96981, CELoss: 0.09071, loss: 0.09071, batch_cost: 0.58067s, reader_cost: 0.01183, ips: 84.38501 samples/s, eta: 0:43:02
[2022/06/19 05:48:10] ppcls INFO: [Train][Epoch 274/300][Avg]top1: 0.96981, CELoss: 0.09071, loss: 0.09071
[2022/06/19 05:48:10] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:48:16] ppcls INFO: [Train][Epoch 275/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00165620, top1: 0.96875, CELoss: 0.11269, loss: 0.11269, batch_cost: 0.61322s, reader_cost: 0.03572, ips: 104.36629 samples/s, eta: 0:45:26
[2022/06/19 05:48:23] ppcls INFO: [Train][Epoch 275/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00164880, top1: 0.97443, CELoss: 0.09433, loss: 0.09433, batch_cost: 0.61606s, reader_cost: 0.01681, ips: 103.88518 samples/s, eta: 0:45:32
[2022/06/19 05:48:29] ppcls INFO: [Train][Epoch 275/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00164142, top1: 0.97619, CELoss: 0.07452, loss: 0.07452, batch_cost: 0.62468s, reader_cost: 0.04674, ips: 102.45282 samples/s, eta: 0:46:04
[2022/06/19 05:48:35] ppcls INFO: [Train][Epoch 275/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00163405, top1: 0.97732, CELoss: 0.07226, loss: 0.07226, batch_cost: 0.63007s, reader_cost: 0.03558, ips: 101.57605 samples/s, eta: 0:46:22
[2022/06/19 05:48:43] ppcls INFO: [Train][Epoch 275/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00162670, top1: 0.97447, CELoss: 0.08062, loss: 0.08062, batch_cost: 0.65704s, reader_cost: 0.07283, ips: 97.40645 samples/s, eta: 0:48:14
[2022/06/19 05:48:48] ppcls INFO: [Train][Epoch 275/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00161937, top1: 0.97335, CELoss: 0.07984, loss: 0.07984, batch_cost: 0.63008s, reader_cost: 0.06192, ips: 101.57418 samples/s, eta: 0:46:09
[2022/06/19 05:48:54] ppcls INFO: [Train][Epoch 275/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00161205, top1: 0.97387, CELoss: 0.07717, loss: 0.07717, batch_cost: 0.61925s, reader_cost: 0.05314, ips: 103.35059 samples/s, eta: 0:45:16
[2022/06/19 05:48:59] ppcls INFO: [Train][Epoch 275/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00160475, top1: 0.97403, CELoss: 0.07790, loss: 0.07790, batch_cost: 0.61145s, reader_cost: 0.04746, ips: 104.66949 samples/s, eta: 0:44:35
[2022/06/19 05:49:05] ppcls INFO: [Train][Epoch 275/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00159746, top1: 0.97357, CELoss: 0.08001, loss: 0.08001, batch_cost: 0.60468s, reader_cost: 0.04230, ips: 105.84179 samples/s, eta: 0:44:00
[2022/06/19 05:49:12] ppcls INFO: [Train][Epoch 275/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00159019, top1: 0.97253, CELoss: 0.08236, loss: 0.08236, batch_cost: 0.61473s, reader_cost: 0.03916, ips: 104.11005 samples/s, eta: 0:44:37
[2022/06/19 05:49:18] ppcls INFO: [Train][Epoch 275/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00158294, top1: 0.97293, CELoss: 0.08187, loss: 0.08187, batch_cost: 0.61944s, reader_cost: 0.03570, ips: 103.31846 samples/s, eta: 0:44:52
[2022/06/19 05:49:25] ppcls INFO: [Train][Epoch 275/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00157570, top1: 0.97340, CELoss: 0.08039, loss: 0.08039, batch_cost: 0.61834s, reader_cost: 0.03443, ips: 103.50253 samples/s, eta: 0:44:41
[2022/06/19 05:49:31] ppcls INFO: [Train][Epoch 275/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00156848, top1: 0.97288, CELoss: 0.08156, loss: 0.08156, batch_cost: 0.62260s, reader_cost: 0.03197, ips: 102.79529 samples/s, eta: 0:44:53
[2022/06/19 05:49:37] ppcls INFO: [Train][Epoch 275/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00156128, top1: 0.97304, CELoss: 0.08190, loss: 0.08190, batch_cost: 0.61860s, reader_cost: 0.03189, ips: 103.45952 samples/s, eta: 0:44:29
[2022/06/19 05:49:45] ppcls INFO: [Train][Epoch 275/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00155409, top1: 0.97263, CELoss: 0.08210, loss: 0.08210, batch_cost: 0.63399s, reader_cost: 0.03020, ips: 100.94739 samples/s, eta: 0:45:29
[2022/06/19 05:49:49] ppcls INFO: [Train][Epoch 275/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00154692, top1: 0.97268, CELoss: 0.08141, loss: 0.08141, batch_cost: 0.61654s, reader_cost: 0.02830, ips: 103.80459 samples/s, eta: 0:44:08
[2022/06/19 05:49:54] ppcls INFO: [Train][Epoch 275/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00153976, top1: 0.97186, CELoss: 0.08423, loss: 0.08423, batch_cost: 0.60777s, reader_cost: 0.02697, ips: 105.30243 samples/s, eta: 0:43:24
[2022/06/19 05:49:56] ppcls INFO: [Train][Epoch 275/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00153262, top1: 0.97127, CELoss: 0.08544, loss: 0.08544, batch_cost: 0.58390s, reader_cost: 0.02536, ips: 83.91832 samples/s, eta: 0:41:36
[2022/06/19 05:49:57] ppcls INFO: [Train][Epoch 275/300][Avg]top1: 0.97127, CELoss: 0.08544, loss: 0.08544
[2022/06/19 05:50:04] ppcls INFO: [Eval][Epoch 275][Iter: 0/16]CELoss: 1.07951, loss: 1.07951, top1: 0.80859, batch_cost: 6.81853s, reader_cost: 3.50967, ips: 9.38618 images/sec
[2022/06/19 05:50:12] ppcls INFO: [Eval][Epoch 275][Iter: 10/16]CELoss: 1.06859, loss: 1.06859, top1: 0.82369, batch_cost: 0.57829s, reader_cost: 0.00394, ips: 110.67113 images/sec
[2022/06/19 05:50:13] ppcls INFO: [Eval][Epoch 275][Avg]CELoss: 0.85536, loss: 0.85536, top1: 0.82978
[2022/06/19 05:50:13] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 05:50:13] ppcls INFO: [Eval][Epoch 275][best metric: 0.8297794461250305]
[2022/06/19 05:50:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:50:20] ppcls INFO: [Train][Epoch 276/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00153191, top1: 0.96875, CELoss: 0.09089, loss: 0.09089, batch_cost: 0.62133s, reader_cost: 0.05721, ips: 103.00543 samples/s, eta: 0:44:16
[2022/06/19 05:50:27] ppcls INFO: [Train][Epoch 276/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00152479, top1: 0.97159, CELoss: 0.08871, loss: 0.08871, batch_cost: 0.76622s, reader_cost: 0.01706, ips: 83.52722 samples/s, eta: 0:54:27
[2022/06/19 05:50:33] ppcls INFO: [Train][Epoch 276/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00151769, top1: 0.97545, CELoss: 0.07416, loss: 0.07416, batch_cost: 0.68816s, reader_cost: 0.01098, ips: 93.00158 samples/s, eta: 0:48:48
[2022/06/19 05:50:40] ppcls INFO: [Train][Epoch 276/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00151060, top1: 0.97480, CELoss: 0.07729, loss: 0.07729, batch_cost: 0.67351s, reader_cost: 0.01052, ips: 95.02453 samples/s, eta: 0:47:39
[2022/06/19 05:50:46] ppcls INFO: [Train][Epoch 276/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00150353, top1: 0.97447, CELoss: 0.07971, loss: 0.07971, batch_cost: 0.65565s, reader_cost: 0.01043, ips: 97.61266 samples/s, eta: 0:46:16
[2022/06/19 05:50:53] ppcls INFO: [Train][Epoch 276/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00149647, top1: 0.97580, CELoss: 0.07593, loss: 0.07593, batch_cost: 0.66153s, reader_cost: 0.00958, ips: 96.74556 samples/s, eta: 0:46:34
[2022/06/19 05:50:59] ppcls INFO: [Train][Epoch 276/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00148943, top1: 0.97413, CELoss: 0.07728, loss: 0.07728, batch_cost: 0.64706s, reader_cost: 0.01030, ips: 98.90817 samples/s, eta: 0:45:27
[2022/06/19 05:51:04] ppcls INFO: [Train][Epoch 276/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00148241, top1: 0.97469, CELoss: 0.07524, loss: 0.07524, batch_cost: 0.63490s, reader_cost: 0.01010, ips: 100.80328 samples/s, eta: 0:44:29
[2022/06/19 05:51:10] ppcls INFO: [Train][Epoch 276/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00147540, top1: 0.97377, CELoss: 0.07855, loss: 0.07855, batch_cost: 0.63050s, reader_cost: 0.01120, ips: 101.50647 samples/s, eta: 0:44:04
[2022/06/19 05:51:17] ppcls INFO: [Train][Epoch 276/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00146841, top1: 0.97321, CELoss: 0.08050, loss: 0.08050, batch_cost: 0.63607s, reader_cost: 0.02734, ips: 100.61824 samples/s, eta: 0:44:21
[2022/06/19 05:51:22] ppcls INFO: [Train][Epoch 276/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00146144, top1: 0.97324, CELoss: 0.08038, loss: 0.08038, batch_cost: 0.62490s, reader_cost: 0.02466, ips: 102.41580 samples/s, eta: 0:43:28
[2022/06/19 05:51:29] ppcls INFO: [Train][Epoch 276/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00145448, top1: 0.97297, CELoss: 0.08138, loss: 0.08138, batch_cost: 0.63125s, reader_cost: 0.02518, ips: 101.38691 samples/s, eta: 0:43:49
[2022/06/19 05:51:36] ppcls INFO: [Train][Epoch 276/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00144754, top1: 0.97211, CELoss: 0.08190, loss: 0.08190, batch_cost: 0.63191s, reader_cost: 0.02405, ips: 101.28085 samples/s, eta: 0:43:45
[2022/06/19 05:51:42] ppcls INFO: [Train][Epoch 276/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00144061, top1: 0.97161, CELoss: 0.08247, loss: 0.08247, batch_cost: 0.62785s, reader_cost: 0.02306, ips: 101.93441 samples/s, eta: 0:43:22
[2022/06/19 05:51:47] ppcls INFO: [Train][Epoch 276/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00143370, top1: 0.97152, CELoss: 0.08293, loss: 0.08293, batch_cost: 0.62067s, reader_cost: 0.02240, ips: 103.11391 samples/s, eta: 0:42:46
[2022/06/19 05:51:54] ppcls INFO: [Train][Epoch 276/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00142681, top1: 0.97134, CELoss: 0.08327, loss: 0.08327, batch_cost: 0.62527s, reader_cost: 0.02176, ips: 102.35565 samples/s, eta: 0:42:59
[2022/06/19 05:51:58] ppcls INFO: [Train][Epoch 276/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00141993, top1: 0.97176, CELoss: 0.08206, loss: 0.08206, batch_cost: 0.61416s, reader_cost: 0.02115, ips: 104.20773 samples/s, eta: 0:42:07
[2022/06/19 05:52:00] ppcls INFO: [Train][Epoch 276/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00141307, top1: 0.97164, CELoss: 0.08268, loss: 0.08268, batch_cost: 0.59018s, reader_cost: 0.01989, ips: 83.02500 samples/s, eta: 0:40:22
[2022/06/19 05:52:01] ppcls INFO: [Train][Epoch 276/300][Avg]top1: 0.97164, CELoss: 0.08268, loss: 0.08268
[2022/06/19 05:52:01] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:52:07] ppcls INFO: [Train][Epoch 277/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00141239, top1: 0.93750, CELoss: 0.17394, loss: 0.17394, batch_cost: 0.62289s, reader_cost: 0.04710, ips: 102.74745 samples/s, eta: 0:42:36
[2022/06/19 05:52:14] ppcls INFO: [Train][Epoch 277/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00140555, top1: 0.96733, CELoss: 0.07795, loss: 0.07795, batch_cost: 0.70257s, reader_cost: 0.01832, ips: 91.09461 samples/s, eta: 0:47:56
[2022/06/19 05:52:20] ppcls INFO: [Train][Epoch 277/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00139872, top1: 0.96875, CELoss: 0.07437, loss: 0.07437, batch_cost: 0.65169s, reader_cost: 0.01432, ips: 98.20603 samples/s, eta: 0:44:21
[2022/06/19 05:52:26] ppcls INFO: [Train][Epoch 277/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00139191, top1: 0.97429, CELoss: 0.06841, loss: 0.06841, batch_cost: 0.63478s, reader_cost: 0.02168, ips: 100.82181 samples/s, eta: 0:43:06
[2022/06/19 05:52:33] ppcls INFO: [Train][Epoch 277/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00138512, top1: 0.97332, CELoss: 0.06910, loss: 0.06910, batch_cost: 0.64411s, reader_cost: 0.02143, ips: 99.36148 samples/s, eta: 0:43:37
[2022/06/19 05:52:39] ppcls INFO: [Train][Epoch 277/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00137834, top1: 0.97335, CELoss: 0.07499, loss: 0.07499, batch_cost: 0.64551s, reader_cost: 0.02145, ips: 99.14674 samples/s, eta: 0:43:36
[2022/06/19 05:52:45] ppcls INFO: [Train][Epoch 277/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00137158, top1: 0.97310, CELoss: 0.07466, loss: 0.07466, batch_cost: 0.63544s, reader_cost: 0.02466, ips: 100.71753 samples/s, eta: 0:42:49
[2022/06/19 05:52:51] ppcls INFO: [Train][Epoch 277/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00136484, top1: 0.97271, CELoss: 0.07628, loss: 0.07628, batch_cost: 0.62259s, reader_cost: 0.02192, ips: 102.79582 samples/s, eta: 0:41:51
[2022/06/19 05:52:57] ppcls INFO: [Train][Epoch 277/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00135811, top1: 0.97203, CELoss: 0.07927, loss: 0.07927, batch_cost: 0.62369s, reader_cost: 0.02083, ips: 102.61541 samples/s, eta: 0:41:49
[2022/06/19 05:53:04] ppcls INFO: [Train][Epoch 277/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00135140, top1: 0.97081, CELoss: 0.08578, loss: 0.08578, batch_cost: 0.63009s, reader_cost: 0.02677, ips: 101.57281 samples/s, eta: 0:42:09
[2022/06/19 05:53:10] ppcls INFO: [Train][Epoch 277/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00134470, top1: 0.97030, CELoss: 0.08679, loss: 0.08679, batch_cost: 0.62366s, reader_cost: 0.02765, ips: 102.61929 samples/s, eta: 0:41:37
[2022/06/19 05:53:16] ppcls INFO: [Train][Epoch 277/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00133803, top1: 0.97100, CELoss: 0.08509, loss: 0.08509, batch_cost: 0.62244s, reader_cost: 0.02744, ips: 102.82154 samples/s, eta: 0:41:26
[2022/06/19 05:53:22] ppcls INFO: [Train][Epoch 277/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00133136, top1: 0.97017, CELoss: 0.08862, loss: 0.08862, batch_cost: 0.62050s, reader_cost: 0.02654, ips: 103.14330 samples/s, eta: 0:41:12
[2022/06/19 05:53:28] ppcls INFO: [Train][Epoch 277/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00132472, top1: 0.97125, CELoss: 0.08676, loss: 0.08676, batch_cost: 0.61963s, reader_cost: 0.02518, ips: 103.28695 samples/s, eta: 0:41:02
[2022/06/19 05:53:34] ppcls INFO: [Train][Epoch 277/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00131809, top1: 0.97119, CELoss: 0.08693, loss: 0.08693, batch_cost: 0.62330s, reader_cost: 0.02375, ips: 102.67897 samples/s, eta: 0:41:10
[2022/06/19 05:53:40] ppcls INFO: [Train][Epoch 277/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00131148, top1: 0.97165, CELoss: 0.08650, loss: 0.08650, batch_cost: 0.62103s, reader_cost: 0.02341, ips: 103.05441 samples/s, eta: 0:40:55
[2022/06/19 05:53:46] ppcls INFO: [Train][Epoch 277/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00130488, top1: 0.97079, CELoss: 0.08729, loss: 0.08729, batch_cost: 0.61573s, reader_cost: 0.02230, ips: 103.94099 samples/s, eta: 0:40:28
[2022/06/19 05:53:48] ppcls INFO: [Train][Epoch 277/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00129830, top1: 0.97109, CELoss: 0.08574, loss: 0.08574, batch_cost: 0.59282s, reader_cost: 0.02100, ips: 82.65515 samples/s, eta: 0:38:52
[2022/06/19 05:53:49] ppcls INFO: [Train][Epoch 277/300][Avg]top1: 0.97109, CELoss: 0.08574, loss: 0.08574
[2022/06/19 05:53:49] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:53:55] ppcls INFO: [Train][Epoch 278/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00129764, top1: 0.98438, CELoss: 0.06611, loss: 0.06611, batch_cost: 0.62681s, reader_cost: 0.04752, ips: 102.10511 samples/s, eta: 0:41:05
[2022/06/19 05:54:02] ppcls INFO: [Train][Epoch 278/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00129108, top1: 0.97869, CELoss: 0.07926, loss: 0.07926, batch_cost: 0.63287s, reader_cost: 0.00765, ips: 101.12722 samples/s, eta: 0:41:22
[2022/06/19 05:54:08] ppcls INFO: [Train][Epoch 278/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00128454, top1: 0.97991, CELoss: 0.06760, loss: 0.06760, batch_cost: 0.63724s, reader_cost: 0.01019, ips: 100.43277 samples/s, eta: 0:41:33
[2022/06/19 05:54:14] ppcls INFO: [Train][Epoch 278/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00127801, top1: 0.97933, CELoss: 0.06838, loss: 0.06838, batch_cost: 0.61484s, reader_cost: 0.01178, ips: 104.09145 samples/s, eta: 0:39:59
[2022/06/19 05:54:20] ppcls INFO: [Train][Epoch 278/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00127149, top1: 0.97561, CELoss: 0.07805, loss: 0.07805, batch_cost: 0.61977s, reader_cost: 0.01224, ips: 103.26336 samples/s, eta: 0:40:12
[2022/06/19 05:54:26] ppcls INFO: [Train][Epoch 278/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00126500, top1: 0.97549, CELoss: 0.07527, loss: 0.07527, batch_cost: 0.60895s, reader_cost: 0.01414, ips: 105.09870 samples/s, eta: 0:39:24
[2022/06/19 05:54:33] ppcls INFO: [Train][Epoch 278/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00125852, top1: 0.97592, CELoss: 0.07239, loss: 0.07239, batch_cost: 0.62701s, reader_cost: 0.01521, ips: 102.07186 samples/s, eta: 0:40:28
[2022/06/19 05:54:39] ppcls INFO: [Train][Epoch 278/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00125205, top1: 0.97557, CELoss: 0.07359, loss: 0.07359, batch_cost: 0.61972s, reader_cost: 0.01599, ips: 103.27225 samples/s, eta: 0:39:53
[2022/06/19 05:54:45] ppcls INFO: [Train][Epoch 278/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00124561, top1: 0.97512, CELoss: 0.07612, loss: 0.07612, batch_cost: 0.61574s, reader_cost: 0.01514, ips: 103.93989 samples/s, eta: 0:39:32
[2022/06/19 05:54:51] ppcls INFO: [Train][Epoch 278/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00123918, top1: 0.97459, CELoss: 0.07842, loss: 0.07842, batch_cost: 0.61261s, reader_cost: 0.01662, ips: 104.47178 samples/s, eta: 0:39:14
[2022/06/19 05:54:57] ppcls INFO: [Train][Epoch 278/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00123276, top1: 0.97478, CELoss: 0.07855, loss: 0.07855, batch_cost: 0.61449s, reader_cost: 0.01598, ips: 104.15207 samples/s, eta: 0:39:15
[2022/06/19 05:55:03] ppcls INFO: [Train][Epoch 278/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00122636, top1: 0.97452, CELoss: 0.08106, loss: 0.08106, batch_cost: 0.61124s, reader_cost: 0.01630, ips: 104.70579 samples/s, eta: 0:38:56
[2022/06/19 05:55:08] ppcls INFO: [Train][Epoch 278/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00121998, top1: 0.97508, CELoss: 0.07904, loss: 0.07904, batch_cost: 0.60519s, reader_cost: 0.01575, ips: 105.75220 samples/s, eta: 0:38:27
[2022/06/19 05:55:15] ppcls INFO: [Train][Epoch 278/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00121362, top1: 0.97555, CELoss: 0.07739, loss: 0.07739, batch_cost: 0.61173s, reader_cost: 0.01607, ips: 104.62172 samples/s, eta: 0:38:46
[2022/06/19 05:55:21] ppcls INFO: [Train][Epoch 278/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00120727, top1: 0.97451, CELoss: 0.07922, loss: 0.07922, batch_cost: 0.60941s, reader_cost: 0.01538, ips: 105.01981 samples/s, eta: 0:38:31
[2022/06/19 05:55:27] ppcls INFO: [Train][Epoch 278/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00120094, top1: 0.97341, CELoss: 0.08205, loss: 0.08205, batch_cost: 0.61280s, reader_cost: 0.01526, ips: 104.43817 samples/s, eta: 0:38:38
[2022/06/19 05:55:32] ppcls INFO: [Train][Epoch 278/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00119462, top1: 0.97312, CELoss: 0.08231, loss: 0.08231, batch_cost: 0.60120s, reader_cost: 0.01474, ips: 106.45322 samples/s, eta: 0:37:48
[2022/06/19 05:55:34] ppcls INFO: [Train][Epoch 278/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00118832, top1: 0.97292, CELoss: 0.08304, loss: 0.08304, batch_cost: 0.57771s, reader_cost: 0.01386, ips: 84.81818 samples/s, eta: 0:36:13
[2022/06/19 05:55:35] ppcls INFO: [Train][Epoch 278/300][Avg]top1: 0.97292, CELoss: 0.08304, loss: 0.08304
[2022/06/19 05:55:35] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:55:42] ppcls INFO: [Train][Epoch 279/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00118769, top1: 0.98438, CELoss: 0.08050, loss: 0.08050, batch_cost: 0.62034s, reader_cost: 0.04249, ips: 103.16961 samples/s, eta: 0:38:53
[2022/06/19 05:55:49] ppcls INFO: [Train][Epoch 279/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00118141, top1: 0.97585, CELoss: 0.07604, loss: 0.07604, batch_cost: 0.65176s, reader_cost: 0.04145, ips: 98.19582 samples/s, eta: 0:40:45
[2022/06/19 05:55:55] ppcls INFO: [Train][Epoch 279/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00117515, top1: 0.96949, CELoss: 0.08937, loss: 0.08937, batch_cost: 0.63743s, reader_cost: 0.03896, ips: 100.40270 samples/s, eta: 0:39:45
[2022/06/19 05:56:01] ppcls INFO: [Train][Epoch 279/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00116890, top1: 0.97429, CELoss: 0.08321, loss: 0.08321, batch_cost: 0.61955s, reader_cost: 0.03455, ips: 103.30026 samples/s, eta: 0:38:32
[2022/06/19 05:56:07] ppcls INFO: [Train][Epoch 279/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00116266, top1: 0.97256, CELoss: 0.08439, loss: 0.08439, batch_cost: 0.61118s, reader_cost: 0.03161, ips: 104.71496 samples/s, eta: 0:37:54
[2022/06/19 05:56:12] ppcls INFO: [Train][Epoch 279/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00115645, top1: 0.97304, CELoss: 0.08390, loss: 0.08390, batch_cost: 0.60233s, reader_cost: 0.02752, ips: 106.25361 samples/s, eta: 0:37:15
[2022/06/19 05:56:18] ppcls INFO: [Train][Epoch 279/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00115025, top1: 0.97362, CELoss: 0.08206, loss: 0.08206, batch_cost: 0.59642s, reader_cost: 0.02856, ips: 107.30747 samples/s, eta: 0:36:47
[2022/06/19 05:56:24] ppcls INFO: [Train][Epoch 279/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00114407, top1: 0.97535, CELoss: 0.07845, loss: 0.07845, batch_cost: 0.59857s, reader_cost: 0.02657, ips: 106.92221 samples/s, eta: 0:36:49
[2022/06/19 05:56:31] ppcls INFO: [Train][Epoch 279/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00113790, top1: 0.97396, CELoss: 0.08061, loss: 0.08061, batch_cost: 0.61217s, reader_cost: 0.02414, ips: 104.54594 samples/s, eta: 0:37:34
[2022/06/19 05:56:37] ppcls INFO: [Train][Epoch 279/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00113175, top1: 0.97270, CELoss: 0.08282, loss: 0.08282, batch_cost: 0.60364s, reader_cost: 0.02290, ips: 106.02349 samples/s, eta: 0:36:56
[2022/06/19 05:56:43] ppcls INFO: [Train][Epoch 279/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00112562, top1: 0.97277, CELoss: 0.08463, loss: 0.08463, batch_cost: 0.60728s, reader_cost: 0.02126, ips: 105.38824 samples/s, eta: 0:37:03
[2022/06/19 05:56:48] ppcls INFO: [Train][Epoch 279/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00111950, top1: 0.97255, CELoss: 0.08437, loss: 0.08437, batch_cost: 0.59913s, reader_cost: 0.02122, ips: 106.82165 samples/s, eta: 0:36:28
[2022/06/19 05:56:54] ppcls INFO: [Train][Epoch 279/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00111340, top1: 0.97146, CELoss: 0.08647, loss: 0.08647, batch_cost: 0.60168s, reader_cost: 0.02216, ips: 106.36958 samples/s, eta: 0:36:31
[2022/06/19 05:57:00] ppcls INFO: [Train][Epoch 279/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00110732, top1: 0.97185, CELoss: 0.08647, loss: 0.08647, batch_cost: 0.59791s, reader_cost: 0.02184, ips: 107.03932 samples/s, eta: 0:36:11
[2022/06/19 05:57:06] ppcls INFO: [Train][Epoch 279/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00110125, top1: 0.97108, CELoss: 0.08802, loss: 0.08802, batch_cost: 0.60143s, reader_cost: 0.02136, ips: 106.41231 samples/s, eta: 0:36:18
[2022/06/19 05:57:12] ppcls INFO: [Train][Epoch 279/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00109520, top1: 0.97061, CELoss: 0.08970, loss: 0.08970, batch_cost: 0.60132s, reader_cost: 0.02094, ips: 106.43264 samples/s, eta: 0:36:11
[2022/06/19 05:57:18] ppcls INFO: [Train][Epoch 279/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00108916, top1: 0.97069, CELoss: 0.08811, loss: 0.08811, batch_cost: 0.59547s, reader_cost: 0.02011, ips: 107.47773 samples/s, eta: 0:35:44
[2022/06/19 05:57:20] ppcls INFO: [Train][Epoch 279/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00108314, top1: 0.97090, CELoss: 0.08877, loss: 0.08877, batch_cost: 0.57232s, reader_cost: 0.01897, ips: 85.61621 samples/s, eta: 0:34:15
[2022/06/19 05:57:20] ppcls INFO: [Train][Epoch 279/300][Avg]top1: 0.97090, CELoss: 0.08877, loss: 0.08877
[2022/06/19 05:57:20] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:57:26] ppcls INFO: [Train][Epoch 280/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00108254, top1: 0.95312, CELoss: 0.09505, loss: 0.09505, batch_cost: 0.60143s, reader_cost: 0.04646, ips: 106.41314 samples/s, eta: 0:35:59
[2022/06/19 05:57:33] ppcls INFO: [Train][Epoch 280/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00107654, top1: 0.96733, CELoss: 0.07385, loss: 0.07385, batch_cost: 0.68127s, reader_cost: 0.00032, ips: 93.94254 samples/s, eta: 0:40:39
[2022/06/19 05:57:40] ppcls INFO: [Train][Epoch 280/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00107056, top1: 0.96949, CELoss: 0.07311, loss: 0.07311, batch_cost: 0.69817s, reader_cost: 0.00621, ips: 91.66852 samples/s, eta: 0:41:33
[2022/06/19 05:57:46] ppcls INFO: [Train][Epoch 280/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00106459, top1: 0.97026, CELoss: 0.07229, loss: 0.07229, batch_cost: 0.66913s, reader_cost: 0.00656, ips: 95.64716 samples/s, eta: 0:39:42
[2022/06/19 05:57:53] ppcls INFO: [Train][Epoch 280/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00105864, top1: 0.97027, CELoss: 0.07591, loss: 0.07591, batch_cost: 0.65786s, reader_cost: 0.01212, ips: 97.28541 samples/s, eta: 0:38:56
[2022/06/19 05:57:59] ppcls INFO: [Train][Epoch 280/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00105271, top1: 0.97151, CELoss: 0.07455, loss: 0.07455, batch_cost: 0.65647s, reader_cost: 0.01121, ips: 97.49186 samples/s, eta: 0:38:44
[2022/06/19 05:58:04] ppcls INFO: [Train][Epoch 280/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00104679, top1: 0.97285, CELoss: 0.07255, loss: 0.07255, batch_cost: 0.63509s, reader_cost: 0.01061, ips: 100.77358 samples/s, eta: 0:37:22
[2022/06/19 05:58:10] ppcls INFO: [Train][Epoch 280/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00104089, top1: 0.97183, CELoss: 0.07573, loss: 0.07573, batch_cost: 0.62564s, reader_cost: 0.01007, ips: 102.29581 samples/s, eta: 0:36:42
[2022/06/19 05:58:16] ppcls INFO: [Train][Epoch 280/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00103501, top1: 0.97184, CELoss: 0.07467, loss: 0.07467, batch_cost: 0.62228s, reader_cost: 0.00970, ips: 102.84689 samples/s, eta: 0:36:24
[2022/06/19 05:58:22] ppcls INFO: [Train][Epoch 280/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00102914, top1: 0.97304, CELoss: 0.07305, loss: 0.07305, batch_cost: 0.62091s, reader_cost: 0.01798, ips: 103.07460 samples/s, eta: 0:36:13
[2022/06/19 05:58:30] ppcls INFO: [Train][Epoch 280/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00102329, top1: 0.97308, CELoss: 0.07284, loss: 0.07284, batch_cost: 0.63199s, reader_cost: 0.04252, ips: 101.26695 samples/s, eta: 0:36:46
[2022/06/19 05:58:35] ppcls INFO: [Train][Epoch 280/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00101745, top1: 0.97297, CELoss: 0.07417, loss: 0.07417, batch_cost: 0.62794s, reader_cost: 0.05059, ips: 101.92009 samples/s, eta: 0:36:25
[2022/06/19 05:58:41] ppcls INFO: [Train][Epoch 280/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00101163, top1: 0.97314, CELoss: 0.07336, loss: 0.07336, batch_cost: 0.61961s, reader_cost: 0.04796, ips: 103.29132 samples/s, eta: 0:35:50
[2022/06/19 05:58:47] ppcls INFO: [Train][Epoch 280/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00100583, top1: 0.97352, CELoss: 0.07352, loss: 0.07352, batch_cost: 0.61811s, reader_cost: 0.04574, ips: 103.54069 samples/s, eta: 0:35:39
[2022/06/19 05:58:53] ppcls INFO: [Train][Epoch 280/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00100004, top1: 0.97374, CELoss: 0.07445, loss: 0.07445, batch_cost: 0.61813s, reader_cost: 0.04312, ips: 103.53848 samples/s, eta: 0:35:33
[2022/06/19 05:58:58] ppcls INFO: [Train][Epoch 280/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00099427, top1: 0.97258, CELoss: 0.07792, loss: 0.07792, batch_cost: 0.61218s, reader_cost: 0.04077, ips: 104.54470 samples/s, eta: 0:35:06
[2022/06/19 05:59:04] ppcls INFO: [Train][Epoch 280/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00098852, top1: 0.97244, CELoss: 0.07814, loss: 0.07814, batch_cost: 0.60865s, reader_cost: 0.03863, ips: 105.15012 samples/s, eta: 0:34:48
[2022/06/19 05:59:06] ppcls INFO: [Train][Epoch 280/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00098279, top1: 0.97319, CELoss: 0.07628, loss: 0.07628, batch_cost: 0.58527s, reader_cost: 0.03636, ips: 83.72238 samples/s, eta: 0:33:22
[2022/06/19 05:59:07] ppcls INFO: [Train][Epoch 280/300][Avg]top1: 0.97319, CELoss: 0.07628, loss: 0.07628
[2022/06/19 05:59:13] ppcls INFO: [Eval][Epoch 280][Iter: 0/16]CELoss: 1.13042, loss: 1.13042, top1: 0.80273, batch_cost: 6.14836s, reader_cost: 2.84087, ips: 10.40928 images/sec
[2022/06/19 05:59:21] ppcls INFO: [Eval][Epoch 280][Iter: 10/16]CELoss: 1.07441, loss: 1.07441, top1: 0.82102, batch_cost: 0.63952s, reader_cost: 0.00508, ips: 100.07521 images/sec
[2022/06/19 05:59:23] ppcls INFO: [Eval][Epoch 280][Avg]CELoss: 0.87263, loss: 0.87263, top1: 0.82880
[2022/06/19 05:59:23] ppcls INFO: [Eval][Epoch 280][best metric: 0.8297794461250305]
[2022/06/19 05:59:23] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_280
[2022/06/19 05:59:23] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 05:59:30] ppcls INFO: [Train][Epoch 281/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00098221, top1: 0.98438, CELoss: 0.04169, loss: 0.04169, batch_cost: 0.62376s, reader_cost: 0.06432, ips: 102.60312 samples/s, eta: 0:35:33
[2022/06/19 05:59:36] ppcls INFO: [Train][Epoch 281/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00097649, top1: 0.98011, CELoss: 0.05953, loss: 0.05953, batch_cost: 0.58426s, reader_cost: 0.00426, ips: 109.53997 samples/s, eta: 0:33:12
[2022/06/19 05:59:42] ppcls INFO: [Train][Epoch 281/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00097079, top1: 0.97470, CELoss: 0.07312, loss: 0.07312, batch_cost: 0.60521s, reader_cost: 0.04479, ips: 105.74794 samples/s, eta: 0:34:17
[2022/06/19 05:59:48] ppcls INFO: [Train][Epoch 281/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00096511, top1: 0.97077, CELoss: 0.08005, loss: 0.08005, batch_cost: 0.60679s, reader_cost: 0.03412, ips: 105.47254 samples/s, eta: 0:34:17
[2022/06/19 05:59:55] ppcls INFO: [Train][Epoch 281/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00095944, top1: 0.97027, CELoss: 0.07953, loss: 0.07953, batch_cost: 0.61639s, reader_cost: 0.03281, ips: 103.83073 samples/s, eta: 0:34:43
[2022/06/19 06:00:00] ppcls INFO: [Train][Epoch 281/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00095379, top1: 0.97212, CELoss: 0.07554, loss: 0.07554, batch_cost: 0.60374s, reader_cost: 0.03067, ips: 106.00673 samples/s, eta: 0:33:54
[2022/06/19 06:00:07] ppcls INFO: [Train][Epoch 281/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00094815, top1: 0.97131, CELoss: 0.07831, loss: 0.07831, batch_cost: 0.62050s, reader_cost: 0.02877, ips: 103.14226 samples/s, eta: 0:34:44
[2022/06/19 06:00:13] ppcls INFO: [Train][Epoch 281/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00094253, top1: 0.97161, CELoss: 0.07939, loss: 0.07939, batch_cost: 0.60260s, reader_cost: 0.02551, ips: 106.20643 samples/s, eta: 0:33:38
[2022/06/19 06:00:19] ppcls INFO: [Train][Epoch 281/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00093693, top1: 0.97184, CELoss: 0.07990, loss: 0.07990, batch_cost: 0.60325s, reader_cost: 0.03553, ips: 106.09148 samples/s, eta: 0:33:34
[2022/06/19 06:00:25] ppcls INFO: [Train][Epoch 281/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00093134, top1: 0.97253, CELoss: 0.07793, loss: 0.07793, batch_cost: 0.60746s, reader_cost: 0.03821, ips: 105.35592 samples/s, eta: 0:33:42
[2022/06/19 06:00:31] ppcls INFO: [Train][Epoch 281/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00092578, top1: 0.97123, CELoss: 0.08186, loss: 0.08186, batch_cost: 0.60995s, reader_cost: 0.03532, ips: 104.92606 samples/s, eta: 0:33:45
[2022/06/19 06:00:37] ppcls INFO: [Train][Epoch 281/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00092022, top1: 0.97058, CELoss: 0.08334, loss: 0.08334, batch_cost: 0.60995s, reader_cost: 0.03323, ips: 104.92694 samples/s, eta: 0:33:38
[2022/06/19 06:00:44] ppcls INFO: [Train][Epoch 281/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00091469, top1: 0.97030, CELoss: 0.08320, loss: 0.08320, batch_cost: 0.61168s, reader_cost: 0.03132, ips: 104.63010 samples/s, eta: 0:33:38
[2022/06/19 06:00:49] ppcls INFO: [Train][Epoch 281/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00090917, top1: 0.96994, CELoss: 0.08563, loss: 0.08563, batch_cost: 0.60360s, reader_cost: 0.02939, ips: 106.03026 samples/s, eta: 0:33:05
[2022/06/19 06:00:55] ppcls INFO: [Train][Epoch 281/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00090366, top1: 0.97008, CELoss: 0.08670, loss: 0.08670, batch_cost: 0.60332s, reader_cost: 0.02820, ips: 106.08020 samples/s, eta: 0:32:58
[2022/06/19 06:01:02] ppcls INFO: [Train][Epoch 281/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00089818, top1: 0.97061, CELoss: 0.08563, loss: 0.08563, batch_cost: 0.60855s, reader_cost: 0.02769, ips: 105.16756 samples/s, eta: 0:33:09
[2022/06/19 06:01:06] ppcls INFO: [Train][Epoch 281/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00089271, top1: 0.97040, CELoss: 0.08635, loss: 0.08635, batch_cost: 0.59803s, reader_cost: 0.02742, ips: 107.01778 samples/s, eta: 0:32:29
[2022/06/19 06:01:08] ppcls INFO: [Train][Epoch 281/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00088725, top1: 0.97099, CELoss: 0.08505, loss: 0.08505, batch_cost: 0.57587s, reader_cost: 0.02580, ips: 85.08900 samples/s, eta: 0:31:11
[2022/06/19 06:01:09] ppcls INFO: [Train][Epoch 281/300][Avg]top1: 0.97099, CELoss: 0.08505, loss: 0.08505
[2022/06/19 06:01:09] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:01:16] ppcls INFO: [Train][Epoch 282/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00088671, top1: 0.90625, CELoss: 0.31835, loss: 0.31835, batch_cost: 0.61082s, reader_cost: 0.05516, ips: 104.77649 samples/s, eta: 0:33:04
[2022/06/19 06:01:23] ppcls INFO: [Train][Epoch 282/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00088127, top1: 0.96875, CELoss: 0.08677, loss: 0.08677, batch_cost: 0.85261s, reader_cost: 0.00836, ips: 75.06322 samples/s, eta: 0:46:01
[2022/06/19 06:01:29] ppcls INFO: [Train][Epoch 282/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00087585, top1: 0.97247, CELoss: 0.07734, loss: 0.07734, batch_cost: 0.67465s, reader_cost: 0.01270, ips: 94.86414 samples/s, eta: 0:36:18
[2022/06/19 06:01:35] ppcls INFO: [Train][Epoch 282/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00087045, top1: 0.97278, CELoss: 0.07960, loss: 0.07960, batch_cost: 0.65359s, reader_cost: 0.01265, ips: 97.92039 samples/s, eta: 0:35:03
[2022/06/19 06:01:42] ppcls INFO: [Train][Epoch 282/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00086507, top1: 0.96875, CELoss: 0.08215, loss: 0.08215, batch_cost: 0.66639s, reader_cost: 0.01092, ips: 96.03937 samples/s, eta: 0:35:38
[2022/06/19 06:01:48] ppcls INFO: [Train][Epoch 282/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00085970, top1: 0.96814, CELoss: 0.08459, loss: 0.08459, batch_cost: 0.65213s, reader_cost: 0.01218, ips: 98.13936 samples/s, eta: 0:34:46
[2022/06/19 06:01:54] ppcls INFO: [Train][Epoch 282/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00085434, top1: 0.96721, CELoss: 0.08503, loss: 0.08503, batch_cost: 0.63749s, reader_cost: 0.01120, ips: 100.39392 samples/s, eta: 0:33:52
[2022/06/19 06:02:00] ppcls INFO: [Train][Epoch 282/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00084901, top1: 0.96721, CELoss: 0.08653, loss: 0.08653, batch_cost: 0.63150s, reader_cost: 0.01398, ips: 101.34632 samples/s, eta: 0:33:27
[2022/06/19 06:02:06] ppcls INFO: [Train][Epoch 282/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00084369, top1: 0.96798, CELoss: 0.08672, loss: 0.08672, batch_cost: 0.63551s, reader_cost: 0.01364, ips: 100.70661 samples/s, eta: 0:33:33
[2022/06/19 06:02:12] ppcls INFO: [Train][Epoch 282/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00083839, top1: 0.96738, CELoss: 0.08906, loss: 0.08906, batch_cost: 0.62992s, reader_cost: 0.01413, ips: 101.59941 samples/s, eta: 0:33:09
[2022/06/19 06:02:19] ppcls INFO: [Train][Epoch 282/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00083310, top1: 0.96813, CELoss: 0.08921, loss: 0.08921, batch_cost: 0.62914s, reader_cost: 0.01454, ips: 101.72587 samples/s, eta: 0:33:01
[2022/06/19 06:02:24] ppcls INFO: [Train][Epoch 282/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00082783, top1: 0.96847, CELoss: 0.08915, loss: 0.08915, batch_cost: 0.62141s, reader_cost: 0.01603, ips: 102.99157 samples/s, eta: 0:32:30
[2022/06/19 06:02:31] ppcls INFO: [Train][Epoch 282/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00082258, top1: 0.96901, CELoss: 0.08830, loss: 0.08830, batch_cost: 0.63085s, reader_cost: 0.01869, ips: 101.45093 samples/s, eta: 0:32:53
[2022/06/19 06:02:37] ppcls INFO: [Train][Epoch 282/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00081734, top1: 0.96911, CELoss: 0.08847, loss: 0.08847, batch_cost: 0.62213s, reader_cost: 0.01979, ips: 102.87259 samples/s, eta: 0:32:20
[2022/06/19 06:02:43] ppcls INFO: [Train][Epoch 282/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00081212, top1: 0.96941, CELoss: 0.08816, loss: 0.08816, batch_cost: 0.62100s, reader_cost: 0.01985, ips: 103.05882 samples/s, eta: 0:32:10
[2022/06/19 06:02:48] ppcls INFO: [Train][Epoch 282/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00080692, top1: 0.96906, CELoss: 0.08979, loss: 0.08979, batch_cost: 0.61756s, reader_cost: 0.01874, ips: 103.63414 samples/s, eta: 0:31:53
[2022/06/19 06:02:54] ppcls INFO: [Train][Epoch 282/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00080173, top1: 0.96894, CELoss: 0.09130, loss: 0.09130, batch_cost: 0.61279s, reader_cost: 0.02660, ips: 104.44081 samples/s, eta: 0:31:32
[2022/06/19 06:02:56] ppcls INFO: [Train][Epoch 282/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00079656, top1: 0.96926, CELoss: 0.09162, loss: 0.09162, batch_cost: 0.58923s, reader_cost: 0.02535, ips: 83.15995 samples/s, eta: 0:30:14
[2022/06/19 06:02:57] ppcls INFO: [Train][Epoch 282/300][Avg]top1: 0.96926, CELoss: 0.09162, loss: 0.09162
[2022/06/19 06:02:57] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:03:03] ppcls INFO: [Train][Epoch 283/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00079604, top1: 1.00000, CELoss: 0.02240, loss: 0.02240, batch_cost: 0.62285s, reader_cost: 0.05052, ips: 102.75310 samples/s, eta: 0:31:57
[2022/06/19 06:03:10] ppcls INFO: [Train][Epoch 283/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00079089, top1: 0.96733, CELoss: 0.07279, loss: 0.07279, batch_cost: 0.74753s, reader_cost: 0.00037, ips: 85.61504 samples/s, eta: 0:38:13
[2022/06/19 06:03:17] ppcls INFO: [Train][Epoch 283/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00078575, top1: 0.96726, CELoss: 0.08789, loss: 0.08789, batch_cost: 0.67514s, reader_cost: 0.02995, ips: 94.79552 samples/s, eta: 0:34:24
[2022/06/19 06:03:22] ppcls INFO: [Train][Epoch 283/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00078063, top1: 0.96825, CELoss: 0.08621, loss: 0.08621, batch_cost: 0.63767s, reader_cost: 0.02117, ips: 100.36511 samples/s, eta: 0:32:23
[2022/06/19 06:03:29] ppcls INFO: [Train][Epoch 283/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00077553, top1: 0.96723, CELoss: 0.08915, loss: 0.08915, batch_cost: 0.64093s, reader_cost: 0.02097, ips: 99.85567 samples/s, eta: 0:32:27
[2022/06/19 06:03:35] ppcls INFO: [Train][Epoch 283/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00077045, top1: 0.96814, CELoss: 0.08992, loss: 0.08992, batch_cost: 0.62766s, reader_cost: 0.01992, ips: 101.96615 samples/s, eta: 0:31:40
[2022/06/19 06:03:42] ppcls INFO: [Train][Epoch 283/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00076538, top1: 0.96824, CELoss: 0.08939, loss: 0.08939, batch_cost: 0.64579s, reader_cost: 0.02963, ips: 99.10363 samples/s, eta: 0:32:28
[2022/06/19 06:03:47] ppcls INFO: [Train][Epoch 283/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00076032, top1: 0.96721, CELoss: 0.09208, loss: 0.09208, batch_cost: 0.63025s, reader_cost: 0.02697, ips: 101.54737 samples/s, eta: 0:31:35
[2022/06/19 06:03:54] ppcls INFO: [Train][Epoch 283/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00075529, top1: 0.96721, CELoss: 0.09204, loss: 0.09204, batch_cost: 0.63365s, reader_cost: 0.02959, ips: 101.00207 samples/s, eta: 0:31:39
[2022/06/19 06:04:00] ppcls INFO: [Train][Epoch 283/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00075027, top1: 0.96720, CELoss: 0.09183, loss: 0.09183, batch_cost: 0.62949s, reader_cost: 0.02750, ips: 101.66951 samples/s, eta: 0:31:20
[2022/06/19 06:04:06] ppcls INFO: [Train][Epoch 283/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00074527, top1: 0.96705, CELoss: 0.09135, loss: 0.09135, batch_cost: 0.62950s, reader_cost: 0.02676, ips: 101.66747 samples/s, eta: 0:31:14
[2022/06/19 06:04:12] ppcls INFO: [Train][Epoch 283/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00074028, top1: 0.96776, CELoss: 0.09109, loss: 0.09109, batch_cost: 0.62210s, reader_cost: 0.02562, ips: 102.87812 samples/s, eta: 0:30:46
[2022/06/19 06:04:18] ppcls INFO: [Train][Epoch 283/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00073531, top1: 0.96810, CELoss: 0.09041, loss: 0.09041, batch_cost: 0.62193s, reader_cost: 0.02499, ips: 102.90598 samples/s, eta: 0:30:39
[2022/06/19 06:04:24] ppcls INFO: [Train][Epoch 283/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00073036, top1: 0.96815, CELoss: 0.09015, loss: 0.09015, batch_cost: 0.62114s, reader_cost: 0.03498, ips: 103.03566 samples/s, eta: 0:30:31
[2022/06/19 06:04:31] ppcls INFO: [Train][Epoch 283/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00072542, top1: 0.96786, CELoss: 0.09099, loss: 0.09099, batch_cost: 0.62252s, reader_cost: 0.03303, ips: 102.80756 samples/s, eta: 0:30:28
[2022/06/19 06:04:37] ppcls INFO: [Train][Epoch 283/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00072050, top1: 0.96803, CELoss: 0.09102, loss: 0.09102, batch_cost: 0.62091s, reader_cost: 0.03120, ips: 103.07513 samples/s, eta: 0:30:18
[2022/06/19 06:04:42] ppcls INFO: [Train][Epoch 283/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00071560, top1: 0.96778, CELoss: 0.09154, loss: 0.09154, batch_cost: 0.61812s, reader_cost: 0.02952, ips: 103.54050 samples/s, eta: 0:30:03
[2022/06/19 06:04:44] ppcls INFO: [Train][Epoch 283/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00071071, top1: 0.96862, CELoss: 0.09036, loss: 0.09036, batch_cost: 0.59371s, reader_cost: 0.02784, ips: 82.53211 samples/s, eta: 0:28:46
[2022/06/19 06:04:45] ppcls INFO: [Train][Epoch 283/300][Avg]top1: 0.96862, CELoss: 0.09036, loss: 0.09036
[2022/06/19 06:04:45] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:04:51] ppcls INFO: [Train][Epoch 284/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00071022, top1: 0.96875, CELoss: 0.12479, loss: 0.12479, batch_cost: 0.62608s, reader_cost: 0.05943, ips: 102.22390 samples/s, eta: 0:30:20
[2022/06/19 06:04:59] ppcls INFO: [Train][Epoch 284/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00070535, top1: 0.96875, CELoss: 0.09605, loss: 0.09605, batch_cost: 0.69764s, reader_cost: 0.03799, ips: 91.73769 samples/s, eta: 0:33:41
[2022/06/19 06:05:05] ppcls INFO: [Train][Epoch 284/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00070050, top1: 0.97098, CELoss: 0.08490, loss: 0.08490, batch_cost: 0.65591s, reader_cost: 0.02026, ips: 97.57441 samples/s, eta: 0:31:33
[2022/06/19 06:05:12] ppcls INFO: [Train][Epoch 284/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00069567, top1: 0.97127, CELoss: 0.08389, loss: 0.08389, batch_cost: 0.66224s, reader_cost: 0.01821, ips: 96.64233 samples/s, eta: 0:31:45
[2022/06/19 06:05:17] ppcls INFO: [Train][Epoch 284/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00069085, top1: 0.97523, CELoss: 0.07491, loss: 0.07491, batch_cost: 0.62524s, reader_cost: 0.01537, ips: 102.36026 samples/s, eta: 0:29:52
[2022/06/19 06:05:23] ppcls INFO: [Train][Epoch 284/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00068605, top1: 0.97518, CELoss: 0.07892, loss: 0.07892, batch_cost: 0.61054s, reader_cost: 0.01521, ips: 104.82538 samples/s, eta: 0:29:04
[2022/06/19 06:05:29] ppcls INFO: [Train][Epoch 284/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00068126, top1: 0.97592, CELoss: 0.07804, loss: 0.07804, batch_cost: 0.60492s, reader_cost: 0.01703, ips: 105.79954 samples/s, eta: 0:28:42
[2022/06/19 06:05:36] ppcls INFO: [Train][Epoch 284/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00067649, top1: 0.97623, CELoss: 0.07852, loss: 0.07852, batch_cost: 0.62256s, reader_cost: 0.01573, ips: 102.80107 samples/s, eta: 0:29:26
[2022/06/19 06:05:41] ppcls INFO: [Train][Epoch 284/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00067174, top1: 0.97627, CELoss: 0.07879, loss: 0.07879, batch_cost: 0.60895s, reader_cost: 0.01574, ips: 105.09909 samples/s, eta: 0:28:41
[2022/06/19 06:05:47] ppcls INFO: [Train][Epoch 284/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00066700, top1: 0.97476, CELoss: 0.08093, loss: 0.08093, batch_cost: 0.61140s, reader_cost: 0.01742, ips: 104.67780 samples/s, eta: 0:28:42
[2022/06/19 06:05:55] ppcls INFO: [Train][Epoch 284/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00066229, top1: 0.97277, CELoss: 0.08625, loss: 0.08625, batch_cost: 0.62585s, reader_cost: 0.01918, ips: 102.26049 samples/s, eta: 0:29:16
[2022/06/19 06:06:00] ppcls INFO: [Train][Epoch 284/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00065758, top1: 0.97283, CELoss: 0.08703, loss: 0.08703, batch_cost: 0.62045s, reader_cost: 0.01866, ips: 103.15114 samples/s, eta: 0:28:55
[2022/06/19 06:06:06] ppcls INFO: [Train][Epoch 284/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00065290, top1: 0.97288, CELoss: 0.08544, loss: 0.08544, batch_cost: 0.61524s, reader_cost: 0.01770, ips: 104.02462 samples/s, eta: 0:28:34
[2022/06/19 06:06:12] ppcls INFO: [Train][Epoch 284/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00064823, top1: 0.97376, CELoss: 0.08388, loss: 0.08388, batch_cost: 0.61650s, reader_cost: 0.01707, ips: 103.81101 samples/s, eta: 0:28:32
[2022/06/19 06:06:18] ppcls INFO: [Train][Epoch 284/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00064358, top1: 0.97285, CELoss: 0.08542, loss: 0.08542, batch_cost: 0.61369s, reader_cost: 0.01642, ips: 104.28686 samples/s, eta: 0:28:18
[2022/06/19 06:06:24] ppcls INFO: [Train][Epoch 284/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00063894, top1: 0.97258, CELoss: 0.08564, loss: 0.08564, batch_cost: 0.61355s, reader_cost: 0.01590, ips: 104.31147 samples/s, eta: 0:28:11
[2022/06/19 06:06:30] ppcls INFO: [Train][Epoch 284/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00063432, top1: 0.97283, CELoss: 0.08574, loss: 0.08574, batch_cost: 0.60856s, reader_cost: 0.01561, ips: 105.16609 samples/s, eta: 0:27:51
[2022/06/19 06:06:32] ppcls INFO: [Train][Epoch 284/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00062972, top1: 0.97246, CELoss: 0.08722, loss: 0.08722, batch_cost: 0.58449s, reader_cost: 0.01470, ips: 83.83392 samples/s, eta: 0:26:39
[2022/06/19 06:06:32] ppcls INFO: [Train][Epoch 284/300][Avg]top1: 0.97246, CELoss: 0.08722, loss: 0.08722
[2022/06/19 06:06:33] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:06:40] ppcls INFO: [Train][Epoch 285/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00062926, top1: 1.00000, CELoss: 0.02199, loss: 0.02199, batch_cost: 0.62486s, reader_cost: 0.04705, ips: 102.42325 samples/s, eta: 0:28:29
[2022/06/19 06:06:46] ppcls INFO: [Train][Epoch 285/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00062468, top1: 0.97017, CELoss: 0.10014, loss: 0.10014, batch_cost: 0.56495s, reader_cost: 0.00044, ips: 113.28499 samples/s, eta: 0:25:40
[2022/06/19 06:06:52] ppcls INFO: [Train][Epoch 285/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00062011, top1: 0.97619, CELoss: 0.08823, loss: 0.08823, batch_cost: 0.61122s, reader_cost: 0.00161, ips: 104.70799 samples/s, eta: 0:27:40
[2022/06/19 06:06:58] ppcls INFO: [Train][Epoch 285/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00061556, top1: 0.97681, CELoss: 0.08839, loss: 0.08839, batch_cost: 0.61788s, reader_cost: 0.01200, ips: 103.58020 samples/s, eta: 0:27:51
[2022/06/19 06:07:06] ppcls INFO: [Train][Epoch 285/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00061102, top1: 0.97637, CELoss: 0.08570, loss: 0.08570, batch_cost: 0.65013s, reader_cost: 0.02757, ips: 98.44172 samples/s, eta: 0:29:12
[2022/06/19 06:07:12] ppcls INFO: [Train][Epoch 285/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00060651, top1: 0.97855, CELoss: 0.08189, loss: 0.08189, batch_cost: 0.63472s, reader_cost: 0.02306, ips: 100.83243 samples/s, eta: 0:28:24
[2022/06/19 06:07:17] ppcls INFO: [Train][Epoch 285/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00060200, top1: 0.97695, CELoss: 0.08308, loss: 0.08308, batch_cost: 0.62681s, reader_cost: 0.02129, ips: 102.10486 samples/s, eta: 0:27:57
[2022/06/19 06:07:23] ppcls INFO: [Train][Epoch 285/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00059752, top1: 0.97689, CELoss: 0.08518, loss: 0.08518, batch_cost: 0.61509s, reader_cost: 0.02104, ips: 104.05004 samples/s, eta: 0:27:19
[2022/06/19 06:07:29] ppcls INFO: [Train][Epoch 285/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00059305, top1: 0.97627, CELoss: 0.08367, loss: 0.08367, batch_cost: 0.61529s, reader_cost: 0.01931, ips: 104.01613 samples/s, eta: 0:27:14
[2022/06/19 06:07:35] ppcls INFO: [Train][Epoch 285/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00058860, top1: 0.97630, CELoss: 0.08397, loss: 0.08397, batch_cost: 0.61718s, reader_cost: 0.01843, ips: 103.69675 samples/s, eta: 0:27:13
[2022/06/19 06:07:42] ppcls INFO: [Train][Epoch 285/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00058417, top1: 0.97664, CELoss: 0.08207, loss: 0.08207, batch_cost: 0.62451s, reader_cost: 0.01726, ips: 102.48036 samples/s, eta: 0:27:26
[2022/06/19 06:07:48] ppcls INFO: [Train][Epoch 285/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00057975, top1: 0.97607, CELoss: 0.08176, loss: 0.08176, batch_cost: 0.61571s, reader_cost: 0.01658, ips: 103.94422 samples/s, eta: 0:26:56
[2022/06/19 06:07:53] ppcls INFO: [Train][Epoch 285/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00057535, top1: 0.97585, CELoss: 0.08267, loss: 0.08267, batch_cost: 0.61276s, reader_cost: 0.01574, ips: 104.44512 samples/s, eta: 0:26:42
[2022/06/19 06:07:59] ppcls INFO: [Train][Epoch 285/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00057096, top1: 0.97591, CELoss: 0.08163, loss: 0.08163, batch_cost: 0.61220s, reader_cost: 0.01569, ips: 104.54052 samples/s, eta: 0:26:35
[2022/06/19 06:08:06] ppcls INFO: [Train][Epoch 285/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00056660, top1: 0.97551, CELoss: 0.08153, loss: 0.08153, batch_cost: 0.61288s, reader_cost: 0.01504, ips: 104.42463 samples/s, eta: 0:26:31
[2022/06/19 06:08:12] ppcls INFO: [Train][Epoch 285/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00056225, top1: 0.97537, CELoss: 0.08173, loss: 0.08173, batch_cost: 0.61118s, reader_cost: 0.01474, ips: 104.71472 samples/s, eta: 0:26:20
[2022/06/19 06:08:17] ppcls INFO: [Train][Epoch 285/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00055791, top1: 0.97554, CELoss: 0.08068, loss: 0.08068, batch_cost: 0.60510s, reader_cost: 0.01400, ips: 105.76731 samples/s, eta: 0:25:58
[2022/06/19 06:08:19] ppcls INFO: [Train][Epoch 285/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00055359, top1: 0.97520, CELoss: 0.08050, loss: 0.08050, batch_cost: 0.58137s, reader_cost: 0.01319, ips: 84.28416 samples/s, eta: 0:24:51
[2022/06/19 06:08:20] ppcls INFO: [Train][Epoch 285/300][Avg]top1: 0.97520, CELoss: 0.08050, loss: 0.08050
[2022/06/19 06:08:27] ppcls INFO: [Eval][Epoch 285][Iter: 0/16]CELoss: 1.07119, loss: 1.07119, top1: 0.80859, batch_cost: 7.30340s, reader_cost: 3.40853, ips: 8.76304 images/sec
[2022/06/19 06:08:35] ppcls INFO: [Eval][Epoch 285][Iter: 10/16]CELoss: 1.04143, loss: 1.04143, top1: 0.82298, batch_cost: 0.60591s, reader_cost: 0.00088, ips: 105.62629 images/sec
[2022/06/19 06:08:37] ppcls INFO: [Eval][Epoch 285][Avg]CELoss: 0.85593, loss: 0.85593, top1: 0.83015
[2022/06/19 06:08:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 06:08:37] ppcls INFO: [Eval][Epoch 285][best metric: 0.8301470875740051]
[2022/06/19 06:08:37] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:08:43] ppcls INFO: [Train][Epoch 286/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00055316, top1: 1.00000, CELoss: 0.03218, loss: 0.03218, batch_cost: 0.61461s, reader_cost: 0.04506, ips: 104.13074 samples/s, eta: 0:26:16
[2022/06/19 06:08:50] ppcls INFO: [Train][Epoch 286/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00054886, top1: 0.97443, CELoss: 0.08135, loss: 0.08135, batch_cost: 0.65512s, reader_cost: 0.07257, ips: 97.69129 samples/s, eta: 0:27:53
[2022/06/19 06:08:56] ppcls INFO: [Train][Epoch 286/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00054458, top1: 0.97470, CELoss: 0.08320, loss: 0.08320, batch_cost: 0.65642s, reader_cost: 0.06536, ips: 97.49917 samples/s, eta: 0:27:50
[2022/06/19 06:09:03] ppcls INFO: [Train][Epoch 286/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00054032, top1: 0.97429, CELoss: 0.08237, loss: 0.08237, batch_cost: 0.65431s, reader_cost: 0.07665, ips: 97.81264 samples/s, eta: 0:27:38
[2022/06/19 06:09:08] ppcls INFO: [Train][Epoch 286/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00053607, top1: 0.97294, CELoss: 0.08480, loss: 0.08480, batch_cost: 0.62516s, reader_cost: 0.05829, ips: 102.37458 samples/s, eta: 0:26:18
[2022/06/19 06:09:15] ppcls INFO: [Train][Epoch 286/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00053183, top1: 0.97212, CELoss: 0.09041, loss: 0.09041, batch_cost: 0.63279s, reader_cost: 0.09309, ips: 101.14012 samples/s, eta: 0:26:31
[2022/06/19 06:09:21] ppcls INFO: [Train][Epoch 286/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00052762, top1: 0.97182, CELoss: 0.09118, loss: 0.09118, batch_cost: 0.62551s, reader_cost: 0.07768, ips: 102.31634 samples/s, eta: 0:26:06
[2022/06/19 06:09:27] ppcls INFO: [Train][Epoch 286/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00052342, top1: 0.97183, CELoss: 0.09069, loss: 0.09069, batch_cost: 0.62277s, reader_cost: 0.06992, ips: 102.76627 samples/s, eta: 0:25:53
[2022/06/19 06:09:32] ppcls INFO: [Train][Epoch 286/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00051924, top1: 0.97222, CELoss: 0.08786, loss: 0.08786, batch_cost: 0.61709s, reader_cost: 0.07208, ips: 103.71268 samples/s, eta: 0:25:33
[2022/06/19 06:09:38] ppcls INFO: [Train][Epoch 286/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00051507, top1: 0.97287, CELoss: 0.08663, loss: 0.08663, batch_cost: 0.61286s, reader_cost: 0.07225, ips: 104.42899 samples/s, eta: 0:25:16
[2022/06/19 06:09:44] ppcls INFO: [Train][Epoch 286/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00051092, top1: 0.97277, CELoss: 0.08813, loss: 0.08813, batch_cost: 0.61360s, reader_cost: 0.07355, ips: 104.30185 samples/s, eta: 0:25:12
[2022/06/19 06:09:50] ppcls INFO: [Train][Epoch 286/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00050679, top1: 0.97255, CELoss: 0.08851, loss: 0.08851, batch_cost: 0.60747s, reader_cost: 0.07170, ips: 105.35581 samples/s, eta: 0:24:51
[2022/06/19 06:09:57] ppcls INFO: [Train][Epoch 286/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00050267, top1: 0.97185, CELoss: 0.08995, loss: 0.08995, batch_cost: 0.61284s, reader_cost: 0.07914, ips: 104.43116 samples/s, eta: 0:24:58
[2022/06/19 06:10:03] ppcls INFO: [Train][Epoch 286/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00049857, top1: 0.97125, CELoss: 0.08998, loss: 0.08998, batch_cost: 0.61036s, reader_cost: 0.07341, ips: 104.85560 samples/s, eta: 0:24:46
[2022/06/19 06:10:10] ppcls INFO: [Train][Epoch 286/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00049449, top1: 0.97152, CELoss: 0.08866, loss: 0.08866, batch_cost: 0.61742s, reader_cost: 0.06978, ips: 103.65651 samples/s, eta: 0:24:57
[2022/06/19 06:10:14] ppcls INFO: [Train][Epoch 286/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00049042, top1: 0.97237, CELoss: 0.08691, loss: 0.08691, batch_cost: 0.60652s, reader_cost: 0.06573, ips: 105.52085 samples/s, eta: 0:24:24
[2022/06/19 06:10:20] ppcls INFO: [Train][Epoch 286/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00048638, top1: 0.97234, CELoss: 0.08562, loss: 0.08562, batch_cost: 0.60790s, reader_cost: 0.06661, ips: 105.28046 samples/s, eta: 0:24:21
[2022/06/19 06:10:23] ppcls INFO: [Train][Epoch 286/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00048234, top1: 0.97228, CELoss: 0.08520, loss: 0.08520, batch_cost: 0.58651s, reader_cost: 0.06260, ips: 83.54462 samples/s, eta: 0:23:24
[2022/06/19 06:10:24] ppcls INFO: [Train][Epoch 286/300][Avg]top1: 0.97228, CELoss: 0.08520, loss: 0.08520
[2022/06/19 06:10:24] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:10:30] ppcls INFO: [Train][Epoch 287/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00048194, top1: 0.95312, CELoss: 0.09517, loss: 0.09517, batch_cost: 0.62046s, reader_cost: 0.09553, ips: 103.14875 samples/s, eta: 0:24:45
[2022/06/19 06:10:36] ppcls INFO: [Train][Epoch 287/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00047793, top1: 0.97301, CELoss: 0.07178, loss: 0.07178, batch_cost: 0.59674s, reader_cost: 0.01815, ips: 107.24922 samples/s, eta: 0:23:42
[2022/06/19 06:10:43] ppcls INFO: [Train][Epoch 287/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00047393, top1: 0.96949, CELoss: 0.08814, loss: 0.08814, batch_cost: 0.64136s, reader_cost: 0.01862, ips: 99.78738 samples/s, eta: 0:25:22
[2022/06/19 06:10:49] ppcls INFO: [Train][Epoch 287/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00046995, top1: 0.97077, CELoss: 0.08741, loss: 0.08741, batch_cost: 0.64147s, reader_cost: 0.01881, ips: 99.77056 samples/s, eta: 0:25:16
[2022/06/19 06:10:56] ppcls INFO: [Train][Epoch 287/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00046598, top1: 0.97027, CELoss: 0.08938, loss: 0.08938, batch_cost: 0.64026s, reader_cost: 0.02228, ips: 99.95898 samples/s, eta: 0:25:07
[2022/06/19 06:11:01] ppcls INFO: [Train][Epoch 287/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00046204, top1: 0.97089, CELoss: 0.08655, loss: 0.08655, batch_cost: 0.62326s, reader_cost: 0.02025, ips: 102.68564 samples/s, eta: 0:24:20
[2022/06/19 06:11:07] ppcls INFO: [Train][Epoch 287/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00045811, top1: 0.97234, CELoss: 0.08441, loss: 0.08441, batch_cost: 0.61385s, reader_cost: 0.02153, ips: 104.26070 samples/s, eta: 0:23:52
[2022/06/19 06:11:14] ppcls INFO: [Train][Epoch 287/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00045419, top1: 0.97205, CELoss: 0.08590, loss: 0.08590, batch_cost: 0.62234s, reader_cost: 0.02108, ips: 102.83775 samples/s, eta: 0:24:06
[2022/06/19 06:11:20] ppcls INFO: [Train][Epoch 287/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00045030, top1: 0.97029, CELoss: 0.08937, loss: 0.08937, batch_cost: 0.62177s, reader_cost: 0.02158, ips: 102.93231 samples/s, eta: 0:23:58
[2022/06/19 06:11:25] ppcls INFO: [Train][Epoch 287/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00044642, top1: 0.96961, CELoss: 0.09226, loss: 0.09226, batch_cost: 0.61205s, reader_cost: 0.02124, ips: 104.56699 samples/s, eta: 0:23:30
[2022/06/19 06:11:31] ppcls INFO: [Train][Epoch 287/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00044255, top1: 0.96968, CELoss: 0.09367, loss: 0.09367, batch_cost: 0.60558s, reader_cost: 0.02047, ips: 105.68437 samples/s, eta: 0:23:09
[2022/06/19 06:11:36] ppcls INFO: [Train][Epoch 287/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00043870, top1: 0.96945, CELoss: 0.09196, loss: 0.09196, batch_cost: 0.59854s, reader_cost: 0.01914, ips: 106.92710 samples/s, eta: 0:22:47
[2022/06/19 06:11:41] ppcls INFO: [Train][Epoch 287/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00043487, top1: 0.97069, CELoss: 0.09025, loss: 0.09025, batch_cost: 0.59169s, reader_cost: 0.01858, ips: 108.16430 samples/s, eta: 0:22:25
[2022/06/19 06:11:48] ppcls INFO: [Train][Epoch 287/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00043106, top1: 0.97090, CELoss: 0.09032, loss: 0.09032, batch_cost: 0.60210s, reader_cost: 0.02537, ips: 106.29409 samples/s, eta: 0:22:43
[2022/06/19 06:11:54] ppcls INFO: [Train][Epoch 287/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00042726, top1: 0.97119, CELoss: 0.08849, loss: 0.08849, batch_cost: 0.59962s, reader_cost: 0.03008, ips: 106.73494 samples/s, eta: 0:22:31
[2022/06/19 06:12:00] ppcls INFO: [Train][Epoch 287/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00042348, top1: 0.97061, CELoss: 0.08896, loss: 0.08896, batch_cost: 0.60030s, reader_cost: 0.03779, ips: 106.61319 samples/s, eta: 0:22:27
[2022/06/19 06:12:05] ppcls INFO: [Train][Epoch 287/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00041972, top1: 0.97069, CELoss: 0.08915, loss: 0.08915, batch_cost: 0.59187s, reader_cost: 0.03696, ips: 108.13237 samples/s, eta: 0:22:02
[2022/06/19 06:12:07] ppcls INFO: [Train][Epoch 287/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00041597, top1: 0.97072, CELoss: 0.08908, loss: 0.08908, batch_cost: 0.56892s, reader_cost: 0.03478, ips: 86.12795 samples/s, eta: 0:21:05
[2022/06/19 06:12:08] ppcls INFO: [Train][Epoch 287/300][Avg]top1: 0.97072, CELoss: 0.08908, loss: 0.08908
[2022/06/19 06:12:08] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:12:14] ppcls INFO: [Train][Epoch 288/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00041560, top1: 0.96875, CELoss: 0.09029, loss: 0.09029, batch_cost: 0.60537s, reader_cost: 0.05930, ips: 105.72015 samples/s, eta: 0:22:25
[2022/06/19 06:12:21] ppcls INFO: [Train][Epoch 288/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00041187, top1: 0.97301, CELoss: 0.09197, loss: 0.09197, batch_cost: 0.70314s, reader_cost: 0.05270, ips: 91.02019 samples/s, eta: 0:25:56
[2022/06/19 06:12:28] ppcls INFO: [Train][Epoch 288/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00040816, top1: 0.97247, CELoss: 0.08449, loss: 0.08449, batch_cost: 0.65095s, reader_cost: 0.04372, ips: 98.31792 samples/s, eta: 0:23:54
[2022/06/19 06:12:34] ppcls INFO: [Train][Epoch 288/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00040446, top1: 0.97228, CELoss: 0.09094, loss: 0.09094, batch_cost: 0.65017s, reader_cost: 0.03210, ips: 98.43643 samples/s, eta: 0:23:45
[2022/06/19 06:12:40] ppcls INFO: [Train][Epoch 288/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00040079, top1: 0.97409, CELoss: 0.08451, loss: 0.08451, batch_cost: 0.64153s, reader_cost: 0.02605, ips: 99.76143 samples/s, eta: 0:23:20
[2022/06/19 06:12:47] ppcls INFO: [Train][Epoch 288/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00039713, top1: 0.97426, CELoss: 0.08478, loss: 0.08478, batch_cost: 0.65205s, reader_cost: 0.02528, ips: 98.15237 samples/s, eta: 0:23:36
[2022/06/19 06:12:52] ppcls INFO: [Train][Epoch 288/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00039348, top1: 0.97362, CELoss: 0.08642, loss: 0.08642, batch_cost: 0.62695s, reader_cost: 0.02387, ips: 102.08073 samples/s, eta: 0:22:36
[2022/06/19 06:12:58] ppcls INFO: [Train][Epoch 288/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00038985, top1: 0.97381, CELoss: 0.08434, loss: 0.08434, batch_cost: 0.62430s, reader_cost: 0.02333, ips: 102.51496 samples/s, eta: 0:22:24
[2022/06/19 06:13:04] ppcls INFO: [Train][Epoch 288/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00038624, top1: 0.97299, CELoss: 0.08478, loss: 0.08478, batch_cost: 0.61954s, reader_cost: 0.02195, ips: 103.30281 samples/s, eta: 0:22:07
[2022/06/19 06:13:10] ppcls INFO: [Train][Epoch 288/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00038265, top1: 0.97236, CELoss: 0.08525, loss: 0.08525, batch_cost: 0.61720s, reader_cost: 0.02082, ips: 103.69450 samples/s, eta: 0:21:56
[2022/06/19 06:13:16] ppcls INFO: [Train][Epoch 288/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00037907, top1: 0.97184, CELoss: 0.08687, loss: 0.08687, batch_cost: 0.61431s, reader_cost: 0.02072, ips: 104.18193 samples/s, eta: 0:21:44
[2022/06/19 06:13:22] ppcls INFO: [Train][Epoch 288/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00037551, top1: 0.97142, CELoss: 0.08788, loss: 0.08788, batch_cost: 0.61489s, reader_cost: 0.01993, ips: 104.08389 samples/s, eta: 0:21:39
[2022/06/19 06:13:29] ppcls INFO: [Train][Epoch 288/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00037196, top1: 0.97043, CELoss: 0.09021, loss: 0.09021, batch_cost: 0.62379s, reader_cost: 0.03156, ips: 102.59788 samples/s, eta: 0:21:51
[2022/06/19 06:13:35] ppcls INFO: [Train][Epoch 288/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00036844, top1: 0.97042, CELoss: 0.09072, loss: 0.09072, batch_cost: 0.61492s, reader_cost: 0.03000, ips: 104.07919 samples/s, eta: 0:21:27
[2022/06/19 06:13:41] ppcls INFO: [Train][Epoch 288/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00036493, top1: 0.97019, CELoss: 0.09063, loss: 0.09063, batch_cost: 0.61673s, reader_cost: 0.02989, ips: 103.77280 samples/s, eta: 0:21:24
[2022/06/19 06:13:47] ppcls INFO: [Train][Epoch 288/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00036143, top1: 0.97072, CELoss: 0.08956, loss: 0.08956, batch_cost: 0.61620s, reader_cost: 0.02824, ips: 103.86205 samples/s, eta: 0:21:17
[2022/06/19 06:13:53] ppcls INFO: [Train][Epoch 288/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00035795, top1: 0.97118, CELoss: 0.08817, loss: 0.08817, batch_cost: 0.61217s, reader_cost: 0.02682, ips: 104.54529 samples/s, eta: 0:21:02
[2022/06/19 06:13:55] ppcls INFO: [Train][Epoch 288/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00035449, top1: 0.97136, CELoss: 0.08683, loss: 0.08683, batch_cost: 0.58800s, reader_cost: 0.02523, ips: 83.33306 samples/s, eta: 0:20:07
[2022/06/19 06:13:55] ppcls INFO: [Train][Epoch 288/300][Avg]top1: 0.97136, CELoss: 0.08683, loss: 0.08683
[2022/06/19 06:13:55] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:14:02] ppcls INFO: [Train][Epoch 289/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00035415, top1: 1.00000, CELoss: 0.05676, loss: 0.05676, batch_cost: 0.62573s, reader_cost: 0.05259, ips: 102.28121 samples/s, eta: 0:21:23
[2022/06/19 06:14:09] ppcls INFO: [Train][Epoch 289/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00035071, top1: 0.97301, CELoss: 0.08167, loss: 0.08167, batch_cost: 0.60233s, reader_cost: 0.00933, ips: 106.25423 samples/s, eta: 0:20:29
[2022/06/19 06:14:16] ppcls INFO: [Train][Epoch 289/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00034728, top1: 0.97396, CELoss: 0.08909, loss: 0.08909, batch_cost: 0.65604s, reader_cost: 0.02085, ips: 97.55522 samples/s, eta: 0:22:13
[2022/06/19 06:14:22] ppcls INFO: [Train][Epoch 289/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00034387, top1: 0.96976, CELoss: 0.09026, loss: 0.09026, batch_cost: 0.63847s, reader_cost: 0.02096, ips: 100.23904 samples/s, eta: 0:21:30
[2022/06/19 06:14:28] ppcls INFO: [Train][Epoch 289/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00034048, top1: 0.96913, CELoss: 0.09055, loss: 0.09055, batch_cost: 0.63041s, reader_cost: 0.01852, ips: 101.52178 samples/s, eta: 0:21:08
[2022/06/19 06:14:33] ppcls INFO: [Train][Epoch 289/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00033710, top1: 0.96844, CELoss: 0.09227, loss: 0.09227, batch_cost: 0.61108s, reader_cost: 0.01574, ips: 104.73233 samples/s, eta: 0:20:23
[2022/06/19 06:14:40] ppcls INFO: [Train][Epoch 289/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00033375, top1: 0.97029, CELoss: 0.08669, loss: 0.08669, batch_cost: 0.61467s, reader_cost: 0.01410, ips: 104.12068 samples/s, eta: 0:20:24
[2022/06/19 06:14:46] ppcls INFO: [Train][Epoch 289/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00033040, top1: 0.96875, CELoss: 0.08864, loss: 0.08864, batch_cost: 0.61656s, reader_cost: 0.01608, ips: 103.80232 samples/s, eta: 0:20:22
[2022/06/19 06:14:52] ppcls INFO: [Train][Epoch 289/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00032708, top1: 0.97087, CELoss: 0.08671, loss: 0.08671, batch_cost: 0.61058s, reader_cost: 0.01502, ips: 104.81896 samples/s, eta: 0:20:04
[2022/06/19 06:14:59] ppcls INFO: [Train][Epoch 289/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00032377, top1: 0.96978, CELoss: 0.08845, loss: 0.08845, batch_cost: 0.62682s, reader_cost: 0.01404, ips: 102.10256 samples/s, eta: 0:20:29
[2022/06/19 06:15:05] ppcls INFO: [Train][Epoch 289/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00032048, top1: 0.96921, CELoss: 0.09034, loss: 0.09034, batch_cost: 0.62492s, reader_cost: 0.01395, ips: 102.41357 samples/s, eta: 0:20:19
[2022/06/19 06:15:11] ppcls INFO: [Train][Epoch 289/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00031721, top1: 0.97030, CELoss: 0.08788, loss: 0.08788, batch_cost: 0.61996s, reader_cost: 0.01409, ips: 103.23187 samples/s, eta: 0:20:03
[2022/06/19 06:15:18] ppcls INFO: [Train][Epoch 289/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00031395, top1: 0.97004, CELoss: 0.08857, loss: 0.08857, batch_cost: 0.62490s, reader_cost: 0.01385, ips: 102.41562 samples/s, eta: 0:20:07
[2022/06/19 06:15:25] ppcls INFO: [Train][Epoch 289/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00031071, top1: 0.97006, CELoss: 0.08922, loss: 0.08922, batch_cost: 0.63115s, reader_cost: 0.01334, ips: 101.40278 samples/s, eta: 0:20:13
[2022/06/19 06:15:29] ppcls INFO: [Train][Epoch 289/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00030748, top1: 0.97063, CELoss: 0.08871, loss: 0.08871, batch_cost: 0.61756s, reader_cost: 0.01270, ips: 103.63396 samples/s, eta: 0:19:40
[2022/06/19 06:15:36] ppcls INFO: [Train][Epoch 289/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00030427, top1: 0.97020, CELoss: 0.08822, loss: 0.08822, batch_cost: 0.61916s, reader_cost: 0.01205, ips: 103.36588 samples/s, eta: 0:19:37
[2022/06/19 06:15:41] ppcls INFO: [Train][Epoch 289/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00030108, top1: 0.97011, CELoss: 0.08747, loss: 0.08747, batch_cost: 0.61097s, reader_cost: 0.01149, ips: 104.75155 samples/s, eta: 0:19:15
[2022/06/19 06:15:43] ppcls INFO: [Train][Epoch 289/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00029791, top1: 0.97090, CELoss: 0.08593, loss: 0.08593, batch_cost: 0.58705s, reader_cost: 0.01081, ips: 83.46844 samples/s, eta: 0:18:24
[2022/06/19 06:15:43] ppcls INFO: [Train][Epoch 289/300][Avg]top1: 0.97090, CELoss: 0.08593, loss: 0.08593
[2022/06/19 06:15:43] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:15:50] ppcls INFO: [Train][Epoch 290/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00029759, top1: 1.00000, CELoss: 0.02563, loss: 0.02563, batch_cost: 0.62323s, reader_cost: 0.04545, ips: 102.69139 samples/s, eta: 0:19:32
[2022/06/19 06:15:57] ppcls INFO: [Train][Epoch 290/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00029444, top1: 0.98722, CELoss: 0.05855, loss: 0.05855, batch_cost: 0.64985s, reader_cost: 0.00036, ips: 98.48462 samples/s, eta: 0:20:15
[2022/06/19 06:16:03] ppcls INFO: [Train][Epoch 290/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00029130, top1: 0.97693, CELoss: 0.08735, loss: 0.08735, batch_cost: 0.62663s, reader_cost: 0.00457, ips: 102.13394 samples/s, eta: 0:19:26
[2022/06/19 06:16:09] ppcls INFO: [Train][Epoch 290/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00028818, top1: 0.97429, CELoss: 0.09014, loss: 0.09014, batch_cost: 0.64215s, reader_cost: 0.00707, ips: 99.66514 samples/s, eta: 0:19:48
[2022/06/19 06:16:16] ppcls INFO: [Train][Epoch 290/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00028507, top1: 0.97294, CELoss: 0.09361, loss: 0.09361, batch_cost: 0.64155s, reader_cost: 0.00963, ips: 99.75829 samples/s, eta: 0:19:41
[2022/06/19 06:16:22] ppcls INFO: [Train][Epoch 290/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00028198, top1: 0.97273, CELoss: 0.09294, loss: 0.09294, batch_cost: 0.64785s, reader_cost: 0.03858, ips: 98.78836 samples/s, eta: 0:19:46
[2022/06/19 06:16:28] ppcls INFO: [Train][Epoch 290/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00027891, top1: 0.97106, CELoss: 0.09771, loss: 0.09771, batch_cost: 0.63379s, reader_cost: 0.03274, ips: 100.98008 samples/s, eta: 0:19:14
[2022/06/19 06:16:34] ppcls INFO: [Train][Epoch 290/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00027585, top1: 0.97139, CELoss: 0.09723, loss: 0.09723, batch_cost: 0.63333s, reader_cost: 0.02944, ips: 101.05310 samples/s, eta: 0:19:06
[2022/06/19 06:16:40] ppcls INFO: [Train][Epoch 290/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00027282, top1: 0.97222, CELoss: 0.09616, loss: 0.09616, batch_cost: 0.61945s, reader_cost: 0.02928, ips: 103.31687 samples/s, eta: 0:18:35
[2022/06/19 06:16:45] ppcls INFO: [Train][Epoch 290/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00026980, top1: 0.97373, CELoss: 0.09229, loss: 0.09229, batch_cost: 0.60918s, reader_cost: 0.02703, ips: 105.06012 samples/s, eta: 0:18:11
[2022/06/19 06:16:51] ppcls INFO: [Train][Epoch 290/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00026679, top1: 0.97308, CELoss: 0.09204, loss: 0.09204, batch_cost: 0.61139s, reader_cost: 0.03568, ips: 104.68015 samples/s, eta: 0:18:08
[2022/06/19 06:16:58] ppcls INFO: [Train][Epoch 290/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00026380, top1: 0.97241, CELoss: 0.09378, loss: 0.09378, batch_cost: 0.61570s, reader_cost: 0.03357, ips: 103.94690 samples/s, eta: 0:18:10
[2022/06/19 06:17:04] ppcls INFO: [Train][Epoch 290/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00026083, top1: 0.97275, CELoss: 0.09232, loss: 0.09232, batch_cost: 0.61177s, reader_cost: 0.03359, ips: 104.61433 samples/s, eta: 0:17:57
[2022/06/19 06:17:10] ppcls INFO: [Train][Epoch 290/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00025788, top1: 0.97257, CELoss: 0.09131, loss: 0.09131, batch_cost: 0.61256s, reader_cost: 0.03166, ips: 104.48019 samples/s, eta: 0:17:52
[2022/06/19 06:17:16] ppcls INFO: [Train][Epoch 290/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00025494, top1: 0.97252, CELoss: 0.09109, loss: 0.09109, batch_cost: 0.60998s, reader_cost: 0.03280, ips: 104.92180 samples/s, eta: 0:17:41
[2022/06/19 06:17:23] ppcls INFO: [Train][Epoch 290/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00025202, top1: 0.97289, CELoss: 0.08965, loss: 0.08965, batch_cost: 0.61552s, reader_cost: 0.03132, ips: 103.97678 samples/s, eta: 0:17:45
[2022/06/19 06:17:28] ppcls INFO: [Train][Epoch 290/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00024911, top1: 0.97302, CELoss: 0.08951, loss: 0.08951, batch_cost: 0.60840s, reader_cost: 0.02994, ips: 105.19468 samples/s, eta: 0:17:27
[2022/06/19 06:17:30] ppcls INFO: [Train][Epoch 290/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00024623, top1: 0.97264, CELoss: 0.09023, loss: 0.09023, batch_cost: 0.58439s, reader_cost: 0.02819, ips: 83.84816 samples/s, eta: 0:16:39
[2022/06/19 06:17:30] ppcls INFO: [Train][Epoch 290/300][Avg]top1: 0.97264, CELoss: 0.09023, loss: 0.09023
[2022/06/19 06:17:37] ppcls INFO: [Eval][Epoch 290][Iter: 0/16]CELoss: 1.09331, loss: 1.09331, top1: 0.81055, batch_cost: 7.08768s, reader_cost: 3.59983, ips: 9.02975 images/sec
[2022/06/19 06:17:46] ppcls INFO: [Eval][Epoch 290][Iter: 10/16]CELoss: 1.02999, loss: 1.02999, top1: 0.82386, batch_cost: 0.60721s, reader_cost: 0.00511, ips: 105.39947 images/sec
[2022/06/19 06:17:47] ppcls INFO: [Eval][Epoch 290][Avg]CELoss: 0.85981, loss: 0.85981, top1: 0.83039
[2022/06/19 06:17:48] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/best_model
[2022/06/19 06:17:48] ppcls INFO: [Eval][Epoch 290][best metric: 0.8303921818733215]
[2022/06/19 06:17:48] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_290
[2022/06/19 06:17:48] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:17:54] ppcls INFO: [Train][Epoch 291/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00024594, top1: 0.98438, CELoss: 0.04738, loss: 0.04738, batch_cost: 0.61907s, reader_cost: 0.06133, ips: 103.38015 samples/s, eta: 0:17:38
[2022/06/19 06:18:00] ppcls INFO: [Train][Epoch 291/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00024307, top1: 0.98438, CELoss: 0.07707, loss: 0.07707, batch_cost: 0.60358s, reader_cost: 0.01217, ips: 106.03322 samples/s, eta: 0:17:06
[2022/06/19 06:18:06] ppcls INFO: [Train][Epoch 291/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00024022, top1: 0.97917, CELoss: 0.07430, loss: 0.07430, batch_cost: 0.59981s, reader_cost: 0.00651, ips: 106.69962 samples/s, eta: 0:16:53
[2022/06/19 06:18:12] ppcls INFO: [Train][Epoch 291/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00023738, top1: 0.97429, CELoss: 0.08581, loss: 0.08581, batch_cost: 0.60390s, reader_cost: 0.00816, ips: 105.97862 samples/s, eta: 0:16:54
[2022/06/19 06:18:18] ppcls INFO: [Train][Epoch 291/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00023456, top1: 0.97180, CELoss: 0.08890, loss: 0.08890, batch_cost: 0.61081s, reader_cost: 0.01178, ips: 104.77891 samples/s, eta: 0:17:00
[2022/06/19 06:18:27] ppcls INFO: [Train][Epoch 291/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00023176, top1: 0.97059, CELoss: 0.09106, loss: 0.09106, batch_cost: 0.65298s, reader_cost: 0.01271, ips: 98.01193 samples/s, eta: 0:18:03
[2022/06/19 06:18:31] ppcls INFO: [Train][Epoch 291/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00022898, top1: 0.97157, CELoss: 0.08823, loss: 0.08823, batch_cost: 0.62504s, reader_cost: 0.01340, ips: 102.39371 samples/s, eta: 0:17:11
[2022/06/19 06:18:37] ppcls INFO: [Train][Epoch 291/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00022621, top1: 0.97205, CELoss: 0.08692, loss: 0.08692, batch_cost: 0.61957s, reader_cost: 0.01363, ips: 103.29766 samples/s, eta: 0:16:56
[2022/06/19 06:18:43] ppcls INFO: [Train][Epoch 291/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00022346, top1: 0.97126, CELoss: 0.08973, loss: 0.08973, batch_cost: 0.60932s, reader_cost: 0.01300, ips: 105.03589 samples/s, eta: 0:16:33
[2022/06/19 06:18:49] ppcls INFO: [Train][Epoch 291/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00022072, top1: 0.97115, CELoss: 0.08858, loss: 0.08858, batch_cost: 0.61495s, reader_cost: 0.01399, ips: 104.07320 samples/s, eta: 0:16:36
[2022/06/19 06:18:55] ppcls INFO: [Train][Epoch 291/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00021801, top1: 0.97061, CELoss: 0.08867, loss: 0.08867, batch_cost: 0.61451s, reader_cost: 0.01326, ips: 104.14821 samples/s, eta: 0:16:29
[2022/06/19 06:19:01] ppcls INFO: [Train][Epoch 291/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00021531, top1: 0.97171, CELoss: 0.08661, loss: 0.08661, batch_cost: 0.61303s, reader_cost: 0.01327, ips: 104.39892 samples/s, eta: 0:16:20
[2022/06/19 06:19:08] ppcls INFO: [Train][Epoch 291/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00021262, top1: 0.97004, CELoss: 0.08984, loss: 0.08984, batch_cost: 0.61724s, reader_cost: 0.01390, ips: 103.68747 samples/s, eta: 0:16:21
[2022/06/19 06:19:14] ppcls INFO: [Train][Epoch 291/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00020995, top1: 0.97054, CELoss: 0.08862, loss: 0.08862, batch_cost: 0.61563s, reader_cost: 0.01391, ips: 103.95900 samples/s, eta: 0:16:12
[2022/06/19 06:19:19] ppcls INFO: [Train][Epoch 291/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00020730, top1: 0.97030, CELoss: 0.08886, loss: 0.08886, batch_cost: 0.60812s, reader_cost: 0.01349, ips: 105.24154 samples/s, eta: 0:15:54
[2022/06/19 06:19:25] ppcls INFO: [Train][Epoch 291/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00020467, top1: 0.97061, CELoss: 0.08815, loss: 0.08815, batch_cost: 0.60688s, reader_cost: 0.01329, ips: 105.45661 samples/s, eta: 0:15:46
[2022/06/19 06:19:32] ppcls INFO: [Train][Epoch 291/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00020205, top1: 0.97069, CELoss: 0.08729, loss: 0.08729, batch_cost: 0.61060s, reader_cost: 0.01256, ips: 104.81574 samples/s, eta: 0:15:46
[2022/06/19 06:19:34] ppcls INFO: [Train][Epoch 291/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00019945, top1: 0.97118, CELoss: 0.08643, loss: 0.08643, batch_cost: 0.58635s, reader_cost: 0.01188, ips: 83.56844 samples/s, eta: 0:15:02
[2022/06/19 06:19:35] ppcls INFO: [Train][Epoch 291/300][Avg]top1: 0.97118, CELoss: 0.08643, loss: 0.08643
[2022/06/19 06:19:35] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:19:42] ppcls INFO: [Train][Epoch 292/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00019919, top1: 0.95312, CELoss: 0.13444, loss: 0.13444, batch_cost: 0.62549s, reader_cost: 0.04852, ips: 102.31997 samples/s, eta: 0:16:02
[2022/06/19 06:19:48] ppcls INFO: [Train][Epoch 292/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00019661, top1: 0.97585, CELoss: 0.06187, loss: 0.06187, batch_cost: 0.66614s, reader_cost: 0.05219, ips: 96.07589 samples/s, eta: 0:16:58
[2022/06/19 06:19:55] ppcls INFO: [Train][Epoch 292/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00019405, top1: 0.96875, CELoss: 0.08842, loss: 0.08842, batch_cost: 0.65605s, reader_cost: 0.05527, ips: 97.55405 samples/s, eta: 0:16:36
[2022/06/19 06:20:01] ppcls INFO: [Train][Epoch 292/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00019150, top1: 0.96875, CELoss: 0.09197, loss: 0.09197, batch_cost: 0.63167s, reader_cost: 0.04733, ips: 101.31909 samples/s, eta: 0:15:53
[2022/06/19 06:20:07] ppcls INFO: [Train][Epoch 292/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00018897, top1: 0.96799, CELoss: 0.09448, loss: 0.09448, batch_cost: 0.62000s, reader_cost: 0.03870, ips: 103.22567 samples/s, eta: 0:15:29
[2022/06/19 06:20:13] ppcls INFO: [Train][Epoch 292/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00018645, top1: 0.96661, CELoss: 0.09699, loss: 0.09699, batch_cost: 0.63026s, reader_cost: 0.03141, ips: 101.54553 samples/s, eta: 0:15:38
[2022/06/19 06:20:19] ppcls INFO: [Train][Epoch 292/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00018396, top1: 0.96798, CELoss: 0.09376, loss: 0.09376, batch_cost: 0.62539s, reader_cost: 0.02787, ips: 102.33589 samples/s, eta: 0:15:24
[2022/06/19 06:20:25] ppcls INFO: [Train][Epoch 292/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00018147, top1: 0.96831, CELoss: 0.09165, loss: 0.09165, batch_cost: 0.61500s, reader_cost: 0.02655, ips: 104.06538 samples/s, eta: 0:15:03
[2022/06/19 06:20:31] ppcls INFO: [Train][Epoch 292/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00017901, top1: 0.96836, CELoss: 0.09216, loss: 0.09216, batch_cost: 0.61987s, reader_cost: 0.02397, ips: 103.24829 samples/s, eta: 0:15:04
[2022/06/19 06:20:37] ppcls INFO: [Train][Epoch 292/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00017656, top1: 0.96858, CELoss: 0.09131, loss: 0.09131, batch_cost: 0.61265s, reader_cost: 0.02186, ips: 104.46421 samples/s, eta: 0:14:47
[2022/06/19 06:20:43] ppcls INFO: [Train][Epoch 292/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00017413, top1: 0.96890, CELoss: 0.09007, loss: 0.09007, batch_cost: 0.61249s, reader_cost: 0.02133, ips: 104.49214 samples/s, eta: 0:14:41
[2022/06/19 06:20:48] ppcls INFO: [Train][Epoch 292/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00017172, top1: 0.96945, CELoss: 0.08815, loss: 0.08815, batch_cost: 0.60263s, reader_cost: 0.01991, ips: 106.20162 samples/s, eta: 0:14:21
[2022/06/19 06:20:54] ppcls INFO: [Train][Epoch 292/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00016932, top1: 0.96978, CELoss: 0.08775, loss: 0.08775, batch_cost: 0.59970s, reader_cost: 0.01921, ips: 106.72042 samples/s, eta: 0:14:10
[2022/06/19 06:21:01] ppcls INFO: [Train][Epoch 292/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00016694, top1: 0.96947, CELoss: 0.08731, loss: 0.08731, batch_cost: 0.61326s, reader_cost: 0.01826, ips: 104.36046 samples/s, eta: 0:14:24
[2022/06/19 06:21:06] ppcls INFO: [Train][Epoch 292/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00016458, top1: 0.96975, CELoss: 0.08685, loss: 0.08685, batch_cost: 0.60427s, reader_cost: 0.01743, ips: 105.91320 samples/s, eta: 0:14:05
[2022/06/19 06:21:14] ppcls INFO: [Train][Epoch 292/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00016223, top1: 0.96947, CELoss: 0.08798, loss: 0.08798, batch_cost: 0.61347s, reader_cost: 0.01698, ips: 104.32472 samples/s, eta: 0:14:12
[2022/06/19 06:21:18] ppcls INFO: [Train][Epoch 292/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00015990, top1: 0.96953, CELoss: 0.08843, loss: 0.08843, batch_cost: 0.60281s, reader_cost: 0.01654, ips: 106.16929 samples/s, eta: 0:13:51
[2022/06/19 06:21:20] ppcls INFO: [Train][Epoch 292/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00015759, top1: 0.96999, CELoss: 0.08705, loss: 0.08705, batch_cost: 0.57927s, reader_cost: 0.01559, ips: 84.58884 samples/s, eta: 0:13:13
[2022/06/19 06:21:21] ppcls INFO: [Train][Epoch 292/300][Avg]top1: 0.96999, CELoss: 0.08705, loss: 0.08705
[2022/06/19 06:21:21] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:21:29] ppcls INFO: [Train][Epoch 293/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00015736, top1: 0.92188, CELoss: 0.26704, loss: 0.26704, batch_cost: 0.62133s, reader_cost: 0.05143, ips: 103.00446 samples/s, eta: 0:14:09
[2022/06/19 06:21:35] ppcls INFO: [Train][Epoch 293/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00015507, top1: 0.97443, CELoss: 0.08197, loss: 0.08197, batch_cost: 0.63018s, reader_cost: 0.01436, ips: 101.55865 samples/s, eta: 0:14:15
[2022/06/19 06:21:41] ppcls INFO: [Train][Epoch 293/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00015279, top1: 0.97321, CELoss: 0.09679, loss: 0.09679, batch_cost: 0.59898s, reader_cost: 0.01048, ips: 106.84742 samples/s, eta: 0:13:27
[2022/06/19 06:21:47] ppcls INFO: [Train][Epoch 293/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00015053, top1: 0.97278, CELoss: 0.09613, loss: 0.09613, batch_cost: 0.62334s, reader_cost: 0.01051, ips: 102.67344 samples/s, eta: 0:13:54
[2022/06/19 06:21:54] ppcls INFO: [Train][Epoch 293/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00014828, top1: 0.97447, CELoss: 0.08987, loss: 0.08987, batch_cost: 0.62231s, reader_cost: 0.01435, ips: 102.84250 samples/s, eta: 0:13:46
[2022/06/19 06:21:59] ppcls INFO: [Train][Epoch 293/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00014606, top1: 0.97212, CELoss: 0.09308, loss: 0.09308, batch_cost: 0.61249s, reader_cost: 0.01380, ips: 104.49092 samples/s, eta: 0:13:27
[2022/06/19 06:22:05] ppcls INFO: [Train][Epoch 293/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00014385, top1: 0.97029, CELoss: 0.09824, loss: 0.09824, batch_cost: 0.61025s, reader_cost: 0.01360, ips: 104.87581 samples/s, eta: 0:13:18
[2022/06/19 06:22:11] ppcls INFO: [Train][Epoch 293/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00014165, top1: 0.97073, CELoss: 0.09489, loss: 0.09489, batch_cost: 0.60728s, reader_cost: 0.01397, ips: 105.38736 samples/s, eta: 0:13:08
[2022/06/19 06:22:17] ppcls INFO: [Train][Epoch 293/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00013948, top1: 0.97126, CELoss: 0.09267, loss: 0.09267, batch_cost: 0.60354s, reader_cost: 0.01263, ips: 106.04057 samples/s, eta: 0:12:57
[2022/06/19 06:22:24] ppcls INFO: [Train][Epoch 293/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00013732, top1: 0.97150, CELoss: 0.09190, loss: 0.09190, batch_cost: 0.61842s, reader_cost: 0.03584, ips: 103.49016 samples/s, eta: 0:13:10
[2022/06/19 06:22:30] ppcls INFO: [Train][Epoch 293/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00013518, top1: 0.97200, CELoss: 0.09190, loss: 0.09190, batch_cost: 0.61426s, reader_cost: 0.03851, ips: 104.19080 samples/s, eta: 0:12:58
[2022/06/19 06:22:36] ppcls INFO: [Train][Epoch 293/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00013305, top1: 0.97185, CELoss: 0.09056, loss: 0.09056, batch_cost: 0.61200s, reader_cost: 0.03938, ips: 104.57581 samples/s, eta: 0:12:49
[2022/06/19 06:22:42] ppcls INFO: [Train][Epoch 293/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00013094, top1: 0.97224, CELoss: 0.08896, loss: 0.08896, batch_cost: 0.61258s, reader_cost: 0.04288, ips: 104.47699 samples/s, eta: 0:12:44
[2022/06/19 06:22:48] ppcls INFO: [Train][Epoch 293/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00012885, top1: 0.97137, CELoss: 0.09003, loss: 0.09003, batch_cost: 0.61162s, reader_cost: 0.04623, ips: 104.64045 samples/s, eta: 0:12:37
[2022/06/19 06:22:54] ppcls INFO: [Train][Epoch 293/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00012677, top1: 0.97152, CELoss: 0.08924, loss: 0.08924, batch_cost: 0.61083s, reader_cost: 0.04771, ips: 104.77566 samples/s, eta: 0:12:30
[2022/06/19 06:23:02] ppcls INFO: [Train][Epoch 293/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00012471, top1: 0.97175, CELoss: 0.08943, loss: 0.08943, batch_cost: 0.62307s, reader_cost: 0.04587, ips: 102.71760 samples/s, eta: 0:12:38
[2022/06/19 06:23:05] ppcls INFO: [Train][Epoch 293/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00012267, top1: 0.97176, CELoss: 0.08936, loss: 0.08936, batch_cost: 0.60458s, reader_cost: 0.04361, ips: 105.85791 samples/s, eta: 0:12:10
[2022/06/19 06:23:08] ppcls INFO: [Train][Epoch 293/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00012065, top1: 0.97200, CELoss: 0.08873, loss: 0.08873, batch_cost: 0.58062s, reader_cost: 0.04099, ips: 84.39212 samples/s, eta: 0:11:35
[2022/06/19 06:23:08] ppcls INFO: [Train][Epoch 293/300][Avg]top1: 0.97200, CELoss: 0.08873, loss: 0.08873
[2022/06/19 06:23:08] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:23:14] ppcls INFO: [Train][Epoch 294/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00012045, top1: 1.00000, CELoss: 0.01965, loss: 0.01965, batch_cost: 0.61074s, reader_cost: 0.07003, ips: 104.79098 samples/s, eta: 0:12:11
[2022/06/19 06:23:22] ppcls INFO: [Train][Epoch 294/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00011844, top1: 0.96875, CELoss: 0.10137, loss: 0.10137, batch_cost: 0.70140s, reader_cost: 0.03153, ips: 91.24589 samples/s, eta: 0:13:52
[2022/06/19 06:23:28] ppcls INFO: [Train][Epoch 294/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00011645, top1: 0.97396, CELoss: 0.08525, loss: 0.08525, batch_cost: 0.64272s, reader_cost: 0.02110, ips: 99.57621 samples/s, eta: 0:12:36
[2022/06/19 06:23:34] ppcls INFO: [Train][Epoch 294/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00011448, top1: 0.97379, CELoss: 0.08628, loss: 0.08628, batch_cost: 0.64179s, reader_cost: 0.01558, ips: 99.72050 samples/s, eta: 0:12:28
[2022/06/19 06:23:40] ppcls INFO: [Train][Epoch 294/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00011252, top1: 0.97256, CELoss: 0.09118, loss: 0.09118, batch_cost: 0.63808s, reader_cost: 0.04546, ips: 100.30020 samples/s, eta: 0:12:18
[2022/06/19 06:23:46] ppcls INFO: [Train][Epoch 294/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00011058, top1: 0.97089, CELoss: 0.09135, loss: 0.09135, batch_cost: 0.62109s, reader_cost: 0.03690, ips: 103.04390 samples/s, eta: 0:11:52
[2022/06/19 06:23:52] ppcls INFO: [Train][Epoch 294/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00010866, top1: 0.96901, CELoss: 0.09385, loss: 0.09385, batch_cost: 0.61766s, reader_cost: 0.03287, ips: 103.61722 samples/s, eta: 0:11:42
[2022/06/19 06:23:59] ppcls INFO: [Train][Epoch 294/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00010675, top1: 0.96963, CELoss: 0.09151, loss: 0.09151, batch_cost: 0.62832s, reader_cost: 0.02990, ips: 101.85896 samples/s, eta: 0:11:48
[2022/06/19 06:24:04] ppcls INFO: [Train][Epoch 294/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00010486, top1: 0.97010, CELoss: 0.09040, loss: 0.09040, batch_cost: 0.61809s, reader_cost: 0.02939, ips: 103.54407 samples/s, eta: 0:11:30
[2022/06/19 06:24:10] ppcls INFO: [Train][Epoch 294/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00010299, top1: 0.97012, CELoss: 0.09039, loss: 0.09039, batch_cost: 0.61489s, reader_cost: 0.02795, ips: 104.08379 samples/s, eta: 0:11:20
[2022/06/19 06:24:17] ppcls INFO: [Train][Epoch 294/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00010114, top1: 0.97123, CELoss: 0.08758, loss: 0.08758, batch_cost: 0.61551s, reader_cost: 0.02662, ips: 103.97902 samples/s, eta: 0:11:15
[2022/06/19 06:24:23] ppcls INFO: [Train][Epoch 294/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00009930, top1: 0.97171, CELoss: 0.08592, loss: 0.08592, batch_cost: 0.61415s, reader_cost: 0.02532, ips: 104.20838 samples/s, eta: 0:11:07
[2022/06/19 06:24:28] ppcls INFO: [Train][Epoch 294/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00009748, top1: 0.97237, CELoss: 0.08464, loss: 0.08464, batch_cost: 0.60752s, reader_cost: 0.02447, ips: 105.34661 samples/s, eta: 0:10:54
[2022/06/19 06:24:34] ppcls INFO: [Train][Epoch 294/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00009567, top1: 0.97257, CELoss: 0.08356, loss: 0.08356, batch_cost: 0.60946s, reader_cost: 0.02429, ips: 105.01085 samples/s, eta: 0:10:50
[2022/06/19 06:24:41] ppcls INFO: [Train][Epoch 294/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00009389, top1: 0.97219, CELoss: 0.08425, loss: 0.08425, batch_cost: 0.61155s, reader_cost: 0.02409, ips: 104.65263 samples/s, eta: 0:10:46
[2022/06/19 06:24:48] ppcls INFO: [Train][Epoch 294/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00009212, top1: 0.97289, CELoss: 0.08281, loss: 0.08281, batch_cost: 0.61758s, reader_cost: 0.02270, ips: 103.62988 samples/s, eta: 0:10:46
[2022/06/19 06:24:52] ppcls INFO: [Train][Epoch 294/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00009036, top1: 0.97253, CELoss: 0.08301, loss: 0.08301, batch_cost: 0.60326s, reader_cost: 0.02156, ips: 106.09023 samples/s, eta: 0:10:25
[2022/06/19 06:24:54] ppcls INFO: [Train][Epoch 294/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00008862, top1: 0.97273, CELoss: 0.08417, loss: 0.08417, batch_cost: 0.57956s, reader_cost: 0.02036, ips: 84.54618 samples/s, eta: 0:09:55
[2022/06/19 06:24:54] ppcls INFO: [Train][Epoch 294/300][Avg]top1: 0.97273, CELoss: 0.08417, loss: 0.08417
[2022/06/19 06:24:55] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:25:01] ppcls INFO: [Train][Epoch 295/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00008845, top1: 1.00000, CELoss: 0.01583, loss: 0.01583, batch_cost: 0.61564s, reader_cost: 0.04908, ips: 103.95692 samples/s, eta: 0:10:31
[2022/06/19 06:25:08] ppcls INFO: [Train][Epoch 295/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00008673, top1: 0.97443, CELoss: 0.07837, loss: 0.07837, batch_cost: 0.66719s, reader_cost: 0.04030, ips: 95.92447 samples/s, eta: 0:11:17
[2022/06/19 06:25:14] ppcls INFO: [Train][Epoch 295/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00008503, top1: 0.97321, CELoss: 0.09639, loss: 0.09639, batch_cost: 0.62396s, reader_cost: 0.02382, ips: 102.57066 samples/s, eta: 0:10:27
[2022/06/19 06:25:20] ppcls INFO: [Train][Epoch 295/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00008335, top1: 0.96925, CELoss: 0.10688, loss: 0.10688, batch_cost: 0.62619s, reader_cost: 0.02010, ips: 102.20516 samples/s, eta: 0:10:23
[2022/06/19 06:25:26] ppcls INFO: [Train][Epoch 295/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00008168, top1: 0.96837, CELoss: 0.10533, loss: 0.10533, batch_cost: 0.61674s, reader_cost: 0.01789, ips: 103.77147 samples/s, eta: 0:10:08
[2022/06/19 06:25:33] ppcls INFO: [Train][Epoch 295/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00008003, top1: 0.96967, CELoss: 0.09915, loss: 0.09915, batch_cost: 0.61908s, reader_cost: 0.01713, ips: 103.37840 samples/s, eta: 0:10:04
[2022/06/19 06:25:39] ppcls INFO: [Train][Epoch 295/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00007839, top1: 0.97054, CELoss: 0.09411, loss: 0.09411, batch_cost: 0.61941s, reader_cost: 0.01861, ips: 103.32340 samples/s, eta: 0:09:58
[2022/06/19 06:25:44] ppcls INFO: [Train][Epoch 295/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00007678, top1: 0.97095, CELoss: 0.09374, loss: 0.09374, batch_cost: 0.60899s, reader_cost: 0.01734, ips: 105.09270 samples/s, eta: 0:09:42
[2022/06/19 06:25:50] ppcls INFO: [Train][Epoch 295/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00007517, top1: 0.97184, CELoss: 0.09309, loss: 0.09309, batch_cost: 0.60503s, reader_cost: 0.01617, ips: 105.77949 samples/s, eta: 0:09:32
[2022/06/19 06:25:57] ppcls INFO: [Train][Epoch 295/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00007359, top1: 0.97236, CELoss: 0.09190, loss: 0.09190, batch_cost: 0.61626s, reader_cost: 0.01652, ips: 103.85237 samples/s, eta: 0:09:36
[2022/06/19 06:26:02] ppcls INFO: [Train][Epoch 295/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00007202, top1: 0.97262, CELoss: 0.08990, loss: 0.08990, batch_cost: 0.60811s, reader_cost: 0.01661, ips: 105.24406 samples/s, eta: 0:09:23
[2022/06/19 06:26:09] ppcls INFO: [Train][Epoch 295/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00007047, top1: 0.97241, CELoss: 0.09110, loss: 0.09110, batch_cost: 0.60757s, reader_cost: 0.02131, ips: 105.33683 samples/s, eta: 0:09:16
[2022/06/19 06:26:16] ppcls INFO: [Train][Epoch 295/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00006894, top1: 0.97146, CELoss: 0.09177, loss: 0.09177, batch_cost: 0.62047s, reader_cost: 0.02882, ips: 103.14719 samples/s, eta: 0:09:22
[2022/06/19 06:26:22] ppcls INFO: [Train][Epoch 295/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00006742, top1: 0.97149, CELoss: 0.09260, loss: 0.09260, batch_cost: 0.62044s, reader_cost: 0.03343, ips: 103.15240 samples/s, eta: 0:09:15
[2022/06/19 06:26:28] ppcls INFO: [Train][Epoch 295/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00006592, top1: 0.97119, CELoss: 0.09325, loss: 0.09325, batch_cost: 0.61463s, reader_cost: 0.03382, ips: 104.12769 samples/s, eta: 0:09:04
[2022/06/19 06:26:34] ppcls INFO: [Train][Epoch 295/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00006444, top1: 0.97082, CELoss: 0.09308, loss: 0.09308, batch_cost: 0.61694s, reader_cost: 0.03403, ips: 103.73712 samples/s, eta: 0:09:00
[2022/06/19 06:26:39] ppcls INFO: [Train][Epoch 295/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00006298, top1: 0.97118, CELoss: 0.09215, loss: 0.09215, batch_cost: 0.60873s, reader_cost: 0.03263, ips: 105.13700 samples/s, eta: 0:08:47
[2022/06/19 06:26:41] ppcls INFO: [Train][Epoch 295/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00006153, top1: 0.97136, CELoss: 0.09195, loss: 0.09195, batch_cost: 0.58476s, reader_cost: 0.03073, ips: 83.79470 samples/s, eta: 0:08:20
[2022/06/19 06:26:42] ppcls INFO: [Train][Epoch 295/300][Avg]top1: 0.97136, CELoss: 0.09195, loss: 0.09195
[2022/06/19 06:26:49] ppcls INFO: [Eval][Epoch 295][Iter: 0/16]CELoss: 1.12066, loss: 1.12066, top1: 0.79492, batch_cost: 7.15588s, reader_cost: 3.34641, ips: 8.94369 images/sec
[2022/06/19 06:26:57] ppcls INFO: [Eval][Epoch 295][Iter: 10/16]CELoss: 1.05326, loss: 1.05326, top1: 0.81960, batch_cost: 0.60716s, reader_cost: 0.00105, ips: 105.40933 images/sec
[2022/06/19 06:26:59] ppcls INFO: [Eval][Epoch 295][Avg]CELoss: 0.86640, loss: 0.86640, top1: 0.82733
[2022/06/19 06:26:59] ppcls INFO: [Eval][Epoch 295][best metric: 0.8303921818733215]
[2022/06/19 06:26:59] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:27:06] ppcls INFO: [Train][Epoch 296/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00006138, top1: 0.96875, CELoss: 0.06315, loss: 0.06315, batch_cost: 0.62385s, reader_cost: 0.05754, ips: 102.58886 samples/s, eta: 0:08:53
[2022/06/19 06:27:12] ppcls INFO: [Train][Epoch 296/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00005995, top1: 0.96165, CELoss: 0.10392, loss: 0.10392, batch_cost: 0.62046s, reader_cost: 0.01629, ips: 103.14965 samples/s, eta: 0:08:44
[2022/06/19 06:27:18] ppcls INFO: [Train][Epoch 296/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00005854, top1: 0.96875, CELoss: 0.08752, loss: 0.08752, batch_cost: 0.62005s, reader_cost: 0.02437, ips: 103.21741 samples/s, eta: 0:08:37
[2022/06/19 06:27:24] ppcls INFO: [Train][Epoch 296/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00005714, top1: 0.96875, CELoss: 0.08723, loss: 0.08723, batch_cost: 0.61622s, reader_cost: 0.01837, ips: 103.85897 samples/s, eta: 0:08:28
[2022/06/19 06:27:31] ppcls INFO: [Train][Epoch 296/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00005576, top1: 0.96799, CELoss: 0.09134, loss: 0.09134, batch_cost: 0.61982s, reader_cost: 0.01469, ips: 103.25596 samples/s, eta: 0:08:25
[2022/06/19 06:27:37] ppcls INFO: [Train][Epoch 296/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00005440, top1: 0.96906, CELoss: 0.08800, loss: 0.08800, batch_cost: 0.61925s, reader_cost: 0.01812, ips: 103.35136 samples/s, eta: 0:08:18
[2022/06/19 06:27:43] ppcls INFO: [Train][Epoch 296/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00005305, top1: 0.97080, CELoss: 0.08447, loss: 0.08447, batch_cost: 0.63016s, reader_cost: 0.01973, ips: 101.56098 samples/s, eta: 0:08:20
[2022/06/19 06:27:49] ppcls INFO: [Train][Epoch 296/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00005172, top1: 0.97051, CELoss: 0.08832, loss: 0.08832, batch_cost: 0.61530s, reader_cost: 0.02038, ips: 104.01481 samples/s, eta: 0:08:03
[2022/06/19 06:27:55] ppcls INFO: [Train][Epoch 296/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00005041, top1: 0.96991, CELoss: 0.08994, loss: 0.08994, batch_cost: 0.61570s, reader_cost: 0.01981, ips: 103.94634 samples/s, eta: 0:07:57
[2022/06/19 06:28:01] ppcls INFO: [Train][Epoch 296/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00004912, top1: 0.97012, CELoss: 0.09123, loss: 0.09123, batch_cost: 0.61839s, reader_cost: 0.01889, ips: 103.49398 samples/s, eta: 0:07:53
[2022/06/19 06:28:07] ppcls INFO: [Train][Epoch 296/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00004784, top1: 0.96937, CELoss: 0.09291, loss: 0.09291, batch_cost: 0.61025s, reader_cost: 0.01736, ips: 104.87542 samples/s, eta: 0:07:40
[2022/06/19 06:28:13] ppcls INFO: [Train][Epoch 296/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00004657, top1: 0.97030, CELoss: 0.09111, loss: 0.09111, batch_cost: 0.61585s, reader_cost: 0.01632, ips: 103.92167 samples/s, eta: 0:07:38
[2022/06/19 06:28:19] ppcls INFO: [Train][Epoch 296/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00004533, top1: 0.97017, CELoss: 0.08939, loss: 0.08939, batch_cost: 0.61115s, reader_cost: 0.01591, ips: 104.72068 samples/s, eta: 0:07:29
[2022/06/19 06:28:25] ppcls INFO: [Train][Epoch 296/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00004410, top1: 0.96982, CELoss: 0.09026, loss: 0.09026, batch_cost: 0.60699s, reader_cost: 0.01681, ips: 105.43863 samples/s, eta: 0:07:20
[2022/06/19 06:28:30] ppcls INFO: [Train][Epoch 296/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00004289, top1: 0.96986, CELoss: 0.09001, loss: 0.09001, batch_cost: 0.59981s, reader_cost: 0.01588, ips: 106.69960 samples/s, eta: 0:07:08
[2022/06/19 06:28:37] ppcls INFO: [Train][Epoch 296/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00004170, top1: 0.96999, CELoss: 0.08969, loss: 0.08969, batch_cost: 0.60818s, reader_cost: 0.01498, ips: 105.23148 samples/s, eta: 0:07:08
[2022/06/19 06:28:43] ppcls INFO: [Train][Epoch 296/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00004052, top1: 0.97001, CELoss: 0.08957, loss: 0.08957, batch_cost: 0.60745s, reader_cost: 0.01460, ips: 105.35850 samples/s, eta: 0:07:02
[2022/06/19 06:28:45] ppcls INFO: [Train][Epoch 296/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00003936, top1: 0.97072, CELoss: 0.08741, loss: 0.08741, batch_cost: 0.58405s, reader_cost: 0.01381, ips: 83.89747 samples/s, eta: 0:06:40
[2022/06/19 06:28:46] ppcls INFO: [Train][Epoch 296/300][Avg]top1: 0.97072, CELoss: 0.08741, loss: 0.08741
[2022/06/19 06:28:46] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:28:52] ppcls INFO: [Train][Epoch 297/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00003924, top1: 0.96875, CELoss: 0.09861, loss: 0.09861, batch_cost: 0.61466s, reader_cost: 0.04257, ips: 104.12302 samples/s, eta: 0:07:00
[2022/06/19 06:28:59] ppcls INFO: [Train][Epoch 297/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00003810, top1: 0.96875, CELoss: 0.09690, loss: 0.09690, batch_cost: 0.79751s, reader_cost: 0.14784, ips: 80.24966 samples/s, eta: 0:08:57
[2022/06/19 06:29:06] ppcls INFO: [Train][Epoch 297/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00003697, top1: 0.96949, CELoss: 0.09724, loss: 0.09724, batch_cost: 0.72892s, reader_cost: 0.05837, ips: 87.80103 samples/s, eta: 0:08:04
[2022/06/19 06:29:12] ppcls INFO: [Train][Epoch 297/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00003587, top1: 0.97278, CELoss: 0.08685, loss: 0.08685, batch_cost: 0.69222s, reader_cost: 0.03889, ips: 92.45599 samples/s, eta: 0:07:32
[2022/06/19 06:29:18] ppcls INFO: [Train][Epoch 297/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00003477, top1: 0.97104, CELoss: 0.09319, loss: 0.09319, batch_cost: 0.66825s, reader_cost: 0.03431, ips: 95.77215 samples/s, eta: 0:07:10
[2022/06/19 06:29:24] ppcls INFO: [Train][Epoch 297/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00003370, top1: 0.97151, CELoss: 0.09608, loss: 0.09608, batch_cost: 0.65591s, reader_cost: 0.03021, ips: 97.57367 samples/s, eta: 0:06:55
[2022/06/19 06:29:30] ppcls INFO: [Train][Epoch 297/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00003264, top1: 0.97080, CELoss: 0.09389, loss: 0.09389, batch_cost: 0.64739s, reader_cost: 0.02909, ips: 98.85814 samples/s, eta: 0:06:43
[2022/06/19 06:29:37] ppcls INFO: [Train][Epoch 297/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00003160, top1: 0.96963, CELoss: 0.09410, loss: 0.09410, batch_cost: 0.65107s, reader_cost: 0.02652, ips: 98.29911 samples/s, eta: 0:06:39
[2022/06/19 06:29:43] ppcls INFO: [Train][Epoch 297/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00003058, top1: 0.97106, CELoss: 0.08977, loss: 0.08977, batch_cost: 0.64779s, reader_cost: 0.02408, ips: 98.79785 samples/s, eta: 0:06:31
[2022/06/19 06:29:49] ppcls INFO: [Train][Epoch 297/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00002957, top1: 0.97167, CELoss: 0.08686, loss: 0.08686, batch_cost: 0.63801s, reader_cost: 0.02352, ips: 100.31133 samples/s, eta: 0:06:18
[2022/06/19 06:29:56] ppcls INFO: [Train][Epoch 297/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00002858, top1: 0.97153, CELoss: 0.08716, loss: 0.08716, batch_cost: 0.64208s, reader_cost: 0.02213, ips: 99.67539 samples/s, eta: 0:06:14
[2022/06/19 06:30:02] ppcls INFO: [Train][Epoch 297/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00002761, top1: 0.97086, CELoss: 0.08836, loss: 0.08836, batch_cost: 0.64392s, reader_cost: 0.02184, ips: 99.39138 samples/s, eta: 0:06:09
[2022/06/19 06:30:08] ppcls INFO: [Train][Epoch 297/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00002665, top1: 0.97159, CELoss: 0.08811, loss: 0.08811, batch_cost: 0.64102s, reader_cost: 0.02156, ips: 99.84019 samples/s, eta: 0:06:01
[2022/06/19 06:30:15] ppcls INFO: [Train][Epoch 297/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00002571, top1: 0.97102, CELoss: 0.08868, loss: 0.08868, batch_cost: 0.63939s, reader_cost: 0.02043, ips: 100.09566 samples/s, eta: 0:05:54
[2022/06/19 06:30:20] ppcls INFO: [Train][Epoch 297/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00002479, top1: 0.96975, CELoss: 0.09324, loss: 0.09324, batch_cost: 0.63041s, reader_cost: 0.02030, ips: 101.52056 samples/s, eta: 0:05:42
[2022/06/19 06:30:26] ppcls INFO: [Train][Epoch 297/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00002388, top1: 0.96937, CELoss: 0.09430, loss: 0.09430, batch_cost: 0.63124s, reader_cost: 0.02044, ips: 101.38709 samples/s, eta: 0:05:37
[2022/06/19 06:30:32] ppcls INFO: [Train][Epoch 297/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00002299, top1: 0.97021, CELoss: 0.09168, loss: 0.09168, batch_cost: 0.62673s, reader_cost: 0.02020, ips: 102.11664 samples/s, eta: 0:05:28
[2022/06/19 06:30:34] ppcls INFO: [Train][Epoch 297/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00002212, top1: 0.97072, CELoss: 0.09001, loss: 0.09001, batch_cost: 0.60171s, reader_cost: 0.01903, ips: 81.43473 samples/s, eta: 0:05:09
[2022/06/19 06:30:35] ppcls INFO: [Train][Epoch 297/300][Avg]top1: 0.97072, CELoss: 0.09001, loss: 0.09001
[2022/06/19 06:30:35] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:30:42] ppcls INFO: [Train][Epoch 298/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00002203, top1: 0.93750, CELoss: 0.18203, loss: 0.18203, batch_cost: 0.63896s, reader_cost: 0.04284, ips: 100.16230 samples/s, eta: 0:05:27
[2022/06/19 06:30:48] ppcls INFO: [Train][Epoch 298/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00002118, top1: 0.96449, CELoss: 0.09087, loss: 0.09087, batch_cost: 0.63226s, reader_cost: 0.01795, ips: 101.22432 samples/s, eta: 0:05:18
[2022/06/19 06:30:54] ppcls INFO: [Train][Epoch 298/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00002034, top1: 0.97173, CELoss: 0.07436, loss: 0.07436, batch_cost: 0.60152s, reader_cost: 0.01223, ips: 106.39785 samples/s, eta: 0:04:56
[2022/06/19 06:31:00] ppcls INFO: [Train][Epoch 298/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00001952, top1: 0.97177, CELoss: 0.08009, loss: 0.08009, batch_cost: 0.63473s, reader_cost: 0.02959, ips: 100.83039 samples/s, eta: 0:05:06
[2022/06/19 06:31:06] ppcls INFO: [Train][Epoch 298/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00001872, top1: 0.96761, CELoss: 0.09055, loss: 0.09055, batch_cost: 0.61423s, reader_cost: 0.02736, ips: 104.19608 samples/s, eta: 0:04:50
[2022/06/19 06:31:12] ppcls INFO: [Train][Epoch 298/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00001793, top1: 0.96507, CELoss: 0.09583, loss: 0.09583, batch_cost: 0.61748s, reader_cost: 0.03659, ips: 103.64703 samples/s, eta: 0:04:45
[2022/06/19 06:31:19] ppcls INFO: [Train][Epoch 298/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00001716, top1: 0.96568, CELoss: 0.09692, loss: 0.09692, batch_cost: 0.63020s, reader_cost: 0.05478, ips: 101.55584 samples/s, eta: 0:04:45
[2022/06/19 06:31:24] ppcls INFO: [Train][Epoch 298/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00001641, top1: 0.96567, CELoss: 0.09626, loss: 0.09626, batch_cost: 0.61197s, reader_cost: 0.04721, ips: 104.58026 samples/s, eta: 0:04:31
[2022/06/19 06:31:30] ppcls INFO: [Train][Epoch 298/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00001567, top1: 0.96740, CELoss: 0.09224, loss: 0.09224, batch_cost: 0.60666s, reader_cost: 0.04384, ips: 105.49602 samples/s, eta: 0:04:22
[2022/06/19 06:31:36] ppcls INFO: [Train][Epoch 298/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00001496, top1: 0.96789, CELoss: 0.09084, loss: 0.09084, batch_cost: 0.60692s, reader_cost: 0.03924, ips: 105.45081 samples/s, eta: 0:04:16
[2022/06/19 06:31:43] ppcls INFO: [Train][Epoch 298/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00001425, top1: 0.96798, CELoss: 0.09089, loss: 0.09089, batch_cost: 0.61755s, reader_cost: 0.04527, ips: 103.63451 samples/s, eta: 0:04:15
[2022/06/19 06:31:49] ppcls INFO: [Train][Epoch 298/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00001357, top1: 0.96903, CELoss: 0.08940, loss: 0.08940, batch_cost: 0.61141s, reader_cost: 0.04442, ips: 104.67676 samples/s, eta: 0:04:06
[2022/06/19 06:31:54] ppcls INFO: [Train][Epoch 298/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00001290, top1: 0.96862, CELoss: 0.08932, loss: 0.08932, batch_cost: 0.60775s, reader_cost: 0.04530, ips: 105.30639 samples/s, eta: 0:03:58
[2022/06/19 06:32:00] ppcls INFO: [Train][Epoch 298/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00001225, top1: 0.96875, CELoss: 0.08985, loss: 0.08985, batch_cost: 0.60545s, reader_cost: 0.05082, ips: 105.70693 samples/s, eta: 0:03:51
[2022/06/19 06:32:08] ppcls INFO: [Train][Epoch 298/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00001161, top1: 0.96720, CELoss: 0.09464, loss: 0.09464, batch_cost: 0.61688s, reader_cost: 0.06424, ips: 103.74713 samples/s, eta: 0:03:50
[2022/06/19 06:32:13] ppcls INFO: [Train][Epoch 298/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00001100, top1: 0.96792, CELoss: 0.09377, loss: 0.09377, batch_cost: 0.60745s, reader_cost: 0.05993, ips: 105.35836 samples/s, eta: 0:03:40
[2022/06/19 06:32:19] ppcls INFO: [Train][Epoch 298/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00001040, top1: 0.96836, CELoss: 0.09348, loss: 0.09348, batch_cost: 0.60586s, reader_cost: 0.06408, ips: 105.63512 samples/s, eta: 0:03:33
[2022/06/19 06:32:21] ppcls INFO: [Train][Epoch 298/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00000981, top1: 0.96825, CELoss: 0.09326, loss: 0.09326, batch_cost: 0.58226s, reader_cost: 0.06027, ips: 84.15442 samples/s, eta: 0:03:19
[2022/06/19 06:32:21] ppcls INFO: [Train][Epoch 298/300][Avg]top1: 0.96825, CELoss: 0.09326, loss: 0.09326
[2022/06/19 06:32:22] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:32:29] ppcls INFO: [Train][Epoch 299/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00000975, top1: 0.96875, CELoss: 0.05392, loss: 0.05392, batch_cost: 0.62121s, reader_cost: 0.09212, ips: 103.02461 samples/s, eta: 0:03:32
[2022/06/19 06:32:35] ppcls INFO: [Train][Epoch 299/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00000919, top1: 0.97301, CELoss: 0.08671, loss: 0.08671, batch_cost: 0.69902s, reader_cost: 0.02209, ips: 91.55699 samples/s, eta: 0:03:52
[2022/06/19 06:32:42] ppcls INFO: [Train][Epoch 299/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00000864, top1: 0.97024, CELoss: 0.09189, loss: 0.09189, batch_cost: 0.68145s, reader_cost: 0.01266, ips: 93.91795 samples/s, eta: 0:03:39
[2022/06/19 06:32:48] ppcls INFO: [Train][Epoch 299/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00000811, top1: 0.97026, CELoss: 0.09253, loss: 0.09253, batch_cost: 0.65388s, reader_cost: 0.01750, ips: 97.87673 samples/s, eta: 0:03:24
[2022/06/19 06:32:54] ppcls INFO: [Train][Epoch 299/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00000759, top1: 0.97027, CELoss: 0.09114, loss: 0.09114, batch_cost: 0.63890s, reader_cost: 0.01452, ips: 100.17216 samples/s, eta: 0:03:12
[2022/06/19 06:33:01] ppcls INFO: [Train][Epoch 299/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00000710, top1: 0.97120, CELoss: 0.08647, loss: 0.08647, batch_cost: 0.64583s, reader_cost: 0.01637, ips: 99.09694 samples/s, eta: 0:03:08
[2022/06/19 06:33:07] ppcls INFO: [Train][Epoch 299/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00000662, top1: 0.97439, CELoss: 0.07989, loss: 0.07989, batch_cost: 0.63571s, reader_cost: 0.01686, ips: 100.67473 samples/s, eta: 0:02:59
[2022/06/19 06:33:12] ppcls INFO: [Train][Epoch 299/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00000615, top1: 0.97271, CELoss: 0.08117, loss: 0.08117, batch_cost: 0.61961s, reader_cost: 0.01573, ips: 103.29024 samples/s, eta: 0:02:48
[2022/06/19 06:33:19] ppcls INFO: [Train][Epoch 299/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00000570, top1: 0.97242, CELoss: 0.08280, loss: 0.08280, batch_cost: 0.62614s, reader_cost: 0.01626, ips: 102.21286 samples/s, eta: 0:02:44
[2022/06/19 06:33:25] ppcls INFO: [Train][Epoch 299/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00000527, top1: 0.97236, CELoss: 0.08202, loss: 0.08202, batch_cost: 0.62438s, reader_cost: 0.01619, ips: 102.50188 samples/s, eta: 0:02:37
[2022/06/19 06:33:31] ppcls INFO: [Train][Epoch 299/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00000486, top1: 0.97246, CELoss: 0.08266, loss: 0.08266, batch_cost: 0.62171s, reader_cost: 0.01602, ips: 102.94128 samples/s, eta: 0:02:30
[2022/06/19 06:33:37] ppcls INFO: [Train][Epoch 299/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00000446, top1: 0.97241, CELoss: 0.08283, loss: 0.08283, batch_cost: 0.62079s, reader_cost: 0.01644, ips: 103.09383 samples/s, eta: 0:02:24
[2022/06/19 06:33:44] ppcls INFO: [Train][Epoch 299/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00000408, top1: 0.97224, CELoss: 0.08333, loss: 0.08333, batch_cost: 0.62347s, reader_cost: 0.01686, ips: 102.65106 samples/s, eta: 0:02:18
[2022/06/19 06:33:50] ppcls INFO: [Train][Epoch 299/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00000372, top1: 0.97197, CELoss: 0.08270, loss: 0.08270, batch_cost: 0.62709s, reader_cost: 0.01645, ips: 102.05945 samples/s, eta: 0:02:12
[2022/06/19 06:33:55] ppcls INFO: [Train][Epoch 299/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00000338, top1: 0.97185, CELoss: 0.08255, loss: 0.08255, batch_cost: 0.61790s, reader_cost: 0.01640, ips: 103.57580 samples/s, eta: 0:02:04
[2022/06/19 06:34:01] ppcls INFO: [Train][Epoch 299/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00000305, top1: 0.97113, CELoss: 0.08412, loss: 0.08412, batch_cost: 0.61329s, reader_cost: 0.01770, ips: 104.35504 samples/s, eta: 0:01:57
[2022/06/19 06:34:07] ppcls INFO: [Train][Epoch 299/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00000273, top1: 0.97137, CELoss: 0.08376, loss: 0.08376, batch_cost: 0.61067s, reader_cost: 0.01691, ips: 104.80214 samples/s, eta: 0:01:51
[2022/06/19 06:34:09] ppcls INFO: [Train][Epoch 299/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00000244, top1: 0.97164, CELoss: 0.08395, loss: 0.08395, batch_cost: 0.58669s, reader_cost: 0.01592, ips: 83.51976 samples/s, eta: 0:01:40
[2022/06/19 06:34:09] ppcls INFO: [Train][Epoch 299/300][Avg]top1: 0.97164, CELoss: 0.08395, loss: 0.08395
[2022/06/19 06:34:10] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
[2022/06/19 06:34:15] ppcls INFO: [Train][Epoch 300/300][Iter: 0/171]lr(CosineAnnealingDecay): 0.00000241, top1: 0.98438, CELoss: 0.07747, loss: 0.07747, batch_cost: 0.61893s, reader_cost: 0.04321, ips: 103.40491 samples/s, eta: 0:01:45
[2022/06/19 06:34:23] ppcls INFO: [Train][Epoch 300/300][Iter: 10/171]lr(CosineAnnealingDecay): 0.00000213, top1: 0.97017, CELoss: 0.08267, loss: 0.08267, batch_cost: 0.88212s, reader_cost: 0.00969, ips: 72.55211 samples/s, eta: 0:02:22
[2022/06/19 06:34:29] ppcls INFO: [Train][Epoch 300/300][Iter: 20/171]lr(CosineAnnealingDecay): 0.00000187, top1: 0.97247, CELoss: 0.07211, loss: 0.07211, batch_cost: 0.68038s, reader_cost: 0.01314, ips: 94.06451 samples/s, eta: 0:01:42
[2022/06/19 06:34:35] ppcls INFO: [Train][Epoch 300/300][Iter: 30/171]lr(CosineAnnealingDecay): 0.00000163, top1: 0.97329, CELoss: 0.07424, loss: 0.07424, batch_cost: 0.65435s, reader_cost: 0.01025, ips: 97.80689 samples/s, eta: 0:01:32
[2022/06/19 06:34:42] ppcls INFO: [Train][Epoch 300/300][Iter: 40/171]lr(CosineAnnealingDecay): 0.00000140, top1: 0.97409, CELoss: 0.07201, loss: 0.07201, batch_cost: 0.65250s, reader_cost: 0.01040, ips: 98.08455 samples/s, eta: 0:01:25
[2022/06/19 06:34:48] ppcls INFO: [Train][Epoch 300/300][Iter: 50/171]lr(CosineAnnealingDecay): 0.00000120, top1: 0.97488, CELoss: 0.07057, loss: 0.07057, batch_cost: 0.64557s, reader_cost: 0.01118, ips: 99.13660 samples/s, eta: 0:01:18
[2022/06/19 06:34:54] ppcls INFO: [Train][Epoch 300/300][Iter: 60/171]lr(CosineAnnealingDecay): 0.00000100, top1: 0.97413, CELoss: 0.07481, loss: 0.07481, batch_cost: 0.64286s, reader_cost: 0.01387, ips: 99.55490 samples/s, eta: 0:01:11
[2022/06/19 06:35:00] ppcls INFO: [Train][Epoch 300/300][Iter: 70/171]lr(CosineAnnealingDecay): 0.00000083, top1: 0.97403, CELoss: 0.07400, loss: 0.07400, batch_cost: 0.63189s, reader_cost: 0.01289, ips: 101.28409 samples/s, eta: 0:01:03
[2022/06/19 06:35:05] ppcls INFO: [Train][Epoch 300/300][Iter: 80/171]lr(CosineAnnealingDecay): 0.00000067, top1: 0.97473, CELoss: 0.07462, loss: 0.07462, batch_cost: 0.61726s, reader_cost: 0.01235, ips: 103.68402 samples/s, eta: 0:00:56
[2022/06/19 06:35:11] ppcls INFO: [Train][Epoch 300/300][Iter: 90/171]lr(CosineAnnealingDecay): 0.00000053, top1: 0.97304, CELoss: 0.07822, loss: 0.07822, batch_cost: 0.61739s, reader_cost: 0.01163, ips: 103.66181 samples/s, eta: 0:00:50
[2022/06/19 06:35:19] ppcls INFO: [Train][Epoch 300/300][Iter: 100/171]lr(CosineAnnealingDecay): 0.00000040, top1: 0.97262, CELoss: 0.08024, loss: 0.08024, batch_cost: 0.63423s, reader_cost: 0.01239, ips: 100.90930 samples/s, eta: 0:00:45
[2022/06/19 06:35:24] ppcls INFO: [Train][Epoch 300/300][Iter: 110/171]lr(CosineAnnealingDecay): 0.00000029, top1: 0.97227, CELoss: 0.08185, loss: 0.08185, batch_cost: 0.62453s, reader_cost: 0.01164, ips: 102.47747 samples/s, eta: 0:00:38
[2022/06/19 06:35:30] ppcls INFO: [Train][Epoch 300/300][Iter: 120/171]lr(CosineAnnealingDecay): 0.00000020, top1: 0.97237, CELoss: 0.08218, loss: 0.08218, batch_cost: 0.62321s, reader_cost: 0.01254, ips: 102.69338 samples/s, eta: 0:00:31
[2022/06/19 06:35:36] ppcls INFO: [Train][Epoch 300/300][Iter: 130/171]lr(CosineAnnealingDecay): 0.00000013, top1: 0.97173, CELoss: 0.08378, loss: 0.08378, batch_cost: 0.61820s, reader_cost: 0.01227, ips: 103.52555 samples/s, eta: 0:00:25
[2022/06/19 06:35:41] ppcls INFO: [Train][Epoch 300/300][Iter: 140/171]lr(CosineAnnealingDecay): 0.00000007, top1: 0.97163, CELoss: 0.08520, loss: 0.08520, batch_cost: 0.61316s, reader_cost: 0.01168, ips: 104.37712 samples/s, eta: 0:00:19
[2022/06/19 06:35:49] ppcls INFO: [Train][Epoch 300/300][Iter: 150/171]lr(CosineAnnealingDecay): 0.00000003, top1: 0.97134, CELoss: 0.08551, loss: 0.08551, batch_cost: 0.62177s, reader_cost: 0.01247, ips: 102.93187 samples/s, eta: 0:00:13
[2022/06/19 06:35:54] ppcls INFO: [Train][Epoch 300/300][Iter: 160/171]lr(CosineAnnealingDecay): 0.00000001, top1: 0.97098, CELoss: 0.08637, loss: 0.08637, batch_cost: 0.61263s, reader_cost: 0.01180, ips: 104.46737 samples/s, eta: 0:00:06
[2022/06/19 06:35:56] ppcls INFO: [Train][Epoch 300/300][Iter: 170/171]lr(CosineAnnealingDecay): 0.00000000, top1: 0.97081, CELoss: 0.08668, loss: 0.08668, batch_cost: 0.58845s, reader_cost: 0.01110, ips: 83.26968 samples/s, eta: 0:00:00
[2022/06/19 06:35:56] ppcls INFO: [Train][Epoch 300/300][Avg]top1: 0.97081, CELoss: 0.08668, loss: 0.08668
[2022/06/19 06:36:04] ppcls INFO: [Eval][Epoch 300][Iter: 0/16]CELoss: 1.09784, loss: 1.09784, top1: 0.79883, batch_cost: 7.30105s, reader_cost: 3.58458, ips: 8.76586 images/sec
[2022/06/19 06:36:12] ppcls INFO: [Eval][Epoch 300][Iter: 10/16]CELoss: 1.04757, loss: 1.04757, top1: 0.82244, batch_cost: 0.59110s, reader_cost: 0.00351, ips: 108.27251 images/sec
[2022/06/19 06:36:13] ppcls INFO: [Eval][Epoch 300][Avg]CELoss: 0.85133, loss: 0.85133, top1: 0.82868
[2022/06/19 06:36:13] ppcls INFO: [Eval][Epoch 300][best metric: 0.8303921818733215]
[2022/06/19 06:36:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/epoch_300
[2022/06/19 06:36:14] ppcls INFO: Already save model in /root/tuantuan1/model/trash_classic/mobilenetv2_cbam/four_classes/MobileNetV2/latest
